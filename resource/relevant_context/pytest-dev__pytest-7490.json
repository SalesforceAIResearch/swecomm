{"instance_id": "pytest-dev__pytest-7490", "identified_spans": [{"file_path": "src/_pytest/nodes.py", "span_ids": ["Node.add_marker"], "content": [{"span_id": "Node.add_marker", "start_line": 261, "end_line": 283, "content": ["    def add_marker(\n", "        self, marker: Union[str, MarkDecorator], append: bool = True\n", "    ) -> None:\n", "        \"\"\"dynamically add a marker object to the node.\n", "\n", "        :type marker: ``str`` or ``pytest.mark.*``  object\n", "        :param marker:\n", "            ``append=True`` whether to append the marker,\n", "            if ``False`` insert at position ``0``.\n", "        \"\"\"\n", "        from _pytest.mark import MARK_GEN\n", "\n", "        if isinstance(marker, MarkDecorator):\n", "            marker_ = marker\n", "        elif isinstance(marker, str):\n", "            marker_ = getattr(MARK_GEN, marker)\n", "        else:\n", "            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n", "        self.keywords[marker_.name] = marker_\n", "        if append:\n", "            self.own_markers.append(marker_.mark)\n", "        else:\n", "            self.own_markers.insert(0, marker_.mark)\n"]}]}, {"file_path": "src/_pytest/skipping.py", "span_ids": ["pytest_runtest_makereport", "evaluate_xfail_marks", "pytest_runtest_setup", "pytest_runtest_call"], "content": [{"span_id": "pytest_runtest_makereport", "start_line": 260, "end_line": 306, "content": ["@hookimpl(hookwrapper=True)\n", "def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n", "    outcome = yield\n", "    rep = outcome.get_result()\n", "    xfailed = item._store.get(xfailed_key, None)\n", "    # unittest special case, see setting of unexpectedsuccess_key\n", "    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n", "        reason = item._store[unexpectedsuccess_key]\n", "        if reason:\n", "            rep.longrepr = \"Unexpected success: {}\".format(reason)\n", "        else:\n", "            rep.longrepr = \"Unexpected success\"\n", "        rep.outcome = \"failed\"\n", "    elif item.config.option.runxfail:\n", "        pass  # don't interfere\n", "    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n", "        assert call.excinfo.value.msg is not None\n", "        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n", "        rep.outcome = \"skipped\"\n", "    elif not rep.skipped and xfailed:\n", "        if call.excinfo:\n", "            raises = xfailed.raises\n", "            if raises is not None and not isinstance(call.excinfo.value, raises):\n", "                rep.outcome = \"failed\"\n", "            else:\n", "                rep.outcome = \"skipped\"\n", "                rep.wasxfail = xfailed.reason\n", "        elif call.when == \"call\":\n", "            if xfailed.strict:\n", "                rep.outcome = \"failed\"\n", "                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n", "            else:\n", "                rep.outcome = \"passed\"\n", "                rep.wasxfail = xfailed.reason\n", "\n", "    if (\n", "        item._store.get(skipped_by_mark_key, True)\n", "        and rep.skipped\n", "        and type(rep.longrepr) is tuple\n", "    ):\n", "        # skipped by mark.skipif; change the location of the failure\n", "        # to point to the item definition, otherwise it will display\n", "        # the location of where the skip exception was raised within pytest\n", "        _, _, reason = rep.longrepr\n", "        filename, line = item.reportinfo()[:2]\n", "        assert line is not None\n", "        rep.longrepr = str(filename), line + 1, reason\n"]}, {"span_id": "evaluate_xfail_marks", "start_line": 200, "end_line": 222, "content": ["def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n", "    \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n", "    for mark in item.iter_markers(name=\"xfail\"):\n", "        run = mark.kwargs.get(\"run\", True)\n", "        strict = mark.kwargs.get(\"strict\", item.config.getini(\"xfail_strict\"))\n", "        raises = mark.kwargs.get(\"raises\", None)\n", "        if \"condition\" not in mark.kwargs:\n", "            conditions = mark.args\n", "        else:\n", "            conditions = (mark.kwargs[\"condition\"],)\n", "\n", "        # Unconditional.\n", "        if not conditions:\n", "            reason = mark.kwargs.get(\"reason\", \"\")\n", "            return Xfail(reason, run, strict, raises)\n", "\n", "        # If any of the conditions are true.\n", "        for condition in conditions:\n", "            result, reason = evaluate_condition(item, mark, condition)\n", "            if result:\n", "                return Xfail(reason, run, strict, raises)\n", "\n", "    return None\n"]}, {"span_id": "pytest_runtest_setup", "start_line": 232, "end_line": 244, "content": ["@hookimpl(tryfirst=True)\n", "def pytest_runtest_setup(item: Item) -> None:\n", "    item._store[skipped_by_mark_key] = False\n", "\n", "    skipped = evaluate_skip_marks(item)\n", "    if skipped:\n", "        item._store[skipped_by_mark_key] = True\n", "        skip(skipped.reason)\n", "\n", "    if not item.config.option.runxfail:\n", "        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n", "        if xfailed and not xfailed.run:\n", "            xfail(\"[NOTRUN] \" + xfailed.reason)\n"]}, {"span_id": "pytest_runtest_call", "start_line": 247, "end_line": 257, "content": ["@hookimpl(hookwrapper=True)\n", "def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n", "    xfailed = item._store.get(xfailed_key, None)\n", "    if xfailed is None:\n", "        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n", "\n", "    if not item.config.option.runxfail:\n", "        if xfailed and not xfailed.run:\n", "            xfail(\"[NOTRUN] \" + xfailed.reason)\n", "\n", "    yield\n"]}]}, {"file_path": "src/_pytest/unittest.py", "span_ids": ["TestCaseFunction.addUnexpectedSuccess", "TestCaseFunction", "TestCaseFunction.addExpectedFailure"], "content": [{"span_id": "TestCaseFunction.addUnexpectedSuccess", "start_line": 232, "end_line": 235, "content": ["    def addUnexpectedSuccess(\n", "        self, testcase: \"unittest.TestCase\", reason: str = \"\"\n", "    ) -> None:\n", "        self._store[unexpectedsuccess_key] = reason\n"]}, {"span_id": "TestCaseFunction", "start_line": 142, "end_line": 145, "content": ["class TestCaseFunction(Function):\n", "    nofuncargs = True\n", "    _excinfo = None  # type: Optional[List[_pytest._code.ExceptionInfo]]\n", "    _testcase = None  # type: Optional[unittest.TestCase]\n"]}, {"span_id": "TestCaseFunction.addExpectedFailure", "start_line": 221, "end_line": 230, "content": ["    def addExpectedFailure(\n", "        self,\n", "        testcase: \"unittest.TestCase\",\n", "        rawexcinfo: \"_SysExcInfoType\",\n", "        reason: str = \"\",\n", "    ) -> None:\n", "        try:\n", "            xfail(str(reason))\n", "        except xfail.Exception:\n", "            self._addexcinfo(sys.exc_info())\n"]}]}]}