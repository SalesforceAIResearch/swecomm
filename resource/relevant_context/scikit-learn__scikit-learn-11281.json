{"instance_id": "scikit-learn__scikit-learn-11281", "identified_spans": [{"file_path": "sklearn/base.py", "span_ids": ["ClusterMixin", "ClusterMixin.fit_predict"], "content": [{"span_id": "ClusterMixin", "start_line": 380, "end_line": 382, "content": ["class ClusterMixin(object):\n", "    \"\"\"Mixin class for all cluster estimators in scikit-learn.\"\"\"\n", "    _estimator_type = \"clusterer\"\n"]}, {"span_id": "ClusterMixin.fit_predict", "start_line": 384, "end_line": 400, "content": ["    def fit_predict(self, X, y=None):\n", "        \"\"\"Performs clustering on X and returns cluster labels.\n", "\n", "        Parameters\n", "        ----------\n", "        X : ndarray, shape (n_samples, n_features)\n", "            Input data.\n", "\n", "        Returns\n", "        -------\n", "        y : ndarray, shape (n_samples,)\n", "            cluster labels\n", "        \"\"\"\n", "        # non-optimized default implementation; override when a better\n", "        # method is possible for a given clustering algorithm\n", "        self.fit(X)\n", "        return self.labels_\n"]}]}, {"file_path": "sklearn/mixture/base.py", "span_ids": ["BaseMixture"], "content": [{"span_id": "BaseMixture", "start_line": 67, "end_line": 72, "content": ["class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n", "    \"\"\"Base class for mixture models.\n", "\n", "    This abstract class specifies an interface for all mixture classes and\n", "    provides basic common methods for mixture models.\n", "    \"\"\"\n"]}]}, {"file_path": "sklearn/mixture/gaussian_mixture.py", "span_ids": ["GaussianMixture"], "content": [{"span_id": "GaussianMixture", "start_line": 435, "end_line": 581, "content": ["class GaussianMixture(BaseMixture):\n", "    \"\"\"Gaussian Mixture.\n", "\n", "    Representation of a Gaussian mixture model probability distribution.\n", "    This class allows to estimate the parameters of a Gaussian mixture\n", "    distribution.\n", "\n", "    Read more in the :ref:`User Guide <gmm>`.\n", "\n", "    .. versionadded:: 0.18\n", "\n", "    Parameters\n", "    ----------\n", "    n_components : int, defaults to 1.\n", "        The number of mixture components.\n", "\n", "    covariance_type : {'full', 'tied', 'diag', 'spherical'},\n", "            defaults to 'full'.\n", "        String describing the type of covariance parameters to use.\n", "        Must be one of::\n", "\n", "            'full' (each component has its own general covariance matrix),\n", "            'tied' (all components share the same general covariance matrix),\n", "            'diag' (each component has its own diagonal covariance matrix),\n", "            'spherical' (each component has its own single variance).\n", "\n", "    tol : float, defaults to 1e-3.\n", "        The convergence threshold. EM iterations will stop when the\n", "        lower bound average gain is below this threshold.\n", "\n", "    reg_covar : float, defaults to 1e-6.\n", "        Non-negative regularization added to the diagonal of covariance.\n", "        Allows to assure that the covariance matrices are all positive.\n", "\n", "    max_iter : int, defaults to 100.\n", "        The number of EM iterations to perform.\n", "\n", "    n_init : int, defaults to 1.\n", "        The number of initializations to perform. The best results are kept.\n", "\n", "    init_params : {'kmeans', 'random'}, defaults to 'kmeans'.\n", "        The method used to initialize the weights, the means and the\n", "        precisions.\n", "        Must be one of::\n", "\n", "            'kmeans' : responsibilities are initialized using kmeans.\n", "            'random' : responsibilities are initialized randomly.\n", "\n", "    weights_init : array-like, shape (n_components, ), optional\n", "        The user-provided initial weights, defaults to None.\n", "        If it None, weights are initialized using the `init_params` method.\n", "\n", "    means_init : array-like, shape (n_components, n_features), optional\n", "        The user-provided initial means, defaults to None,\n", "        If it None, means are initialized using the `init_params` method.\n", "\n", "    precisions_init : array-like, optional.\n", "        The user-provided initial precisions (inverse of the covariance\n", "        matrices), defaults to None.\n", "        If it None, precisions are initialized using the 'init_params' method.\n", "        The shape depends on 'covariance_type'::\n", "\n", "            (n_components,)                        if 'spherical',\n", "            (n_features, n_features)               if 'tied',\n", "            (n_components, n_features)             if 'diag',\n", "            (n_components, n_features, n_features) if 'full'\n", "\n", "    random_state : int, RandomState instance or None, optional (default=None)\n", "        If int, random_state is the seed used by the random number generator;\n", "        If RandomState instance, random_state is the random number generator;\n", "        If None, the random number generator is the RandomState instance used\n", "        by `np.random`.\n", "\n", "    warm_start : bool, default to False.\n", "        If 'warm_start' is True, the solution of the last fitting is used as\n", "        initialization for the next call of fit(). This can speed up\n", "        convergence when fit is called several times on similar problems.\n", "        See :term:`the Glossary <warm_start>`.\n", "\n", "    verbose : int, default to 0.\n", "        Enable verbose output. If 1 then it prints the current\n", "        initialization and each iteration step. If greater than 1 then\n", "        it prints also the log probability and the time needed\n", "        for each step.\n", "\n", "    verbose_interval : int, default to 10.\n", "        Number of iteration done before the next print.\n", "\n", "    Attributes\n", "    ----------\n", "    weights_ : array-like, shape (n_components,)\n", "        The weights of each mixture components.\n", "\n", "    means_ : array-like, shape (n_components, n_features)\n", "        The mean of each mixture component.\n", "\n", "    covariances_ : array-like\n", "        The covariance of each mixture component.\n", "        The shape depends on `covariance_type`::\n", "\n", "            (n_components,)                        if 'spherical',\n", "            (n_features, n_features)               if 'tied',\n", "            (n_components, n_features)             if 'diag',\n", "            (n_components, n_features, n_features) if 'full'\n", "\n", "    precisions_ : array-like\n", "        The precision matrices for each component in the mixture. A precision\n", "        matrix is the inverse of a covariance matrix. A covariance matrix is\n", "        symmetric positive definite so the mixture of Gaussian can be\n", "        equivalently parameterized by the precision matrices. Storing the\n", "        precision matrices instead of the covariance matrices makes it more\n", "        efficient to compute the log-likelihood of new samples at test time.\n", "        The shape depends on `covariance_type`::\n", "\n", "            (n_components,)                        if 'spherical',\n", "            (n_features, n_features)               if 'tied',\n", "            (n_components, n_features)             if 'diag',\n", "            (n_components, n_features, n_features) if 'full'\n", "\n", "    precisions_cholesky_ : array-like\n", "        The cholesky decomposition of the precision matrices of each mixture\n", "        component. A precision matrix is the inverse of a covariance matrix.\n", "        A covariance matrix is symmetric positive definite so the mixture of\n", "        Gaussian can be equivalently parameterized by the precision matrices.\n", "        Storing the precision matrices instead of the covariance matrices makes\n", "        it more efficient to compute the log-likelihood of new samples at test\n", "        time. The shape depends on `covariance_type`::\n", "\n", "            (n_components,)                        if 'spherical',\n", "            (n_features, n_features)               if 'tied',\n", "            (n_components, n_features)             if 'diag',\n", "            (n_components, n_features, n_features) if 'full'\n", "\n", "    converged_ : bool\n", "        True when convergence was reached in fit(), False otherwise.\n", "\n", "    n_iter_ : int\n", "        Number of step used by the best fit of EM to reach the convergence.\n", "\n", "    lower_bound_ : float\n", "        Log-likelihood of the best fit of EM.\n", "\n", "    See Also\n", "    --------\n", "    BayesianGaussianMixture : Gaussian mixture model fit with a variational\n", "        inference.\n", "    \"\"\"\n"]}]}]}