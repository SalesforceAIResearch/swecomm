{"instance_id": "django__django-11039", "identified_spans": [{"file_path": "django/core/management/commands/sqlmigrate.py", "span_ids": ["Command", "Command.handle"], "content": [{"span_id": "Command", "start_line": 8, "end_line": 11, "content": ["class Command(BaseCommand):\n", "    help = \"Prints the SQL statements for the named migration.\"\n", "\n", "    output_transaction = True\n"]}, {"span_id": "Command.handle", "start_line": 32, "end_line": 65, "content": ["    def handle(self, *args, **options):\n", "        # Get the database we're operating from\n", "        connection = connections[options['database']]\n", "\n", "        # Load up an executor to get all the migration data\n", "        executor = MigrationExecutor(connection)\n", "\n", "        # Resolve command-line arguments into a migration\n", "        app_label, migration_name = options['app_label'], options['migration_name']\n", "        # Validate app_label\n", "        try:\n", "            apps.get_app_config(app_label)\n", "        except LookupError as err:\n", "            raise CommandError(str(err))\n", "        if app_label not in executor.loader.migrated_apps:\n", "            raise CommandError(\"App '%s' does not have migrations\" % app_label)\n", "        try:\n", "            migration = executor.loader.get_migration_by_prefix(app_label, migration_name)\n", "        except AmbiguityError:\n", "            raise CommandError(\"More than one migration matches '%s' in app '%s'. Please be more specific.\" % (\n", "                migration_name, app_label))\n", "        except KeyError:\n", "            raise CommandError(\"Cannot find a migration matching '%s' from app '%s'. Is it in INSTALLED_APPS?\" % (\n", "                migration_name, app_label))\n", "        targets = [(app_label, migration.name)]\n", "\n", "        # Show begin/end around output only for atomic migrations\n", "        self.output_transaction = migration.atomic\n", "\n", "        # Make a plan that represents just the requested migrations and show SQL\n", "        # for it\n", "        plan = [(executor.loader.graph.nodes[targets[0]], options['backwards'])]\n", "        sql_statements = executor.collect_sql(plan)\n", "        return '\\n'.join(sql_statements)\n"]}]}, {"file_path": "django/db/backends/base/features.py", "span_ids": ["BaseDatabaseFeatures"], "content": [{"span_id": "BaseDatabaseFeatures", "start_line": 5, "end_line": 282, "content": ["class BaseDatabaseFeatures:\n", "    gis_enabled = False\n", "    allows_group_by_pk = False\n", "    allows_group_by_selected_pks = False\n", "    empty_fetchmany_value = []\n", "    update_can_self_select = True\n", "\n", "    # Does the backend distinguish between '' and None?\n", "    interprets_empty_strings_as_nulls = False\n", "\n", "    # Does the backend allow inserting duplicate NULL rows in a nullable\n", "    # unique field? All core backends implement this correctly, but other\n", "    # databases such as SQL Server do not.\n", "    supports_nullable_unique_constraints = True\n", "\n", "    # Does the backend allow inserting duplicate rows when a unique_together\n", "    # constraint exists and some fields are nullable but not all of them?\n", "    supports_partially_nullable_unique_constraints = True\n", "\n", "    can_use_chunked_reads = True\n", "    can_return_columns_from_insert = False\n", "    can_return_rows_from_bulk_insert = False\n", "    has_bulk_insert = True\n", "    uses_savepoints = True\n", "    can_release_savepoints = False\n", "\n", "    # If True, don't use integer foreign keys referring to, e.g., positive\n", "    # integer primary keys.\n", "    related_fields_match_type = False\n", "    allow_sliced_subqueries_with_in = True\n", "    has_select_for_update = False\n", "    has_select_for_update_nowait = False\n", "    has_select_for_update_skip_locked = False\n", "    has_select_for_update_of = False\n", "    # Does the database's SELECT FOR UPDATE OF syntax require a column rather\n", "    # than a table?\n", "    select_for_update_of_column = False\n", "\n", "    # Does the default test database allow multiple connections?\n", "    # Usually an indication that the test database is in-memory\n", "    test_db_allows_multiple_connections = True\n", "\n", "    # Can an object be saved without an explicit primary key?\n", "    supports_unspecified_pk = False\n", "\n", "    # Can a fixture contain forward references? i.e., are\n", "    # FK constraints checked at the end of transaction, or\n", "    # at the end of each save operation?\n", "    supports_forward_references = True\n", "\n", "    # Does the backend truncate names properly when they are too long?\n", "    truncates_names = False\n", "\n", "    # Is there a REAL datatype in addition to floats/doubles?\n", "    has_real_datatype = False\n", "    supports_subqueries_in_group_by = True\n", "\n", "    # Is there a true datatype for uuid?\n", "    has_native_uuid_field = False\n", "\n", "    # Is there a true datatype for timedeltas?\n", "    has_native_duration_field = False\n", "\n", "    # Does the database driver supports same type temporal data subtraction\n", "    # by returning the type used to store duration field?\n", "    supports_temporal_subtraction = False\n", "\n", "    # Does the __regex lookup support backreferencing and grouping?\n", "    supports_regex_backreferencing = True\n", "\n", "    # Can date/datetime lookups be performed using a string?\n", "    supports_date_lookup_using_string = True\n", "\n", "    # Can datetimes with timezones be used?\n", "    supports_timezones = True\n", "\n", "    # Does the database have a copy of the zoneinfo database?\n", "    has_zoneinfo_database = True\n", "\n", "    # When performing a GROUP BY, is an ORDER BY NULL required\n", "    # to remove any ordering?\n", "    requires_explicit_null_ordering_when_grouping = False\n", "\n", "    # Does the backend order NULL values as largest or smallest?\n", "    nulls_order_largest = False\n", "\n", "    # The database's limit on the number of query parameters.\n", "    max_query_params = None\n", "\n", "    # Can an object have an autoincrement primary key of 0? MySQL says No.\n", "    allows_auto_pk_0 = True\n", "\n", "    # Do we need to NULL a ForeignKey out, or can the constraint check be\n", "    # deferred\n", "    can_defer_constraint_checks = False\n", "\n", "    # date_interval_sql can properly handle mixed Date/DateTime fields and timedeltas\n", "    supports_mixed_date_datetime_comparisons = True\n", "\n", "    # Does the backend support tablespaces? Default to False because it isn't\n", "    # in the SQL standard.\n", "    supports_tablespaces = False\n", "\n", "    # Does the backend reset sequences between tests?\n", "    supports_sequence_reset = True\n", "\n", "    # Can the backend introspect the default value of a column?\n", "    can_introspect_default = True\n", "\n", "    # Confirm support for introspected foreign keys\n", "    # Every database can do this reliably, except MySQL,\n", "    # which can't do it for MyISAM tables\n", "    can_introspect_foreign_keys = True\n", "\n", "    # Can the backend introspect an AutoField, instead of an IntegerField?\n", "    can_introspect_autofield = False\n", "\n", "    # Can the backend introspect a BigIntegerField, instead of an IntegerField?\n", "    can_introspect_big_integer_field = True\n", "\n", "    # Can the backend introspect an BinaryField, instead of an TextField?\n", "    can_introspect_binary_field = True\n", "\n", "    # Can the backend introspect an DecimalField, instead of an FloatField?\n", "    can_introspect_decimal_field = True\n", "\n", "    # Can the backend introspect a DurationField, instead of a BigIntegerField?\n", "    can_introspect_duration_field = True\n", "\n", "    # Can the backend introspect an IPAddressField, instead of an CharField?\n", "    can_introspect_ip_address_field = False\n", "\n", "    # Can the backend introspect a PositiveIntegerField, instead of an IntegerField?\n", "    can_introspect_positive_integer_field = False\n", "\n", "    # Can the backend introspect a SmallIntegerField, instead of an IntegerField?\n", "    can_introspect_small_integer_field = False\n", "\n", "    # Can the backend introspect a TimeField, instead of a DateTimeField?\n", "    can_introspect_time_field = True\n", "\n", "    # Some backends may not be able to differentiate BigAutoField from other\n", "    # fields such as AutoField.\n", "    introspected_big_auto_field_type = 'BigAutoField'\n", "\n", "    # Some backends may not be able to differentiate BooleanField from other\n", "    # fields such as IntegerField.\n", "    introspected_boolean_field_type = 'BooleanField'\n", "\n", "    # Can the backend introspect the column order (ASC/DESC) for indexes?\n", "    supports_index_column_ordering = True\n", "\n", "    # Does the backend support introspection of materialized views?\n", "    can_introspect_materialized_views = False\n", "\n", "    # Support for the DISTINCT ON clause\n", "    can_distinct_on_fields = False\n", "\n", "    # Does the backend prevent running SQL queries in broken transactions?\n", "    atomic_transactions = True\n", "\n", "    # Can we roll back DDL in a transaction?\n", "    can_rollback_ddl = False\n", "\n", "    # Does it support operations requiring references rename in a transaction?\n", "    supports_atomic_references_rename = True\n", "\n", "    # Can we issue more than one ALTER COLUMN clause in an ALTER TABLE?\n", "    supports_combined_alters = False\n", "\n", "    # Does it support foreign keys?\n", "    supports_foreign_keys = True\n", "\n", "    # Can it create foreign key constraints inline when adding columns?\n", "    can_create_inline_fk = True\n", "\n", "    # Does it support CHECK constraints?\n", "    supports_column_check_constraints = True\n", "    supports_table_check_constraints = True\n", "\n", "    # Does the backend support 'pyformat' style (\"... %(name)s ...\", {'name': value})\n", "    # parameter passing? Note this can be provided by the backend even if not\n", "    # supported by the Python driver\n", "    supports_paramstyle_pyformat = True\n", "\n", "    # Does the backend require literal defaults, rather than parameterized ones?\n", "    requires_literal_defaults = False\n", "\n", "    # Does the backend require a connection reset after each material schema change?\n", "    connection_persists_old_columns = False\n", "\n", "    # What kind of error does the backend throw when accessing closed cursor?\n", "    closed_cursor_error_class = ProgrammingError\n", "\n", "    # Does 'a' LIKE 'A' match?\n", "    has_case_insensitive_like = True\n", "\n", "    # Suffix for backends that don't support \"SELECT xxx;\" queries.\n", "    bare_select_suffix = ''\n", "\n", "    # If NULL is implied on columns without needing to be explicitly specified\n", "    implied_column_null = False\n", "\n", "    # Does the backend support \"select for update\" queries with limit (and offset)?\n", "    supports_select_for_update_with_limit = True\n", "\n", "    # Does the backend ignore null expressions in GREATEST and LEAST queries unless\n", "    # every expression is null?\n", "    greatest_least_ignores_nulls = False\n", "\n", "    # Can the backend clone databases for parallel test execution?\n", "    # Defaults to False to allow third-party backends to opt-in.\n", "    can_clone_databases = False\n", "\n", "    # Does the backend consider table names with different casing to\n", "    # be equal?\n", "    ignores_table_name_case = False\n", "\n", "    # Place FOR UPDATE right after FROM clause. Used on MSSQL.\n", "    for_update_after_from = False\n", "\n", "    # Combinatorial flags\n", "    supports_select_union = True\n", "    supports_select_intersection = True\n", "    supports_select_difference = True\n", "    supports_slicing_ordering_in_compound = False\n", "    supports_parentheses_in_compound = True\n", "\n", "    # Does the database support SQL 2003 FILTER (WHERE ...) in aggregate\n", "    # expressions?\n", "    supports_aggregate_filter_clause = False\n", "\n", "    # Does the backend support indexing a TextField?\n", "    supports_index_on_text_field = True\n", "\n", "    # Does the backend support window expressions (expression OVER (...))?\n", "    supports_over_clause = False\n", "    supports_frame_range_fixed_distance = False\n", "\n", "    # Does the backend support CAST with precision?\n", "    supports_cast_with_precision = True\n", "\n", "    # How many second decimals does the database return when casting a value to\n", "    # a type with time?\n", "    time_cast_precision = 6\n", "\n", "    # SQL to create a procedure for use by the Django test suite. The\n", "    # functionality of the procedure isn't important.\n", "    create_test_procedure_without_params_sql = None\n", "    create_test_procedure_with_int_param_sql = None\n", "\n", "    # Does the backend support keyword parameters for cursor.callproc()?\n", "    supports_callproc_kwargs = False\n", "\n", "    # Convert CharField results from bytes to str in database functions.\n", "    db_functions_convert_bytes_to_str = False\n", "\n", "    # What formats does the backend EXPLAIN syntax support?\n", "    supported_explain_formats = set()\n", "\n", "    # Does DatabaseOperations.explain_query_prefix() raise ValueError if\n", "    # unknown kwargs are passed to QuerySet.explain()?\n", "    validates_explain_options = True\n", "\n", "    # Does the backend support the default parameter in lead() and lag()?\n", "    supports_default_in_lead_lag = True\n", "\n", "    # Does the backend support ignoring constraint or uniqueness errors during\n", "    # INSERT?\n", "    supports_ignore_conflicts = True\n", "\n", "    # Does this backend require casting the results of CASE expressions used\n", "    # in UPDATE statements to ensure the expression has the correct type?\n", "    requires_casted_case_in_updates = False\n", "\n", "    # Does the backend support partial indexes (CREATE INDEX ... WHERE ...)?\n", "    supports_partial_indexes = True\n", "    supports_functions_in_partial_indexes = True\n"]}]}, {"file_path": "django/db/migrations/executor.py", "span_ids": ["MigrationExecutor.collect_sql"], "content": [{"span_id": "MigrationExecutor.collect_sql", "start_line": 213, "end_line": 229, "content": ["    def collect_sql(self, plan):\n", "        \"\"\"\n", "        Take a migration plan and return a list of collected SQL statements\n", "        that represent the best-efforts version of that plan.\n", "        \"\"\"\n", "        statements = []\n", "        state = None\n", "        for migration, backwards in plan:\n", "            with self.connection.schema_editor(collect_sql=True, atomic=migration.atomic) as schema_editor:\n", "                if state is None:\n", "                    state = self.loader.project_state((migration.app_label, migration.name), at_end=False)\n", "                if not backwards:\n", "                    state = migration.apply(state, schema_editor, collect_sql=True)\n", "                else:\n", "                    state = migration.unapply(state, schema_editor, collect_sql=True)\n", "            statements.extend(schema_editor.collected_sql)\n", "        return statements\n"]}]}]}