{"instance_id": "scikit-learn__scikit-learn-10508", "identified_spans": [{"file_path": "sklearn/preprocessing/label.py", "span_ids": ["LabelEncoder.transform", "LabelEncoder"], "content": [{"span_id": "LabelEncoder.transform", "start_line": 115, "end_line": 135, "content": ["    def transform(self, y):\n", "        \"\"\"Transform labels to normalized encoding.\n", "\n", "        Parameters\n", "        ----------\n", "        y : array-like of shape [n_samples]\n", "            Target values.\n", "\n", "        Returns\n", "        -------\n", "        y : array-like of shape [n_samples]\n", "        \"\"\"\n", "        check_is_fitted(self, 'classes_')\n", "        y = column_or_1d(y, warn=True)\n", "\n", "        classes = np.unique(y)\n", "        if len(np.intersect1d(classes, self.classes_)) < len(classes):\n", "            diff = np.setdiff1d(classes, self.classes_)\n", "            raise ValueError(\n", "                    \"y contains previously unseen labels: %s\" % str(diff))\n", "        return np.searchsorted(self.classes_, y)\n"]}, {"span_id": "LabelEncoder", "start_line": 39, "end_line": 81, "content": ["class LabelEncoder(BaseEstimator, TransformerMixin):\n", "    \"\"\"Encode labels with value between 0 and n_classes-1.\n", "\n", "    Read more in the :ref:`User Guide <preprocessing_targets>`.\n", "\n", "    Attributes\n", "    ----------\n", "    classes_ : array of shape (n_class,)\n", "        Holds the label for each class.\n", "\n", "    Examples\n", "    --------\n", "    `LabelEncoder` can be used to normalize labels.\n", "\n", "    >>> from sklearn import preprocessing\n", "    >>> le = preprocessing.LabelEncoder()\n", "    >>> le.fit([1, 2, 2, 6])\n", "    LabelEncoder()\n", "    >>> le.classes_\n", "    array([1, 2, 6])\n", "    >>> le.transform([1, 1, 2, 6]) #doctest: +ELLIPSIS\n", "    array([0, 0, 1, 2]...)\n", "    >>> le.inverse_transform([0, 0, 1, 2])\n", "    array([1, 1, 2, 6])\n", "\n", "    It can also be used to transform non-numerical labels (as long as they are\n", "    hashable and comparable) to numerical labels.\n", "\n", "    >>> le = preprocessing.LabelEncoder()\n", "    >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n", "    LabelEncoder()\n", "    >>> list(le.classes_)\n", "    ['amsterdam', 'paris', 'tokyo']\n", "    >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"]) #doctest: +ELLIPSIS\n", "    array([2, 2, 1]...)\n", "    >>> list(le.inverse_transform([2, 2, 1]))\n", "    ['tokyo', 'tokyo', 'paris']\n", "\n", "    See also\n", "    --------\n", "    sklearn.preprocessing.CategoricalEncoder : encode categorical features\n", "        using a one-hot or ordinal encoding scheme.\n", "    \"\"\"\n"]}]}]}