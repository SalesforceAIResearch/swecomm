{"instance_id": "scikit-learn__scikit-learn-13241", "identified_spans": [{"file_path": "sklearn/decomposition/kernel_pca.py", "span_ids": ["KernelPCA", "KernelPCA.fit_transform", "KernelPCA._fit_transform"], "content": [{"span_id": "KernelPCA", "start_line": 18, "end_line": 140, "content": ["class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n", "    \"\"\"Kernel Principal component analysis (KPCA)\n", "\n", "    Non-linear dimensionality reduction through the use of kernels (see\n", "    :ref:`metrics`).\n", "\n", "    Read more in the :ref:`User Guide <kernel_PCA>`.\n", "\n", "    Parameters\n", "    ----------\n", "    n_components : int, default=None\n", "        Number of components. If None, all non-zero components are kept.\n", "\n", "    kernel : \"linear\" | \"poly\" | \"rbf\" | \"sigmoid\" | \"cosine\" | \"precomputed\"\n", "        Kernel. Default=\"linear\".\n", "\n", "    gamma : float, default=1/n_features\n", "        Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other\n", "        kernels.\n", "\n", "    degree : int, default=3\n", "        Degree for poly kernels. Ignored by other kernels.\n", "\n", "    coef0 : float, default=1\n", "        Independent term in poly and sigmoid kernels.\n", "        Ignored by other kernels.\n", "\n", "    kernel_params : mapping of string to any, default=None\n", "        Parameters (keyword arguments) and values for kernel passed as\n", "        callable object. Ignored by other kernels.\n", "\n", "    alpha : int, default=1.0\n", "        Hyperparameter of the ridge regression that learns the\n", "        inverse transform (when fit_inverse_transform=True).\n", "\n", "    fit_inverse_transform : bool, default=False\n", "        Learn the inverse transform for non-precomputed kernels.\n", "        (i.e. learn to find the pre-image of a point)\n", "\n", "    eigen_solver : string ['auto'|'dense'|'arpack'], default='auto'\n", "        Select eigensolver to use. If n_components is much less than\n", "        the number of training samples, arpack may be more efficient\n", "        than the dense eigensolver.\n", "\n", "    tol : float, default=0\n", "        Convergence tolerance for arpack.\n", "        If 0, optimal value will be chosen by arpack.\n", "\n", "    max_iter : int, default=None\n", "        Maximum number of iterations for arpack.\n", "        If None, optimal value will be chosen by arpack.\n", "\n", "    remove_zero_eig : boolean, default=False\n", "        If True, then all components with zero eigenvalues are removed, so\n", "        that the number of components in the output may be < n_components\n", "        (and sometimes even zero due to numerical instability).\n", "        When n_components is None, this parameter is ignored and components\n", "        with zero eigenvalues are removed regardless.\n", "\n", "    random_state : int, RandomState instance or None, optional (default=None)\n", "        If int, random_state is the seed used by the random number generator;\n", "        If RandomState instance, random_state is the random number generator;\n", "        If None, the random number generator is the RandomState instance used\n", "        by `np.random`. Used when ``eigen_solver`` == 'arpack'.\n", "\n", "        .. versionadded:: 0.18\n", "\n", "    copy_X : boolean, default=True\n", "        If True, input X is copied and stored by the model in the `X_fit_`\n", "        attribute. If no further changes will be done to X, setting\n", "        `copy_X=False` saves memory by storing a reference.\n", "\n", "        .. versionadded:: 0.18\n", "\n", "    n_jobs : int or None, optional (default=None)\n", "        The number of parallel jobs to run.\n", "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n", "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n", "        for more details.\n", "\n", "        .. versionadded:: 0.18\n", "\n", "    Attributes\n", "    ----------\n", "    lambdas_ : array, (n_components,)\n", "        Eigenvalues of the centered kernel matrix in decreasing order.\n", "        If `n_components` and `remove_zero_eig` are not set,\n", "        then all values are stored.\n", "\n", "    alphas_ : array, (n_samples, n_components)\n", "        Eigenvectors of the centered kernel matrix. If `n_components` and\n", "        `remove_zero_eig` are not set, then all components are stored.\n", "\n", "    dual_coef_ : array, (n_samples, n_features)\n", "        Inverse transform matrix. Only available when\n", "        ``fit_inverse_transform`` is True.\n", "\n", "    X_transformed_fit_ : array, (n_samples, n_components)\n", "        Projection of the fitted data on the kernel principal components.\n", "        Only available when ``fit_inverse_transform`` is True.\n", "\n", "    X_fit_ : (n_samples, n_features)\n", "        The data used to fit the model. If `copy_X=False`, then `X_fit_` is\n", "        a reference. This attribute is used for the calls to transform.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn.datasets import load_digits\n", "    >>> from sklearn.decomposition import KernelPCA\n", "    >>> X, _ = load_digits(return_X_y=True)\n", "    >>> transformer = KernelPCA(n_components=7, kernel='linear')\n", "    >>> X_transformed = transformer.fit_transform(X)\n", "    >>> X_transformed.shape\n", "    (1797, 7)\n", "\n", "    References\n", "    ----------\n", "    Kernel PCA was introduced in:\n", "        Bernhard Schoelkopf, Alexander J. Smola,\n", "        and Klaus-Robert Mueller. 1999. Kernel principal\n", "        component analysis. In Advances in kernel methods,\n", "        MIT Press, Cambridge, MA, USA 327-352.\n", "    \"\"\"\n"]}, {"span_id": "KernelPCA.fit_transform", "start_line": 263, "end_line": 283, "content": ["    def fit_transform(self, X, y=None, **params):\n", "        \"\"\"Fit the model from data in X and transform X.\n", "\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape (n_samples, n_features)\n", "            Training vector, where n_samples in the number of samples\n", "            and n_features is the number of features.\n", "\n", "        Returns\n", "        -------\n", "        X_new : array-like, shape (n_samples, n_components)\n", "        \"\"\"\n", "        self.fit(X, **params)\n", "\n", "        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n", "\n", "        if self.fit_inverse_transform:\n", "            self._fit_inverse_transform(X_transformed, X)\n", "\n", "        return X_transformed\n"]}, {"span_id": "KernelPCA._fit_transform", "start_line": 181, "end_line": 223, "content": ["    def _fit_transform(self, K):\n", "        \"\"\" Fit's using kernel K\"\"\"\n", "        # center kernel\n", "        K = self._centerer.fit_transform(K)\n", "\n", "        if self.n_components is None:\n", "            n_components = K.shape[0]\n", "        else:\n", "            n_components = min(K.shape[0], self.n_components)\n", "\n", "        # compute eigenvectors\n", "        if self.eigen_solver == 'auto':\n", "            if K.shape[0] > 200 and n_components < 10:\n", "                eigen_solver = 'arpack'\n", "            else:\n", "                eigen_solver = 'dense'\n", "        else:\n", "            eigen_solver = self.eigen_solver\n", "\n", "        if eigen_solver == 'dense':\n", "            self.lambdas_, self.alphas_ = linalg.eigh(\n", "                K, eigvals=(K.shape[0] - n_components, K.shape[0] - 1))\n", "        elif eigen_solver == 'arpack':\n", "            random_state = check_random_state(self.random_state)\n", "            # initialize with [-1,1] as in ARPACK\n", "            v0 = random_state.uniform(-1, 1, K.shape[0])\n", "            self.lambdas_, self.alphas_ = eigsh(K, n_components,\n", "                                                which=\"LA\",\n", "                                                tol=self.tol,\n", "                                                maxiter=self.max_iter,\n", "                                                v0=v0)\n", "\n", "        # sort eigenvectors in descending order\n", "        indices = self.lambdas_.argsort()[::-1]\n", "        self.lambdas_ = self.lambdas_[indices]\n", "        self.alphas_ = self.alphas_[:, indices]\n", "\n", "        # remove eigenvectors with a zero eigenvalue\n", "        if self.remove_zero_eig or self.n_components is None:\n", "            self.alphas_ = self.alphas_[:, self.lambdas_ > 0]\n", "            self.lambdas_ = self.lambdas_[self.lambdas_ > 0]\n", "\n", "        return K\n"]}]}]}