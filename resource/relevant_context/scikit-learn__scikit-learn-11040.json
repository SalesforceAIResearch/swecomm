{"instance_id": "scikit-learn__scikit-learn-11040", "identified_spans": [{"file_path": "sklearn/neighbors/base.py", "span_ids": ["NeighborsBase.__init__", "KNeighborsMixin.kneighbors"], "content": [{"span_id": "NeighborsBase.__init__", "start_line": 105, "end_line": 118, "content": ["    @abstractmethod\n", "    def __init__(self, n_neighbors=None, radius=None,\n", "                 algorithm='auto', leaf_size=30, metric='minkowski',\n", "                 p=2, metric_params=None, n_jobs=1):\n", "\n", "        self.n_neighbors = n_neighbors\n", "        self.radius = radius\n", "        self.algorithm = algorithm\n", "        self.leaf_size = leaf_size\n", "        self.metric = metric\n", "        self.metric_params = metric_params\n", "        self.p = p\n", "        self.n_jobs = n_jobs\n", "        self._check_algorithm_metric()\n"]}, {"span_id": "KNeighborsMixin.kneighbors", "start_line": 273, "end_line": 421, "content": ["    def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n", "        \"\"\"Finds the K-neighbors of a point.\n", "\n", "        Returns indices of and distances to the neighbors of each point.\n", "\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape (n_query, n_features), \\\n", "                or (n_query, n_indexed) if metric == 'precomputed'\n", "            The query point or points.\n", "            If not provided, neighbors of each indexed point are returned.\n", "            In this case, the query point is not considered its own neighbor.\n", "\n", "        n_neighbors : int\n", "            Number of neighbors to get (default is the value\n", "            passed to the constructor).\n", "\n", "        return_distance : boolean, optional. Defaults to True.\n", "            If False, distances will not be returned\n", "\n", "        Returns\n", "        -------\n", "        dist : array\n", "            Array representing the lengths to points, only present if\n", "            return_distance=True\n", "\n", "        ind : array\n", "            Indices of the nearest points in the population matrix.\n", "\n", "        Examples\n", "        --------\n", "        In the following example, we construct a NeighborsClassifier\n", "        class from an array representing our data set and ask who's\n", "        the closest point to [1,1,1]\n", "\n", "        >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n", "        >>> from sklearn.neighbors import NearestNeighbors\n", "        >>> neigh = NearestNeighbors(n_neighbors=1)\n", "        >>> neigh.fit(samples) # doctest: +ELLIPSIS\n", "        NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n", "        >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n", "        (array([[0.5]]), array([[2]]))\n", "\n", "        As you can see, it returns [[0.5]], and [[2]], which means that the\n", "        element is at distance 0.5 and is the third element of samples\n", "        (indexes start at 0). You can also query for multiple points:\n", "\n", "        >>> X = [[0., 1., 0.], [1., 0., 1.]]\n", "        >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n", "        array([[1],\n", "               [2]]...)\n", "\n", "        \"\"\"\n", "        check_is_fitted(self, \"_fit_method\")\n", "\n", "        if n_neighbors is None:\n", "            n_neighbors = self.n_neighbors\n", "\n", "        if X is not None:\n", "            query_is_train = False\n", "            X = check_array(X, accept_sparse='csr')\n", "        else:\n", "            query_is_train = True\n", "            X = self._fit_X\n", "            # Include an extra neighbor to account for the sample itself being\n", "            # returned, which is removed later\n", "            n_neighbors += 1\n", "\n", "        train_size = self._fit_X.shape[0]\n", "        if n_neighbors > train_size:\n", "            raise ValueError(\n", "                \"Expected n_neighbors <= n_samples, \"\n", "                \" but n_samples = %d, n_neighbors = %d\" %\n", "                (train_size, n_neighbors)\n", "            )\n", "        n_samples, _ = X.shape\n", "        sample_range = np.arange(n_samples)[:, None]\n", "\n", "        n_jobs = _get_n_jobs(self.n_jobs)\n", "        if self._fit_method == 'brute':\n", "            # for efficiency, use squared euclidean distances\n", "            if self.effective_metric_ == 'euclidean':\n", "                dist = pairwise_distances(X, self._fit_X, 'euclidean',\n", "                                          n_jobs=n_jobs, squared=True)\n", "            else:\n", "                dist = pairwise_distances(\n", "                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,\n", "                    **self.effective_metric_params_)\n", "\n", "            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)\n", "            neigh_ind = neigh_ind[:, :n_neighbors]\n", "            # argpartition doesn't guarantee sorted order, so we sort again\n", "            neigh_ind = neigh_ind[\n", "                sample_range, np.argsort(dist[sample_range, neigh_ind])]\n", "\n", "            if return_distance:\n", "                if self.effective_metric_ == 'euclidean':\n", "                    result = np.sqrt(dist[sample_range, neigh_ind]), neigh_ind\n", "                else:\n", "                    result = dist[sample_range, neigh_ind], neigh_ind\n", "            else:\n", "                result = neigh_ind\n", "\n", "        elif self._fit_method in ['ball_tree', 'kd_tree']:\n", "            if issparse(X):\n", "                raise ValueError(\n", "                    \"%s does not work with sparse matrices. Densify the data, \"\n", "                    \"or set algorithm='brute'\" % self._fit_method)\n", "            result = Parallel(n_jobs, backend='threading')(\n", "                delayed(self._tree.query, check_pickle=False)(\n", "                    X[s], n_neighbors, return_distance)\n", "                for s in gen_even_slices(X.shape[0], n_jobs)\n", "            )\n", "            if return_distance:\n", "                dist, neigh_ind = tuple(zip(*result))\n", "                result = np.vstack(dist), np.vstack(neigh_ind)\n", "            else:\n", "                result = np.vstack(result)\n", "        else:\n", "            raise ValueError(\"internal: _fit_method not recognized\")\n", "\n", "        if not query_is_train:\n", "            return result\n", "        else:\n", "            # If the query data is the same as the indexed data, we would like\n", "            # to ignore the first nearest neighbor of every sample, i.e\n", "            # the sample itself.\n", "            if return_distance:\n", "                dist, neigh_ind = result\n", "            else:\n", "                neigh_ind = result\n", "\n", "            sample_mask = neigh_ind != sample_range\n", "\n", "            # Corner case: When the number of duplicates are more\n", "            # than the number of neighbors, the first NN will not\n", "            # be the sample, but a duplicate.\n", "            # In that case mask the first duplicate.\n", "            dup_gr_nbrs = np.all(sample_mask, axis=1)\n", "            sample_mask[:, 0][dup_gr_nbrs] = False\n", "\n", "            neigh_ind = np.reshape(\n", "                neigh_ind[sample_mask], (n_samples, n_neighbors - 1))\n", "\n", "            if return_distance:\n", "                dist = np.reshape(\n", "                    dist[sample_mask], (n_samples, n_neighbors - 1))\n", "                return dist, neigh_ind\n", "            return neigh_ind\n"]}]}, {"file_path": "sklearn/neighbors/unsupervised.py", "span_ids": ["NearestNeighbors", "NearestNeighbors.__init__"], "content": [{"span_id": "NearestNeighbors", "start_line": 9, "end_line": 113, "content": ["class NearestNeighbors(NeighborsBase, KNeighborsMixin,\n", "                       RadiusNeighborsMixin, UnsupervisedMixin):\n", "    \"\"\"Unsupervised learner for implementing neighbor searches.\n", "\n", "    Read more in the :ref:`User Guide <unsupervised_neighbors>`.\n", "\n", "    Parameters\n", "    ----------\n", "    n_neighbors : int, optional (default = 5)\n", "        Number of neighbors to use by default for :meth:`kneighbors` queries.\n", "\n", "    radius : float, optional (default = 1.0)\n", "        Range of parameter space to use by default for :meth:`radius_neighbors`\n", "        queries.\n", "\n", "    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n", "        Algorithm used to compute the nearest neighbors:\n", "\n", "        - 'ball_tree' will use :class:`BallTree`\n", "        - 'kd_tree' will use :class:`KDTree`\n", "        - 'brute' will use a brute-force search.\n", "        - 'auto' will attempt to decide the most appropriate algorithm\n", "          based on the values passed to :meth:`fit` method.\n", "\n", "        Note: fitting on sparse input will override the setting of\n", "        this parameter, using brute force.\n", "\n", "    leaf_size : int, optional (default = 30)\n", "        Leaf size passed to BallTree or KDTree.  This can affect the\n", "        speed of the construction and query, as well as the memory\n", "        required to store the tree.  The optimal value depends on the\n", "        nature of the problem.\n", "\n", "    metric : string or callable, default 'minkowski'\n", "        metric to use for distance computation. Any metric from scikit-learn\n", "        or scipy.spatial.distance can be used.\n", "\n", "        If metric is a callable function, it is called on each\n", "        pair of instances (rows) and the resulting value recorded. The callable\n", "        should take two arrays as input and return one value indicating the\n", "        distance between them. This works for Scipy's metrics, but is less\n", "        efficient than passing the metric name as a string.\n", "\n", "        Distance matrices are not supported.\n", "\n", "        Valid values for metric are:\n", "\n", "        - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n", "          'manhattan']\n", "\n", "        - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n", "          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n", "          'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n", "          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n", "          'yule']\n", "\n", "        See the documentation for scipy.spatial.distance for details on these\n", "        metrics.\n", "\n", "    p : integer, optional (default = 2)\n", "        Parameter for the Minkowski metric from\n", "        sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is\n", "        equivalent to using manhattan_distance (l1), and euclidean_distance\n", "        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n", "\n", "    metric_params : dict, optional (default = None)\n", "        Additional keyword arguments for the metric function.\n", "\n", "    n_jobs : int, optional (default = 1)\n", "        The number of parallel jobs to run for neighbors search.\n", "        If ``-1``, then the number of jobs is set to the number of CPU cores.\n", "\n", "    Examples\n", "    --------\n", "      >>> import numpy as np\n", "      >>> from sklearn.neighbors import NearestNeighbors\n", "      >>> samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]\n", "\n", "      >>> neigh = NearestNeighbors(2, 0.4)\n", "      >>> neigh.fit(samples)  #doctest: +ELLIPSIS\n", "      NearestNeighbors(...)\n", "\n", "      >>> neigh.kneighbors([[0, 0, 1.3]], 2, return_distance=False)\n", "      ... #doctest: +ELLIPSIS\n", "      array([[2, 0]]...)\n", "\n", "      >>> nbrs = neigh.radius_neighbors([[0, 0, 1.3]], 0.4, return_distance=False)\n", "      >>> np.asarray(nbrs[0][0])\n", "      array(2)\n", "\n", "    See also\n", "    --------\n", "    KNeighborsClassifier\n", "    RadiusNeighborsClassifier\n", "    KNeighborsRegressor\n", "    RadiusNeighborsRegressor\n", "    BallTree\n", "\n", "    Notes\n", "    -----\n", "    See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n", "    for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n", "\n", "    https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n", "    \"\"\"\n"]}, {"span_id": "NearestNeighbors.__init__", "start_line": 115, "end_line": 123, "content": ["    def __init__(self, n_neighbors=5, radius=1.0,\n", "                 algorithm='auto', leaf_size=30, metric='minkowski',\n", "                 p=2, metric_params=None, n_jobs=1, **kwargs):\n", "        super(NearestNeighbors, self).__init__(\n", "              n_neighbors=n_neighbors,\n", "              radius=radius,\n", "              algorithm=algorithm,\n", "              leaf_size=leaf_size, metric=metric, p=p,\n", "              metric_params=metric_params, n_jobs=n_jobs, **kwargs)\n"]}]}]}