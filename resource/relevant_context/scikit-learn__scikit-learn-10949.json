{"instance_id": "scikit-learn__scikit-learn-10949", "identified_spans": [{"file_path": "sklearn/utils/validation.py", "span_ids": ["check_array"], "content": [{"span_id": "check_array", "start_line": 354, "end_line": 584, "content": ["def check_array(array, accept_sparse=False, accept_large_sparse=True,\n", "                dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n", "                ensure_2d=True, allow_nd=False, ensure_min_samples=1,\n", "                ensure_min_features=1, warn_on_dtype=False, estimator=None):\n", "\n", "    \"\"\"Input validation on an array, list, sparse matrix or similar.\n", "\n", "    By default, the input is converted to an at least 2D numpy array.\n", "    If the dtype of the array is object, attempt converting to float,\n", "    raising on failure.\n", "\n", "    Parameters\n", "    ----------\n", "    array : object\n", "        Input object to check / convert.\n", "\n", "    accept_sparse : string, boolean or list/tuple of strings (default=False)\n", "        String[s] representing allowed sparse matrix formats, such as 'csc',\n", "        'csr', etc. If the input is sparse but not in the allowed format,\n", "        it will be converted to the first listed format. True allows the input\n", "        to be any format. False means that a sparse matrix input will\n", "        raise an error.\n", "\n", "        .. deprecated:: 0.19\n", "           Passing 'None' to parameter ``accept_sparse`` in methods is\n", "           deprecated in version 0.19 \"and will be removed in 0.21. Use\n", "           ``accept_sparse=False`` instead.\n", "\n", "    accept_large_sparse : bool (default=True)\n", "        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n", "        accept_sparse, accept_large_sparse=False will cause it to be accepted\n", "        only if its indices are stored with a 32-bit dtype.\n", "\n", "        .. versionadded:: 0.20\n", "\n", "    dtype : string, type, list of types or None (default=\"numeric\")\n", "        Data type of result. If None, the dtype of the input is preserved.\n", "        If \"numeric\", dtype is preserved unless array.dtype is object.\n", "        If dtype is a list of types, conversion on the first type is only\n", "        performed if the dtype of the input is not in the list.\n", "\n", "    order : 'F', 'C' or None (default=None)\n", "        Whether an array will be forced to be fortran or c-style.\n", "        When order is None (default), then if copy=False, nothing is ensured\n", "        about the memory layout of the output array; otherwise (copy=True)\n", "        the memory layout of the returned array is kept as close as possible\n", "        to the original array.\n", "\n", "    copy : boolean (default=False)\n", "        Whether a forced copy will be triggered. If copy=False, a copy might\n", "        be triggered by a conversion.\n", "\n", "    force_all_finite : boolean or 'allow-nan', (default=True)\n", "        Whether to raise an error on np.inf and np.nan in X. The possibilities\n", "        are:\n", "\n", "        - True: Force all values of X to be finite.\n", "        - False: accept both np.inf and np.nan in X.\n", "        - 'allow-nan':  accept  only  np.nan  values in  X.  Values  cannot  be\n", "          infinite.\n", "\n", "        .. versionadded:: 0.20\n", "           ``force_all_finite`` accepts the string ``'allow-nan'``.\n", "\n", "    ensure_2d : boolean (default=True)\n", "        Whether to raise a value error if X is not 2d.\n", "\n", "    allow_nd : boolean (default=False)\n", "        Whether to allow X.ndim > 2.\n", "\n", "    ensure_min_samples : int (default=1)\n", "        Make sure that the array has a minimum number of samples in its first\n", "        axis (rows for a 2D array). Setting to 0 disables this check.\n", "\n", "    ensure_min_features : int (default=1)\n", "        Make sure that the 2D array has some minimum number of features\n", "        (columns). The default value of 1 rejects empty datasets.\n", "        This check is only enforced when the input data has effectively 2\n", "        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n", "        disables this check.\n", "\n", "    warn_on_dtype : boolean (default=False)\n", "        Raise DataConversionWarning if the dtype of the input data structure\n", "        does not match the requested dtype, causing a memory copy.\n", "\n", "    estimator : str or estimator instance (default=None)\n", "        If passed, include the name of the estimator in warning messages.\n", "\n", "    Returns\n", "    -------\n", "    X_converted : object\n", "        The converted and validated X.\n", "\n", "    \"\"\"\n", "    # accept_sparse 'None' deprecation check\n", "    if accept_sparse is None:\n", "        warnings.warn(\n", "            \"Passing 'None' to parameter 'accept_sparse' in methods \"\n", "            \"check_array and check_X_y is deprecated in version 0.19 \"\n", "            \"and will be removed in 0.21. Use 'accept_sparse=False' \"\n", "            \" instead.\", DeprecationWarning)\n", "        accept_sparse = False\n", "\n", "    # store reference to original array to check if copy is needed when\n", "    # function returns\n", "    array_orig = array\n", "\n", "    # store whether originally we wanted numeric dtype\n", "    dtype_numeric = isinstance(dtype, six.string_types) and dtype == \"numeric\"\n", "\n", "    dtype_orig = getattr(array, \"dtype\", None)\n", "    if not hasattr(dtype_orig, 'kind'):\n", "        # not a data type (e.g. a column named dtype in a pandas DataFrame)\n", "        dtype_orig = None\n", "\n", "    if dtype_numeric:\n", "        if dtype_orig is not None and dtype_orig.kind == \"O\":\n", "            # if input is object, convert to float.\n", "            dtype = np.float64\n", "        else:\n", "            dtype = None\n", "\n", "    if isinstance(dtype, (list, tuple)):\n", "        if dtype_orig is not None and dtype_orig in dtype:\n", "            # no dtype conversion required\n", "            dtype = None\n", "        else:\n", "            # dtype conversion required. Let's select the first element of the\n", "            # list of accepted types.\n", "            dtype = dtype[0]\n", "\n", "    if force_all_finite not in (True, False, 'allow-nan'):\n", "        raise ValueError('force_all_finite should be a bool or \"allow-nan\"'\n", "                         '. Got {!r} instead'.format(force_all_finite))\n", "\n", "    if estimator is not None:\n", "        if isinstance(estimator, six.string_types):\n", "            estimator_name = estimator\n", "        else:\n", "            estimator_name = estimator.__class__.__name__\n", "    else:\n", "        estimator_name = \"Estimator\"\n", "    context = \" by %s\" % estimator_name if estimator is not None else \"\"\n", "\n", "    if sp.issparse(array):\n", "        _ensure_no_complex_data(array)\n", "        array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n", "                                      dtype=dtype, copy=copy,\n", "                                      force_all_finite=force_all_finite,\n", "                                      accept_large_sparse=accept_large_sparse)\n", "    else:\n", "        # If np.array(..) gives ComplexWarning, then we convert the warning\n", "        # to an error. This is needed because specifying a non complex\n", "        # dtype to the function converts complex to real dtype,\n", "        # thereby passing the test made in the lines following the scope\n", "        # of warnings context manager.\n", "        with warnings.catch_warnings():\n", "            try:\n", "                warnings.simplefilter('error', ComplexWarning)\n", "                array = np.asarray(array, dtype=dtype, order=order)\n", "            except ComplexWarning:\n", "                raise ValueError(\"Complex data not supported\\n\"\n", "                                 \"{}\\n\".format(array))\n", "\n", "        # It is possible that the np.array(..) gave no warning. This happens\n", "        # when no dtype conversion happened, for example dtype = None. The\n", "        # result is that np.array(..) produces an array of complex dtype\n", "        # and we need to catch and raise exception for such cases.\n", "        _ensure_no_complex_data(array)\n", "\n", "        if ensure_2d:\n", "            # If input is scalar raise error\n", "            if array.ndim == 0:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array))\n", "            # If input is 1D raise error\n", "            if array.ndim == 1:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array))\n", "\n", "        # in the future np.flexible dtypes will be handled like object dtypes\n", "        if dtype_numeric and np.issubdtype(array.dtype, np.flexible):\n", "            warnings.warn(\n", "                \"Beginning in version 0.22, arrays of strings will be \"\n", "                \"interpreted as decimal numbers if parameter 'dtype' is \"\n", "                \"'numeric'. It is recommended that you convert the array to \"\n", "                \"type np.float64 before passing it to check_array.\",\n", "                FutureWarning)\n", "\n", "        # make sure we actually converted to numeric:\n", "        if dtype_numeric and array.dtype.kind == \"O\":\n", "            array = array.astype(np.float64)\n", "        if not allow_nd and array.ndim >= 3:\n", "            raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n", "                             % (array.ndim, estimator_name))\n", "        if force_all_finite:\n", "            _assert_all_finite(array,\n", "                               allow_nan=force_all_finite == 'allow-nan')\n", "\n", "    shape_repr = _shape_repr(array.shape)\n", "    if ensure_min_samples > 0:\n", "        n_samples = _num_samples(array)\n", "        if n_samples < ensure_min_samples:\n", "            raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n", "                             \" minimum of %d is required%s.\"\n", "                             % (n_samples, shape_repr, ensure_min_samples,\n", "                                context))\n", "\n", "    if ensure_min_features > 0 and array.ndim == 2:\n", "        n_features = array.shape[1]\n", "        if n_features < ensure_min_features:\n", "            raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n", "                             \" a minimum of %d is required%s.\"\n", "                             % (n_features, shape_repr, ensure_min_features,\n", "                                context))\n", "\n", "    if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n", "        msg = (\"Data with input dtype %s was converted to %s%s.\"\n", "               % (dtype_orig, array.dtype, context))\n", "        warnings.warn(msg, DataConversionWarning)\n", "\n", "    if copy and np.may_share_memory(array, array_orig):\n", "        array = np.array(array, dtype=dtype, order=order)\n", "\n", "    return array\n"]}]}]}