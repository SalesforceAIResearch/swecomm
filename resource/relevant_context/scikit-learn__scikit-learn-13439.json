{"instance_id": "scikit-learn__scikit-learn-13439", "identified_spans": [{"file_path": "sklearn/pipeline.py", "span_ids": ["Pipeline", "Pipeline._validate_steps"], "content": [{"span_id": "Pipeline", "start_line": 29, "end_line": 127, "content": ["class Pipeline(_BaseComposition):\n", "    \"\"\"Pipeline of transforms with a final estimator.\n", "\n", "    Sequentially apply a list of transforms and a final estimator.\n", "    Intermediate steps of the pipeline must be 'transforms', that is, they\n", "    must implement fit and transform methods.\n", "    The final estimator only needs to implement fit.\n", "    The transformers in the pipeline can be cached using ``memory`` argument.\n", "\n", "    The purpose of the pipeline is to assemble several steps that can be\n", "    cross-validated together while setting different parameters.\n", "    For this, it enables setting parameters of the various steps using their\n", "    names and the parameter name separated by a '__', as in the example below.\n", "    A step's estimator may be replaced entirely by setting the parameter\n", "    with its name to another estimator, or a transformer removed by setting\n", "    it to 'passthrough' or ``None``.\n", "\n", "    Read more in the :ref:`User Guide <pipeline>`.\n", "\n", "    Parameters\n", "    ----------\n", "    steps : list\n", "        List of (name, transform) tuples (implementing fit/transform) that are\n", "        chained, in the order in which they are chained, with the last object\n", "        an estimator.\n", "\n", "    memory : None, str or object with the joblib.Memory interface, optional\n", "        Used to cache the fitted transformers of the pipeline. By default,\n", "        no caching is performed. If a string is given, it is the path to\n", "        the caching directory. Enabling caching triggers a clone of\n", "        the transformers before fitting. Therefore, the transformer\n", "        instance given to the pipeline cannot be inspected\n", "        directly. Use the attribute ``named_steps`` or ``steps`` to\n", "        inspect estimators within the pipeline. Caching the\n", "        transformers is advantageous when fitting is time consuming.\n", "\n", "    Attributes\n", "    ----------\n", "    named_steps : bunch object, a dictionary with attribute access\n", "        Read-only attribute to access any step parameter by user given name.\n", "        Keys are step names and values are steps parameters.\n", "\n", "    See also\n", "    --------\n", "    sklearn.pipeline.make_pipeline : convenience function for simplified\n", "        pipeline construction.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn import svm\n", "    >>> from sklearn.datasets import samples_generator\n", "    >>> from sklearn.feature_selection import SelectKBest\n", "    >>> from sklearn.feature_selection import f_regression\n", "    >>> from sklearn.pipeline import Pipeline\n", "    >>> # generate some data to play with\n", "    >>> X, y = samples_generator.make_classification(\n", "    ...     n_informative=5, n_redundant=0, random_state=42)\n", "    >>> # ANOVA SVM-C\n", "    >>> anova_filter = SelectKBest(f_regression, k=5)\n", "    >>> clf = svm.SVC(kernel='linear')\n", "    >>> anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\n", "    >>> # You can set the parameters using the names issued\n", "    >>> # For instance, fit using a k of 10 in the SelectKBest\n", "    >>> # and a parameter 'C' of the svm\n", "    >>> anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\n", "    ...                      # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n", "    Pipeline(memory=None,\n", "             steps=[('anova', SelectKBest(...)),\n", "                    ('svc', SVC(...))])\n", "    >>> prediction = anova_svm.predict(X)\n", "    >>> anova_svm.score(X, y)                        # doctest: +ELLIPSIS\n", "    0.83\n", "    >>> # getting the selected features chosen by anova_filter\n", "    >>> anova_svm['anova'].get_support()\n", "    ... # doctest: +NORMALIZE_WHITESPACE\n", "    array([False, False,  True,  True, False, False,  True,  True, False,\n", "           True, False,  True,  True, False,  True, False,  True,  True,\n", "           False, False])\n", "    >>> # Another way to get selected features chosen by anova_filter\n", "    >>> anova_svm.named_steps.anova.get_support()\n", "    ... # doctest: +NORMALIZE_WHITESPACE\n", "    array([False, False,  True,  True, False, False,  True,  True, False,\n", "           True, False,  True,  True, False,  True, False,  True,  True,\n", "           False, False])\n", "    >>> # Indexing can also be used to extract a sub-pipeline.\n", "    >>> sub_pipeline = anova_svm[:1]\n", "    >>> sub_pipeline  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n", "    Pipeline(memory=None, steps=[('anova', ...)])\n", "    >>> coef = anova_svm[-1].coef_\n", "    >>> anova_svm['svc'] is anova_svm[-1]\n", "    True\n", "    >>> coef.shape\n", "    (1, 10)\n", "    >>> sub_pipeline.inverse_transform(coef).shape\n", "    (1, 20)\n", "    \"\"\"\n", "\n", "    # BaseEstimator interface\n", "    _required_parameters = ['steps']\n"]}, {"span_id": "Pipeline._validate_steps", "start_line": 162, "end_line": 188, "content": ["    def _validate_steps(self):\n", "        names, estimators = zip(*self.steps)\n", "\n", "        # validate names\n", "        self._validate_names(names)\n", "\n", "        # validate estimators\n", "        transformers = estimators[:-1]\n", "        estimator = estimators[-1]\n", "\n", "        for t in transformers:\n", "            if t is None or t == 'passthrough':\n", "                continue\n", "            if (not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not\n", "                    hasattr(t, \"transform\")):\n", "                raise TypeError(\"All intermediate steps should be \"\n", "                                \"transformers and implement fit and transform \"\n", "                                \"or be the string 'passthrough' \"\n", "                                \"'%s' (type %s) doesn't\" % (t, type(t)))\n", "\n", "        # We allow last estimator to be None as an identity transformation\n", "        if (estimator is not None and estimator != 'passthrough'\n", "                and not hasattr(estimator, \"fit\")):\n", "            raise TypeError(\n", "                \"Last step of Pipeline should implement fit \"\n", "                \"or be the string 'passthrough'. \"\n", "                \"'%s' (type %s) doesn't\" % (estimator, type(estimator)))\n"]}]}]}