{"instance_id": "scikit-learn__scikit-learn-14092", "identified_spans": [{"file_path": "sklearn/neighbors/nca.py", "span_ids": ["NeighborhoodComponentsAnalysis._validate_params", "NeighborhoodComponentsAnalysis.__init__"], "content": [{"span_id": "NeighborhoodComponentsAnalysis._validate_params", "start_line": 262, "end_line": 368, "content": ["    def _validate_params(self, X, y):\n", "        \"\"\"Validate parameters as soon as :meth:`fit` is called.\n", "\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape (n_samples, n_features)\n", "            The training samples.\n", "\n", "        y : array-like, shape (n_samples,)\n", "            The corresponding training labels.\n", "\n", "        Returns\n", "        -------\n", "        X : array, shape (n_samples, n_features)\n", "            The validated training samples.\n", "\n", "        y : array, shape (n_samples,)\n", "            The validated training labels, encoded to be integers in\n", "            the range(0, n_classes).\n", "\n", "        init : string or numpy array of shape (n_features_a, n_features_b)\n", "            The validated initialization of the linear transformation.\n", "\n", "        Raises\n", "        -------\n", "        TypeError\n", "            If a parameter is not an instance of the desired type.\n", "\n", "        ValueError\n", "            If a parameter's value violates its legal value range or if the\n", "            combination of two or more given parameters is incompatible.\n", "        \"\"\"\n", "\n", "        # Validate the inputs X and y, and converts y to numerical classes.\n", "        X, y = check_X_y(X, y, ensure_min_samples=2)\n", "        check_classification_targets(y)\n", "        y = LabelEncoder().fit_transform(y)\n", "\n", "        # Check the preferred dimensionality of the projected space\n", "        if self.n_components is not None:\n", "            check_scalar(self.n_components, 'n_components', int, 1)\n", "\n", "            if self.n_components > X.shape[1]:\n", "                raise ValueError('The preferred dimensionality of the '\n", "                                 'projected space `n_components` ({}) cannot '\n", "                                 'be greater than the given data '\n", "                                 'dimensionality ({})!'\n", "                                 .format(self.n_components, X.shape[1]))\n", "\n", "        # If warm_start is enabled, check that the inputs are consistent\n", "        check_scalar(self.warm_start, 'warm_start', bool)\n", "        if self.warm_start and hasattr(self, 'components_'):\n", "            if self.components_.shape[1] != X.shape[1]:\n", "                raise ValueError('The new inputs dimensionality ({}) does not '\n", "                                 'match the input dimensionality of the '\n", "                                 'previously learned transformation ({}).'\n", "                                 .format(X.shape[1],\n", "                                         self.components_.shape[1]))\n", "\n", "        check_scalar(self.max_iter, 'max_iter', int, 1)\n", "        check_scalar(self.tol, 'tol', float, 0.)\n", "        check_scalar(self.verbose, 'verbose', int, 0)\n", "\n", "        if self.callback is not None:\n", "            if not callable(self.callback):\n", "                raise ValueError('`callback` is not callable.')\n", "\n", "        # Check how the linear transformation should be initialized\n", "        init = self.init\n", "\n", "        if isinstance(init, np.ndarray):\n", "            init = check_array(init)\n", "\n", "            # Assert that init.shape[1] = X.shape[1]\n", "            if init.shape[1] != X.shape[1]:\n", "                raise ValueError(\n", "                    'The input dimensionality ({}) of the given '\n", "                    'linear transformation `init` must match the '\n", "                    'dimensionality of the given inputs `X` ({}).'\n", "                    .format(init.shape[1], X.shape[1]))\n", "\n", "            # Assert that init.shape[0] <= init.shape[1]\n", "            if init.shape[0] > init.shape[1]:\n", "                raise ValueError(\n", "                    'The output dimensionality ({}) of the given '\n", "                    'linear transformation `init` cannot be '\n", "                    'greater than its input dimensionality ({}).'\n", "                    .format(init.shape[0], init.shape[1]))\n", "\n", "            if self.n_components is not None:\n", "                # Assert that self.n_components = init.shape[0]\n", "                if self.n_components != init.shape[0]:\n", "                    raise ValueError('The preferred dimensionality of the '\n", "                                     'projected space `n_components` ({}) does'\n", "                                     ' not match the output dimensionality of '\n", "                                     'the given linear transformation '\n", "                                     '`init` ({})!'\n", "                                     .format(self.n_components,\n", "                                             init.shape[0]))\n", "        elif init in ['auto', 'pca', 'lda', 'identity', 'random']:\n", "            pass\n", "        else:\n", "            raise ValueError(\n", "                \"`init` must be 'auto', 'pca', 'lda', 'identity', 'random' \"\n", "                \"or a numpy array of shape (n_components, n_features).\")\n", "\n", "        return X, y, init\n"]}, {"span_id": "NeighborhoodComponentsAnalysis.__init__", "start_line": 158, "end_line": 168, "content": ["    def __init__(self, n_components=None, init='auto', warm_start=False,\n", "                 max_iter=50, tol=1e-5, callback=None, verbose=0,\n", "                 random_state=None):\n", "        self.n_components = n_components\n", "        self.init = init\n", "        self.warm_start = warm_start\n", "        self.max_iter = max_iter\n", "        self.tol = tol\n", "        self.callback = callback\n", "        self.verbose = verbose\n", "        self.random_state = random_state\n"]}]}, {"file_path": "sklearn/utils/validation.py", "span_ids": ["check_X_y", "check_array"], "content": [{"span_id": "check_X_y", "start_line": 600, "end_line": 731, "content": ["def check_X_y(X, y, accept_sparse=False, accept_large_sparse=True,\n", "              dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n", "              ensure_2d=True, allow_nd=False, multi_output=False,\n", "              ensure_min_samples=1, ensure_min_features=1, y_numeric=False,\n", "              warn_on_dtype=None, estimator=None):\n", "    \"\"\"Input validation for standard estimators.\n", "\n", "    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n", "    default, X is checked to be non-empty and containing only finite values.\n", "    Standard input checks are also applied to y, such as checking that y\n", "    does not have np.nan or np.inf targets. For multi-label y, set\n", "    multi_output=True to allow 2D and sparse y. If the dtype of X is\n", "    object, attempt converting to float, raising on failure.\n", "\n", "    Parameters\n", "    ----------\n", "    X : nd-array, list or sparse matrix\n", "        Input data.\n", "\n", "    y : nd-array, list or sparse matrix\n", "        Labels.\n", "\n", "    accept_sparse : string, boolean or list of string (default=False)\n", "        String[s] representing allowed sparse matrix formats, such as 'csc',\n", "        'csr', etc. If the input is sparse but not in the allowed format,\n", "        it will be converted to the first listed format. True allows the input\n", "        to be any format. False means that a sparse matrix input will\n", "        raise an error.\n", "\n", "    accept_large_sparse : bool (default=True)\n", "        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n", "        accept_sparse, accept_large_sparse will cause it to be accepted only\n", "        if its indices are stored with a 32-bit dtype.\n", "\n", "        .. versionadded:: 0.20\n", "\n", "    dtype : string, type, list of types or None (default=\"numeric\")\n", "        Data type of result. If None, the dtype of the input is preserved.\n", "        If \"numeric\", dtype is preserved unless array.dtype is object.\n", "        If dtype is a list of types, conversion on the first type is only\n", "        performed if the dtype of the input is not in the list.\n", "\n", "    order : 'F', 'C' or None (default=None)\n", "        Whether an array will be forced to be fortran or c-style.\n", "\n", "    copy : boolean (default=False)\n", "        Whether a forced copy will be triggered. If copy=False, a copy might\n", "        be triggered by a conversion.\n", "\n", "    force_all_finite : boolean or 'allow-nan', (default=True)\n", "        Whether to raise an error on np.inf and np.nan in X. This parameter\n", "        does not influence whether y can have np.inf or np.nan values.\n", "        The possibilities are:\n", "\n", "        - True: Force all values of X to be finite.\n", "        - False: accept both np.inf and np.nan in X.\n", "        - 'allow-nan': accept only np.nan values in X. Values cannot be\n", "          infinite.\n", "\n", "        .. versionadded:: 0.20\n", "           ``force_all_finite`` accepts the string ``'allow-nan'``.\n", "\n", "    ensure_2d : boolean (default=True)\n", "        Whether to raise a value error if X is not 2D.\n", "\n", "    allow_nd : boolean (default=False)\n", "        Whether to allow X.ndim > 2.\n", "\n", "    multi_output : boolean (default=False)\n", "        Whether to allow 2D y (array or sparse matrix). If false, y will be\n", "        validated as a vector. y cannot have np.nan or np.inf values if\n", "        multi_output=True.\n", "\n", "    ensure_min_samples : int (default=1)\n", "        Make sure that X has a minimum number of samples in its first\n", "        axis (rows for a 2D array).\n", "\n", "    ensure_min_features : int (default=1)\n", "        Make sure that the 2D array has some minimum number of features\n", "        (columns). The default value of 1 rejects empty datasets.\n", "        This check is only enforced when X has effectively 2 dimensions or\n", "        is originally 1D and ``ensure_2d`` is True. Setting to 0 disables\n", "        this check.\n", "\n", "    y_numeric : boolean (default=False)\n", "        Whether to ensure that y has a numeric type. If dtype of y is object,\n", "        it is converted to float64. Should only be used for regression\n", "        algorithms.\n", "\n", "    warn_on_dtype : boolean or None, optional (default=None)\n", "        Raise DataConversionWarning if the dtype of the input data structure\n", "        does not match the requested dtype, causing a memory copy.\n", "\n", "        .. deprecated:: 0.21\n", "            ``warn_on_dtype`` is deprecated in version 0.21 and will be\n", "             removed in 0.23.\n", "\n", "    estimator : str or estimator instance (default=None)\n", "        If passed, include the name of the estimator in warning messages.\n", "\n", "    Returns\n", "    -------\n", "    X_converted : object\n", "        The converted and validated X.\n", "\n", "    y_converted : object\n", "        The converted and validated y.\n", "    \"\"\"\n", "    if y is None:\n", "        raise ValueError(\"y cannot be None\")\n", "\n", "    X = check_array(X, accept_sparse=accept_sparse,\n", "                    accept_large_sparse=accept_large_sparse,\n", "                    dtype=dtype, order=order, copy=copy,\n", "                    force_all_finite=force_all_finite,\n", "                    ensure_2d=ensure_2d, allow_nd=allow_nd,\n", "                    ensure_min_samples=ensure_min_samples,\n", "                    ensure_min_features=ensure_min_features,\n", "                    warn_on_dtype=warn_on_dtype,\n", "                    estimator=estimator)\n", "    if multi_output:\n", "        y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n", "                        dtype=None)\n", "    else:\n", "        y = column_or_1d(y, warn=True)\n", "        _assert_all_finite(y)\n", "    if y_numeric and y.dtype.kind == 'O':\n", "        y = y.astype(np.float64)\n", "\n", "    check_consistent_length(X, y)\n", "\n", "    return X, y\n"]}, {"span_id": "check_array", "start_line": 332, "end_line": 578, "content": ["def check_array(array, accept_sparse=False, accept_large_sparse=True,\n", "                dtype=\"numeric\", order=None, copy=False, force_all_finite=True,\n", "                ensure_2d=True, allow_nd=False, ensure_min_samples=1,\n", "                ensure_min_features=1, warn_on_dtype=None, estimator=None):\n", "\n", "    \"\"\"Input validation on an array, list, sparse matrix or similar.\n", "\n", "    By default, the input is checked to be a non-empty 2D array containing\n", "    only finite values. If the dtype of the array is object, attempt\n", "    converting to float, raising on failure.\n", "\n", "    Parameters\n", "    ----------\n", "    array : object\n", "        Input object to check / convert.\n", "\n", "    accept_sparse : string, boolean or list/tuple of strings (default=False)\n", "        String[s] representing allowed sparse matrix formats, such as 'csc',\n", "        'csr', etc. If the input is sparse but not in the allowed format,\n", "        it will be converted to the first listed format. True allows the input\n", "        to be any format. False means that a sparse matrix input will\n", "        raise an error.\n", "\n", "    accept_large_sparse : bool (default=True)\n", "        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n", "        accept_sparse, accept_large_sparse=False will cause it to be accepted\n", "        only if its indices are stored with a 32-bit dtype.\n", "\n", "        .. versionadded:: 0.20\n", "\n", "    dtype : string, type, list of types or None (default=\"numeric\")\n", "        Data type of result. If None, the dtype of the input is preserved.\n", "        If \"numeric\", dtype is preserved unless array.dtype is object.\n", "        If dtype is a list of types, conversion on the first type is only\n", "        performed if the dtype of the input is not in the list.\n", "\n", "    order : 'F', 'C' or None (default=None)\n", "        Whether an array will be forced to be fortran or c-style.\n", "        When order is None (default), then if copy=False, nothing is ensured\n", "        about the memory layout of the output array; otherwise (copy=True)\n", "        the memory layout of the returned array is kept as close as possible\n", "        to the original array.\n", "\n", "    copy : boolean (default=False)\n", "        Whether a forced copy will be triggered. If copy=False, a copy might\n", "        be triggered by a conversion.\n", "\n", "    force_all_finite : boolean or 'allow-nan', (default=True)\n", "        Whether to raise an error on np.inf and np.nan in array. The\n", "        possibilities are:\n", "\n", "        - True: Force all values of array to be finite.\n", "        - False: accept both np.inf and np.nan in array.\n", "        - 'allow-nan': accept only np.nan values in array. Values cannot\n", "          be infinite.\n", "\n", "        For object dtyped data, only np.nan is checked and not np.inf.\n", "\n", "        .. versionadded:: 0.20\n", "           ``force_all_finite`` accepts the string ``'allow-nan'``.\n", "\n", "    ensure_2d : boolean (default=True)\n", "        Whether to raise a value error if array is not 2D.\n", "\n", "    allow_nd : boolean (default=False)\n", "        Whether to allow array.ndim > 2.\n", "\n", "    ensure_min_samples : int (default=1)\n", "        Make sure that the array has a minimum number of samples in its first\n", "        axis (rows for a 2D array). Setting to 0 disables this check.\n", "\n", "    ensure_min_features : int (default=1)\n", "        Make sure that the 2D array has some minimum number of features\n", "        (columns). The default value of 1 rejects empty datasets.\n", "        This check is only enforced when the input data has effectively 2\n", "        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n", "        disables this check.\n", "\n", "    warn_on_dtype : boolean or None, optional (default=None)\n", "        Raise DataConversionWarning if the dtype of the input data structure\n", "        does not match the requested dtype, causing a memory copy.\n", "\n", "        .. deprecated:: 0.21\n", "            ``warn_on_dtype`` is deprecated in version 0.21 and will be\n", "            removed in 0.23.\n", "\n", "    estimator : str or estimator instance (default=None)\n", "        If passed, include the name of the estimator in warning messages.\n", "\n", "    Returns\n", "    -------\n", "    array_converted : object\n", "        The converted and validated array.\n", "    \"\"\"\n", "    # warn_on_dtype deprecation\n", "    if warn_on_dtype is not None:\n", "        warnings.warn(\n", "            \"'warn_on_dtype' is deprecated in version 0.21 and will be \"\n", "            \"removed in 0.23. Don't set `warn_on_dtype` to remove this \"\n", "            \"warning.\",\n", "            DeprecationWarning)\n", "\n", "    # store reference to original array to check if copy is needed when\n", "    # function returns\n", "    array_orig = array\n", "\n", "    # store whether originally we wanted numeric dtype\n", "    dtype_numeric = isinstance(dtype, str) and dtype == \"numeric\"\n", "\n", "    dtype_orig = getattr(array, \"dtype\", None)\n", "    if not hasattr(dtype_orig, 'kind'):\n", "        # not a data type (e.g. a column named dtype in a pandas DataFrame)\n", "        dtype_orig = None\n", "\n", "    # check if the object contains several dtypes (typically a pandas\n", "    # DataFrame), and store them. If not, store None.\n", "    dtypes_orig = None\n", "    if hasattr(array, \"dtypes\") and hasattr(array.dtypes, '__array__'):\n", "        dtypes_orig = np.array(array.dtypes)\n", "\n", "    if dtype_numeric:\n", "        if dtype_orig is not None and dtype_orig.kind == \"O\":\n", "            # if input is object, convert to float.\n", "            dtype = np.float64\n", "        else:\n", "            dtype = None\n", "\n", "    if isinstance(dtype, (list, tuple)):\n", "        if dtype_orig is not None and dtype_orig in dtype:\n", "            # no dtype conversion required\n", "            dtype = None\n", "        else:\n", "            # dtype conversion required. Let's select the first element of the\n", "            # list of accepted types.\n", "            dtype = dtype[0]\n", "\n", "    if force_all_finite not in (True, False, 'allow-nan'):\n", "        raise ValueError('force_all_finite should be a bool or \"allow-nan\"'\n", "                         '. Got {!r} instead'.format(force_all_finite))\n", "\n", "    if estimator is not None:\n", "        if isinstance(estimator, str):\n", "            estimator_name = estimator\n", "        else:\n", "            estimator_name = estimator.__class__.__name__\n", "    else:\n", "        estimator_name = \"Estimator\"\n", "    context = \" by %s\" % estimator_name if estimator is not None else \"\"\n", "\n", "    if sp.issparse(array):\n", "        _ensure_no_complex_data(array)\n", "        array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n", "                                      dtype=dtype, copy=copy,\n", "                                      force_all_finite=force_all_finite,\n", "                                      accept_large_sparse=accept_large_sparse)\n", "    else:\n", "        # If np.array(..) gives ComplexWarning, then we convert the warning\n", "        # to an error. This is needed because specifying a non complex\n", "        # dtype to the function converts complex to real dtype,\n", "        # thereby passing the test made in the lines following the scope\n", "        # of warnings context manager.\n", "        with warnings.catch_warnings():\n", "            try:\n", "                warnings.simplefilter('error', ComplexWarning)\n", "                array = np.asarray(array, dtype=dtype, order=order)\n", "            except ComplexWarning:\n", "                raise ValueError(\"Complex data not supported\\n\"\n", "                                 \"{}\\n\".format(array))\n", "\n", "        # It is possible that the np.array(..) gave no warning. This happens\n", "        # when no dtype conversion happened, for example dtype = None. The\n", "        # result is that np.array(..) produces an array of complex dtype\n", "        # and we need to catch and raise exception for such cases.\n", "        _ensure_no_complex_data(array)\n", "\n", "        if ensure_2d:\n", "            # If input is scalar raise error\n", "            if array.ndim == 0:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array))\n", "            # If input is 1D raise error\n", "            if array.ndim == 1:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array))\n", "\n", "        # in the future np.flexible dtypes will be handled like object dtypes\n", "        if dtype_numeric and np.issubdtype(array.dtype, np.flexible):\n", "            warnings.warn(\n", "                \"Beginning in version 0.22, arrays of bytes/strings will be \"\n", "                \"converted to decimal numbers if dtype='numeric'. \"\n", "                \"It is recommended that you convert the array to \"\n", "                \"a float dtype before using it in scikit-learn, \"\n", "                \"for example by using \"\n", "                \"your_array = your_array.astype(np.float64).\",\n", "                FutureWarning)\n", "\n", "        # make sure we actually converted to numeric:\n", "        if dtype_numeric and array.dtype.kind == \"O\":\n", "            array = array.astype(np.float64)\n", "        if not allow_nd and array.ndim >= 3:\n", "            raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n", "                             % (array.ndim, estimator_name))\n", "        if force_all_finite:\n", "            _assert_all_finite(array,\n", "                               allow_nan=force_all_finite == 'allow-nan')\n", "\n", "    if ensure_min_samples > 0:\n", "        n_samples = _num_samples(array)\n", "        if n_samples < ensure_min_samples:\n", "            raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n", "                             \" minimum of %d is required%s.\"\n", "                             % (n_samples, array.shape, ensure_min_samples,\n", "                                context))\n", "\n", "    if ensure_min_features > 0 and array.ndim == 2:\n", "        n_features = array.shape[1]\n", "        if n_features < ensure_min_features:\n", "            raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n", "                             \" a minimum of %d is required%s.\"\n", "                             % (n_features, array.shape, ensure_min_features,\n", "                                context))\n", "\n", "    if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n", "        msg = (\"Data with input dtype %s was converted to %s%s.\"\n", "               % (dtype_orig, array.dtype, context))\n", "        warnings.warn(msg, DataConversionWarning)\n", "\n", "    if copy and np.may_share_memory(array, array_orig):\n", "        array = np.array(array, dtype=dtype, order=order)\n", "\n", "    if (warn_on_dtype and dtypes_orig is not None and\n", "            {array.dtype} != set(dtypes_orig)):\n", "        # if there was at the beginning some other types than the final one\n", "        # (for instance in a DataFrame that can contain several dtypes) then\n", "        # some data must have been converted\n", "        msg = (\"Data with input dtype %s were all converted to %s%s.\"\n", "               % (', '.join(map(str, sorted(set(dtypes_orig)))), array.dtype,\n", "                  context))\n", "        warnings.warn(msg, DataConversionWarning, stacklevel=3)\n", "\n", "    return array\n"]}]}]}