{"instance_id": "django__django-12908", "identified_spans": [{"file_path": "django/db/models/query.py", "span_ids": ["QuerySet._combinator_query", "QuerySet.distinct", "QuerySet.union", "QuerySet"], "content": [{"span_id": "QuerySet._combinator_query", "start_line": 988, "end_line": 997, "content": ["    def _combinator_query(self, combinator, *other_qs, all=False):\n", "        # Clone the query to inherit the select list and everything\n", "        clone = self._chain()\n", "        # Clear limits and ordering so they can be reapplied\n", "        clone.query.clear_ordering(True)\n", "        clone.query.clear_limits()\n", "        clone.query.combined_queries = (self.query,) + tuple(qs.query for qs in other_qs)\n", "        clone.query.combinator = combinator\n", "        clone.query.combinator_all = all\n", "        return clone\n"]}, {"span_id": "QuerySet.distinct", "start_line": 1137, "end_line": 1145, "content": ["    def distinct(self, *field_names):\n", "        \"\"\"\n", "        Return a new QuerySet instance that will select only distinct results.\n", "        \"\"\"\n", "        assert not self.query.is_sliced, \\\n", "            \"Cannot create distinct fields once a slice has been taken.\"\n", "        obj = self._chain()\n", "        obj.query.add_distinct_fields(*field_names)\n", "        return obj\n"]}, {"span_id": "QuerySet.union", "start_line": 999, "end_line": 1004, "content": ["    def union(self, *other_qs, all=False):\n", "        # If the query is an EmptyQuerySet, combine all nonempty querysets.\n", "        if isinstance(self, EmptyQuerySet):\n", "            qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]\n", "            return qs[0]._combinator_query('union', *qs[1:], all=all) if qs else self\n", "        return self._combinator_query('union', *other_qs, all=all)\n"]}, {"span_id": "QuerySet", "start_line": 184, "end_line": 185, "content": ["class QuerySet:\n", "    \"\"\"Represent a lazy database lookup for a set of objects.\"\"\"\n"]}]}, {"file_path": "django/db/models/sql/compiler.py", "span_ids": ["SQLCompiler.get_distinct", "SQLCompiler.get_combinator_sql", "SQLCompiler"], "content": [{"span_id": "SQLCompiler.get_distinct", "start_line": 680, "end_line": 702, "content": ["    def get_distinct(self):\n", "        \"\"\"\n", "        Return a quoted list of fields to use in DISTINCT ON part of the query.\n", "\n", "        This method can alter the tables in the query, and thus it must be\n", "        called before get_from_clause().\n", "        \"\"\"\n", "        result = []\n", "        params = []\n", "        opts = self.query.get_meta()\n", "\n", "        for name in self.query.distinct_fields:\n", "            parts = name.split(LOOKUP_SEP)\n", "            _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n", "            targets, alias, _ = self.query.trim_joins(targets, joins, path)\n", "            for target in targets:\n", "                if name in self.query.annotation_select:\n", "                    result.append(name)\n", "                else:\n", "                    r, p = self.compile(transform_function(target, alias))\n", "                    result.append(r)\n", "                    params.append(p)\n", "        return result, params\n"]}, {"span_id": "SQLCompiler.get_combinator_sql", "start_line": 429, "end_line": 482, "content": ["    def get_combinator_sql(self, combinator, all):\n", "        features = self.connection.features\n", "        compilers = [\n", "            query.get_compiler(self.using, self.connection)\n", "            for query in self.query.combined_queries if not query.is_empty()\n", "        ]\n", "        if not features.supports_slicing_ordering_in_compound:\n", "            for query, compiler in zip(self.query.combined_queries, compilers):\n", "                if query.low_mark or query.high_mark:\n", "                    raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n", "                if compiler.get_order_by():\n", "                    raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n", "        parts = ()\n", "        for compiler in compilers:\n", "            try:\n", "                # If the columns list is limited, then all combined queries\n", "                # must have the same columns list. Set the selects defined on\n", "                # the query on all combined queries, if not already set.\n", "                if not compiler.query.values_select and self.query.values_select:\n", "                    compiler.query = compiler.query.clone()\n", "                    compiler.query.set_values((\n", "                        *self.query.extra_select,\n", "                        *self.query.values_select,\n", "                        *self.query.annotation_select,\n", "                    ))\n", "                part_sql, part_args = compiler.as_sql()\n", "                if compiler.query.combinator:\n", "                    # Wrap in a subquery if wrapping in parentheses isn't\n", "                    # supported.\n", "                    if not features.supports_parentheses_in_compound:\n", "                        part_sql = 'SELECT * FROM ({})'.format(part_sql)\n", "                    # Add parentheses when combining with compound query if not\n", "                    # already added for all compound queries.\n", "                    elif not features.supports_slicing_ordering_in_compound:\n", "                        part_sql = '({})'.format(part_sql)\n", "                parts += ((part_sql, part_args),)\n", "            except EmptyResultSet:\n", "                # Omit the empty queryset with UNION and with DIFFERENCE if the\n", "                # first queryset is nonempty.\n", "                if combinator == 'union' or (combinator == 'difference' and parts):\n", "                    continue\n", "                raise\n", "        if not parts:\n", "            raise EmptyResultSet\n", "        combinator_sql = self.connection.ops.set_operators[combinator]\n", "        if all and combinator == 'union':\n", "            combinator_sql += ' ALL'\n", "        braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n", "        sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n", "        result = [' {} '.format(combinator_sql).join(sql_parts)]\n", "        params = []\n", "        for part in args_parts:\n", "            params.extend(part)\n", "        return result, params\n"]}, {"span_id": "SQLCompiler", "start_line": 22, "end_line": 27, "content": ["class SQLCompiler:\n", "    # Multiline ordering SQL clause may appear from RawSQL.\n", "    ordering_parts = _lazy_re_compile(\n", "        r'^(.*)\\s(?:ASC|DESC).*',\n", "        re.MULTILINE | re.DOTALL,\n", "    )\n"]}]}, {"file_path": "django/db/models/sql/query.py", "span_ids": ["Query.add_distinct_fields", "Query.combine", "Query.__init__"], "content": [{"span_id": "Query.add_distinct_fields", "start_line": 1840, "end_line": 1845, "content": ["    def add_distinct_fields(self, *field_names):\n", "        \"\"\"\n", "        Add and resolve the given fields to the query's \"distinct on\" clause.\n", "        \"\"\"\n", "        self.distinct_fields = field_names\n", "        self.distinct = True\n"]}, {"span_id": "Query.combine", "start_line": 545, "end_line": 644, "content": ["    def combine(self, rhs, connector):\n", "        \"\"\"\n", "        Merge the 'rhs' query into the current one (with any 'rhs' effects\n", "        being applied *after* (that is, \"to the right of\") anything in the\n", "        current query. 'rhs' is not modified during a call to this function.\n", "\n", "        The 'connector' parameter describes how to connect filters from the\n", "        'rhs' query.\n", "        \"\"\"\n", "        assert self.model == rhs.model, \\\n", "            \"Cannot combine queries on two different base models.\"\n", "        assert not self.is_sliced, \\\n", "            \"Cannot combine queries once a slice has been taken.\"\n", "        assert self.distinct == rhs.distinct, \\\n", "            \"Cannot combine a unique query with a non-unique query.\"\n", "        assert self.distinct_fields == rhs.distinct_fields, \\\n", "            \"Cannot combine queries with different distinct fields.\"\n", "\n", "        # Work out how to relabel the rhs aliases, if necessary.\n", "        change_map = {}\n", "        conjunction = (connector == AND)\n", "\n", "        # Determine which existing joins can be reused. When combining the\n", "        # query with AND we must recreate all joins for m2m filters. When\n", "        # combining with OR we can reuse joins. The reason is that in AND\n", "        # case a single row can't fulfill a condition like:\n", "        #     revrel__col=1 & revrel__col=2\n", "        # But, there might be two different related rows matching this\n", "        # condition. In OR case a single True is enough, so single row is\n", "        # enough, too.\n", "        #\n", "        # Note that we will be creating duplicate joins for non-m2m joins in\n", "        # the AND case. The results will be correct but this creates too many\n", "        # joins. This is something that could be fixed later on.\n", "        reuse = set() if conjunction else set(self.alias_map)\n", "        # Base table must be present in the query - this is the same\n", "        # table on both sides.\n", "        self.get_initial_alias()\n", "        joinpromoter = JoinPromoter(connector, 2, False)\n", "        joinpromoter.add_votes(\n", "            j for j in self.alias_map if self.alias_map[j].join_type == INNER)\n", "        rhs_votes = set()\n", "        # Now, add the joins from rhs query into the new query (skipping base\n", "        # table).\n", "        rhs_tables = list(rhs.alias_map)[1:]\n", "        for alias in rhs_tables:\n", "            join = rhs.alias_map[alias]\n", "            # If the left side of the join was already relabeled, use the\n", "            # updated alias.\n", "            join = join.relabeled_clone(change_map)\n", "            new_alias = self.join(join, reuse=reuse)\n", "            if join.join_type == INNER:\n", "                rhs_votes.add(new_alias)\n", "            # We can't reuse the same join again in the query. If we have two\n", "            # distinct joins for the same connection in rhs query, then the\n", "            # combined query must have two joins, too.\n", "            reuse.discard(new_alias)\n", "            if alias != new_alias:\n", "                change_map[alias] = new_alias\n", "            if not rhs.alias_refcount[alias]:\n", "                # The alias was unused in the rhs query. Unref it so that it\n", "                # will be unused in the new query, too. We have to add and\n", "                # unref the alias so that join promotion has information of\n", "                # the join type for the unused alias.\n", "                self.unref_alias(new_alias)\n", "        joinpromoter.add_votes(rhs_votes)\n", "        joinpromoter.update_join_types(self)\n", "\n", "        # Now relabel a copy of the rhs where-clause and add it to the current\n", "        # one.\n", "        w = rhs.where.clone()\n", "        w.relabel_aliases(change_map)\n", "        self.where.add(w, connector)\n", "\n", "        # Selection columns and extra extensions are those provided by 'rhs'.\n", "        if rhs.select:\n", "            self.set_select([col.relabeled_clone(change_map) for col in rhs.select])\n", "        else:\n", "            self.select = ()\n", "\n", "        if connector == OR:\n", "            # It would be nice to be able to handle this, but the queries don't\n", "            # really make sense (or return consistent value sets). Not worth\n", "            # the extra complexity when you can write a real query instead.\n", "            if self.extra and rhs.extra:\n", "                raise ValueError(\"When merging querysets using 'or', you cannot have extra(select=...) on both sides.\")\n", "        self.extra.update(rhs.extra)\n", "        extra_select_mask = set()\n", "        if self.extra_select_mask is not None:\n", "            extra_select_mask.update(self.extra_select_mask)\n", "        if rhs.extra_select_mask is not None:\n", "            extra_select_mask.update(rhs.extra_select_mask)\n", "        if extra_select_mask:\n", "            self.set_extra_mask(extra_select_mask)\n", "        self.extra_tables += rhs.extra_tables\n", "\n", "        # Ordering uses the 'rhs' ordering, unless it has none, in which case\n", "        # the current ordering is used.\n", "        self.order_by = rhs.order_by or self.order_by\n", "        self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n"]}, {"span_id": "Query.__init__", "start_line": 144, "end_line": 229, "content": ["    def __init__(self, model, where=WhereNode, alias_cols=True):\n", "        self.model = model\n", "        self.alias_refcount = {}\n", "        # alias_map is the most important data structure regarding joins.\n", "        # It's used for recording which joins exist in the query and what\n", "        # types they are. The key is the alias of the joined table (possibly\n", "        # the table name) and the value is a Join-like object (see\n", "        # sql.datastructures.Join for more information).\n", "        self.alias_map = {}\n", "        # Whether to provide alias to columns during reference resolving.\n", "        self.alias_cols = alias_cols\n", "        # Sometimes the query contains references to aliases in outer queries (as\n", "        # a result of split_exclude). Correct alias quoting needs to know these\n", "        # aliases too.\n", "        # Map external tables to whether they are aliased.\n", "        self.external_aliases = {}\n", "        self.table_map = {}     # Maps table names to list of aliases.\n", "        self.default_cols = True\n", "        self.default_ordering = True\n", "        self.standard_ordering = True\n", "        self.used_aliases = set()\n", "        self.filter_is_sticky = False\n", "        self.subquery = False\n", "\n", "        # SQL-related attributes\n", "        # Select and related select clauses are expressions to use in the\n", "        # SELECT clause of the query.\n", "        # The select is used for cases where we want to set up the select\n", "        # clause to contain other than default fields (values(), subqueries...)\n", "        # Note that annotations go to annotations dictionary.\n", "        self.select = ()\n", "        self.where = where()\n", "        self.where_class = where\n", "        # The group_by attribute can have one of the following forms:\n", "        #  - None: no group by at all in the query\n", "        #  - A tuple of expressions: group by (at least) those expressions.\n", "        #    String refs are also allowed for now.\n", "        #  - True: group by all select fields of the model\n", "        # See compiler.get_group_by() for details.\n", "        self.group_by = None\n", "        self.order_by = ()\n", "        self.low_mark, self.high_mark = 0, None  # Used for offset/limit\n", "        self.distinct = False\n", "        self.distinct_fields = ()\n", "        self.select_for_update = False\n", "        self.select_for_update_nowait = False\n", "        self.select_for_update_skip_locked = False\n", "        self.select_for_update_of = ()\n", "\n", "        self.select_related = False\n", "        # Arbitrary limit for select_related to prevents infinite recursion.\n", "        self.max_depth = 5\n", "\n", "        # Holds the selects defined by a call to values() or values_list()\n", "        # excluding annotation_select and extra_select.\n", "        self.values_select = ()\n", "\n", "        # SQL annotation-related attributes\n", "        self.annotations = {}  # Maps alias -> Annotation Expression\n", "        self.annotation_select_mask = None\n", "        self._annotation_select_cache = None\n", "\n", "        # Set combination attributes\n", "        self.combinator = None\n", "        self.combinator_all = False\n", "        self.combined_queries = ()\n", "\n", "        # These are for extensions. The contents are more or less appended\n", "        # verbatim to the appropriate clause.\n", "        self.extra = {}  # Maps col_alias -> (col_sql, params).\n", "        self.extra_select_mask = None\n", "        self._extra_select_cache = None\n", "\n", "        self.extra_tables = ()\n", "        self.extra_order_by = ()\n", "\n", "        # A tuple that is a set of model field names and either True, if these\n", "        # are the fields to defer, or False if these are the only fields to\n", "        # load.\n", "        self.deferred_loading = (frozenset(), True)\n", "\n", "        self._filtered_relations = {}\n", "\n", "        self.explain_query = False\n", "        self.explain_format = None\n", "        self.explain_options = {}\n"]}]}]}