{"instance_id": "psf__requests-2674", "identified_spans": [{"file_path": "requests/adapters.py", "span_ids": ["HTTPAdapter", "docstring", "HTTPAdapter.build_response"], "content": [{"span_id": "HTTPAdapter", "start_line": 54, "end_line": 81, "content": ["class HTTPAdapter(BaseAdapter):\n", "    \"\"\"The built-in HTTP Adapter for urllib3.\n", "\n", "    Provides a general-case interface for Requests sessions to contact HTTP and\n", "    HTTPS urls by implementing the Transport Adapter interface. This class will\n", "    usually be created by the :class:`Session <Session>` class under the\n", "    covers.\n", "\n", "    :param pool_connections: The number of urllib3 connection pools to cache.\n", "    :param pool_maxsize: The maximum number of connections to save in the pool.\n", "    :param int max_retries: The maximum number of retries each connection\n", "        should attempt. Note, this applies only to failed DNS lookups, socket\n", "        connections and connection timeouts, never to requests where data has\n", "        made it to the server. By default, Requests does not retry failed\n", "        connections. If you need granular control over the conditions under\n", "        which we retry a request, import urllib3's ``Retry`` class and pass\n", "        that instead.\n", "    :param pool_block: Whether the connection pool should block for connections.\n", "\n", "    Usage::\n", "\n", "      >>> import requests\n", "      >>> s = requests.Session()\n", "      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n", "      >>> s.mount('http://', a)\n", "    \"\"\"\n", "    __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n", "                 '_pool_block']\n"]}, {"span_id": "docstring", "start_line": 1, "end_line": 38, "content": ["# -*- coding: utf-8 -*-\n", "\n", "\"\"\"\n", "requests.adapters\n", "~~~~~~~~~~~~~~~~~\n", "\n", "This module contains the transport adapters that Requests uses to define\n", "and maintain connections.\n", "\"\"\"\n", "\n", "import socket\n", "\n", "from .models import Response\n", "from .packages.urllib3.poolmanager import PoolManager, proxy_from_url\n", "from .packages.urllib3.response import HTTPResponse\n", "from .packages.urllib3.util import Timeout as TimeoutSauce\n", "from .packages.urllib3.util.retry import Retry\n", "from .compat import urlparse, basestring\n", "from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n", "                    prepend_scheme_if_needed, get_auth_from_url, urldefragauth)\n", "from .structures import CaseInsensitiveDict\n", "from .packages.urllib3.exceptions import ConnectTimeoutError\n", "from .packages.urllib3.exceptions import HTTPError as _HTTPError\n", "from .packages.urllib3.exceptions import MaxRetryError\n", "from .packages.urllib3.exceptions import ProxyError as _ProxyError\n", "from .packages.urllib3.exceptions import ProtocolError\n", "from .packages.urllib3.exceptions import ReadTimeoutError\n", "from .packages.urllib3.exceptions import SSLError as _SSLError\n", "from .packages.urllib3.exceptions import ResponseError\n", "from .cookies import extract_cookies_to_jar\n", "from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n", "                         ProxyError, RetryError)\n", "from .auth import _basic_auth_str\n", "\n", "DEFAULT_POOLBLOCK = False\n", "DEFAULT_POOLSIZE = 10\n", "DEFAULT_RETRIES = 0\n", "DEFAULT_POOL_TIMEOUT = None\n"]}, {"span_id": "HTTPAdapter.build_response", "start_line": 197, "end_line": 231, "content": ["    def build_response(self, req, resp):\n", "        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n", "        response. This should not be called from user code, and is only exposed\n", "        for use when subclassing the\n", "        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n", "\n", "        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n", "        :param resp: The urllib3 response object.\n", "        \"\"\"\n", "        response = Response()\n", "\n", "        # Fallback to None if there's no status_code, for whatever reason.\n", "        response.status_code = getattr(resp, 'status', None)\n", "\n", "        # Make headers case-insensitive.\n", "        response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n", "\n", "        # Set encoding.\n", "        response.encoding = get_encoding_from_headers(response.headers)\n", "        response.raw = resp\n", "        response.reason = response.raw.reason\n", "\n", "        if isinstance(req.url, bytes):\n", "            response.url = req.url.decode('utf-8')\n", "        else:\n", "            response.url = req.url\n", "\n", "        # Add new cookies from the server.\n", "        extract_cookies_to_jar(response.cookies, req, resp)\n", "\n", "        # Give the Response some context.\n", "        response.request = req\n", "        response.connection = self\n", "\n", "        return response\n"]}]}, {"file_path": "requests/packages/urllib3/connectionpool.py", "span_ids": ["HTTPConnectionPool._raise_timeout", "HTTPConnectionPool"], "content": [{"span_id": "HTTPConnectionPool._raise_timeout", "start_line": 300, "end_line": 315, "content": ["    def _raise_timeout(self, err, url, timeout_value):\n", "        \"\"\"Is the error actually a timeout? Will raise a ReadTimeout or pass\"\"\"\n", "\n", "        if isinstance(err, SocketTimeout):\n", "            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n", "\n", "        # See the above comment about EAGAIN in Python 3. In Python 2 we have\n", "        # to specifically catch it and throw the timeout error\n", "        if hasattr(err, 'errno') and err.errno in _blocking_errnos:\n", "            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n", "\n", "        # Catch possible read timeouts thrown as SSL errors. If not the\n", "        # case, rethrow the original. We need to do this because of:\n", "        # http://bugs.python.org/issue10272\n", "        if 'timed out' in str(err) or 'did not complete (read)' in str(err):  # Python 2.6\n", "            raise ReadTimeoutError(self, url, \"Read timed out. (read timeout=%s)\" % timeout_value)\n"]}, {"span_id": "HTTPConnectionPool", "start_line": 94, "end_line": 155, "content": ["class HTTPConnectionPool(ConnectionPool, RequestMethods):\n", "    \"\"\"\n", "    Thread-safe connection pool for one host.\n", "\n", "    :param host:\n", "        Host used for this HTTP Connection (e.g. \"localhost\"), passed into\n", "        :class:`httplib.HTTPConnection`.\n", "\n", "    :param port:\n", "        Port used for this HTTP Connection (None is equivalent to 80), passed\n", "        into :class:`httplib.HTTPConnection`.\n", "\n", "    :param strict:\n", "        Causes BadStatusLine to be raised if the status line can't be parsed\n", "        as a valid HTTP/1.0 or 1.1 status line, passed into\n", "        :class:`httplib.HTTPConnection`.\n", "\n", "        .. note::\n", "           Only works in Python 2. This parameter is ignored in Python 3.\n", "\n", "    :param timeout:\n", "        Socket timeout in seconds for each individual connection. This can\n", "        be a float or integer, which sets the timeout for the HTTP request,\n", "        or an instance of :class:`urllib3.util.Timeout` which gives you more\n", "        fine-grained control over request timeouts. After the constructor has\n", "        been parsed, this is always a `urllib3.util.Timeout` object.\n", "\n", "    :param maxsize:\n", "        Number of connections to save that can be reused. More than 1 is useful\n", "        in multithreaded situations. If ``block`` is set to false, more\n", "        connections will be created but they will not be saved once they've\n", "        been used.\n", "\n", "    :param block:\n", "        If set to True, no more than ``maxsize`` connections will be used at\n", "        a time. When no free connections are available, the call will block\n", "        until a connection has been released. This is a useful side effect for\n", "        particular multithreaded situations where one does not want to use more\n", "        than maxsize connections per host to prevent flooding.\n", "\n", "    :param headers:\n", "        Headers to include with all requests, unless other headers are given\n", "        explicitly.\n", "\n", "    :param retries:\n", "        Retry configuration to use by default with requests in this pool.\n", "\n", "    :param _proxy:\n", "        Parsed proxy URL, should not be used directly, instead, see\n", "        :class:`urllib3.connectionpool.ProxyManager`\"\n", "\n", "    :param _proxy_headers:\n", "        A dictionary with proxy headers, should not be used directly,\n", "        instead, see :class:`urllib3.connectionpool.ProxyManager`\"\n", "\n", "    :param \\**conn_kw:\n", "        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,\n", "        :class:`urllib3.connection.HTTPSConnection` instances.\n", "    \"\"\"\n", "\n", "    scheme = 'http'\n", "    ConnectionCls = HTTPConnection\n"]}]}, {"file_path": "requests/packages/urllib3/exceptions.py", "span_ids": ["TimeoutError", "ConnectTimeoutError", "DecodeError", "ReadTimeoutError"], "content": [{"span_id": "TimeoutError", "start_line": 95, "end_line": 101, "content": ["class TimeoutError(HTTPError):\n", "    \"\"\" Raised when a socket timeout error occurs.\n", "\n", "    Catching this error will catch both :exc:`ReadTimeoutErrors\n", "    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.\n", "    \"\"\"\n", "    pass\n"]}, {"span_id": "ConnectTimeoutError", "start_line": 111, "end_line": 113, "content": ["class ConnectTimeoutError(TimeoutError):\n", "    \"Raised when a socket timeout occurs while connecting to a server\"\n", "    pass\n"]}, {"span_id": "DecodeError", "start_line": 46, "end_line": 48, "content": ["class DecodeError(HTTPError):\n", "    \"Raised when automatic decoding based on Content-Type fails.\"\n", "    pass\n"]}, {"span_id": "ReadTimeoutError", "start_line": 104, "end_line": 106, "content": ["class ReadTimeoutError(TimeoutError, RequestError):\n", "    \"Raised when a socket timeout occurs while receiving data from a server\"\n", "    pass\n"]}]}, {"file_path": "requests/packages/urllib3/response.py", "span_ids": ["HTTPResponse._decode", "HTTPResponse._init_decoder", "HTTPResponse"], "content": [{"span_id": "HTTPResponse._decode", "start_line": 186, "end_line": 203, "content": ["    def _decode(self, data, decode_content, flush_decoder):\n", "        \"\"\"\n", "        Decode the data passed in and potentially flush the decoder.\n", "        \"\"\"\n", "        try:\n", "            if decode_content and self._decoder:\n", "                data = self._decoder.decompress(data)\n", "        except (IOError, zlib.error) as e:\n", "            content_encoding = self.headers.get('content-encoding', '').lower()\n", "            raise DecodeError(\n", "                \"Received response with content-encoding: %s, but \"\n", "                \"failed to decode it.\" % content_encoding, e)\n", "\n", "        if flush_decoder and decode_content and self._decoder:\n", "            buf = self._decoder.decompress(binary_type())\n", "            data += buf + self._decoder.flush()\n", "\n", "        return data\n"]}, {"span_id": "HTTPResponse._init_decoder", "start_line": 176, "end_line": 184, "content": ["    def _init_decoder(self):\n", "        \"\"\"\n", "        Set-up the _decoder attribute if necessar.\n", "        \"\"\"\n", "        # Note: content-encoding value should be case-insensitive, per RFC 7230\n", "        # Section 3.2\n", "        content_encoding = self.headers.get('content-encoding', '').lower()\n", "        if self._decoder is None and content_encoding in self.CONTENT_DECODERS:\n", "            self._decoder = _get_decoder(content_encoding)\n"]}, {"span_id": "HTTPResponse", "start_line": 68, "end_line": 95, "content": ["class HTTPResponse(io.IOBase):\n", "    \"\"\"\n", "    HTTP Response container.\n", "\n", "    Backwards-compatible to httplib's HTTPResponse but the response ``body`` is\n", "    loaded and decoded on-demand when the ``data`` property is accessed.  This\n", "    class is also compatible with the Python standard library's :mod:`io`\n", "    module, and can hence be treated as a readable object in the context of that\n", "    framework.\n", "\n", "    Extra parameters for behaviour not present in httplib.HTTPResponse:\n", "\n", "    :param preload_content:\n", "        If True, the response's body will be preloaded during construction.\n", "\n", "    :param decode_content:\n", "        If True, attempts to decode specific content-encoding's based on headers\n", "        (like 'gzip' and 'deflate') will be skipped and raw data will be used\n", "        instead.\n", "\n", "    :param original_response:\n", "        When this HTTPResponse wrapper is generated from an httplib.HTTPResponse\n", "        object, it's convenient to include the original for debug purposes. It's\n", "        otherwise unused.\n", "    \"\"\"\n", "\n", "    CONTENT_DECODERS = ['gzip', 'deflate']\n", "    REDIRECT_STATUSES = [301, 302, 303, 307, 308]\n"]}]}]}