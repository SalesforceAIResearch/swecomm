{"instance_id": "scikit-learn__scikit-learn-25638", "identified_spans": [{"file_path": "sklearn/utils/multiclass.py", "span_ids": ["_unique_multiclass", "unique_labels", "type_of_target"], "content": [{"span_id": "_unique_multiclass", "start_line": 23, "end_line": 28, "content": ["def _unique_multiclass(y):\n", "    xp, is_array_api = get_namespace(y)\n", "    if hasattr(y, \"__array__\") or is_array_api:\n", "        return xp.unique_values(xp.asarray(y))\n", "    else:\n", "        return set(y)\n"]}, {"span_id": "unique_labels", "start_line": 44, "end_line": 119, "content": ["def unique_labels(*ys):\n", "    \"\"\"Extract an ordered array of unique labels.\n", "\n", "    We don't allow:\n", "        - mix of multilabel and multiclass (single label) targets\n", "        - mix of label indicator matrix and anything else,\n", "          because there are no explicit labels)\n", "        - mix of label indicator matrices of different sizes\n", "        - mix of string and integer labels\n", "\n", "    At the moment, we also don't allow \"multiclass-multioutput\" input type.\n", "\n", "    Parameters\n", "    ----------\n", "    *ys : array-likes\n", "        Label values.\n", "\n", "    Returns\n", "    -------\n", "    out : ndarray of shape (n_unique_labels,)\n", "        An ordered array of unique labels.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn.utils.multiclass import unique_labels\n", "    >>> unique_labels([3, 5, 5, 5, 7, 7])\n", "    array([3, 5, 7])\n", "    >>> unique_labels([1, 2, 3, 4], [2, 2, 3, 4])\n", "    array([1, 2, 3, 4])\n", "    >>> unique_labels([1, 2, 10], [5, 11])\n", "    array([ 1,  2,  5, 10, 11])\n", "    \"\"\"\n", "    xp, is_array_api = get_namespace(*ys)\n", "    if not ys:\n", "        raise ValueError(\"No argument has been passed.\")\n", "    # Check that we don't mix label format\n", "\n", "    ys_types = set(type_of_target(x) for x in ys)\n", "    if ys_types == {\"binary\", \"multiclass\"}:\n", "        ys_types = {\"multiclass\"}\n", "\n", "    if len(ys_types) > 1:\n", "        raise ValueError(\"Mix type of y not allowed, got types %s\" % ys_types)\n", "\n", "    label_type = ys_types.pop()\n", "\n", "    # Check consistency for the indicator format\n", "    if (\n", "        label_type == \"multilabel-indicator\"\n", "        and len(\n", "            set(\n", "                check_array(y, accept_sparse=[\"csr\", \"csc\", \"coo\"]).shape[1] for y in ys\n", "            )\n", "        )\n", "        > 1\n", "    ):\n", "        raise ValueError(\n", "            \"Multi-label binary indicator input with different numbers of labels\"\n", "        )\n", "\n", "    # Get the unique set of labels\n", "    _unique_labels = _FN_UNIQUE_LABELS.get(label_type, None)\n", "    if not _unique_labels:\n", "        raise ValueError(\"Unknown label type: %s\" % repr(ys))\n", "\n", "    if is_array_api:\n", "        # array_api does not allow for mixed dtypes\n", "        unique_ys = xp.concat([_unique_labels(y) for y in ys])\n", "        return xp.unique_values(unique_ys)\n", "\n", "    ys_labels = set(chain.from_iterable((i for i in _unique_labels(y)) for y in ys))\n", "    # Check that we don't mix string type with number type\n", "    if len(set(isinstance(label, str) for label in ys_labels)) > 1:\n", "        raise ValueError(\"Mix of label input types (string and number)\")\n", "\n", "    return xp.asarray(sorted(ys_labels))\n"]}, {"span_id": "type_of_target", "start_line": 210, "end_line": 367, "content": ["def type_of_target(y, input_name=\"\"):\n", "    \"\"\"Determine the type of data indicated by the target.\n", "\n", "    Note that this type is the most specific type that can be inferred.\n", "    For example:\n", "\n", "        * ``binary`` is more specific but compatible with ``multiclass``.\n", "        * ``multiclass`` of integers is more specific but compatible with\n", "          ``continuous``.\n", "        * ``multilabel-indicator`` is more specific but compatible with\n", "          ``multiclass-multioutput``.\n", "\n", "    Parameters\n", "    ----------\n", "    y : {array-like, sparse matrix}\n", "        Target values. If a sparse matrix, `y` is expected to be a\n", "        CSR/CSC matrix.\n", "\n", "    input_name : str, default=\"\"\n", "        The data name used to construct the error message.\n", "\n", "        .. versionadded:: 1.1.0\n", "\n", "    Returns\n", "    -------\n", "    target_type : str\n", "        One of:\n", "\n", "        * 'continuous': `y` is an array-like of floats that are not all\n", "          integers, and is 1d or a column vector.\n", "        * 'continuous-multioutput': `y` is a 2d array of floats that are\n", "          not all integers, and both dimensions are of size > 1.\n", "        * 'binary': `y` contains <= 2 discrete values and is 1d or a column\n", "          vector.\n", "        * 'multiclass': `y` contains more than two discrete values, is not a\n", "          sequence of sequences, and is 1d or a column vector.\n", "        * 'multiclass-multioutput': `y` is a 2d array that contains more\n", "          than two discrete values, is not a sequence of sequences, and both\n", "          dimensions are of size > 1.\n", "        * 'multilabel-indicator': `y` is a label indicator matrix, an array\n", "          of two dimensions with at least two columns, and at most 2 unique\n", "          values.\n", "        * 'unknown': `y` is array-like but none of the above, such as a 3d\n", "          array, sequence of sequences, or an array of non-sequence objects.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn.utils.multiclass import type_of_target\n", "    >>> import numpy as np\n", "    >>> type_of_target([0.1, 0.6])\n", "    'continuous'\n", "    >>> type_of_target([1, -1, -1, 1])\n", "    'binary'\n", "    >>> type_of_target(['a', 'b', 'a'])\n", "    'binary'\n", "    >>> type_of_target([1.0, 2.0])\n", "    'binary'\n", "    >>> type_of_target([1, 0, 2])\n", "    'multiclass'\n", "    >>> type_of_target([1.0, 0.0, 3.0])\n", "    'multiclass'\n", "    >>> type_of_target(['a', 'b', 'c'])\n", "    'multiclass'\n", "    >>> type_of_target(np.array([[1, 2], [3, 1]]))\n", "    'multiclass-multioutput'\n", "    >>> type_of_target([[1, 2]])\n", "    'multilabel-indicator'\n", "    >>> type_of_target(np.array([[1.5, 2.0], [3.0, 1.6]]))\n", "    'continuous-multioutput'\n", "    >>> type_of_target(np.array([[0, 1], [1, 1]]))\n", "    'multilabel-indicator'\n", "    \"\"\"\n", "    xp, is_array_api = get_namespace(y)\n", "    valid = (\n", "        (isinstance(y, Sequence) or issparse(y) or hasattr(y, \"__array__\"))\n", "        and not isinstance(y, str)\n", "        or is_array_api\n", "    )\n", "\n", "    if not valid:\n", "        raise ValueError(\n", "            \"Expected array-like (array or non-string sequence), got %r\" % y\n", "        )\n", "\n", "    sparse_pandas = y.__class__.__name__ in [\"SparseSeries\", \"SparseArray\"]\n", "    if sparse_pandas:\n", "        raise ValueError(\"y cannot be class 'SparseSeries' or 'SparseArray'\")\n", "\n", "    if is_multilabel(y):\n", "        return \"multilabel-indicator\"\n", "\n", "    # DeprecationWarning will be replaced by ValueError, see NEP 34\n", "    # https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\n", "    # We therefore catch both deprecation (NumPy < 1.24) warning and\n", "    # value error (NumPy >= 1.24).\n", "    with warnings.catch_warnings():\n", "        warnings.simplefilter(\"error\", np.VisibleDeprecationWarning)\n", "        if not issparse(y):\n", "            try:\n", "                y = xp.asarray(y)\n", "            except (np.VisibleDeprecationWarning, ValueError):\n", "                # dtype=object should be provided explicitly for ragged arrays,\n", "                # see NEP 34\n", "                y = xp.asarray(y, dtype=object)\n", "\n", "    # The old sequence of sequences format\n", "    try:\n", "        if (\n", "            not hasattr(y[0], \"__array__\")\n", "            and isinstance(y[0], Sequence)\n", "            and not isinstance(y[0], str)\n", "        ):\n", "            raise ValueError(\n", "                \"You appear to be using a legacy multi-label data\"\n", "                \" representation. Sequence of sequences are no\"\n", "                \" longer supported; use a binary array or sparse\"\n", "                \" matrix instead - the MultiLabelBinarizer\"\n", "                \" transformer can convert to this format.\"\n", "            )\n", "    except IndexError:\n", "        pass\n", "\n", "    # Invalid inputs\n", "    if y.ndim not in (1, 2):\n", "        # Number of dimension greater than 2: [[[1, 2]]]\n", "        return \"unknown\"\n", "    if not min(y.shape):\n", "        # Empty ndarray: []/[[]]\n", "        if y.ndim == 1:\n", "            # 1-D empty array: []\n", "            return \"binary\"  # []\n", "        # 2-D empty array: [[]]\n", "        return \"unknown\"\n", "    if not issparse(y) and y.dtype == object and not isinstance(y.flat[0], str):\n", "        # [obj_1] and not [\"label_1\"]\n", "        return \"unknown\"\n", "\n", "    # Check if multioutput\n", "    if y.ndim == 2 and y.shape[1] > 1:\n", "        suffix = \"-multioutput\"  # [[1, 2], [1, 2]]\n", "    else:\n", "        suffix = \"\"  # [1, 2, 3] or [[1], [2], [3]]\n", "\n", "    # Check float and contains non-integer float values\n", "    if y.dtype.kind == \"f\":\n", "        # [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\n", "        data = y.data if issparse(y) else y\n", "        if xp.any(data != data.astype(int)):\n", "            _assert_all_finite(data, input_name=input_name)\n", "            return \"continuous\" + suffix\n", "\n", "    # Check multiclass\n", "    first_row = y[0] if not issparse(y) else y.getrow(0).data\n", "    if xp.unique_values(y).shape[0] > 2 or (y.ndim == 2 and len(first_row) > 1):\n", "        # [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\n", "        return \"multiclass\" + suffix\n", "    else:\n", "        return \"binary\"  # [1, 2] or [[\"a\"], [\"b\"]]\n"]}]}, {"file_path": "sklearn/utils/validation.py", "span_ids": ["check_array"], "content": [{"span_id": "check_array", "start_line": 629, "end_line": 959, "content": ["def check_array(\n", "    array,\n", "    accept_sparse=False,\n", "    *,\n", "    accept_large_sparse=True,\n", "    dtype=\"numeric\",\n", "    order=None,\n", "    copy=False,\n", "    force_all_finite=True,\n", "    ensure_2d=True,\n", "    allow_nd=False,\n", "    ensure_min_samples=1,\n", "    ensure_min_features=1,\n", "    estimator=None,\n", "    input_name=\"\",\n", "):\n", "\n", "    \"\"\"Input validation on an array, list, sparse matrix or similar.\n", "\n", "    By default, the input is checked to be a non-empty 2D array containing\n", "    only finite values. If the dtype of the array is object, attempt\n", "    converting to float, raising on failure.\n", "\n", "    Parameters\n", "    ----------\n", "    array : object\n", "        Input object to check / convert.\n", "\n", "    accept_sparse : str, bool or list/tuple of str, default=False\n", "        String[s] representing allowed sparse matrix formats, such as 'csc',\n", "        'csr', etc. If the input is sparse but not in the allowed format,\n", "        it will be converted to the first listed format. True allows the input\n", "        to be any format. False means that a sparse matrix input will\n", "        raise an error.\n", "\n", "    accept_large_sparse : bool, default=True\n", "        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n", "        accept_sparse, accept_large_sparse=False will cause it to be accepted\n", "        only if its indices are stored with a 32-bit dtype.\n", "\n", "        .. versionadded:: 0.20\n", "\n", "    dtype : 'numeric', type, list of type or None, default='numeric'\n", "        Data type of result. If None, the dtype of the input is preserved.\n", "        If \"numeric\", dtype is preserved unless array.dtype is object.\n", "        If dtype is a list of types, conversion on the first type is only\n", "        performed if the dtype of the input is not in the list.\n", "\n", "    order : {'F', 'C'} or None, default=None\n", "        Whether an array will be forced to be fortran or c-style.\n", "        When order is None (default), then if copy=False, nothing is ensured\n", "        about the memory layout of the output array; otherwise (copy=True)\n", "        the memory layout of the returned array is kept as close as possible\n", "        to the original array.\n", "\n", "    copy : bool, default=False\n", "        Whether a forced copy will be triggered. If copy=False, a copy might\n", "        be triggered by a conversion.\n", "\n", "    force_all_finite : bool or 'allow-nan', default=True\n", "        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n", "        possibilities are:\n", "\n", "        - True: Force all values of array to be finite.\n", "        - False: accepts np.inf, np.nan, pd.NA in array.\n", "        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n", "          cannot be infinite.\n", "\n", "        .. versionadded:: 0.20\n", "           ``force_all_finite`` accepts the string ``'allow-nan'``.\n", "\n", "        .. versionchanged:: 0.23\n", "           Accepts `pd.NA` and converts it into `np.nan`\n", "\n", "    ensure_2d : bool, default=True\n", "        Whether to raise a value error if array is not 2D.\n", "\n", "    allow_nd : bool, default=False\n", "        Whether to allow array.ndim > 2.\n", "\n", "    ensure_min_samples : int, default=1\n", "        Make sure that the array has a minimum number of samples in its first\n", "        axis (rows for a 2D array). Setting to 0 disables this check.\n", "\n", "    ensure_min_features : int, default=1\n", "        Make sure that the 2D array has some minimum number of features\n", "        (columns). The default value of 1 rejects empty datasets.\n", "        This check is only enforced when the input data has effectively 2\n", "        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n", "        disables this check.\n", "\n", "    estimator : str or estimator instance, default=None\n", "        If passed, include the name of the estimator in warning messages.\n", "\n", "    input_name : str, default=\"\"\n", "        The data name used to construct the error message. In particular\n", "        if `input_name` is \"X\" and the data has NaN values and\n", "        allow_nan is False, the error message will link to the imputer\n", "        documentation.\n", "\n", "        .. versionadded:: 1.1.0\n", "\n", "    Returns\n", "    -------\n", "    array_converted : object\n", "        The converted and validated array.\n", "    \"\"\"\n", "    if isinstance(array, np.matrix):\n", "        raise TypeError(\n", "            \"np.matrix is not supported. Please convert to a numpy array with \"\n", "            \"np.asarray. For more information see: \"\n", "            \"https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\"\n", "        )\n", "\n", "    xp, is_array_api = get_namespace(array)\n", "\n", "    # store reference to original array to check if copy is needed when\n", "    # function returns\n", "    array_orig = array\n", "\n", "    # store whether originally we wanted numeric dtype\n", "    dtype_numeric = isinstance(dtype, str) and dtype == \"numeric\"\n", "\n", "    dtype_orig = getattr(array, \"dtype\", None)\n", "    if not hasattr(dtype_orig, \"kind\"):\n", "        # not a data type (e.g. a column named dtype in a pandas DataFrame)\n", "        dtype_orig = None\n", "\n", "    # check if the object contains several dtypes (typically a pandas\n", "    # DataFrame), and store them. If not, store None.\n", "    dtypes_orig = None\n", "    pandas_requires_conversion = False\n", "    if hasattr(array, \"dtypes\") and hasattr(array.dtypes, \"__array__\"):\n", "        # throw warning if columns are sparse. If all columns are sparse, then\n", "        # array.sparse exists and sparsity will be preserved (later).\n", "        with suppress(ImportError):\n", "            from pandas.api.types import is_sparse\n", "\n", "            if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n", "                warnings.warn(\n", "                    \"pandas.DataFrame with sparse columns found.\"\n", "                    \"It will be converted to a dense numpy array.\"\n", "                )\n", "\n", "        dtypes_orig = list(array.dtypes)\n", "        pandas_requires_conversion = any(\n", "            _pandas_dtype_needs_early_conversion(i) for i in dtypes_orig\n", "        )\n", "        if all(isinstance(dtype_iter, np.dtype) for dtype_iter in dtypes_orig):\n", "            dtype_orig = np.result_type(*dtypes_orig)\n", "\n", "    elif hasattr(array, \"iloc\") and hasattr(array, \"dtype\"):\n", "        # array is a pandas series\n", "        pandas_requires_conversion = _pandas_dtype_needs_early_conversion(array.dtype)\n", "        if isinstance(array.dtype, np.dtype):\n", "            dtype_orig = array.dtype\n", "        else:\n", "            # Set to None to let array.astype work out the best dtype\n", "            dtype_orig = None\n", "\n", "    if dtype_numeric:\n", "        if dtype_orig is not None and dtype_orig.kind == \"O\":\n", "            # if input is object, convert to float.\n", "            dtype = xp.float64\n", "        else:\n", "            dtype = None\n", "\n", "    if isinstance(dtype, (list, tuple)):\n", "        if dtype_orig is not None and dtype_orig in dtype:\n", "            # no dtype conversion required\n", "            dtype = None\n", "        else:\n", "            # dtype conversion required. Let's select the first element of the\n", "            # list of accepted types.\n", "            dtype = dtype[0]\n", "\n", "    if pandas_requires_conversion:\n", "        # pandas dataframe requires conversion earlier to handle extension dtypes with\n", "        # nans\n", "        # Use the original dtype for conversion if dtype is None\n", "        new_dtype = dtype_orig if dtype is None else dtype\n", "        array = array.astype(new_dtype)\n", "        # Since we converted here, we do not need to convert again later\n", "        dtype = None\n", "\n", "    if force_all_finite not in (True, False, \"allow-nan\"):\n", "        raise ValueError(\n", "            'force_all_finite should be a bool or \"allow-nan\". Got {!r} instead'.format(\n", "                force_all_finite\n", "            )\n", "        )\n", "\n", "    estimator_name = _check_estimator_name(estimator)\n", "    context = \" by %s\" % estimator_name if estimator is not None else \"\"\n", "\n", "    # When all dataframe columns are sparse, convert to a sparse array\n", "    if hasattr(array, \"sparse\") and array.ndim > 1:\n", "        with suppress(ImportError):\n", "            from pandas.api.types import is_sparse\n", "\n", "            if array.dtypes.apply(is_sparse).all():\n", "                # DataFrame.sparse only supports `to_coo`\n", "                array = array.sparse.to_coo()\n", "                if array.dtype == np.dtype(\"object\"):\n", "                    unique_dtypes = set([dt.subtype.name for dt in array_orig.dtypes])\n", "                    if len(unique_dtypes) > 1:\n", "                        raise ValueError(\n", "                            \"Pandas DataFrame with mixed sparse extension arrays \"\n", "                            \"generated a sparse matrix with object dtype which \"\n", "                            \"can not be converted to a scipy sparse matrix.\"\n", "                            \"Sparse extension arrays should all have the same \"\n", "                            \"numeric type.\"\n", "                        )\n", "\n", "    if sp.issparse(array):\n", "        _ensure_no_complex_data(array)\n", "        array = _ensure_sparse_format(\n", "            array,\n", "            accept_sparse=accept_sparse,\n", "            dtype=dtype,\n", "            copy=copy,\n", "            force_all_finite=force_all_finite,\n", "            accept_large_sparse=accept_large_sparse,\n", "            estimator_name=estimator_name,\n", "            input_name=input_name,\n", "        )\n", "    else:\n", "        # If np.array(..) gives ComplexWarning, then we convert the warning\n", "        # to an error. This is needed because specifying a non complex\n", "        # dtype to the function converts complex to real dtype,\n", "        # thereby passing the test made in the lines following the scope\n", "        # of warnings context manager.\n", "        with warnings.catch_warnings():\n", "            try:\n", "                warnings.simplefilter(\"error\", ComplexWarning)\n", "                if dtype is not None and np.dtype(dtype).kind in \"iu\":\n", "                    # Conversion float -> int should not contain NaN or\n", "                    # inf (numpy#14412). We cannot use casting='safe' because\n", "                    # then conversion float -> int would be disallowed.\n", "                    array = _asarray_with_order(array, order=order, xp=xp)\n", "                    if array.dtype.kind == \"f\":\n", "                        _assert_all_finite(\n", "                            array,\n", "                            allow_nan=False,\n", "                            msg_dtype=dtype,\n", "                            estimator_name=estimator_name,\n", "                            input_name=input_name,\n", "                        )\n", "                    array = xp.astype(array, dtype, copy=False)\n", "                else:\n", "                    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n", "            except ComplexWarning as complex_warning:\n", "                raise ValueError(\n", "                    \"Complex data not supported\\n{}\\n\".format(array)\n", "                ) from complex_warning\n", "\n", "        # It is possible that the np.array(..) gave no warning. This happens\n", "        # when no dtype conversion happened, for example dtype = None. The\n", "        # result is that np.array(..) produces an array of complex dtype\n", "        # and we need to catch and raise exception for such cases.\n", "        _ensure_no_complex_data(array)\n", "\n", "        if ensure_2d:\n", "            # If input is scalar raise error\n", "            if array.ndim == 0:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array)\n", "                )\n", "            # If input is 1D raise error\n", "            if array.ndim == 1:\n", "                raise ValueError(\n", "                    \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n", "                    \"Reshape your data either using array.reshape(-1, 1) if \"\n", "                    \"your data has a single feature or array.reshape(1, -1) \"\n", "                    \"if it contains a single sample.\".format(array)\n", "                )\n", "\n", "        if dtype_numeric and array.dtype.kind in \"USV\":\n", "            raise ValueError(\n", "                \"dtype='numeric' is not compatible with arrays of bytes/strings.\"\n", "                \"Convert your data to numeric values explicitly instead.\"\n", "            )\n", "        if not allow_nd and array.ndim >= 3:\n", "            raise ValueError(\n", "                \"Found array with dim %d. %s expected <= 2.\"\n", "                % (array.ndim, estimator_name)\n", "            )\n", "\n", "        if force_all_finite:\n", "            _assert_all_finite(\n", "                array,\n", "                input_name=input_name,\n", "                estimator_name=estimator_name,\n", "                allow_nan=force_all_finite == \"allow-nan\",\n", "            )\n", "\n", "    if ensure_min_samples > 0:\n", "        n_samples = _num_samples(array)\n", "        if n_samples < ensure_min_samples:\n", "            raise ValueError(\n", "                \"Found array with %d sample(s) (shape=%s) while a\"\n", "                \" minimum of %d is required%s.\"\n", "                % (n_samples, array.shape, ensure_min_samples, context)\n", "            )\n", "\n", "    if ensure_min_features > 0 and array.ndim == 2:\n", "        n_features = array.shape[1]\n", "        if n_features < ensure_min_features:\n", "            raise ValueError(\n", "                \"Found array with %d feature(s) (shape=%s) while\"\n", "                \" a minimum of %d is required%s.\"\n", "                % (n_features, array.shape, ensure_min_features, context)\n", "            )\n", "\n", "    if copy:\n", "        if xp.__name__ in {\"numpy\", \"numpy.array_api\"}:\n", "            # only make a copy if `array` and `array_orig` may share memory`\n", "            if np.may_share_memory(array, array_orig):\n", "                array = _asarray_with_order(\n", "                    array, dtype=dtype, order=order, copy=True, xp=xp\n", "                )\n", "        else:\n", "            # always make a copy for non-numpy arrays\n", "            array = _asarray_with_order(\n", "                array, dtype=dtype, order=order, copy=True, xp=xp\n", "            )\n", "\n", "    return array\n"]}]}]}