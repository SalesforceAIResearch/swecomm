{"instance_id": "scikit-learn__scikit-learn-15512", "identified_spans": [{"file_path": "sklearn/cluster/_affinity_propagation.py", "span_ids": ["AffinityPropagation.fit", "affinity_propagation", "AffinityPropagation", "AffinityPropagation.predict"], "content": [{"span_id": "AffinityPropagation.fit", "start_line": 352, "end_line": 394, "content": ["    def fit(self, X, y=None):\n", "        \"\"\"Fit the clustering from features, or affinity matrix.\n", "\n", "        Parameters\n", "        ----------\n", "        X : array-like or sparse matrix, shape (n_samples, n_features), or \\\n", "            array-like, shape (n_samples, n_samples)\n", "            Training instances to cluster, or similarities / affinities between\n", "            instances if ``affinity='precomputed'``. If a sparse feature matrix\n", "            is provided, it will be converted into a sparse ``csr_matrix``.\n", "\n", "        y : Ignored\n", "            Not used, present here for API consistency by convention.\n", "\n", "        Returns\n", "        -------\n", "        self\n", "\n", "        \"\"\"\n", "        if self.affinity == \"precomputed\":\n", "            accept_sparse = False\n", "        else:\n", "            accept_sparse = 'csr'\n", "        X = check_array(X, accept_sparse=accept_sparse)\n", "        if self.affinity == \"precomputed\":\n", "            self.affinity_matrix_ = X\n", "        elif self.affinity == \"euclidean\":\n", "            self.affinity_matrix_ = -euclidean_distances(X, squared=True)\n", "        else:\n", "            raise ValueError(\"Affinity must be 'precomputed' or \"\n", "                             \"'euclidean'. Got %s instead\"\n", "                             % str(self.affinity))\n", "\n", "        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n", "            affinity_propagation(\n", "                self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n", "                convergence_iter=self.convergence_iter, damping=self.damping,\n", "                copy=self.copy, verbose=self.verbose, return_n_iter=True)\n", "\n", "        if self.affinity != \"precomputed\":\n", "            self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n", "\n", "        return self\n"]}, {"span_id": "affinity_propagation", "start_line": 33, "end_line": 231, "content": ["def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n", "                         damping=0.5, copy=True, verbose=False,\n", "                         return_n_iter=False):\n", "    \"\"\"Perform Affinity Propagation Clustering of data\n", "\n", "    Read more in the :ref:`User Guide <affinity_propagation>`.\n", "\n", "    Parameters\n", "    ----------\n", "\n", "    S : array-like, shape (n_samples, n_samples)\n", "        Matrix of similarities between points\n", "\n", "    preference : array-like, shape (n_samples,) or float, optional\n", "        Preferences for each point - points with larger values of\n", "        preferences are more likely to be chosen as exemplars. The number of\n", "        exemplars, i.e. of clusters, is influenced by the input preferences\n", "        value. If the preferences are not passed as arguments, they will be\n", "        set to the median of the input similarities (resulting in a moderate\n", "        number of clusters). For a smaller amount of clusters, this can be set\n", "        to the minimum value of the similarities.\n", "\n", "    convergence_iter : int, optional, default: 15\n", "        Number of iterations with no change in the number\n", "        of estimated clusters that stops the convergence.\n", "\n", "    max_iter : int, optional, default: 200\n", "        Maximum number of iterations\n", "\n", "    damping : float, optional, default: 0.5\n", "        Damping factor between 0.5 and 1.\n", "\n", "    copy : boolean, optional, default: True\n", "        If copy is False, the affinity matrix is modified inplace by the\n", "        algorithm, for memory efficiency\n", "\n", "    verbose : boolean, optional, default: False\n", "        The verbosity level\n", "\n", "    return_n_iter : bool, default False\n", "        Whether or not to return the number of iterations.\n", "\n", "    Returns\n", "    -------\n", "\n", "    cluster_centers_indices : array, shape (n_clusters,)\n", "        index of clusters centers\n", "\n", "    labels : array, shape (n_samples,)\n", "        cluster labels for each point\n", "\n", "    n_iter : int\n", "        number of iterations run. Returned only if `return_n_iter` is\n", "        set to True.\n", "\n", "    Notes\n", "    -----\n", "    For an example, see :ref:`examples/cluster/plot_affinity_propagation.py\n", "    <sphx_glr_auto_examples_cluster_plot_affinity_propagation.py>`.\n", "\n", "    When the algorithm does not converge, it returns an empty array as\n", "    ``cluster_center_indices`` and ``-1`` as label for each training sample.\n", "\n", "    When all training samples have equal similarities and equal preferences,\n", "    the assignment of cluster centers and labels depends on the preference.\n", "    If the preference is smaller than the similarities, a single cluster center\n", "    and label ``0`` for every sample will be returned. Otherwise, every\n", "    training sample becomes its own cluster center and is assigned a unique\n", "    label.\n", "\n", "    References\n", "    ----------\n", "    Brendan J. Frey and Delbert Dueck, \"Clustering by Passing Messages\n", "    Between Data Points\", Science Feb. 2007\n", "    \"\"\"\n", "    S = as_float_array(S, copy=copy)\n", "    n_samples = S.shape[0]\n", "\n", "    if S.shape[0] != S.shape[1]:\n", "        raise ValueError(\"S must be a square array (shape=%s)\" % repr(S.shape))\n", "\n", "    if preference is None:\n", "        preference = np.median(S)\n", "    if damping < 0.5 or damping >= 1:\n", "        raise ValueError('damping must be >= 0.5 and < 1')\n", "\n", "    preference = np.array(preference)\n", "\n", "    if (n_samples == 1 or\n", "            _equal_similarities_and_preferences(S, preference)):\n", "        # It makes no sense to run the algorithm in this case, so return 1 or\n", "        # n_samples clusters, depending on preferences\n", "        warnings.warn(\"All samples have mutually equal similarities. \"\n", "                      \"Returning arbitrary cluster center(s).\")\n", "        if preference.flat[0] >= S.flat[n_samples - 1]:\n", "            return ((np.arange(n_samples), np.arange(n_samples), 0)\n", "                    if return_n_iter\n", "                    else (np.arange(n_samples), np.arange(n_samples)))\n", "        else:\n", "            return ((np.array([0]), np.array([0] * n_samples), 0)\n", "                    if return_n_iter\n", "                    else (np.array([0]), np.array([0] * n_samples)))\n", "\n", "    random_state = np.random.RandomState(0)\n", "\n", "    # Place preference on the diagonal of S\n", "    S.flat[::(n_samples + 1)] = preference\n", "\n", "    A = np.zeros((n_samples, n_samples))\n", "    R = np.zeros((n_samples, n_samples))  # Initialize messages\n", "    # Intermediate results\n", "    tmp = np.zeros((n_samples, n_samples))\n", "\n", "    # Remove degeneracies\n", "    S += ((np.finfo(np.double).eps * S + np.finfo(np.double).tiny * 100) *\n", "          random_state.randn(n_samples, n_samples))\n", "\n", "    # Execute parallel affinity propagation updates\n", "    e = np.zeros((n_samples, convergence_iter))\n", "\n", "    ind = np.arange(n_samples)\n", "\n", "    for it in range(max_iter):\n", "        # tmp = A + S; compute responsibilities\n", "        np.add(A, S, tmp)\n", "        I = np.argmax(tmp, axis=1)\n", "        Y = tmp[ind, I]  # np.max(A + S, axis=1)\n", "        tmp[ind, I] = -np.inf\n", "        Y2 = np.max(tmp, axis=1)\n", "\n", "        # tmp = Rnew\n", "        np.subtract(S, Y[:, None], tmp)\n", "        tmp[ind, I] = S[ind, I] - Y2\n", "\n", "        # Damping\n", "        tmp *= 1 - damping\n", "        R *= damping\n", "        R += tmp\n", "\n", "        # tmp = Rp; compute availabilities\n", "        np.maximum(R, 0, tmp)\n", "        tmp.flat[::n_samples + 1] = R.flat[::n_samples + 1]\n", "\n", "        # tmp = -Anew\n", "        tmp -= np.sum(tmp, axis=0)\n", "        dA = np.diag(tmp).copy()\n", "        tmp.clip(0, np.inf, tmp)\n", "        tmp.flat[::n_samples + 1] = dA\n", "\n", "        # Damping\n", "        tmp *= 1 - damping\n", "        A *= damping\n", "        A -= tmp\n", "\n", "        # Check for convergence\n", "        E = (np.diag(A) + np.diag(R)) > 0\n", "        e[:, it % convergence_iter] = E\n", "        K = np.sum(E, axis=0)\n", "\n", "        if it >= convergence_iter:\n", "            se = np.sum(e, axis=1)\n", "            unconverged = (np.sum((se == convergence_iter) + (se == 0))\n", "                           != n_samples)\n", "            if (not unconverged and (K > 0)) or (it == max_iter):\n", "                if verbose:\n", "                    print(\"Converged after %d iterations.\" % it)\n", "                break\n", "    else:\n", "        if verbose:\n", "            print(\"Did not converge\")\n", "\n", "    I = np.flatnonzero(E)\n", "    K = I.size  # Identify exemplars\n", "\n", "    if K > 0:\n", "        c = np.argmax(S[:, I], axis=1)\n", "        c[I] = np.arange(K)  # Identify clusters\n", "        # Refine the final set of exemplars and clusters and return results\n", "        for k in range(K):\n", "            ii = np.where(c == k)[0]\n", "            j = np.argmax(np.sum(S[ii[:, np.newaxis], ii], axis=0))\n", "            I[k] = ii[j]\n", "\n", "        c = np.argmax(S[:, I], axis=1)\n", "        c[I] = np.arange(K)\n", "        labels = I[c]\n", "        # Reduce labels to a sorted, gapless, list\n", "        cluster_centers_indices = np.unique(labels)\n", "        labels = np.searchsorted(cluster_centers_indices, labels)\n", "    else:\n", "        warnings.warn(\"Affinity propagation did not converge, this model \"\n", "                      \"will not have any cluster centers.\", ConvergenceWarning)\n", "        labels = np.array([-1] * n_samples)\n", "        cluster_centers_indices = []\n", "\n", "    if return_n_iter:\n", "        return cluster_centers_indices, labels, it + 1\n", "    else:\n", "        return cluster_centers_indices, labels\n"]}, {"span_id": "AffinityPropagation", "start_line": 236, "end_line": 334, "content": ["class AffinityPropagation(ClusterMixin, BaseEstimator):\n", "    \"\"\"Perform Affinity Propagation Clustering of data.\n", "\n", "    Read more in the :ref:`User Guide <affinity_propagation>`.\n", "\n", "    Parameters\n", "    ----------\n", "    damping : float, optional, default: 0.5\n", "        Damping factor (between 0.5 and 1) is the extent to\n", "        which the current value is maintained relative to\n", "        incoming values (weighted 1 - damping). This in order\n", "        to avoid numerical oscillations when updating these\n", "        values (messages).\n", "\n", "    max_iter : int, optional, default: 200\n", "        Maximum number of iterations.\n", "\n", "    convergence_iter : int, optional, default: 15\n", "        Number of iterations with no change in the number\n", "        of estimated clusters that stops the convergence.\n", "\n", "    copy : boolean, optional, default: True\n", "        Make a copy of input data.\n", "\n", "    preference : array-like, shape (n_samples,) or float, optional\n", "        Preferences for each point - points with larger values of\n", "        preferences are more likely to be chosen as exemplars. The number\n", "        of exemplars, ie of clusters, is influenced by the input\n", "        preferences value. If the preferences are not passed as arguments,\n", "        they will be set to the median of the input similarities.\n", "\n", "    affinity : string, optional, default=``euclidean``\n", "        Which affinity to use. At the moment ``precomputed`` and\n", "        ``euclidean`` are supported. ``euclidean`` uses the\n", "        negative squared euclidean distance between points.\n", "\n", "    verbose : boolean, optional, default: False\n", "        Whether to be verbose.\n", "\n", "\n", "    Attributes\n", "    ----------\n", "    cluster_centers_indices_ : array, shape (n_clusters,)\n", "        Indices of cluster centers\n", "\n", "    cluster_centers_ : array, shape (n_clusters, n_features)\n", "        Cluster centers (if affinity != ``precomputed``).\n", "\n", "    labels_ : array, shape (n_samples,)\n", "        Labels of each point\n", "\n", "    affinity_matrix_ : array, shape (n_samples, n_samples)\n", "        Stores the affinity matrix used in ``fit``.\n", "\n", "    n_iter_ : int\n", "        Number of iterations taken to converge.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn.cluster import AffinityPropagation\n", "    >>> import numpy as np\n", "    >>> X = np.array([[1, 2], [1, 4], [1, 0],\n", "    ...               [4, 2], [4, 4], [4, 0]])\n", "    >>> clustering = AffinityPropagation().fit(X)\n", "    >>> clustering\n", "    AffinityPropagation()\n", "    >>> clustering.labels_\n", "    array([0, 0, 0, 1, 1, 1])\n", "    >>> clustering.predict([[0, 0], [4, 4]])\n", "    array([0, 1])\n", "    >>> clustering.cluster_centers_\n", "    array([[1, 2],\n", "           [4, 2]])\n", "\n", "    Notes\n", "    -----\n", "    For an example, see :ref:`examples/cluster/plot_affinity_propagation.py\n", "    <sphx_glr_auto_examples_cluster_plot_affinity_propagation.py>`.\n", "\n", "    The algorithmic complexity of affinity propagation is quadratic\n", "    in the number of points.\n", "\n", "    When ``fit`` does not converge, ``cluster_centers_`` becomes an empty\n", "    array and all training samples will be labelled as ``-1``. In addition,\n", "    ``predict`` will then label every sample as ``-1``.\n", "\n", "    When all training samples have equal similarities and equal preferences,\n", "    the assignment of cluster centers and labels depends on the preference.\n", "    If the preference is smaller than the similarities, ``fit`` will result in\n", "    a single cluster center and label ``0`` for every sample. Otherwise, every\n", "    training sample becomes its own cluster center and is assigned a unique\n", "    label.\n", "\n", "    References\n", "    ----------\n", "\n", "    Brendan J. Frey and Delbert Dueck, \"Clustering by Passing Messages\n", "    Between Data Points\", Science Feb. 2007\n", "    \"\"\"\n"]}, {"span_id": "AffinityPropagation.predict", "start_line": 396, "end_line": 421, "content": ["    def predict(self, X):\n", "        \"\"\"Predict the closest cluster each sample in X belongs to.\n", "\n", "        Parameters\n", "        ----------\n", "        X : array-like or sparse matrix, shape (n_samples, n_features)\n", "            New data to predict. If a sparse matrix is provided, it will be\n", "            converted into a sparse ``csr_matrix``.\n", "\n", "        Returns\n", "        -------\n", "        labels : ndarray, shape (n_samples,)\n", "            Cluster labels.\n", "        \"\"\"\n", "        check_is_fitted(self)\n", "        if not hasattr(self, \"cluster_centers_\"):\n", "            raise ValueError(\"Predict method is not supported when \"\n", "                             \"affinity='precomputed'.\")\n", "\n", "        if self.cluster_centers_.shape[0] > 0:\n", "            return pairwise_distances_argmin(X, self.cluster_centers_)\n", "        else:\n", "            warnings.warn(\"This model does not have any cluster centers \"\n", "                          \"because affinity propagation did not converge. \"\n", "                          \"Labeling every sample as '-1'.\", ConvergenceWarning)\n", "            return np.array([-1] * X.shape[0])\n"]}]}]}