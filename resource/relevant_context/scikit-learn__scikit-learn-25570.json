{"instance_id": "scikit-learn__scikit-learn-25570", "identified_spans": [{"file_path": "sklearn/compose/_column_transformer.py", "span_ids": ["ColumnTransformer._iter", "ColumnTransformer._add_prefix_for_feature_names_out", "ColumnTransformer._hstack", "ColumnTransformer.fit_transform", "ColumnTransformer"], "content": [{"span_id": "ColumnTransformer._iter", "start_line": 347, "end_line": 408, "content": ["    def _iter(self, fitted=False, replace_strings=False, column_as_strings=False):\n", "        \"\"\"\n", "        Generate (name, trans, column, weight) tuples.\n", "\n", "        If fitted=True, use the fitted transformers, else use the\n", "        user specified transformers updated with converted column names\n", "        and potentially appended with transformer for remainder.\n", "\n", "        \"\"\"\n", "        if fitted:\n", "            if replace_strings:\n", "                # Replace \"passthrough\" with the fitted version in\n", "                # _name_to_fitted_passthrough\n", "                def replace_passthrough(name, trans, columns):\n", "                    if name not in self._name_to_fitted_passthrough:\n", "                        return name, trans, columns\n", "                    return name, self._name_to_fitted_passthrough[name], columns\n", "\n", "                transformers = [\n", "                    replace_passthrough(*trans) for trans in self.transformers_\n", "                ]\n", "            else:\n", "                transformers = self.transformers_\n", "        else:\n", "            # interleave the validated column specifiers\n", "            transformers = [\n", "                (name, trans, column)\n", "                for (name, trans, _), column in zip(self.transformers, self._columns)\n", "            ]\n", "            # add transformer tuple for remainder\n", "            if self._remainder[2]:\n", "                transformers = chain(transformers, [self._remainder])\n", "        get_weight = (self.transformer_weights or {}).get\n", "\n", "        output_config = _get_output_config(\"transform\", self)\n", "        for name, trans, columns in transformers:\n", "            if replace_strings:\n", "                # replace 'passthrough' with identity transformer and\n", "                # skip in case of 'drop'\n", "                if trans == \"passthrough\":\n", "                    trans = FunctionTransformer(\n", "                        accept_sparse=True,\n", "                        check_inverse=False,\n", "                        feature_names_out=\"one-to-one\",\n", "                    ).set_output(transform=output_config[\"dense\"])\n", "                elif trans == \"drop\":\n", "                    continue\n", "                elif _is_empty_column_selection(columns):\n", "                    continue\n", "\n", "            if column_as_strings:\n", "                # Convert all columns to using their string labels\n", "                columns_is_scalar = np.isscalar(columns)\n", "\n", "                indices = self._transformer_to_input_indices[name]\n", "                columns = self.feature_names_in_[indices]\n", "\n", "                if columns_is_scalar:\n", "                    # selection is done with one dimension\n", "                    columns = columns[0]\n", "\n", "            yield (name, trans, columns, get_weight(name))\n"]}, {"span_id": "ColumnTransformer._add_prefix_for_feature_names_out", "start_line": 533, "end_line": 579, "content": ["    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):\n", "        \"\"\"Add prefix for feature names out that includes the transformer names.\n", "\n", "        Parameters\n", "        ----------\n", "        transformer_with_feature_names_out : list of tuples of (str, array-like of str)\n", "            The tuple consistent of the transformer's name and its feature names out.\n", "\n", "        Returns\n", "        -------\n", "        feature_names_out : ndarray of shape (n_features,), dtype=str\n", "            Transformed feature names.\n", "        \"\"\"\n", "        if self.verbose_feature_names_out:\n", "            # Prefix the feature names out with the transformers name\n", "            names = list(\n", "                chain.from_iterable(\n", "                    (f\"{name}__{i}\" for i in feature_names_out)\n", "                    for name, feature_names_out in transformer_with_feature_names_out\n", "                )\n", "            )\n", "            return np.asarray(names, dtype=object)\n", "\n", "        # verbose_feature_names_out is False\n", "        # Check that names are all unique without a prefix\n", "        feature_names_count = Counter(\n", "            chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n", "        )\n", "        top_6_overlap = [\n", "            name for name, count in feature_names_count.most_common(6) if count > 1\n", "        ]\n", "        top_6_overlap.sort()\n", "        if top_6_overlap:\n", "            if len(top_6_overlap) == 6:\n", "                # There are more than 5 overlapping names, we only show the 5\n", "                # of the feature names\n", "                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n", "            else:\n", "                names_repr = str(top_6_overlap)\n", "            raise ValueError(\n", "                f\"Output feature names: {names_repr} are not unique. Please set \"\n", "                \"verbose_feature_names_out=True to add prefixes to feature names\"\n", "            )\n", "\n", "        return np.concatenate(\n", "            [name for _, name in transformer_with_feature_names_out],\n", "        )\n"]}, {"span_id": "ColumnTransformer._hstack", "start_line": 824, "end_line": 875, "content": ["    def _hstack(self, Xs):\n", "        \"\"\"Stacks Xs horizontally.\n", "\n", "        This allows subclasses to control the stacking behavior, while reusing\n", "        everything else from ColumnTransformer.\n", "\n", "        Parameters\n", "        ----------\n", "        Xs : list of {array-like, sparse matrix, dataframe}\n", "        \"\"\"\n", "        if self.sparse_output_:\n", "            try:\n", "                # since all columns should be numeric before stacking them\n", "                # in a sparse matrix, `check_array` is used for the\n", "                # dtype conversion if necessary.\n", "                converted_Xs = [\n", "                    check_array(X, accept_sparse=True, force_all_finite=False)\n", "                    for X in Xs\n", "                ]\n", "            except ValueError as e:\n", "                raise ValueError(\n", "                    \"For a sparse output, all columns should \"\n", "                    \"be a numeric or convertible to a numeric.\"\n", "                ) from e\n", "\n", "            return sparse.hstack(converted_Xs).tocsr()\n", "        else:\n", "            Xs = [f.toarray() if sparse.issparse(f) else f for f in Xs]\n", "            config = _get_output_config(\"transform\", self)\n", "            if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n", "                pd = check_pandas_support(\"transform\")\n", "                output = pd.concat(Xs, axis=1)\n", "\n", "                # If all transformers define `get_feature_names_out`, then transform\n", "                # will adjust the column names to be consistent with\n", "                # verbose_feature_names_out. Here we prefix the feature names if\n", "                # verbose_feature_names_out=True.\n", "\n", "                if not self.verbose_feature_names_out:\n", "                    return output\n", "\n", "                transformer_names = [\n", "                    t[0] for t in self._iter(fitted=True, replace_strings=True)\n", "                ]\n", "                feature_names_outs = [X.columns for X in Xs]\n", "                names_out = self._add_prefix_for_feature_names_out(\n", "                    list(zip(transformer_names, feature_names_outs))\n", "                )\n", "                output.columns = names_out\n", "                return output\n", "\n", "            return np.hstack(Xs)\n"]}, {"span_id": "ColumnTransformer.fit_transform", "start_line": 705, "end_line": 760, "content": ["    def fit_transform(self, X, y=None):\n", "        \"\"\"Fit all transformers, transform the data and concatenate results.\n", "\n", "        Parameters\n", "        ----------\n", "        X : {array-like, dataframe} of shape (n_samples, n_features)\n", "            Input data, of which specified subsets are used to fit the\n", "            transformers.\n", "\n", "        y : array-like of shape (n_samples,), default=None\n", "            Targets for supervised learning.\n", "\n", "        Returns\n", "        -------\n", "        X_t : {array-like, sparse matrix} of \\\n", "                shape (n_samples, sum_n_components)\n", "            Horizontally stacked results of transformers. sum_n_components is the\n", "            sum of n_components (output dimension) over transformers. If\n", "            any result is a sparse matrix, everything will be converted to\n", "            sparse matrices.\n", "        \"\"\"\n", "        self._validate_params()\n", "        self._check_feature_names(X, reset=True)\n", "\n", "        X = _check_X(X)\n", "        # set n_features_in_ attribute\n", "        self._check_n_features(X, reset=True)\n", "        self._validate_transformers()\n", "        self._validate_column_callables(X)\n", "        self._validate_remainder(X)\n", "\n", "        result = self._fit_transform(X, y, _fit_transform_one)\n", "\n", "        if not result:\n", "            self._update_fitted_transformers([])\n", "            # All transformers are None\n", "            return np.zeros((X.shape[0], 0))\n", "\n", "        Xs, transformers = zip(*result)\n", "\n", "        # determine if concatenated output will be sparse or not\n", "        if any(sparse.issparse(X) for X in Xs):\n", "            nnz = sum(X.nnz if sparse.issparse(X) else X.size for X in Xs)\n", "            total = sum(\n", "                X.shape[0] * X.shape[1] if sparse.issparse(X) else X.size for X in Xs\n", "            )\n", "            density = nnz / total\n", "            self.sparse_output_ = density < self.sparse_threshold\n", "        else:\n", "            self.sparse_output_ = False\n", "\n", "        self._update_fitted_transformers(transformers)\n", "        self._validate_output(Xs)\n", "        self._record_output_indices(Xs)\n", "\n", "        return self._hstack(list(Xs))\n"]}, {"span_id": "ColumnTransformer", "start_line": 41, "end_line": 230, "content": ["class ColumnTransformer(TransformerMixin, _BaseComposition):\n", "    \"\"\"Applies transformers to columns of an array or pandas DataFrame.\n", "\n", "    This estimator allows different columns or column subsets of the input\n", "    to be transformed separately and the features generated by each transformer\n", "    will be concatenated to form a single feature space.\n", "    This is useful for heterogeneous or columnar data, to combine several\n", "    feature extraction mechanisms or transformations into a single transformer.\n", "\n", "    Read more in the :ref:`User Guide <column_transformer>`.\n", "\n", "    .. versionadded:: 0.20\n", "\n", "    Parameters\n", "    ----------\n", "    transformers : list of tuples\n", "        List of (name, transformer, columns) tuples specifying the\n", "        transformer objects to be applied to subsets of the data.\n", "\n", "        name : str\n", "            Like in Pipeline and FeatureUnion, this allows the transformer and\n", "            its parameters to be set using ``set_params`` and searched in grid\n", "            search.\n", "        transformer : {'drop', 'passthrough'} or estimator\n", "            Estimator must support :term:`fit` and :term:`transform`.\n", "            Special-cased strings 'drop' and 'passthrough' are accepted as\n", "            well, to indicate to drop the columns or to pass them through\n", "            untransformed, respectively.\n", "        columns :  str, array-like of str, int, array-like of int, \\\n", "                array-like of bool, slice or callable\n", "            Indexes the data on its second axis. Integers are interpreted as\n", "            positional columns, while strings can reference DataFrame columns\n", "            by name.  A scalar string or int should be used where\n", "            ``transformer`` expects X to be a 1d array-like (vector),\n", "            otherwise a 2d array will be passed to the transformer.\n", "            A callable is passed the input data `X` and can return any of the\n", "            above. To select multiple columns by name or dtype, you can use\n", "            :obj:`make_column_selector`.\n", "\n", "    remainder : {'drop', 'passthrough'} or estimator, default='drop'\n", "        By default, only the specified columns in `transformers` are\n", "        transformed and combined in the output, and the non-specified\n", "        columns are dropped. (default of ``'drop'``).\n", "        By specifying ``remainder='passthrough'``, all remaining columns that\n", "        were not specified in `transformers`, but present in the data passed\n", "        to `fit` will be automatically passed through. This subset of columns\n", "        is concatenated with the output of the transformers. For dataframes,\n", "        extra columns not seen during `fit` will be excluded from the output\n", "        of `transform`.\n", "        By setting ``remainder`` to be an estimator, the remaining\n", "        non-specified columns will use the ``remainder`` estimator. The\n", "        estimator must support :term:`fit` and :term:`transform`.\n", "        Note that using this feature requires that the DataFrame columns\n", "        input at :term:`fit` and :term:`transform` have identical order.\n", "\n", "    sparse_threshold : float, default=0.3\n", "        If the output of the different transformers contains sparse matrices,\n", "        these will be stacked as a sparse matrix if the overall density is\n", "        lower than this value. Use ``sparse_threshold=0`` to always return\n", "        dense.  When the transformed output consists of all dense data, the\n", "        stacked result will be dense, and this keyword will be ignored.\n", "\n", "    n_jobs : int, default=None\n", "        Number of jobs to run in parallel.\n", "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n", "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n", "        for more details.\n", "\n", "    transformer_weights : dict, default=None\n", "        Multiplicative weights for features per transformer. The output of the\n", "        transformer is multiplied by these weights. Keys are transformer names,\n", "        values the weights.\n", "\n", "    verbose : bool, default=False\n", "        If True, the time elapsed while fitting each transformer will be\n", "        printed as it is completed.\n", "\n", "    verbose_feature_names_out : bool, default=True\n", "        If True, :meth:`get_feature_names_out` will prefix all feature names\n", "        with the name of the transformer that generated that feature.\n", "        If False, :meth:`get_feature_names_out` will not prefix any feature\n", "        names and will error if feature names are not unique.\n", "\n", "        .. versionadded:: 1.0\n", "\n", "    Attributes\n", "    ----------\n", "    transformers_ : list\n", "        The collection of fitted transformers as tuples of\n", "        (name, fitted_transformer, column). `fitted_transformer` can be an\n", "        estimator, 'drop', or 'passthrough'. In case there were no columns\n", "        selected, this will be the unfitted transformer.\n", "        If there are remaining columns, the final element is a tuple of the\n", "        form:\n", "        ('remainder', transformer, remaining_columns) corresponding to the\n", "        ``remainder`` parameter. If there are remaining columns, then\n", "        ``len(transformers_)==len(transformers)+1``, otherwise\n", "        ``len(transformers_)==len(transformers)``.\n", "\n", "    named_transformers_ : :class:`~sklearn.utils.Bunch`\n", "        Read-only attribute to access any transformer by given name.\n", "        Keys are transformer names and values are the fitted transformer\n", "        objects.\n", "\n", "    sparse_output_ : bool\n", "        Boolean flag indicating whether the output of ``transform`` is a\n", "        sparse matrix or a dense numpy array, which depends on the output\n", "        of the individual transformers and the `sparse_threshold` keyword.\n", "\n", "    output_indices_ : dict\n", "        A dictionary from each transformer name to a slice, where the slice\n", "        corresponds to indices in the transformed output. This is useful to\n", "        inspect which transformer is responsible for which transformed\n", "        feature(s).\n", "\n", "        .. versionadded:: 1.0\n", "\n", "    n_features_in_ : int\n", "        Number of features seen during :term:`fit`. Only defined if the\n", "        underlying transformers expose such an attribute when fit.\n", "\n", "        .. versionadded:: 0.24\n", "\n", "    See Also\n", "    --------\n", "    make_column_transformer : Convenience function for\n", "        combining the outputs of multiple transformer objects applied to\n", "        column subsets of the original feature space.\n", "    make_column_selector : Convenience function for selecting\n", "        columns based on datatype or the columns name with a regex pattern.\n", "\n", "    Notes\n", "    -----\n", "    The order of the columns in the transformed feature matrix follows the\n", "    order of how the columns are specified in the `transformers` list.\n", "    Columns of the original feature matrix that are not specified are\n", "    dropped from the resulting transformed feature matrix, unless specified\n", "    in the `passthrough` keyword. Those columns specified with `passthrough`\n", "    are added at the right to the output of the transformers.\n", "\n", "    Examples\n", "    --------\n", "    >>> import numpy as np\n", "    >>> from sklearn.compose import ColumnTransformer\n", "    >>> from sklearn.preprocessing import Normalizer\n", "    >>> ct = ColumnTransformer(\n", "    ...     [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n", "    ...      (\"norm2\", Normalizer(norm='l1'), slice(2, 4))])\n", "    >>> X = np.array([[0., 1., 2., 2.],\n", "    ...               [1., 1., 0., 1.]])\n", "    >>> # Normalizer scales each row of X to unit norm. A separate scaling\n", "    >>> # is applied for the two first and two last elements of each\n", "    >>> # row independently.\n", "    >>> ct.fit_transform(X)\n", "    array([[0. , 1. , 0.5, 0.5],\n", "           [0.5, 0.5, 0. , 1. ]])\n", "\n", "    :class:`ColumnTransformer` can be configured with a transformer that requires\n", "    a 1d array by setting the column to a string:\n", "\n", "    >>> from sklearn.feature_extraction import FeatureHasher\n", "    >>> from sklearn.preprocessing import MinMaxScaler\n", "    >>> import pandas as pd   # doctest: +SKIP\n", "    >>> X = pd.DataFrame({\n", "    ...     \"documents\": [\"First item\", \"second one here\", \"Is this the last?\"],\n", "    ...     \"width\": [3, 4, 5],\n", "    ... })  # doctest: +SKIP\n", "    >>> # \"documents\" is a string which configures ColumnTransformer to\n", "    >>> # pass the documents column as a 1d array to the FeatureHasher\n", "    >>> ct = ColumnTransformer(\n", "    ...     [(\"text_preprocess\", FeatureHasher(input_type=\"string\"), \"documents\"),\n", "    ...      (\"num_preprocess\", MinMaxScaler(), [\"width\"])])\n", "    >>> X_trans = ct.fit_transform(X)  # doctest: +SKIP\n", "    \"\"\"\n", "\n", "    _required_parameters = [\"transformers\"]\n", "\n", "    _parameter_constraints: dict = {\n", "        \"transformers\": [list, Hidden(tuple)],\n", "        \"remainder\": [\n", "            StrOptions({\"drop\", \"passthrough\"}),\n", "            HasMethods([\"fit\", \"transform\"]),\n", "            HasMethods([\"fit_transform\", \"transform\"]),\n", "        ],\n", "        \"sparse_threshold\": [Interval(Real, 0, 1, closed=\"both\")],\n", "        \"n_jobs\": [Integral, None],\n", "        \"transformer_weights\": [dict, None],\n", "        \"verbose\": [\"verbose\"],\n", "        \"verbose_feature_names_out\": [\"boolean\"],\n", "    }\n"]}]}]}