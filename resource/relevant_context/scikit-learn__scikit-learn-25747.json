{"instance_id": "scikit-learn__scikit-learn-25747", "identified_spans": [{"file_path": "sklearn/pipeline.py", "span_ids": ["FeatureUnion.transform", "FeatureUnion", "FeatureUnion._hstack"], "content": [{"span_id": "FeatureUnion.transform", "start_line": 1254, "end_line": 1277, "content": ["    def transform(self, X):\n", "        \"\"\"Transform X separately by each transformer, concatenate results.\n", "\n", "        Parameters\n", "        ----------\n", "        X : iterable or array-like, depending on transformers\n", "            Input data to be transformed.\n", "\n", "        Returns\n", "        -------\n", "        X_t : array-like or sparse matrix of \\\n", "                shape (n_samples, sum_n_components)\n", "            The `hstack` of results of transformers. `sum_n_components` is the\n", "            sum of `n_components` (output dimension) over transformers.\n", "        \"\"\"\n", "        Xs = Parallel(n_jobs=self.n_jobs)(\n", "            delayed(_transform_one)(trans, X, None, weight)\n", "            for name, trans, weight in self._iter()\n", "        )\n", "        if not Xs:\n", "            # All transformers are None\n", "            return np.zeros((X.shape[0], 0))\n", "\n", "        return self._hstack(Xs)\n"]}, {"span_id": "FeatureUnion", "start_line": 931, "end_line": 1020, "content": ["class FeatureUnion(TransformerMixin, _BaseComposition):\n", "    \"\"\"Concatenates results of multiple transformer objects.\n", "\n", "    This estimator applies a list of transformer objects in parallel to the\n", "    input data, then concatenates the results. This is useful to combine\n", "    several feature extraction mechanisms into a single transformer.\n", "\n", "    Parameters of the transformers may be set using its name and the parameter\n", "    name separated by a '__'. A transformer may be replaced entirely by\n", "    setting the parameter with its name to another transformer, removed by\n", "    setting to 'drop' or disabled by setting to 'passthrough' (features are\n", "    passed without transformation).\n", "\n", "    Read more in the :ref:`User Guide <feature_union>`.\n", "\n", "    .. versionadded:: 0.13\n", "\n", "    Parameters\n", "    ----------\n", "    transformer_list : list of (str, transformer) tuples\n", "        List of transformer objects to be applied to the data. The first\n", "        half of each tuple is the name of the transformer. The transformer can\n", "        be 'drop' for it to be ignored or can be 'passthrough' for features to\n", "        be passed unchanged.\n", "\n", "        .. versionadded:: 1.1\n", "           Added the option `\"passthrough\"`.\n", "\n", "        .. versionchanged:: 0.22\n", "           Deprecated `None` as a transformer in favor of 'drop'.\n", "\n", "    n_jobs : int, default=None\n", "        Number of jobs to run in parallel.\n", "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n", "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n", "        for more details.\n", "\n", "        .. versionchanged:: v0.20\n", "           `n_jobs` default changed from 1 to None\n", "\n", "    transformer_weights : dict, default=None\n", "        Multiplicative weights for features per transformer.\n", "        Keys are transformer names, values the weights.\n", "        Raises ValueError if key not present in ``transformer_list``.\n", "\n", "    verbose : bool, default=False\n", "        If True, the time elapsed while fitting each transformer will be\n", "        printed as it is completed.\n", "\n", "    Attributes\n", "    ----------\n", "    named_transformers : :class:`~sklearn.utils.Bunch`\n", "        Dictionary-like object, with the following attributes.\n", "        Read-only attribute to access any transformer parameter by user\n", "        given name. Keys are transformer names and values are\n", "        transformer parameters.\n", "\n", "        .. versionadded:: 1.2\n", "\n", "    n_features_in_ : int\n", "        Number of features seen during :term:`fit`. Only defined if the\n", "        underlying first transformer in `transformer_list` exposes such an\n", "        attribute when fit.\n", "\n", "        .. versionadded:: 0.24\n", "\n", "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n", "        Names of features seen during :term:`fit`. Defined only when\n", "        `X` has feature names that are all strings.\n", "\n", "        .. versionadded:: 1.3\n", "\n", "    See Also\n", "    --------\n", "    make_union : Convenience function for simplified feature union\n", "        construction.\n", "\n", "    Examples\n", "    --------\n", "    >>> from sklearn.pipeline import FeatureUnion\n", "    >>> from sklearn.decomposition import PCA, TruncatedSVD\n", "    >>> union = FeatureUnion([(\"pca\", PCA(n_components=1)),\n", "    ...                       (\"svd\", TruncatedSVD(n_components=2))])\n", "    >>> X = [[0., 1., 3], [2., 2., 5]]\n", "    >>> union.fit_transform(X)\n", "    array([[ 1.5       ,  3.0...,  0.8...],\n", "           [-1.5       ,  5.7..., -0.4...]])\n", "    \"\"\"\n", "\n", "    _required_parameters = [\"transformer_list\"]\n"]}, {"span_id": "FeatureUnion._hstack", "start_line": 1279, "end_line": 1289, "content": ["    def _hstack(self, Xs):\n", "        config = _get_output_config(\"transform\", self)\n", "        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n", "            pd = check_pandas_support(\"transform\")\n", "            return pd.concat(Xs, axis=1)\n", "\n", "        if any(sparse.issparse(f) for f in Xs):\n", "            Xs = sparse.hstack(Xs).tocsr()\n", "        else:\n", "            Xs = np.hstack(Xs)\n", "        return Xs\n"]}]}, {"file_path": "sklearn/utils/_set_output.py", "span_ids": ["_wrap_in_pandas_container"], "content": [{"span_id": "_wrap_in_pandas_container", "start_line": 10, "end_line": 62, "content": ["def _wrap_in_pandas_container(\n", "    data_to_wrap,\n", "    *,\n", "    columns,\n", "    index=None,\n", "):\n", "    \"\"\"Create a Pandas DataFrame.\n", "\n", "    If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be changed\n", "    inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is created with\n", "    `columns` and `index`.\n", "\n", "    Parameters\n", "    ----------\n", "    data_to_wrap : {ndarray, dataframe}\n", "        Data to be wrapped as pandas dataframe.\n", "\n", "    columns : callable, ndarray, or None\n", "        The column names or a callable that returns the column names. The\n", "        callable is useful if the column names require some computation.\n", "        If `columns` is a callable that raises an error, `columns` will have\n", "        the same semantics as `None`. If `None` and `data_to_wrap` is already a\n", "        dataframe, then the column names are not changed. If `None` and\n", "        `data_to_wrap` is **not** a dataframe, then columns are\n", "        `range(n_features)`.\n", "\n", "    index : array-like, default=None\n", "        Index for data.\n", "\n", "    Returns\n", "    -------\n", "    dataframe : DataFrame\n", "        Container with column names or unchanged `output`.\n", "    \"\"\"\n", "    if issparse(data_to_wrap):\n", "        raise ValueError(\"Pandas output does not support sparse data.\")\n", "\n", "    if callable(columns):\n", "        try:\n", "            columns = columns()\n", "        except Exception:\n", "            columns = None\n", "\n", "    pd = check_pandas_support(\"Setting output container to 'pandas'\")\n", "\n", "    if isinstance(data_to_wrap, pd.DataFrame):\n", "        if columns is not None:\n", "            data_to_wrap.columns = columns\n", "        if index is not None:\n", "            data_to_wrap.index = index\n", "        return data_to_wrap\n", "\n", "    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n"]}]}]}