{
  "name": "AgenticLoop",
  "initial_message": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n",
  "transitions": [
    {
      "name": "SearchCode",
      "state": {
        "include_message_history": true,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "max_search_results": 75,
        "max_retries_with_any_file_context": 3,
        "provide_initial_context": true,
        "initial_context_tokens": 6000,
        "initial_search_results": 100,
        "initial_context_spans_per_file": 5,
        "support_test_files": false
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The issue is related to the NeighborhoodComponentsAnalysis (NCA) class failing in GridSearch due to strict parameter checks. The problem arises because parameters like 'tol' and 'n_components' are not being validated correctly when passed through GridSearchCV. The user suggests a more flexible parameter checking mechanism.\n\nRelevant files identified:\n1. sklearn/model_selection/_search.py\n2. sklearn/neighbors/nca.py\n3. sklearn/utils/estimator_checks.py\n4. sklearn/neural_network/multilayer_perceptron.py\n5. sklearn/utils/validation.py\n6. sklearn/linear_model/stochastic_gradient.py\n7. sklearn/ensemble/gradient_boosting.py\n8. sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n9. sklearn/decomposition/online_lda.py\n10. sklearn/covariance/graph_lasso_.py\n11. sklearn/base.py\n12. sklearn/mixture/base.py\n13. sklearn/linear_model/coordinate_descent.py\n14. sklearn/cluster/bicluster.py\n15. sklearn/linear_model/logistic.py\n16. benchmarks/bench_plot_lasso_path.py\n17. sklearn/tree/tree.py\n18. build_tools/generate_authors_table.py\n19. sklearn/neighbors/base.py\n20. sklearn/feature_extraction/text.py\n\nNext steps:\n1. Search for the '_validate_params' function in 'sklearn/neighbors/nca.py' to understand the current parameter validation logic.\n2. Search for the '_check_params' function in 'sklearn/decomposition/online_lda.py' to understand how parameters are validated in LDA.\n3. Search for 'check_param' function or similar in 'sklearn/utils/validation.py' to see if there's an existing utility for parameter validation.",
            "search_requests": [
              {
                "file_pattern": "sklearn/neighbors/nca.py",
                "class_names": [],
                "function_names": [
                  "_validate_params"
                ]
              },
              {
                "file_pattern": "sklearn/decomposition/online_lda.py",
                "class_names": [],
                "function_names": [
                  "_check_params"
                ]
              },
              {
                "file_pattern": "sklearn/utils/validation.py",
                "query": "parameter validation",
                "class_names": [],
                "function_names": []
              }
            ],
            "complete": false
          },
          "output": {
            "ranked_spans": [
              {
                "file_path": "sklearn/neighbors/nca.py",
                "span_id": "NeighborhoodComponentsAnalysis._validate_params",
                "rank": 0,
                "tokens": 849
              },
              {
                "file_path": "sklearn/decomposition/online_lda.py",
                "span_id": "LatentDirichletAllocation._check_params",
                "rank": 0,
                "tokens": 123
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "docstring",
                "rank": 0,
                "tokens": 188
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_array",
                "rank": 1,
                "tokens": 2301
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_X_y",
                "rank": 2,
                "tokens": 1235
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_non_negative",
                "rank": 5,
                "tokens": 145
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_consistent_length",
                "rank": 7,
                "tokens": 123
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "column_or_1d",
                "rank": 8,
                "tokens": 172
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "has_fit_parameter",
                "rank": 9,
                "tokens": 119
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "_num_samples",
                "rank": 10,
                "tokens": 204
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "_is_arraylike",
                "rank": 10,
                "tokens": 44
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "_ensure_no_complex_data",
                "rank": 11,
                "tokens": 56
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "_ensure_sparse_format",
                "rank": 11,
                "tokens": 690
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "assert_all_finite",
                "rank": 12,
                "tokens": 62
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "_assert_all_finite",
                "rank": 12,
                "tokens": 273
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "indexable",
                "rank": 13,
                "tokens": 150
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_symmetric",
                "rank": 14,
                "tokens": 445
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "check_is_fitted",
                "rank": 15,
                "tokens": 371
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_id": "as_float_array",
                "rank": 16,
                "tokens": 439
              }
            ],
            "search_requests": [
              {
                "file_pattern": "sklearn/neighbors/nca.py",
                "query": null,
                "code_snippet": null,
                "class_names": [],
                "function_names": [
                  "_validate_params"
                ]
              },
              {
                "file_pattern": "sklearn/decomposition/online_lda.py",
                "query": null,
                "code_snippet": null,
                "class_names": [],
                "function_names": [
                  "_check_params"
                ]
              },
              {
                "file_pattern": "sklearn/utils/validation.py",
                "query": "parameter validation",
                "code_snippet": null,
                "class_names": [],
                "function_names": []
              }
            ],
            "complete": false
          },
          "completion_cost": 0.014928,
          "input_tokens": 2776,
          "output_tokens": 440
        }
      ]
    },
    {
      "name": "IdentifyCode",
      "state": {
        "include_message_history": false,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "ranked_spans": [
          {
            "file_path": "sklearn/neighbors/nca.py",
            "span_id": "NeighborhoodComponentsAnalysis._validate_params",
            "rank": 0,
            "tokens": 849
          },
          {
            "file_path": "sklearn/decomposition/online_lda.py",
            "span_id": "LatentDirichletAllocation._check_params",
            "rank": 0,
            "tokens": 123
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "docstring",
            "rank": 0,
            "tokens": 188
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_array",
            "rank": 1,
            "tokens": 2301
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_X_y",
            "rank": 2,
            "tokens": 1235
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_non_negative",
            "rank": 5,
            "tokens": 145
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_consistent_length",
            "rank": 7,
            "tokens": 123
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "column_or_1d",
            "rank": 8,
            "tokens": 172
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "has_fit_parameter",
            "rank": 9,
            "tokens": 119
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "_num_samples",
            "rank": 10,
            "tokens": 204
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "_is_arraylike",
            "rank": 10,
            "tokens": 44
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "_ensure_no_complex_data",
            "rank": 11,
            "tokens": 56
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "_ensure_sparse_format",
            "rank": 11,
            "tokens": 690
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "assert_all_finite",
            "rank": 12,
            "tokens": 62
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "_assert_all_finite",
            "rank": 12,
            "tokens": 273
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "indexable",
            "rank": 13,
            "tokens": 150
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_symmetric",
            "rank": 14,
            "tokens": 445
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_is_fitted",
            "rank": 15,
            "tokens": 371
          },
          {
            "file_path": "sklearn/utils/validation.py",
            "span_id": "as_float_array",
            "rank": 16,
            "tokens": 439
          }
        ],
        "expand_context": true,
        "max_prompt_file_tokens": 12000
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The issue reported is that the NeighborhoodComponentsAnalysis (NCA) class in scikit-learn has strict parameter type checks that cause failures when used with GridSearchCV. Specifically, the parameters 'tol' and 'n_components' are expected to be of specific types (float and int, respectively), but GridSearchCV may pass them as different types (e.g., int for 'tol' and np.int64 for 'n_components').\n\nThe relevant code spans identified in the search results are:\n\n1. In `sklearn/neighbors/nca.py`:\n   - The `NeighborhoodComponentsAnalysis` class and its `_validate_params` method, which contains the parameter checks for 'tol' and 'n_components'.\n\n2. In `sklearn/utils/validation.py`:\n   - The `check_scalar` function, which is used in `_validate_params` to check the types of the parameters.\n\nThe `_validate_params` method in `NeighborhoodComponentsAnalysis` is directly responsible for the strict type checks that are causing the issue. The `check_scalar` function in `sklearn/utils/validation.py` is used to perform these checks.\n\nTo address the issue, the type checks in `_validate_params` need to be modified to allow for more flexible types, such as accepting both int and float for 'tol' and both int and np.int64 for 'n_components'.\n\nThe identified relevant code spans are:\n\n- `sklearn/neighbors/nca.py` (spans: NeighborhoodComponentsAnalysis, NeighborhoodComponentsAnalysis._validate_params)\n- `sklearn/utils/validation.py` (spans: check_scalar)",
            "identified_spans": [
              {
                "file_path": "sklearn/neighbors/nca.py",
                "span_ids": [
                  "NeighborhoodComponentsAnalysis",
                  "NeighborhoodComponentsAnalysis._validate_params"
                ]
              },
              {
                "file_path": "sklearn/utils/validation.py",
                "span_ids": [
                  "check_scalar"
                ]
              }
            ]
          },
          "output": {},
          "completion_cost": 0.026274,
          "input_tokens": 6773,
          "output_tokens": 397
        }
      ]
    },
    {
      "name": "DecideRelevance",
      "state": {
        "include_message_history": false,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "expand_context": true,
        "finish_after_relevant_count": 2,
        "max_prompt_file_tokens": 12000
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The issue is related to the NeighborhoodComponentsAnalysis (NCA) class failing in GridSearch due to strict parameter checks. The problem arises because parameters like 'tol' and 'n_components' are not being validated correctly when passed through GridSearchCV. The user suggests a more flexible parameter checking mechanism.\n\nRelevant files identified:\n1. sklearn/model_selection/_search.py\n2. sklearn/neighbors/nca.py\n3. sklearn/utils/estimator_checks.py\n4. sklearn/neural_network/multilayer_perceptron.py\n5. sklearn/utils/validation.py\n6. sklearn/linear_model/stochastic_gradient.py\n7. sklearn/ensemble/gradient_boosting.py\n8. sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n9. sklearn/decomposition/online_lda.py\n10. sklearn/covariance/graph_lasso_.py\n11. sklearn/base.py\n12. sklearn/mixture/base.py\n13. sklearn/linear_model/coordinate_descent.py\n14. sklearn/cluster/bicluster.py\n15. sklearn/linear_model/logistic.py\n16. benchmarks/bench_plot_lasso_path.py\n17. sklearn/tree/tree.py\n18. build_tools/generate_authors_table.py\n19. sklearn/neighbors/base.py\n20. sklearn/feature_extraction/text.py\n\nNext steps:\n1. Search for the '_validate_params' function in 'sklearn/neighbors/nca.py' to understand the current parameter validation logic.\n2. Search for the '_check_params' function in 'sklearn/decomposition/online_lda.py' to understand how parameters are validated in LDA.\n3. Search for 'check_param' function or similar in 'sklearn/utils/validation.py' to see if there's an existing utility for parameter validation.\n\nThe file context includes the '_validate_params' function in 'sklearn/neighbors/nca.py' and the 'check_scalar' function in 'sklearn/utils/validation.py'. These are relevant to the issue.",
            "relevant": true,
            "complete": true
          },
          "output": {},
          "completion_cost": 0.014382,
          "input_tokens": 2624,
          "output_tokens": 434
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "include_message_history": true,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "max_iterations": 8,
        "max_prompt_file_tokens": 12000,
        "max_tokens_in_edit_prompt": 750,
        "expand_context_with_related_spans": false,
        "allow_hallucinated_spans": false,
        "finish_on_review": true
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "To address the issue, we need to modify the `check_scalar` function in `sklearn/utils/validation.py` to handle numpy scalar types correctly. Specifically, we should allow `np.float64` for float checks and `np.int64` for int checks. This will ensure that the parameter checks in `NeighborhoodComponentsAnalysis` do not fail when using GridSearchCV with numpy scalar types.",
            "action": "modify",
            "instructions": "Update the `check_scalar` function to handle numpy scalar types correctly by allowing `np.float64` for float checks and `np.int64` for int checks.",
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_scalar"
          },
          "output": {
            "instructions": "Update the `check_scalar` function to handle numpy scalar types correctly by allowing `np.float64` for float checks and `np.int64` for int checks.",
            "file_path": "sklearn/utils/validation.py",
            "span_id": "check_scalar",
            "start_line": 944,
            "end_line": 983
          },
          "completion_cost": 0.009183,
          "input_tokens": 2366,
          "output_tokens": 139
        }
      ]
    },
    {
      "name": "EditCode",
      "state": {
        "include_message_history": true,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "max_iterations": 8,
        "instructions": "Update the `check_scalar` function to handle numpy scalar types correctly by allowing `np.float64` for float checks and `np.int64` for int checks.",
        "file_path": "sklearn/utils/validation.py",
        "span_id": "check_scalar",
        "start_line": 944,
        "end_line": 983,
        "show_initial_message": true,
        "show_file_context": false,
        "verify": true,
        "chain_of_thought": false,
        "max_prompt_file_tokens": 8000
      },
      "actions": [
        {
          "action": {
            "content": "<replace>\ndef check_scalar(x, name, target_type, min_val=None, max_val=None):\n    \"\"\"Validate scalar parameters type and value.\n\n    Parameters\n    ----------\n    x : object\n        The scalar parameter to validate.\n\n    name : str\n        The name of the parameter to be printed in error messages.\n\n    target_type : type or tuple\n        Acceptable data types for the parameter.\n\n    min_val : float or int, optional (default=None)\n        The minimum valid value the parameter can take. If None (default) it\n        is implied that the parameter does not have a lower bound.\n\n    max_val : float or int, optional (default=None)\n        The maximum valid value the parameter can take. If None (default) it\n        is implied that the parameter does not have an upper bound.\n\n    Raises\n    -------\n    TypeError\n        If the parameter's type does not match the desired type.\n\n    ValueError\n        If the parameter's value violates the given bounds.\n    \"\"\"\n\n    if not isinstance(x, target_type) and not (isinstance(x, (np.float64, np.int64)) and target_type in [float, int]):\n        raise TypeError('`{}` must be an instance of {}, not {}.'\n                        .format(name, target_type, type(x)))\n\n    if min_val is not None and x < min_val:\n        raise ValueError('`{}`= {}, must be >= {}.'.format(name, x, min_val))\n\n    if max_val is not None and x > max_val:\n        raise ValueError('`{}`= {}, must be <= {}.'.format(name, x, max_val))\n"
          },
          "output": {
            "message": "Applied the change to sklearn/utils/validation.py.",
            "diff": "--- sklearn/utils/validation.py\n+++ sklearn/utils/validation.py\n@@ -972,7 +972,7 @@\n         If the parameter's value violates the given bounds.\n     \"\"\"\n \n-    if not isinstance(x, target_type):\n+    if not isinstance(x, target_type) and not (isinstance(x, (np.float64, np.int64)) and target_type in [float, int]):\n         raise TypeError('`{}` must be an instance of {}, not {}.'\n                         .format(name, target_type, type(x)))\n \n",
            "verification_errors": []
          },
          "completion_cost": 0.010779,
          "input_tokens": 1888,
          "output_tokens": 341
        }
      ]
    },
    {
      "name": "PlanToCode",
      "state": {
        "include_message_history": true,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 2000,
        "max_iterations": 8,
        "message": "Applied the change to sklearn/utils/validation.py.",
        "diff": "--- sklearn/utils/validation.py\n+++ sklearn/utils/validation.py\n@@ -972,7 +972,7 @@\n         If the parameter's value violates the given bounds.\n     \"\"\"\n \n-    if not isinstance(x, target_type):\n+    if not isinstance(x, target_type) and not (isinstance(x, (np.float64, np.int64)) and target_type in [float, int]):\n         raise TypeError('`{}` must be an instance of {}, not {}.'\n                         .format(name, target_type, type(x)))\n \n",
        "verification_errors": [],
        "max_prompt_file_tokens": 12000,
        "max_tokens_in_edit_prompt": 750,
        "expand_context_with_related_spans": false,
        "allow_hallucinated_spans": false,
        "finish_on_review": true
      },
      "actions": [
        {
          "action": {
            "scratch_pad": "The `check_scalar` function has been updated to handle numpy scalar types correctly. Now, we need to ensure that the `NeighborhoodComponentsAnalysis` class in `sklearn/neighbors/nca.py` uses this updated function for parameter validation.",
            "action": "finish",
            "finish": "The issue has been resolved by updating the `check_scalar` function to handle numpy scalar types correctly. This ensures that the parameter checks in `NeighborhoodComponentsAnalysis` do not fail when using GridSearchCV with numpy scalar types."
          },
          "output": {
            "message": "The issue has been resolved by updating the `check_scalar` function to handle numpy scalar types correctly. This ensures that the parameter checks in `NeighborhoodComponentsAnalysis` do not fail when using GridSearchCV with numpy scalar types."
          },
          "completion_cost": 0.009588000000000001,
          "input_tokens": 2676,
          "output_tokens": 104
        }
      ]
    },
    {
      "name": "Finished",
      "state": {
        "include_message_history": false,
        "model": "gpt-4o",
        "temperature": 0.0,
        "max_tokens": 1000,
        "message": "The issue has been resolved by updating the `check_scalar` function to handle numpy scalar types correctly. This ensures that the parameter checks in `NeighborhoodComponentsAnalysis` do not fail when using GridSearchCV with numpy scalar types.",
        "output": {
          "max_tokens": 2000,
          "max_prompt_file_tokens": 12000
        }
      },
      "actions": []
    }
  ],
  "info": {
    "evaluation_name": "20240705_sima_fulltest",
    "instance_id": "scikit-learn__scikit-learn-14092",
    "status": "finished",
    "duration": 216.7010235786438,
    "total_cost": 0.749358,
    "submission": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..7f221eab5 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,7 +299,7 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            check_scalar(self.n_components, 'n_components', (int, np.integer), 1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -319,7 +319,7 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                          self.components_.shape[1]))\n \n         check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n+        check_scalar(self.tol, 'tol', (float, np.floating), 0.)\n         check_scalar(self.verbose, 'verbose', int, 0)\n \n         if self.callback is not None:\n"
  }
}