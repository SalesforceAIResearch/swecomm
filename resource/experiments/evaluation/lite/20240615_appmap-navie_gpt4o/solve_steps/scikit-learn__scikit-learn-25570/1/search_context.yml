- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    Examples
        --------
        >>> from sklearn.preprocessing import StandardScaler, OneHotEncoder
        >>> from sklearn.compose import make_column_transformer
        >>> make_column_transformer(
        ...     (StandardScaler(), ['numerical_column']),
        ...     (OneHotEncoder(), ['categorical_column']))
        ColumnTransformer(transformers=[('standardscaler', StandardScaler(...),
                                         ['numerical_column']),
                                        ('onehotencoder', OneHotEncoder(...),
                                         ['categorical_column'])])
        """
        # transformer_weights keyword is not passed through because the user
        # would need to know the automatically generated names of the transformers
        transformer_list = _get_transformer_list(transformers)
        return ColumnTransformer(
            transformer_list,
            n_jobs=n_jobs,
            remainder=remainder,
            sparse_threshold=sparse_threshold,
            verbose=verbose,
  location: sklearn/compose/_column_transformer.py:1025-1045
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    def fit(self, X, y=None, **fit_params):
            """Fit the model.

            Fit all the transformers one after the other and transform the
            data. Finally, fit the transformed data using the final estimator.

            Parameters
            ----------
            X : iterable
                Training data. Must fulfill input requirements of first step of the
                pipeline.

            y : iterable, default=None
                Training targets. Must fulfill label requirements for all steps of
                the pipeline.

            **fit_params : dict of string -> object
                Parameters passed to the ``fit`` method of each step, where
                each parameter name is prefixed such that parameter ``p`` for step
                ``s`` has key ``s__p``.
  location: sklearn/pipeline.py:388-407
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    output_config = _get_output_config("transform", self)
            for name, trans, columns in transformers:
                if replace_strings:
                    # replace 'passthrough' with identity transformer and
                    # skip in case of 'drop'
                    if trans == "passthrough":
                        trans = FunctionTransformer(
                            accept_sparse=True,
                            check_inverse=False,
                            feature_names_out="one-to-one",
                        ).set_output(transform=output_config["dense"])
                    elif trans == "drop":
                        continue
                    elif _is_empty_column_selection(columns):
                        continue

                if column_as_strings:
                    # Convert all columns to using their string labels
                    columns_is_scalar = np.isscalar(columns)

                    indices = self._transformer_to_input_indices[name]
                    columns = self.feature_names_in_[indices]
  location: sklearn/compose/_column_transformer.py:381-402
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    name : str
                Like in Pipeline and FeatureUnion, this allows the transformer and
                its parameters to be set using ``set_params`` and searched in grid
                search.
            transformer : {'drop', 'passthrough'} or estimator
                Estimator must support :term:`fit` and :term:`transform`.
                Special-cased strings 'drop' and 'passthrough' are accepted as
                well, to indicate to drop the columns or to pass them through
                untransformed, respectively.
            columns :  str, array-like of str, int, array-like of int, \
                    array-like of bool, slice or callable
                Indexes the data on its second axis. Integers are interpreted as
                positional columns, while strings can reference DataFrame columns
                by name.  A scalar string or int should be used where
                ``transformer`` expects X to be a 1d array-like (vector),
                otherwise a 2d array will be passed to the transformer.
  location: sklearn/compose/_column_transformer.py:60-75
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    # Estimator interface

        def _fit(self, X, y=None, **fit_params_steps):
            # shallow copy of steps - this should really be steps_
            self.steps = list(self.steps)
            self._validate_steps()
            # Setup the memory
            memory = check_memory(self.memory)

            fit_transform_one_cached = memory.cache(_fit_transform_one)

            for step_idx, name, transformer in self._iter(
                with_final=False, filter_passthrough=False
            ):
                if transformer is None or transformer == "passthrough":
                    with _print_elapsed_time("Pipeline", self._log_message(step_idx)):
                        continue
  location: sklearn/pipeline.py:348-364
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    return sparse.hstack(converted_Xs).tocsr()
            else:
                Xs = [f.toarray() if sparse.issparse(f) else f for f in Xs]
                config = _get_output_config("transform", self)
                if config["dense"] == "pandas" and all(hasattr(X, "iloc") for X in Xs):
                    pd = check_pandas_support("transform")
                    output = pd.concat(Xs, axis=1)

                    # If all transformers define `get_feature_names_out`, then transform
                    # will adjust the column names to be consistent with
                    # verbose_feature_names_out. Here we prefix the feature names if
                    # verbose_feature_names_out=True.

                    if not self.verbose_feature_names_out:
                        return output
  location: sklearn/compose/_column_transformer.py:849-863
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: >-
    import numpy as np

    from scipy import sparse


    from ..base import clone, TransformerMixin

    from ..utils._estimator_html_repr import _VisualBlock

    from ..pipeline import _fit_transform_one, _transform_one, _name_estimators

    from ..preprocessing import FunctionTransformer

    from ..utils import Bunch

    from ..utils import _safe_indexing

    from ..utils import _get_column_indices

    from ..utils._param_validation import HasMethods, Interval, StrOptions,
    Hidden

    from ..utils._set_output import _get_output_config, _safe_set_output

    from ..utils import check_pandas_support

    from ..utils.metaestimators import _BaseComposition

    from ..utils.validation import check_array, check_is_fitted,
    _check_feature_names_in

    from ..utils.parallel import delayed, Parallel



    __all__ = ["ColumnTransformer", "make_column_transformer",
    "make_column_selector"]
  location: sklearn/compose/_column_transformer.py:13-31
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    Fits all the transformers one after the other and transform the
            data. Then uses `fit_transform` on transformed data with the final
            estimator.

            Parameters
            ----------
            X : iterable
                Training data. Must fulfill input requirements of first step of the
                pipeline.

            y : iterable, default=None
                Training targets. Must fulfill label requirements for all steps of
                the pipeline.

            **fit_params : dict of string -> object
                Parameters passed to the ``fit`` method of each step, where
                each parameter name is prefixed such that parameter ``p`` for step
                ``s`` has key ``s__p``.

            Returns
            -------
            Xt : ndarray of shape (n_samples, n_transformed_features)
                Transformed samples.
            """
            self._validate_params()
            fit_params_steps = self._check_fit_params(**fit_params)
            Xt = self._fit(X, y, **fit_params_steps)
  location: sklearn/pipeline.py:427-453
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    class TransformerMixin(_SetOutputMixin):
        """Mixin class for all transformers in scikit-learn.

        If :term:`get_feature_names_out` is defined, then `BaseEstimator` will
        automatically wrap `transform` and `fit_transform` to follow the `set_output`
        API. See the :ref:`developer_api_set_output` for details.

        :class:`base.OneToOneFeatureMixin` and
        :class:`base.ClassNamePrefixFeaturesOutMixin` are helpful mixins for
        defining :term:`get_feature_names_out`.
        """

        def fit_transform(self, X, y=None, **fit_params):
            """
            Fit to data, then transform it.

            Fits transformer to `X` and `y` with optional parameters `fit_params`
            and returns a transformed version of `X`.

            Parameters
            ----------
            X : array-like of shape (n_samples, n_features)
                Input samples.
  location: sklearn/base.py:831-853
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    if not self.verbose_feature_names_out:
                        return output

                    transformer_names = [
                        t[0] for t in self._iter(fitted=True, replace_strings=True)
                    ]
                    feature_names_outs = [X.columns for X in Xs]
                    names_out = self._add_prefix_for_feature_names_out(
                        list(zip(transformer_names, feature_names_outs))
                    )
                    output.columns = names_out
                    return output

                return np.hstack(Xs)
  location: sklearn/compose/_column_transformer.py:862-875
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    remainder : {'drop', 'passthrough'} or estimator, default='drop'
            By default, only the specified columns in `transformers` are
            transformed and combined in the output, and the non-specified
            columns are dropped. (default of ``'drop'``).
            By specifying ``remainder='passthrough'``, all remaining columns that
            were not specified in `transformers`, but present in the data passed
            to `fit` will be automatically passed through. This subset of columns
            is concatenated with the output of the transformers. For dataframes,
            extra columns not seen during `fit` will be excluded from the output
            of `transform`.
            By setting ``remainder`` to be an estimator, the remaining
            non-specified columns will use the ``remainder`` estimator. The
            estimator must support :term:`fit` and :term:`transform`.
            Note that using this feature requires that the DataFrame columns
  location: sklearn/compose/_column_transformer.py:80-93
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    remainder : {'drop', 'passthrough'} or estimator, default='drop'
            By default, only the specified columns in `transformers` are
            transformed and combined in the output, and the non-specified
            columns are dropped. (default of ``'drop'``).
            By specifying ``remainder='passthrough'``, all remaining columns that
            were not specified in `transformers` will be automatically passed
            through. This subset of columns is concatenated with the output of
            the transformers.
            By setting ``remainder`` to be an estimator, the remaining
            non-specified columns will use the ``remainder`` estimator. The
            estimator must support :term:`fit` and :term:`transform`.
  location: sklearn/compose/_column_transformer.py:976-986
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    class Pipeline(_BaseComposition):
        """
        Pipeline of transforms with a final estimator.

        Sequentially apply a list of transforms and a final estimator.
        Intermediate steps of the pipeline must be 'transforms', that is, they
        must implement `fit` and `transform` methods.
        The final estimator only needs to implement `fit`.
        The transformers in the pipeline can be cached using ``memory`` argument.

        The purpose of the pipeline is to assemble several steps that can be
        cross-validated together while setting different parameters. For this, it
        enables setting parameters of the various steps using their names and the
        parameter name separated by a `'__'`, as in the example below. A step's
        estimator may be replaced entirely by setting the parameter with its name
        to another estimator, or a transformer removed by setting it to
        `'passthrough'` or `None`.

        Read more in the :ref:`User Guide <pipeline>`.

        .. versionadded:: 0.5
  location: sklearn/pipeline.py:53-73
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    if hasattr(memory, "location") and memory.location is None:
                    # we do not clone when caching is disabled to
                    # preserve backward compatibility
                    cloned_transformer = transformer
                else:
                    cloned_transformer = clone(transformer)
                # Fit or load from cache the current transformer
                X, fitted_transformer = fit_transform_one_cached(
                    cloned_transformer,
                    X,
                    y,
                    None,
                    message_clsname="Pipeline",
                    message=self._log_message(step_idx),
                    **fit_params_steps[name],
                )
                # Replace the transformer of the step with the fitted
                # transformer. This is necessary when loading the transformer
                # from the cache.
                self.steps[step_idx] = (name, fitted_transformer)
            return X

        def fit(self, X, y=None, **fit_params):
            """Fit the model.
  location: sklearn/pipeline.py:366-389
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    If a feature value is a sequence or set of strings, this transformer
        will iterate over the values and will count the occurrences of each string
        value.

        However, note that this transformer will only do a binary one-hot encoding
        when feature values are of type string. If categorical features are
        represented as numeric values such as int or iterables of strings, the
        DictVectorizer can be followed by
        :class:`~sklearn.preprocessing.OneHotEncoder` to complete
        binary one-hot encoding.

        Features that do not occur in a sample (mapping) will have a zero value
        in the resulting array/matrix.

        Read more in the :ref:`User Guide <dict_feature_extraction>`.
  location: sklearn/feature_extraction/_dict_vectorizer.py:31-45
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    @available_if(_final_estimator_has("fit_predict"))
        def fit_predict(self, X, y=None, **fit_params):
            """Transform the data, and apply `fit_predict` with the final estimator.

            Call `fit_transform` of each transformer in the pipeline. The
            transformed data are finally passed to the final estimator that calls
            `fit_predict` method. Only valid if the final estimator implements
            `fit_predict`.

            Parameters
            ----------
            X : iterable
                Training data. Must fulfill input requirements of first step of
                the pipeline.

            y : iterable, default=None
                Training targets. Must fulfill label requirements for all steps
                of the pipeline.

            **fit_params : dict of string -> object
                Parameters passed to the ``fit`` method of each step, where
                each parameter name is prefixed such that parameter ``p`` for step
                ``s`` has key ``s__p``.
  location: sklearn/pipeline.py:499-521
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    Returns
            -------
            self : object
                Pipeline with fitted steps.
            """
            self._validate_params()
            fit_params_steps = self._check_fit_params(**fit_params)
            Xt = self._fit(X, y, **fit_params_steps)
            with _print_elapsed_time("Pipeline", self._log_message(len(self.steps) - 1)):
                if self._final_estimator != "passthrough":
                    fit_params_last_step = fit_params_steps[self.steps[-1][0]]
                    self._final_estimator.fit(Xt, y, **fit_params_last_step)

            return self

        def fit_transform(self, X, y=None, **fit_params):
            """Fit the model and transform with the final estimator.

            Fits all the transformers one after the other and transform the
            data. Then uses `fit_transform` on transformed data with the final
            estimator.
  location: sklearn/pipeline.py:409-429
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    return self._hstack(Xs)

        def _hstack(self, Xs):
            config = _get_output_config("transform", self)
            if config["dense"] == "pandas" and all(hasattr(X, "iloc") for X in Xs):
                pd = check_pandas_support("transform")
                return pd.concat(Xs, axis=1)

            if any(sparse.issparse(f) for f in Xs):
                Xs = sparse.hstack(Xs).tocsr()
            else:
                Xs = np.hstack(Xs)
            return Xs

        def _update_transformer_list(self, transformers):
            transformers = iter(transformers)
            self.transformer_list[:] = [
                (name, old if old == "drop" else next(transformers))
                for name, old in self.transformer_list
            ]

        @property
        def n_features_in_(self):
            """Number of features seen during :term:`fit`."""

            # X is passed to all transformers so we just delegate to the first one
            return self.transformer_list[0][1].n_features_in_
  location: sklearn/pipeline.py:1277-1303
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    strategy : str, default='mean'
            The imputation strategy.

            - If "mean", then replace missing values using the mean along
              each column. Can only be used with numeric data.
            - If "median", then replace missing values using the median along
              each column. Can only be used with numeric data.
            - If "most_frequent", then replace missing using the most frequent
              value along each column. Can be used with strings or numeric data.
              If there is more than one such value, only the smallest is returned.
            - If "constant", then replace missing values with fill_value. Can be
              used with strings or numeric data.

            .. versionadded:: 0.20
               strategy="constant" for fixed value imputation.
  location: sklearn/impute/_base.py:162-176
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    all_indices = set(chain(*non_dropped_indices))
                all_names = set(self.feature_names_in_[ind] for ind in all_indices)

                diff = all_names - set(X.columns)
                if diff:
                    raise ValueError(f"columns are missing: {diff}")
            else:
                # ndarray was used for fitting or transforming, thus we only
                # check that n_features_in_ is consistent
                self._check_n_features(X, reset=False)

            Xs = self._fit_transform(
                X,
                None,
                _transform_one,
                fitted=True,
                column_as_strings=fit_dataframe_and_transform_dataframe,
            )
            self._validate_output(Xs)

            if not Xs:
                # All transformers are None
                return np.zeros((X.shape[0], 0))

            return self._hstack(list(Xs))

        def _hstack(self, Xs):
            """Stacks Xs horizontally.
  location: sklearn/compose/_column_transformer.py:798-825
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    # List of tuples (name, feature_names_out)
            transformer_with_feature_names_out = []
            for name, trans, column, _ in self._iter(fitted=True):
                feature_names_out = self._get_feature_name_out_for_transformer(
                    name, trans, column, input_features
                )
                if feature_names_out is None:
                    continue
                transformer_with_feature_names_out.append((name, feature_names_out))

            if not transformer_with_feature_names_out:
                # No feature names
                return np.array([], dtype=object)

            return self._add_prefix_for_feature_names_out(
                transformer_with_feature_names_out
            )

        def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):
            """Add prefix for feature names out that includes the transformer names.
  location: sklearn/compose/_column_transformer.py:515-534
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    transformer : {'drop', 'passthrough'} or estimator
                Estimator must support :term:`fit` and :term:`transform`.
                Special-cased strings 'drop' and 'passthrough' are accepted as
                well, to indicate to drop the columns or to pass them through
                untransformed, respectively.
            columns : str,  array-like of str, int, array-like of int, slice, \
                    array-like of bool or callable
                Indexes the data on its second axis. Integers are interpreted as
                positional columns, while strings can reference DataFrame columns
                by name. A scalar string or int should be used where
                ``transformer`` expects X to be a 1d array-like (vector),
                otherwise a 2d array will be passed to the transformer.
                A callable is passed the input data `X` and can return any of the
                above. To select multiple columns by name or dtype, you can use
                :obj:`make_column_selector`.
  location: sklearn/compose/_column_transformer.py:960-974
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    def _validate_transformer_weights(self):
            if not self.transformer_weights:
                return

            transformer_names = set(name for name, _ in self.transformer_list)
            for name in self.transformer_weights:
                if name not in transformer_names:
                    raise ValueError(
                        f'Attempting to weight transformer "{name}", '
                        "but it is not present in transformer_list."
                    )

        def _iter(self):
            """
            Generate (name, trans, weight) tuples excluding None and
            'drop' transformers.
            """

            get_weight = (self.transformer_weights or {}).get

            for name, trans in self.transformer_list:
                if trans == "drop":
                    continue
                if trans == "passthrough":
                    trans = FunctionTransformer(feature_names_out="one-to-one")
                yield (name, trans, get_weight(name))
  location: sklearn/pipeline.py:1119-1144
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    - `"default"`: Default output format of a transformer
                - `"pandas"`: DataFrame output
                - `None`: Transform configuration is unchanged

            Returns
            -------
            self : estimator instance
                Estimator instance.
            """
            for _, _, step in self._iter():
                _safe_set_output(step, transform=transform)
            return self

        def get_params(self, deep=True):
            """Get parameters for this estimator.

            Returns the parameters given in the constructor as well as the
            estimators contained within the `steps` of the `Pipeline`.

            Parameters
            ----------
            deep : bool, default=True
                If True, will return the parameters for this estimator and
                contained subobjects that are estimators.
  location: sklearn/pipeline.py:167-190
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    - `"default"`: Default output format of a transformer
                - `"pandas"`: DataFrame output
                - `None`: Transform configuration is unchanged

            Returns
            -------
            self : estimator instance
                Estimator instance.
            """
            super().set_output(transform=transform)
            transformers = (
                trans
                for _, trans, _ in chain(
                    self.transformers, getattr(self, "transformers_", [])
                )
                if trans not in {"passthrough", "drop"}
            )
            for trans in transformers:
                _safe_set_output(trans, transform=transform)

            return self

        def get_params(self, deep=True):
            """Get parameters for this estimator.

            Returns the parameters given in the constructor as well as the
            estimators contained within the `transformers` of the
            `ColumnTransformer`.
  location: sklearn/compose/_column_transformer.py:285-312
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    # BaseEstimator interface
        _required_parameters = ["steps"]

        _parameter_constraints: dict = {
            "steps": [list, Hidden(tuple)],
            "memory": [None, str, HasMethods(["cache"])],
            "verbose": ["boolean"],
        }

        def __init__(self, steps, *, memory=None, verbose=False):
            self.steps = steps
            self.memory = memory
            self.verbose = verbose

        def set_output(self, *, transform=None):
            """Set the output container when `"transform"` and `"fit_transform"` are called.

            Calling `set_output` will set the output of all estimators in `steps`.

            Parameters
            ----------
            transform : {"default", "pandas"}, default=None
                Configure output of `transform` and `fit_transform`.

                - `"default"`: Default output format of a transformer
                - `"pandas"`: DataFrame output
                - `None`: Transform configuration is unchanged
  location: sklearn/pipeline.py:143-169
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    transformers = [
                        replace_passthrough(*trans) for trans in self.transformers_
                    ]
                else:
                    transformers = self.transformers_
            else:
                # interleave the validated column specifiers
                transformers = [
                    (name, trans, column)
                    for (name, trans, _), column in zip(self.transformers, self._columns)
                ]
                # add transformer tuple for remainder
                if self._remainder[2]:
                    transformers = chain(transformers, [self._remainder])
            get_weight = (self.transformer_weights or {}).get
  location: sklearn/compose/_column_transformer.py:365-379
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: |-
    Returns
            -------
            self : object
                Pipeline class instance.
            """
            self._set_params("steps", **kwargs)
            return self

        def _validate_steps(self):
            names, estimators = zip(*self.steps)

            # validate names
            self._validate_names(names)

            # validate estimators
            transformers = estimators[:-1]
            estimator = estimators[-1]

            for t in transformers:
                if t is None or t == "passthrough":
                    continue
                if not (hasattr(t, "fit") or hasattr(t, "fit_transform")) or not hasattr(
                    t, "transform"
                ):
                    raise TypeError(
                        "All intermediate steps should be "
                        "transformers and implement fit and transform "
                        "or be the string 'passthrough' "
                        "'%s' (type %s) doesn't" % (t, type(t))
                    )
  location: sklearn/pipeline.py:213-242
- directory: /home/runner/work/_temp/tmp_897ng0y/scikit-learn__scikit-learn__1.3-0
  type: code-snippet
  content: >-
    :class:`ColumnTransformer` can be configured with a transformer that
    requires
        a 1d array by setting the column to a string:

        >>> from sklearn.feature_extraction import FeatureHasher
        >>> from sklearn.preprocessing import MinMaxScaler
        >>> import pandas as pd   # doctest: +SKIP
        >>> X = pd.DataFrame({
        ...     "documents": ["First item", "second one here", "Is this the last?"],
        ...     "width": [3, 4, 5],
        ... })  # doctest: +SKIP
        >>> # "documents" is a string which configures ColumnTransformer to
        >>> # pass the documents column as a 1d array to the FeatureHasher
        >>> ct = ColumnTransformer(
        ...     [("text_preprocess", FeatureHasher(input_type="string"), "documents"),
        ...      ("num_preprocess", MinMaxScaler(), ["width"])])
        >>> X_trans = ct.fit_transform(X)  # doctest: +SKIP
        """

        _required_parameters = ["transformers"]
  location: sklearn/compose/_column_transformer.py:198-216
