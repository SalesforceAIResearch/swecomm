diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py
index 8376b487..ee43d320 100644
--- a/xarray/core/dataset.py
+++ b/xarray/core/dataset.py
@@ -3881,7 +3881,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):
         return result
 
     def update(self, other: "CoercibleMapping") -> "Dataset":
-        """Update this dataset's variables with those from another dataset.
+        """Update this dataset's variables with those from another dataset,
+        maintaining Dask chunks in DataArray where applicable.
 
         Parameters
         ----------
@@ -3906,7 +3907,22 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):
             If any dimensions would have inconsistent sizes in the updated
             dataset.
         """
-        merge_result = dataset_update_method(self, other)
+        # Ensure data is aligned
+        other_ds = as_dataset(other)
+        self, other_ds = align(self, other_ds, join="outer", copy=False)
+
+        # Maintain chunks if original is chunked
+        for name, var in self.variables.items():
+            if name in other_ds.variables:
+                other_var = other_ds.variables[name]
+                if (
+                    hasattr(var.data, "chunks")
+                    and hasattr(other_var.data, "chunks")
+                    and var.data.chunks != other_var.data.chunks
+                ):
+                    other_ds.variables[name].data = var.data.rechunk(var.data.chunks)
+        
+        merge_result = dataset_update_method(self, other_ds)
         return self._replace(inplace=True, **merge_result._asdict())
 
     def merge(
