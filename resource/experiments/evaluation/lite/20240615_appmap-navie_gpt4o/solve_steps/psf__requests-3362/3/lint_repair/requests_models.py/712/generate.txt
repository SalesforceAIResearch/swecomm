@generate /noformat /noterms
                    
<lint-errors>
requests/models.py:706:9: E999 IndentationError: expected an indented block
</lint-errors>
<diff>--- /home/runner/work/SWE-bench/SWE-bench/logs/solve/psf__requests-3362/3/diff/requests_models.py/pre/base	2024-06-14 18:17:12.855118926 +0000
+++ /home/runner/work/SWE-bench/SWE-bench/logs/solve/psf__requests-3362/3/diff/requests_models.py/pre/updated	2024-06-14 18:17:12.855118926 +0000
@@ -656,10 +656,18 @@
         large responses.  The chunk size is the number of bytes it should
         read into memory.  This is not necessarily the length of each item
         returned as decoding can take place.
-
+    
         If decode_unicode is True, content will be decoded using the best
         available encoding based on the response.
         """
+        def decode_unicode_chunk(chunk):
+            if chunk:
+                enc = self.encoding or self.apparent_encoding
+                try:
+                    return chunk.decode(enc, errors='replace')
+                except (LookupError, TypeError):
+                    return chunk.decode(errors='replace')
+            return chunk
 
         def generate():
             # Special case for urllib3.
@@ -695,11 +703,11 @@
         chunks = reused_chunks if self._content_consumed else stream_chunks
 
         if decode_unicode:
-            chunks = stream_decode_response_unicode(chunks, self)
+            chunks = (decode_unicode_chunk(chunk) for chunk in chunks)
 
         return chunks
 
-    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
+        def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
         """Iterates over the response data, one line at a time.  When
         stream=True is set on the request, this avoids reading the
         content at once into memory for large responses.

</diff>
<file>
<path>requests/models.py
</path>
<content>
700: 
701:         stream_chunks = generate()
702: 
703:         chunks = reused_chunks if self._content_consumed else stream_chunks
704: 
705:         if decode_unicode:
706:             chunks = (decode_unicode_chunk(chunk) for chunk in chunks)
707: 
708:         return chunks
709: 
710:         def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
711:         """Iterates over the response data, one line at a time.  When
712:         stream=True is set on the request, this avoids reading the
713:         content at once into memory for large responses.

</content>
</file>
