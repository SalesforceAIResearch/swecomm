diff --git a/requests/models.py b/requests/models.py
index fbb3c7e6..ca41678c 100644
--- a/requests/models.py
+++ b/requests/models.py
@@ -656,10 +656,18 @@ class Response(object):
         large responses.  The chunk size is the number of bytes it should
         read into memory.  This is not necessarily the length of each item
         returned as decoding can take place.
-
+    
         If decode_unicode is True, content will be decoded using the best
         available encoding based on the response.
         """
+        def decode_unicode_chunk(chunk):
+            if chunk:
+                enc = self.encoding or self.apparent_encoding
+                try:
+                    return chunk.decode(enc, errors='replace')
+                except (LookupError, TypeError):
+                    return chunk.decode(errors='replace')
+            return chunk
 
         def generate():
             # Special case for urllib3.
@@ -695,11 +703,11 @@ class Response(object):
         chunks = reused_chunks if self._content_consumed else stream_chunks
 
         if decode_unicode:
-            chunks = stream_decode_response_unicode(chunks, self)
+            chunks = (decode_unicode_chunk(chunk) for chunk in chunks)
 
         return chunks
 
-    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
+        def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
         """Iterates over the response data, one line at a time.  When
         stream=True is set on the request, this avoids reading the
         content at once into memory for large responses.
