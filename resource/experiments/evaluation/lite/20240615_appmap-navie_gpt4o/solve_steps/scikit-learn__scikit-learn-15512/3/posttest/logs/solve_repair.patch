diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py
index 4806afee9..5cf4fec70 100644
--- a/sklearn/cluster/_affinity_propagation.py
+++ b/sklearn/cluster/_affinity_propagation.py
@@ -118,10 +118,13 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,
 
     preference = np.array(preference)
 
-    if (n_samples == 1 or
-            _equal_similarities_and_preferences(S, preference)):
-        # It makes no sense to run the algorithm in this case, so return 1 or
-        # n_samples clusters, depending on preferences
+    if n_samples == 1:
+        # It makes no sense to run the algorithm in this case, return 1 cluster
+        warnings.warn("Only one sample provided. Returning this sample as the cluster center.")
+        return ((np.array([0]), np.array([0]), 0) if return_n_iter else (np.array([0]), np.array([0])))
+
+    if _equal_similarities_and_preferences(S, preference):
+        # All samples have mutually equal similarities and preferences
         warnings.warn("All samples have mutually equal similarities. "
                       "Returning arbitrary cluster center(s).")
         if preference.flat[0] >= S.flat[n_samples - 1]:
@@ -191,27 +194,28 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,
 
         if it >= convergence_iter:
             se = np.sum(e, axis=1)
-            unconverged = (np.sum((se == convergence_iter) + (se == 0))
-                           != n_samples)
-            if (not unconverged and (K > 0)) or (it == max_iter):
+            if (np.all(se == convergence_iter) or np.all(se == 0)) and (K > 0):
                 if verbose:
                     print("Converged after %d iterations." % it)
+                converged = True
                 break
+            converged = False
     else:
+        converged = False
         if verbose:
             print("Did not converge")
 
-    I = np.flatnonzero(E)
-    K = I.size  # Identify exemplars
+    exemplar_indices = np.flatnonzero(E)
+    K = exemplar_indices.size  # Identify exemplars
 
-    if K > 0:
-        c = np.argmax(S[:, I], axis=1)
-        c[I] = np.arange(K)  # Identify clusters
+    if converged and K > 0:
+        c = np.argmax(S[:, exemplar_indices], axis=1)
+        c[exemplar_indices] = np.arange(K)  # Identify clusters
         # Refine the final set of exemplars and clusters and return results
         for k in range(K):
             ii = np.where(c == k)[0]
             j = np.argmax(np.sum(S[ii[:, np.newaxis], ii], axis=0))
-            I[k] = ii[j]
+            exemplar_indices[k] = ii[j]
 
         c = np.argmax(S[:, I], axis=1)
         c[I] = np.arange(K)
@@ -220,10 +224,11 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,
         cluster_centers_indices = np.unique(labels)
         labels = np.searchsorted(cluster_centers_indices, labels)
     else:
-        warnings.warn("Affinity propagation did not converge, this model "
-                      "will not have any cluster centers.", ConvergenceWarning)
+        cluster_centers_indices = np.array([])
         labels = np.array([-1] * n_samples)
-        cluster_centers_indices = []
+        if not converged:
+            warnings.warn("Affinity propagation did not converge, this model "
+                          "will not have any cluster centers.", ConvergenceWarning)
 
     if return_n_iter:
         return cluster_centers_indices, labels, it + 1
