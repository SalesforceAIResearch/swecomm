{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\nindex 29c7e19d7..2a3260fc6 100644\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -111,7 +111,7 @@ class TempPathFactory:\n         else:\n             from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n             temproot = Path(from_env or tempfile.gettempdir()).resolve()\n-            user = get_user() or \"unknown\"\n+            user = sanitize_username(get_user() or \"unknown\")\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n             rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n@@ -158,6 +158,10 @@ def get_user() -> Optional[str]:\n     except (ImportError, KeyError):\n         return None\n \n+def sanitize_username(username: str) -> str:\n+    \"\"\"Sanitize the username to remove or replace illegal characters for directory names.\"\"\"\n+    return re.sub(r'[<>:\"/\\\\|?*]', '_', username)\n+\n \n def pytest_configure(config: Config) -> None:\n     \"\"\"Create a TempdirFactory and attach it to the config object.\n", "instance_id": "pytest-dev__pytest-8365"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex b6adb7ceb..d09dc0615 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -108,6 +108,10 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n             obj = attrgetter(obj, mangled_name)\n             logger.debug('[autodoc] => %r', obj)\n             object_name = attrname\n+        # Check for empty __all__ attribute\n+        if hasattr(module, '__all__') and not module.__all__:\n+            return [module, parent, object_name, []]\n+\n         return [module, parent, object_name, obj]\n     except (AttributeError, ImportError) as exc:\n         if isinstance(exc, AttributeError) and exc_on_importing:\n", "instance_id": "sphinx-doc__sphinx-8595"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/_io/saferepr.py b/src/_pytest/_io/saferepr.py\nindex 23af4d0bb..453e1c46e 100644\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -8,8 +8,8 @@ def _try_repr_or_str(obj):\n         return repr(obj)\n     except (KeyboardInterrupt, SystemExit):\n         raise\n-    except BaseException:\n-        return '{}(\"{}\")'.format(type(obj).__name__, obj)\n+    except BaseException as exc:\n+        return '{}(\"{}\")'.format(type(exc).__name__, str(exc))\n \n \n def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n@@ -17,8 +17,8 @@ def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n         exc_info = _try_repr_or_str(exc)\n     except (KeyboardInterrupt, SystemExit):\n         raise\n-    except BaseException as exc:\n-        exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc))\n+    except BaseException as exc2:\n+        exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc2))\n     return \"<[{} raised in repr()] {} object at 0x{:x}>\".format(\n         exc_info, obj.__class__.__name__, id(obj)\n     )\n", "instance_id": "pytest-dev__pytest-7168"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex af0815d41d..ddc79ab885 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2021,9 +2021,13 @@ class Axis(martist.Artist):\n         other limits, you should set the limits explicitly after setting the\n         ticks.\n         \"\"\"\n+        if kwargs:\n+            _api.check_in_list(mtext.Text().properties().keys(), **kwargs)\n         result = self._set_tick_locations(ticks, minor=minor)\n         if labels is not None:\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n+        elif kwargs:\n+            raise ValueError(\"kwargs can only be used if labels are set.\")\n         return result\n \n     def _get_tick_boxes_siblings(self, renderer):\n", "instance_id": "matplotlib__matplotlib-24334"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13497"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-13033"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 7649c39262..687b773587 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -353,7 +353,8 @@ class SQLCompiler:\n             # not taken into account so we strip it. When this entire method\n             # is refactored into expressions, then we can check each part as we\n             # generate it.\n-            without_ordering = self.ordering_parts.search(sql).group(1)\n+            sql_oneline = ' '.join(sql.split('\\n'))\n+            without_ordering = self.ordering_parts.search(sql_oneline).group(1)\n             params_hash = make_hashable(params)\n             if (without_ordering, params_hash) in seen:\n                 continue\n", "instance_id": "django__django-11001"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8376b487..f1cc5476 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1878,6 +1878,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             Number,\n             str,\n             Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]],\n+            Tuple[Tuple[Number, ...], ...],\n         ] = {},  # {} even though it's technically unsafe, is being used intentionally here (#4667)\n         name_prefix: str = \"xarray-\",\n         token: str = None,\n@@ -3907,7 +3908,11 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             dataset.\n         \"\"\"\n         merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        variables = {\n+            k: (v if not is_duck_dask_array(v.data) else v.chunk())\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, variables=variables, **merge_result._asdict())\n \n     def merge(\n         self,\n", "instance_id": "pydata__xarray-4493"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f33bcbdccf..0085e0b3c4 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -182,10 +182,14 @@ class Command(BaseCommand):\n                             if ref_db_table == table_name\n                             else table2model(ref_db_table)\n                         )\n-                        if rel_to in known_models:\n-                            field_type = \"%s(%s\" % (rel_type, rel_to)\n+                        related_name = f\"related_{att_name}\"\n+                        if rel_to == \"self\":\n+                            field_type = \"%s(%s, related_name='%s'\" % (rel_type, rel_to, related_name)\n                         else:\n-                            field_type = \"%s('%s'\" % (rel_type, rel_to)\n+                            if rel_to in known_models:\n+                                field_type = \"%s(%s, related_name='%s'\" % (rel_type, rel_to, related_name)\n+                            else:\n+                                field_type = \"%s('%s', related_name='%s'\" % (rel_type, rel_to, related_name)\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.\n", "instance_id": "django__django-15819"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex f0b663222a..b51d1739a4 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -56,7 +56,7 @@ class Command(BaseCommand):\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n", "instance_id": "django__django-11039"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/cache/backends/filebased.py b/django/core/cache/backends/filebased.py\nindex 631da49444..215fefbcc0 100644\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -90,10 +90,11 @@ class FileBasedCache(BaseCache):\n \n     def has_key(self, key, version=None):\n         fname = self._key_to_file(key, version)\n-        if os.path.exists(fname):\n+        try:\n             with open(fname, \"rb\") as f:\n                 return not self._is_expired(f)\n-        return False\n+        except FileNotFoundError:\n+            return False\n \n     def _cull(self):\n         \"\"\"\n", "instance_id": "django__django-16379"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..38d4478e76 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,10 +501,14 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n+        if not rv.exp.is_real or not isinstance(rv.base, (sin, cos)):\n+            return rv\n         if (rv.exp < 0) == True:\n             return rv\n         if (rv.exp > max) == True:\n             return rv\n+        if not rv.exp.is_real:\n+            return rv\n         if rv.exp == 2:\n             return h(g(rv.base.args[0])**2)\n         else:\n", "instance_id": "sympy__sympy-17139"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\nindex bd6afb12d1..6e2e850a5a 100644\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -447,6 +447,12 @@ def _prototype_arg(self, arg):\n             mtype = np_types[t]\n             return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n         else:\n+            # Ensure that array arguments are correctly handled\n+            if isinstance(arg, (InputArgument, InOutArgument)) and arg.dimensions:\n+                self._need_numpy = True\n+                ndim = len(arg.dimensions)\n+                mtype = np_types[t]\n+                return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n             return \"%s %s\" % (t, self._string_var(arg.name))\n \n     def _declare_arg(self, arg):\n", "instance_id": "sympy__sympy-16792"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 95ed85f769..28102f7067 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -140,27 +140,14 @@ def _hashable_content(self):\n         been defined by a class. See note about this in Basic.__eq__.\"\"\"\n         return self._args\n \n-    def __eq__(self, other):\n-        try:\n-            other = _sympify(other)\n-            if not isinstance(other, Expr):\n-                return False\n-        except (SympifyError, SyntaxError):\n-            return False\n-        # check for pure number expr\n-        if  not (self.is_Number and other.is_Number) and (\n-                type(self) != type(other)):\n-            return False\n-        a, b = self._hashable_content(), other._hashable_content()\n-        if a != b:\n-            return False\n-        # check number *in* an expression\n-        for a, b in zip(a, b):\n-            if not isinstance(a, Expr):\n-                continue\n-            if a.is_Number and type(a) != type(b):\n-                return False\n-        return True\n+    @property\n+    def is_zero(self):\n+        \"\"\"Returns True if 'self' is zero.\"\"\"\n+        if self == S.Zero:\n+            return True\n+        if isinstance(self, cosh):\n+            return self._eval_is_zero()\n+        return False\n \n     # ***************\n     # * Arithmetics *\n@@ -4081,5 +4068,6 @@ def search_element(self, elem):\n from .power import Pow\n from .function import Function, _derivative_dispatch\n from .mod import Mod\n+from sympy.functions.elementary.hyperbolic import cosh\n from .exprtools import factor_terms\n from .numbers import Integer, Rational\ndiff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 892e19cabb..a9f47bc73d 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -268,6 +268,17 @@ def _eval_is_zero(self):\n         arg = self.args[0]\n         if arg.is_zero:\n             return True\n+        if isinstance(arg, cosh):\n+            return arg.args[0].is_zero\n+        if isinstance(arg, acosh):\n+            return arg.args[0] == 1\n+        if isinstance(arg, asinh):\n+            return arg.args[0].is_zero\n+        if isinstance(arg, atanh):\n+            return arg.args[0].is_zero\n+        if isinstance(arg, acoth):\n+            return arg.args[0].is_zero\n+        return False\n \n \n class cosh(HyperbolicFunction):\n", "instance_id": "sympy__sympy-21627"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\nindex 1f33b9d3ec..8570971d2b 100644\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -1304,12 +1304,13 @@ class Artist:\n             normed = self.norm(data)\n             if np.isfinite(normed):\n                 # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n-                g_sig_digits = cbook._g_sig_digits(data, delta)\n-            else:\n-                g_sig_digits = 3  # Consistent with default below.\n+                try:\n+                    neighbors = self.norm.inverse(\n+                        (int(self.norm(data) * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n+                    g_sig_digits = cbook._g_sig_digits(data, delta)\n+                except ValueError:\n+                    g_sig_digits = 3  # Consistent with default below.\n             return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n         else:\n             try:\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2e51914952..1d6f5a3320 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1909,7 +1909,7 @@ class BoundaryNorm(Normalize):\n             BoundaryNorm is not invertible, so calling this method will always\n             raise an error\n         \"\"\"\n-        raise ValueError(\"BoundaryNorm is not invertible\")\n+        raise ValueError(\"BoundaryNorm is not invertible.\")\n \n \n class NoNorm(Normalize):\n", "instance_id": "matplotlib__matplotlib-22835"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..e9429a8e 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,6 +425,14 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n         method = builtin_str(method)\n \n         # Create the Request.\n", "instance_id": "psf__requests-2317"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d8456375..51cb543c 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -148,8 +148,12 @@ class Request(object):\n \n         hooks = hooks or {}\n \n-        for (k, v) in list(hooks.items()):\n-            self.register_hook(event=k, hook=v)\n+        for (k, v) in hooks.items():\n+            if isinstance(v, list):\n+                for hook in v:\n+                    self.register_hook(event=k, hook=hook)\n+            else:\n+                self.register_hook(event=k, hook=v)\n \n         #: Session.\n         self.session = session\n", "instance_id": "psf__requests-863"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex 872a4c98dc..df59081f84 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -251,11 +251,39 @@ class ForwardManyToOneDescriptor:\n             for lh_field, rh_field in self.field.related_fields:\n                 setattr(instance, lh_field.attname, None)\n \n-        # Set the values of the related field.\n+        if value is None:\n+            # Look up the previously-related object, which may still be available\n+            # since we've not yet cleared out the related field.\n+            # Use the cache directly, instead of the accessor; if we haven't\n+            # populated the cache, then we don't care - we're only accessing\n+            # the object to invalidate the accessor cache, so there's no\n+            # need to populate the cache just to expire it again.\n+            related = self.field.get_cached_value(instance, default=None)\n+\n+            # If we've got an old related object, we need to clear out its\n+            # cache. This cache also might not exist if the related object\n+            # hasn't been accessed yet.\n+            if related is not None:\n+                remote_field.set_cached_value(related, None)\n+\n+            for lh_field, rh_field in self.field.related_fields:\n+                setattr(instance, lh_field.attname, None)\n         else:\n+            # Ensure the primary key is set before saving the parent object.\n+            if value.pk is None:\n+                value.save()\n+\n             for lh_field, rh_field in self.field.related_fields:\n                 setattr(instance, lh_field.attname, getattr(value, rh_field.attname))\n \n+            # Validate the related object assignment\n+            if not router.allow_relation(value, instance):\n+                raise ValueError('Cannot assign \"%r\": the current database router prevents this relation.' % value)\n+\n+            # Validate the related object assignment\n+            if not router.allow_relation(value, instance):\n+                raise ValueError('Cannot assign \"%r\": the current database router prevents this relation.' % value)\n+\n         # Set the related instance cache used by __get__ to avoid an SQL query\n         # when accessing the attribute we just set.\n         self.field.set_cached_value(instance, value)\n", "instance_id": "django__django-13964"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex f88662de12..097d831bf8 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -2598,15 +2598,105 @@ class RelatedPopulator:\n             obj_data = self.reorder_for_init(row)\n         else:\n             obj_data = row[self.cols_start : self.cols_end]\n-        if obj_data[self.pk_idx] is None:\n-            obj = None\n+        if obj_data[self.pk_idx] is not None:\n+            obj = self.model_cls.from_db(self.db, self.init_list, obj_data)\n+            for rel_iter in self.related_populators:\n+                rel_iter.populate(row, obj)\n+            self.local_setter(from_obj, obj)\n+            self.remote_setter(obj, from_obj)\n+        else:\n+            self.local_setter(from_obj, None)\n+\n+\n+def get_related_populators(klass_info, select, db):\n+    iterators = []\n+    related_klass_infos = klass_info.get(\"related_klass_infos\", [])\n+    for rel_klass_info in related_klass_infos:\n+        rel_cls = RelatedPopulator(rel_klass_info, select, db)\n+        iterators.append(rel_cls)\n+    return iterators\n+    \"\"\"\n+    RelatedPopulator is used for select_related() object instantiation.\n+\n+    The idea is that each select_related() model will be populated by a\n+    different RelatedPopulator instance. The RelatedPopulator instances get\n+    klass_info and select (computed in SQLCompiler) plus the used db as\n+    input for initialization. That data is used to compute which columns\n+    to use, how to instantiate the model, and how to populate the links\n+    between the objects.\n+\n+    The actual creation of the objects is done in populate() method. This\n+    method gets row and from_obj as input and populates the select_related()\n+    model instance.\n+    \"\"\"\n+\n+    def __init__(self, klass_info, select, db):\n+        self.db = db\n+        # Pre-compute needed attributes. The attributes are:\n+        #  - model_cls: the possibly deferred model class to instantiate\n+        #  - either:\n+        #    - cols_start, cols_end: usually the columns in the row are\n+        #      in the same order model_cls.__init__ expects them, so we\n+        #      can instantiate by model_cls(*row[cols_start:cols_end])\n+        #    - reorder_for_init: When select_related descends to a child\n+        #      class, then we want to reuse the already selected parent\n+        #      data. However, in this case the parent data isn't necessarily\n+        #      in the same order that Model.__init__ expects it to be, so\n+        #      we have to reorder the parent data. The reorder_for_init\n+        #      attribute contains a function used to reorder the field data\n+        #      in the order __init__ expects it.\n+        #  - pk_idx: the index of the primary key field in the reordered\n+        #    model data. Used to check if a related object exists at all.\n+        #  - init_list: the field attnames fetched from the database. For\n+        #    deferred models this isn't the same as all attnames of the\n+        #    model's fields.\n+        #  - related_populators: a list of RelatedPopulator instances if\n+        #    select_related() descends to related models from this model.\n+        #  - local_setter, remote_setter: Methods to set cached values on\n+        #    the object being populated and on the remote object. Usually\n+        #    these are Field.set_cached_value() methods.\n+        select_fields = klass_info[\"select_fields\"]\n+        from_parent = klass_info[\"from_parent\"]\n+        if not from_parent:\n+            self.cols_start = select_fields[0]\n+            self.cols_end = select_fields[-1] + 1\n+            self.init_list = [\n+                f[0].target.attname for f in select[self.cols_start : self.cols_end]\n+            ]\n+            self.reorder_for_init = None\n+        else:\n+            attname_indexes = {\n+                select[idx][0].target.attname: idx for idx in select_fields\n+            }\n+            model_init_attnames = (\n+                f.attname for f in klass_info[\"model\"]._meta.concrete_fields\n+            )\n+            self.init_list = [\n+                attname for attname in model_init_attnames if attname in attname_indexes\n+            ]\n+            self.reorder_for_init = operator.itemgetter(\n+                *[attname_indexes[attname] for attname in self.init_list]\n+            )\n+\n+        self.model_cls = klass_info[\"model\"]\n+        self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n+        self.related_populators = get_related_populators(klass_info, select, self.db)\n+        self.local_setter = klass_info[\"local_setter\"]\n+        self.remote_setter = klass_info[\"remote_setter\"]\n+\n+    def populate(self, row, from_obj):\n+        if self.reorder_for_init:\n+            obj_data = self.reorder_for_init(row)\n         else:\n+            obj_data = row[self.cols_start : self.cols_end]\n+        if obj_data[self.pk_idx] is not None:\n             obj = self.model_cls.from_db(self.db, self.init_list, obj_data)\n             for rel_iter in self.related_populators:\n                 rel_iter.populate(row, obj)\n-        self.local_setter(from_obj, obj)\n-        if obj is not None:\n+            self.local_setter(from_obj, obj)\n             self.remote_setter(obj, from_obj)\n+        else:\n+            self.local_setter(from_obj, None)\n \n \n def get_related_populators(klass_info, select, db):\n", "instance_id": "django__django-16408"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..50cb33837b 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -484,6 +484,14 @@ def _entry(self, i, j):\n     def _eval_determinant(self):\n         return S.One\n \n+    def __add__(self, other):\n+        if isinstance(other, Identity):\n+            return Identity(self.rows + other.rows)\n+        return super(Identity, self).__add__(other)\n+\n+    def __radd__(self, other):\n+        return self.__add__(other)\n+\n \n class ZeroMatrix(MatrixExpr):\n     \"\"\"The Matrix Zero 0 - additive identity\n", "instance_id": "sympy__sympy-12419"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex e16ab8ce5..4cc6599cb 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -131,6 +131,151 @@ def class_doc_from_option(arg: Any) -> Optional[str]:\n SUPPRESS = object()\n \n \n+def annotation_option(arg: Any) -> Any:\n+    if arg in (None, True):\n+        # suppress showing the representation of the object\n+        return SUPPRESS\n+    else:\n+        return arg\n+\n+\n+def bool_option(arg: Any) -> bool:\n+    \"\"\"Used to convert flag options to auto directives.  (Instead of\n+    directives.flag(), which returns None).\n+    \"\"\"\n+    return True\n+\n+\n+def merge_members_option(options: Dict) -> None:\n+    \"\"\"Merge :private-members: and :special-members: options to the\n+    :members: option.\n+    \"\"\"\n+    if options.get('members') is ALL:\n+        # merging is not needed when members: ALL\n+        return\n+\n+    members = options.setdefault('members', [])\n+    for key in {'private-members', 'special-members'}:\n+        if key in options and options[key] not in (ALL, None):\n+            for member in options[key]:\n+                if member not in members:\n+                    members.append(member)\n+\n+\n+# Some useful event listener factories for autodoc-process-docstring.\n+\n+def cut_lines(pre: int, post: int = 0, what: str = None) -> Callable:\n+    \"\"\"Return a listener that removes the first *pre* and last *post*\n+    lines of every docstring.  If *what* is a sequence of strings,\n+    only docstrings of a type in *what* will be processed.\n+\n+    Use like this (e.g. in the ``setup()`` function of :file:`conf.py`)::\n+\n+       from sphinx.ext.autodoc import cut_lines\n+       app.connect('autodoc-process-docstring', cut_lines(4, what=['module']))\n+\n+    This can (and should) be used in place of :confval:`automodule_skip_lines`.\n+    \"\"\"\n+    def process(app: Sphinx, what_: str, name: str, obj: Any, options: Any, lines: List[str]\n+                ) -> None:\n+        if what and what_ not in what:\n+            return\n+        del lines[:pre]\n+        if post:\n+            # remove one trailing blank line.\n+            if lines and not lines[-1]:\n+                lines.pop(-1)\n+            del lines[-post:]\n+        # make sure there is a blank line at the end\n+        if lines and lines[-1]:\n+            lines.append('')\n+    return process\n+\n+\n+def between(marker: str, what: Sequence[str] = None, keepempty: bool = False,\n+            exclude: bool = False) -> Callable:\n+    \"\"\"Return a listener that either keeps, or if *exclude* is True excludes,\n+    lines between lines that match the *marker* regular expression.  If no line\n+    matches, the resulting docstring would be empty, so no change will be made\n+    unless *keepempty* is true.\n+\n+    If *what* is a sequence of strings, only docstrings of a type in *what* will\n+    be processed.\n+    \"\"\"\n+    marker_re = re.compile(marker)\n+\n+    def process(app: Sphinx, what_: str, name: str, obj: Any, options: Any, lines: List[str]\n+                ) -> None:\n+        if what and what_ not in what:\n+            return\n+        deleted = 0\n+        delete = not exclude\n+        orig_lines = lines[:]\n+        for i, line in enumerate(orig_lines):\n+            if delete:\n+                lines.pop(i - deleted)\n+                deleted += 1\n+            if marker_re.match(line):\n+                delete = not delete\n+                if delete:\n+                    lines.pop(i - deleted)\n+                    deleted += 1\n+        if not lines and not keepempty:\n+            lines[:] = orig_lines\n+        # make sure there is a blank line at the end\n+        if lines and lines[-1]:\n+            lines.append('')\n+    return process\n+\n+\n+def members_option(arg: Any) -> Union[object, List[str]]:\n+    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    if arg in (None, True):\n+        return ALL\n+    elif arg is False:\n+        return None\n+    else:\n+        return [x.strip() for x in arg.split(',') if x.strip()]\n+\n+\n+def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n+    \"\"\"Used to convert the :exclude-members: option.\"\"\"\n+    if arg in (None, True):\n+        return EMPTY\n+    return {x.strip() for x in arg.split(',') if x.strip()}\n+\n+\n+def inherited_members_option(arg: Any) -> Set[str]:\n+    \"\"\"Used to convert the :inherited-members: option to auto directives.\"\"\"\n+    if arg in (None, True):\n+        return {'object'}\n+    elif arg:\n+        return set(x.strip() for x in arg.split(','))\n+    else:\n+        return set()\n+\n+\n+def member_order_option(arg: Any) -> Optional[str]:\n+    \"\"\"Used to convert the :member-order: option to auto directives.\"\"\"\n+    if arg in (None, True):\n+        return None\n+    elif arg in ('alphabetical', 'bysource', 'groupwise'):\n+        return arg\n+    else:\n+        raise ValueError(__('invalid value for member-order option: %s') % arg)\n+\n+\n+def class_doc_from_option(arg: Any) -> Optional[str]:\n+    \"\"\"Used to convert the :class-doc-from: option to autoclass directives.\"\"\"\n+    if arg in ('both', 'class', 'init'):\n+        return arg\n+    else:\n+        raise ValueError(__('invalid value for class-doc-from option: %s') % arg)\n+\n+\n+SUPPRESS = object()\n+\n+\n def annotation_option(arg: Any) -> Any:\n     if arg in (None, True):\n         # suppress showing the representation of the object\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex be2248320..573abda13 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -65,8 +65,36 @@ class DocumenterBridge:\n         return self.record_dependencies\n \n \n-def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict\n-                               ) -> Options:\n+def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict) -> Options:\n+    \"\"\"Recognize options of Documenter from user input.\"\"\"\n+    for name in AUTODOC_DEFAULT_OPTIONS:\n+        if name not in documenter.option_spec:\n+            continue\n+        else:\n+            negated = options.pop('no-' + name, True) is None\n+            if name in config.autodoc_default_options and not negated:\n+                if name in options and isinstance(config.autodoc_default_options[name], str):\n+                    # take value from options if present or extend it\n+                    # with autodoc_default_options if necessary\n+                    if name in AUTODOC_EXTENDABLE_OPTIONS:\n+                        if options[name] is not None and options[name].startswith('+'):\n+                            options[name] = ','.join([config.autodoc_default_options[name],\n+                                                      options[name][1:]])\n+                else:\n+                    options[name] = config.autodoc_default_options[name]\n+\n+            elif options.get(name) is not None:\n+                # remove '+' from option argument if there's nothing to merge it with\n+                options[name] = options[name].lstrip('+')\n+\n+    # Remove duplicated *args and **kwargs\n+    if config.autodoc_typehints == \"description\":\n+        if \"*args\" in options:\n+            options.pop(\"*args\")\n+        if \"**kwargs\" in options:\n+            options.pop(\"**kwargs\")\n+\n+    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n     \"\"\"Recognize options of Documenter from user input.\"\"\"\n     for name in AUTODOC_DEFAULT_OPTIONS:\n         if name not in documenter.option_spec:\n", "instance_id": "sphinx-doc__sphinx-10451"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 5bbb786984..8ea17ebbd4 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -1311,10 +1311,11 @@ default: %(va)s\n         \"\"\"\n         if (self.get_layout_engine() is not None and\n                 not self.get_layout_engine().adjust_compatible):\n-            _api.warn_external(\n-                \"This figure was using a layout engine that is \"\n-                \"incompatible with subplots_adjust and/or tight_layout; \"\n-                \"not calling subplots_adjust.\")\n+            if self.get_layout_engine().__class__.__name__ != 'PlaceHolderLayoutEngine':\n+                _api.warn_external(\n+                    \"This figure was using a layout engine that is \"\n+                    \"incompatible with subplots_adjust and/or tight_layout; \"\n+                    \"not calling subplots_adjust.\")\n             return\n         self.subplotpars.update(left, bottom, right, top, wspace, hspace)\n         for ax in self.axes:\n", "instance_id": "matplotlib__matplotlib-23987"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0c64748ccd..0dfeb1eff8 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1074,6 +1074,8 @@ class CharField(Field):\n     def to_python(self, value):\n         if isinstance(value, str) or value is None:\n             return value\n+        if callable(self.path):\n+            self.path = self.path()\n         return str(value)\n \n     def get_prep_value(self, value):\n@@ -1663,7 +1665,8 @@ class FilePathField(Field):\n \n     def __init__(self, verbose_name=None, name=None, path='', match=None,\n                  recursive=False, allow_files=True, allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+        self.match, self.recursive = match, recursive\n+        self.path = path() if callable(path) else path\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n         kwargs.setdefault('max_length', 100)\n         super().__init__(verbose_name, name, **kwargs)\n", "instance_id": "django__django-10924"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 75349099..44f3b486 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -2102,6 +2102,22 @@ def pairplot(\n     diag_kws = {} if diag_kws is None else diag_kws.copy()\n     grid_kws = {} if grid_kws is None else grid_kws.copy()\n \n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n     # Resolve \"auto\" diag kind\n     if diag_kind == \"auto\":\n         if hue is None:\n", "instance_id": "mwaskom__seaborn-3407"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/python_api.py b/src/_pytest/python_api.py\nindex 011181a40..521c9f2f5 100644\n--- a/src/_pytest/python_api.py\n+++ b/src/_pytest/python_api.py\n@@ -713,6 +713,9 @@ class RaisesContext:\n         self.match_expr = match_expr\n         self.excinfo = None\n \n+    def __str__(self):\n+        return str(self.excinfo.value) if self.excinfo else \"\"\n+\n     def __enter__(self):\n         self.excinfo = _pytest._code.ExceptionInfo.for_later()\n         return self.excinfo\n", "instance_id": "pytest-dev__pytest-5413"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 3894f4fd1c..020037aaf8 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -889,6 +889,8 @@ def subs(self, *args, **kwargs):\n                    When a single argument is passed to subs\n                    it should be a dictionary of old: new pairs or an iterable\n                    of (old, new) tuples.\"\"\"))\n+            elif isinstance(sequence, Piecewise):\n+                sequence = sequence.args\n         elif len(args) == 2:\n             sequence = [args]\n         else:\ndiff --git a/sympy/functions/elementary/exponential.py b/sympy/functions/elementary/exponential.py\nindex bdedc455c2..4780191ab9 100644\n--- a/sympy/functions/elementary/exponential.py\n+++ b/sympy/functions/elementary/exponential.py\n@@ -428,18 +428,10 @@ def as_real_imag(self, deep=True, **hints):\n \n     def _eval_subs(self, old, new):\n         # keep processing of power-like args centralized in Pow\n-        if old.is_Pow:  # handle (exp(3*log(x))).subs(x**2, z) -> z**(3/2)\n-            old = exp(old.exp*log(old.base))\n-        elif old is S.Exp1 and new.is_Function:\n-            old = exp\n-        if isinstance(old, exp) or old is S.Exp1:\n-            f = lambda a: Pow(*a.as_base_exp(), evaluate=False) if (\n-                a.is_Pow or isinstance(a, exp)) else a\n-            return Pow._eval_subs(f(self), f(old), new)\n-\n-        if old is exp and not new.is_Function:\n-            return new**self.exp._subs(old, new)\n-        return Function._eval_subs(self, old, new)\n+        if isinstance(old, Piecewise):\n+            return Piecewise(*[(self._subs(old_arg, new), cond) for old_arg, cond in old.args])\n+        else:\n+            return super()._eval_subs(old, new)\n \n     def _eval_is_extended_real(self):\n         if self.args[0].is_extended_real:\ndiff --git a/sympy/functions/elementary/piecewise.py b/sympy/functions/elementary/piecewise.py\nindex 91bfceafaa..0945583ef4 100644\n--- a/sympy/functions/elementary/piecewise.py\n+++ b/sympy/functions/elementary/piecewise.py\n@@ -805,24 +805,10 @@ def _eval_power(self, s):\n         return self.func(*[(e**s, c) for e, c in self.args])\n \n     def _eval_subs(self, old, new):\n-        # this is strictly not necessary, but we can keep track\n-        # of whether True or False conditions arise and be\n-        # somewhat more efficient by avoiding other substitutions\n-        # and avoiding invalid conditions that appear after a\n-        # True condition\n-        args = list(self.args)\n-        args_exist = False\n-        for i, (e, c) in enumerate(args):\n-            c = c._subs(old, new)\n-            if c != False:\n-                args_exist = True\n-                e = e._subs(old, new)\n-            args[i] = (e, c)\n-            if c == True:\n-                break\n-        if not args_exist:\n-            args = ((Undefined, True),)\n-        return self.func(*args)\n+        if isinstance(old, Piecewise):\n+            return Piecewise(*[(self._subs(old_arg, new), cond) for old_arg, cond in old.args])\n+        else:\n+            return super()._eval_subs(old, new)\n \n     def _eval_transpose(self):\n         return self.func(*[(e.transpose(), c) for e, c in self.args])\n", "instance_id": "sympy__sympy-21379"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..882d4e39d 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1216,6 +1216,14 @@ class RepeatedKFold(_RepeatedSplits):\n         super().__init__(\n             KFold, n_repeats, random_state, n_splits=n_splits)\n \n+    def __repr__(self):\n+        return ('{name}(n_splits={n_splits}, n_repeats={n_repeats}, '\n+                'random_state={random_state})').format(\n+                    name=self.__class__.__name__,\n+                    n_splits=self.cvargs['n_splits'],\n+                    n_repeats=self.n_repeats,\n+                    random_state=self.random_state)\n+\n \n class RepeatedStratifiedKFold(_RepeatedSplits):\n     \"\"\"Repeated Stratified K-Fold cross validator.\n@@ -1269,6 +1277,14 @@ class RepeatedStratifiedKFold(_RepeatedSplits):\n         super().__init__(\n             StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n \n+    def __repr__(self):\n+        return ('{name}(n_splits={n_splits}, n_repeats={n_repeats}, '\n+                'random_state={random_state})').format(\n+                    name=self.__class__.__name__,\n+                    n_splits=self.cvargs['n_splits'],\n+                    n_repeats=self.n_repeats,\n+                    random_state=self.random_state)\n+\n \n class BaseShuffleSplit(metaclass=ABCMeta):\n     \"\"\"Base class for ShuffleSplit and StratifiedShuffleSplit\"\"\"\n", "instance_id": "scikit-learn__scikit-learn-14983"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex f0c81c123b..62e40c09a5 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -215,15 +215,12 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # Work inside a new app registry\n         apps = Apps()\n \n-        # Work out the new value of unique_together, taking renames into\n-        # account\n+        # Work out the new value of unique_together and constraints, taking renames into account\n         unique_together = [\n             [rename_mapping.get(n, n) for n in unique]\n             for unique in model._meta.unique_together\n         ]\n \n-        # Work out the new value for index_together, taking renames into\n-        # account\n         index_together = [\n             [rename_mapping.get(n, n) for n in index]\n             for index in model._meta.index_together\n@@ -236,7 +233,11 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n                 if delete_field.name not in index.fields\n             ]\n \n-        constraints = list(model._meta.constraints)\n+        constraints = [\n+            constraint\n+            for constraint in model._meta.constraints\n+            if not isinstance(constraint, UniqueConstraint) or not constraint.contains_expressions\n+        ]\n \n         # Provide isolated instances of the fields to the new model body so\n         # that the existing model's internals aren't interfered with when\n", "instance_id": "django__django-14997"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 583c2be647..5507eed3f6 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -19,6 +19,7 @@ from django.apps import apps\n from django.core.signals import request_finished\n from django.dispatch import Signal\n from django.utils.functional import cached_property\n+from django.conf import settings\n from django.utils.version import get_version_tuple\n \n autoreload_started = Signal()\n@@ -113,7 +114,9 @@ def iter_all_python_module_files():\n     # aren't loaded on the fly.\n     keys = sorted(sys.modules)\n     modules = tuple(m for m in map(sys.modules.__getitem__, keys) if not isinstance(m, weakref.ProxyTypes))\n-    return iter_modules_and_files(modules, frozenset(_error_files))\n+    template_dirs = getattr(settings, 'TEMPLATES', [{}])[0].get('DIRS', [])\n+    template_dirs = [Path(d).resolve().absolute() for d in template_dirs]\n+    return iter_modules_and_files(modules, frozenset(_error_files).union(template_dirs))\n \n \n @functools.lru_cache(maxsize=1)\n", "instance_id": "django__django-15388"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/ccode.py b/sympy/printing/ccode.py\nindex 30a07a7b59..e81734f040 100644\n--- a/sympy/printing/ccode.py\n+++ b/sympy/printing/ccode.py\n@@ -43,6 +43,7 @@\n     \"atanh\": \"atanh\",\n     \"floor\": \"floor\",\n     \"ceiling\": \"ceil\",\n+    \"sinc\": \"sinc\",\n }\n \n # These are the core reserved words in the C language. Taken from:\n@@ -248,6 +249,12 @@ def _print_For(self, expr):\n                 '{step}) {{\\n{body}\\n}}').format(target=target, start=start,\n                 stop=stop, step=step, body=body)\n \n+    def _print_sinc(self, expr):\n+        from sympy import Piecewise, sin, Ne\n+        theta = expr.args[0]\n+        piecewise_expr = Piecewise((sin(theta)/theta, Ne(theta, 0)), (1, True))\n+        return self._print(piecewise_expr)\n+\n     def _print_sign(self, func):\n         return '((({0}) > 0) - (({0}) < 0))'.format(self._print(func.args[0]))\n \n", "instance_id": "sympy__sympy-11400"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 755088ca5..fef75816c 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -682,7 +682,11 @@ class GoogleDocstring:\n         return self._parse_generic_section(_('Notes'), use_admonition)\n \n     def _parse_other_parameters_section(self, section: str) -> List[str]:\n-        return self._format_fields(_('Other Parameters'), self._consume_fields())\n+        fields = self._consume_fields()\n+        if self._config.napoleon_use_param:\n+            return self._format_docutils_params(fields)\n+        else:\n+            return self._format_fields(_('Other Parameters'), fields)\n \n     def _parse_parameters_section(self, section: str) -> List[str]:\n         if self._config.napoleon_use_param:\n@@ -926,28 +930,28 @@ def _token_type(token: str, location: str = None) -> str:\n             (token.startswith(\"'\") and token.endswith(\"'\"))\n     ):\n         type_ = \"literal\"\n-    elif token.startswith(\"{\"):\n+    elif token.startswith(\"{\") and not token.endswith(\"}\"):\n         logger.warning(\n             __(\"invalid value set (missing closing brace): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.endswith(\"}\"):\n+    elif token.endswith(\"}\") and not token.startswith(\"{\"):\n         logger.warning(\n             __(\"invalid value set (missing opening brace): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.startswith(\"'\") or token.startswith('\"'):\n+    elif (token.startswith(\"'\") and not token.endswith(\"'\")) or (token.startswith('\"') and not token.endswith('\"')):\n         logger.warning(\n             __(\"malformed string literal (missing closing quote): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.endswith(\"'\") or token.endswith('\"'):\n+    elif (token.endswith(\"'\") and not token.startswith(\"'\")) or (token.endswith('\"') and not token.startswith('\"')):\n         logger.warning(\n             __(\"malformed string literal (missing opening quote): %s\"),\n             token,\n", "instance_id": "sphinx-doc__sphinx-8713"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c2623f099f..3e97007f7d 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -9,6 +9,7 @@ import copy\n import functools\n import inspect\n from collections import namedtuple\n+from collections import dict_keys, dict_values\n \n from django.core.exceptions import FieldError\n from django.db.models.constants import LOOKUP_SEP\n@@ -38,7 +39,12 @@ class Q(tree.Node):\n     conditional = True\n \n     def __init__(self, *args, _connector=None, _negated=False, **kwargs):\n-        super().__init__(children=[*args, *sorted(kwargs.items())], connector=_connector, negated=_negated)\n+        children = [*args, *sorted(kwargs.items())]\n+        # Convert non-pickleable types to list\n+        for i, child in enumerate(children):\n+            if isinstance(child, tuple) and isinstance(child[1], (dict_keys, dict_values)):\n+                children[i] = (child[0], list(child[1]))\n+        super().__init__(children=children, connector=_connector, negated=_negated)\n \n     def _combine(self, other, conn):\n         if not isinstance(other, Q):\n", "instance_id": "django__django-14016"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/functions/elementary/trigonometric.py b/sympy/functions/elementary/trigonometric.py\nindex da2e919375..3b0699b4cc 100644\n--- a/sympy/functions/elementary/trigonometric.py\n+++ b/sympy/functions/elementary/trigonometric.py\n@@ -332,6 +332,24 @@ def eval(cls, arg):\n                     return cls(pi_coeff*S.Pi)\n                 return None\n \n+        if arg.is_Rational:\n+            return sin(arg.evalf())\n+\n+        if arg.is_Rational:\n+            return sin(arg.evalf())\n+\n+        if arg.is_Rational:\n+            pi_coeff = _pi_coeff(arg)\n+            if pi_coeff is not None:\n+                return sin(pi_coeff * S.Pi)\n+            return sin(arg.evalf())\n+\n+        if arg.is_Rational:\n+            pi_coeff = _pi_coeff(arg)\n+            if pi_coeff is not None:\n+                return sin(pi_coeff * S.Pi)\n+            return sin(arg.evalf())\n+\n         if arg.is_Add:\n             x, m = _peeloff_pi(arg)\n             if m:\n@@ -635,6 +653,24 @@ def eval(cls, arg):\n                     return sign_cos*sqrt( (1 + nval)/2 )\n             return None\n \n+        if arg.is_Rational:\n+            return cos(arg.evalf())\n+\n+        if arg.is_Rational:\n+            return cos(arg.evalf())\n+\n+        if arg.is_Rational:\n+            pi_coeff = _pi_coeff(arg)\n+            if pi_coeff is not None:\n+                return cos(pi_coeff * S.Pi)\n+            return cos(arg.evalf())\n+\n+        if arg.is_Rational:\n+            pi_coeff = _pi_coeff(arg)\n+            if pi_coeff is not None:\n+                return cos(pi_coeff * S.Pi)\n+            return cos(arg.evalf())\n+\n         if arg.is_Add:\n             x, m = _peeloff_pi(arg)\n             if m:\n", "instance_id": "sympy__sympy-15346"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\nindex 15c630b1d..677f0af4a 100644\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -13,6 +13,8 @@ import os\n import re\n import sys\n import time\n+import socket\n+from datetime import datetime\n \n import py\n \n@@ -80,7 +82,9 @@ families[\"xunit2\"] = families[\"_base\"]\n \n \n class _NodeReporter:\n-    def __init__(self, nodeid, xml):\n+    def __init__(self, nodeid, xml, hostname=None, timestamp=None):\n+        self.hostname = hostname\n+        self.timestamp = timestamp\n         self.id = nodeid\n         self.xml = xml\n         self.add_stats = self.xml.add_stats\n@@ -483,6 +487,8 @@ class LogXML:\n         self.report_duration = report_duration\n         self.family = family\n         self.stats = dict.fromkeys([\"error\", \"passed\", \"failure\", \"skipped\"], 0)\n+        self.hostname = None\n+        self.timestamp = None\n         self.node_reporters = {}  # nodeid -> _NodeReporter\n         self.node_reporters_ordered = []\n         self.global_properties = []\n@@ -514,7 +520,7 @@ class LogXML:\n             # TODO: breasks for --dist=each\n             return self.node_reporters[key]\n \n-        reporter = _NodeReporter(nodeid, self)\n+        reporter = _NodeReporter(nodeid, self, self.hostname, self.timestamp)\n \n         self.node_reporters[key] = reporter\n         self.node_reporters_ordered.append(reporter)\n@@ -639,6 +645,8 @@ class LogXML:\n \n     def pytest_sessionstart(self):\n         self.suite_start_time = time.time()\n+        self.hostname = socket.gethostname()\n+        self.timestamp = datetime.utcnow().isoformat()\n \n     def pytest_sessionfinish(self):\n         dirname = os.path.dirname(os.path.abspath(self.logfile))\n", "instance_id": "pytest-dev__pytest-5692"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-10914"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13142"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/units/prefixes.py b/sympy/physics/units/prefixes.py\nindex ca6a642156..376876d271 100644\n--- a/sympy/physics/units/prefixes.py\n+++ b/sympy/physics/units/prefixes.py\n@@ -80,21 +80,20 @@ def __repr__(self):\n \n     def __mul__(self, other):\n         from sympy.physics.units import Quantity\n-        if not isinstance(other, (Quantity, Prefix)):\n-            return super().__mul__(other)\n-\n-        fact = self.scale_factor * other.scale_factor\n+        from sympy.physics.units import Unit\n \n-        if fact == 1:\n-            return 1\n+        if isinstance(other, Unit):\n+            return other * self.scale_factor\n         elif isinstance(other, Prefix):\n-            # simplify prefix\n+            fact = self.scale_factor * other.scale_factor\n+            if fact == 1:\n+                return 1\n             for p in PREFIXES:\n                 if PREFIXES[p].scale_factor == fact:\n                     return PREFIXES[p]\n             return fact\n-\n-        return self.scale_factor * other\n+        else:\n+            return super().__mul__(other)\n \n     def __truediv__(self, other):\n         if not hasattr(other, \"scale_factor\"):\n", "instance_id": "sympy__sympy-24909"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..64d9ee6ce7 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -1638,6 +1638,12 @@ def atom(self):\n         def frac(self):\n             return self.getTypedRuleContext(LaTeXParser.FracContext,0)\n \n+        def L_PAREN(self):\n+            return self.getToken(LaTeXParser.L_PAREN, 0)\n+\n+        def R_PAREN(self):\n+            return self.getToken(LaTeXParser.R_PAREN, 0)\n+\n \n         def binom(self):\n             return self.getTypedRuleContext(LaTeXParser.BinomContext,0)\n@@ -2309,14 +2315,22 @@ def frac(self):\n             self.state = 306\n             self.match(LaTeXParser.L_BRACE)\n             self.state = 307\n-            localctx.upper = self.expr()\n+            self.match(LaTeXParser.L_PAREN)\n             self.state = 308\n-            self.match(LaTeXParser.R_BRACE)\n+            localctx.upper = self.expr()\n             self.state = 309\n-            self.match(LaTeXParser.L_BRACE)\n+            self.match(LaTeXParser.R_PAREN)\n             self.state = 310\n-            localctx.lower = self.expr()\n+            self.match(LaTeXParser.R_BRACE)\n             self.state = 311\n+            self.match(LaTeXParser.L_BRACE)\n+            self.state = 312\n+            self.match(LaTeXParser.L_PAREN)\n+            self.state = 313\n+            localctx.lower = self.expr()\n+            self.state = 314\n+            self.match(LaTeXParser.R_PAREN)\n+            self.state = 315\n             self.match(LaTeXParser.R_BRACE)\n         except RecognitionException as re:\n             localctx.exception = re\n", "instance_id": "sympy__sympy-21612"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/lambdarepr.py b/sympy/printing/lambdarepr.py\nindex 8f60434e89..e1d3e743fe 100644\n--- a/sympy/printing/lambdarepr.py\n+++ b/sympy/printing/lambdarepr.py\n@@ -5,6 +5,7 @@\n     NumPyPrinter  # NumPyPrinter is imported for backward compatibility\n )\n from sympy.utilities import default_sort_key\n+from sympy.matrices.expressions import Identity\n \n \n class LambdaPrinter(PythonCodePrinter):\n@@ -43,6 +44,11 @@ def _print_BooleanTrue(self, expr):\n     def _print_BooleanFalse(self, expr):\n         return \"False\"\n \n+    def _print_Identity(self, expr):\n+        from sympy.matrices.expressions import Identity\n+        return \"np.eye(%s)\" % expr.shape[0]\n+        \n+\n     def _print_ITE(self, expr):\n         result = [\n             '((', self._print(expr.args[1]),\n", "instance_id": "sympy__sympy-17022"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a0eb97792e..13c552451b 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1403,7 +1403,6 @@ def _print_Piecewise(self, expr):\n         tex = r\"\\begin{cases} %s \\end{cases}\"\n         return tex % r\" \\\\\".join(ecpairs)\n \n-    def _print_MatrixBase(self, expr):\n         lines = []\n \n         for line in range(expr.rows):  # horrible, should be 'rows'\n@@ -1430,8 +1429,7 @@ def _print_MatrixBase(self, expr):\n                       r'\\right' + right_delim\n         return out_str % r\"\\\\\".join(lines)\n     _print_ImmutableMatrix = _print_ImmutableDenseMatrix \\\n-                           = _print_Matrix \\\n-                           = _print_MatrixBase\n+                           = _print_Matrix\n \n     def _print_MatrixElement(self, expr):\n         return self.parenthesize(expr.parent, PRECEDENCE[\"Atom\"], strict=True) \\\n", "instance_id": "sympy__sympy-15308"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..1304f20a60 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n", "instance_id": "django__django-11099"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..95501cf9d 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -56,8 +56,6 @@ def doctree_read(app: Sphinx, doctree: Node) -> None:\n         env._viewcode_modules = {}  # type: ignore\n     if app.builder.name == \"singlehtml\":\n         return\n-    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n-        return\n \n     def has_tag(modname: str, fullname: str, docname: str, refname: str) -> bool:\n         entry = env._viewcode_modules.get(modname, None)  # type: ignore\n@@ -182,6 +180,9 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n+    highlighter = app.builder.highlighter  # type: ignore\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n", "instance_id": "sphinx-doc__sphinx-8721"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/axes_grid.py b/lib/mpl_toolkits/axes_grid1/axes_grid.py\nindex 2b1b1d3200..101628cd95 100644\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -13,8 +13,12 @@ from .mpl_axes import Axes\n def _tick_only(ax, bottom_on, left_on):\n     bottom_off = not bottom_on\n     left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    if isinstance(ax.axis, dict):\n+        ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n+        ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    else:\n+        ax.tick_params(axis='x', labelbottom=bottom_on)\n+        ax.tick_params(axis='y', labelleft=left_on)\n \n \n class CbarAxesBase:\n", "instance_id": "matplotlib__matplotlib-26020"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-11910"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "instance_id": "sympy__sympy-13480"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..adc0b356fa 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,12 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n+            current_year = datetime.datetime.utcnow().year\n+            current_century = current_year // 100 * 100\n+            if year + current_century > current_year + 50:\n+                year += current_century - 100\n             else:\n-                year += 1900\n+                year += current_century\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n", "instance_id": "django__django-11848"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/commands/dbshell.py b/django/core/management/commands/dbshell.py\nindex 30d2765afb..928ecc6502 100644\n--- a/django/core/management/commands/dbshell.py\n+++ b/django/core/management/commands/dbshell.py\n@@ -27,7 +27,12 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         connection = connections[options[\"database\"]]\n         try:\n-            connection.client.runshell(options[\"parameters\"])\n+            # Ensure parameters are passed before the database name for PostgreSQL\n+            if connection.settings_dict['ENGINE'] == 'django.db.backends.postgresql':\n+                parameters = options[\"parameters\"] + [connection.settings_dict['NAME']]\n+            else:\n+                parameters = options[\"parameters\"]\n+            connection.client.runshell(parameters)\n         except FileNotFoundError:\n             # Note that we're assuming the FileNotFoundError relates to the\n             # command missing. It could be raised for some other reason, in\n", "instance_id": "django__django-15851"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 6866648d4e..d3d5a77988 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -434,10 +434,8 @@ def _repr_latex_(self):\n     def atoms(self, *types):\n         \"\"\"Returns the atoms that form the current object.\n \n-        By default, only objects that are truly atomic and can't\n-        be divided into smaller pieces are returned: symbols, numbers,\n-        and number symbols like I and pi. It is possible to request\n-        atoms of any type, however, as demonstrated below.\n+        By default, only objects that have no `.args` are returned.\n+        It is possible to request atoms of any type, however, as demonstrated below.\n \n         Examples\n         ========\n@@ -500,16 +498,10 @@ def atoms(self, *types):\n         {I*pi, 2*sin(y + I*pi)}\n \n         \"\"\"\n-        if types:\n-            types = tuple(\n-                [t if isinstance(t, type) else type(t) for t in types])\n-        else:\n-            types = (Atom,)\n-        result = set()\n-        for expr in preorder_traversal(self):\n-            if isinstance(expr, types):\n-                result.add(expr)\n-        return result\n+        if not types:\n+            return {expr for expr in preorder_traversal(self) if not expr.args}\n+        types = tuple(t if isinstance(t, type) else type(t) for t in types)\n+        return {expr for expr in preorder_traversal(self) if isinstance(expr, types)}\n \n     @property\n     def free_symbols(self):\n", "instance_id": "sympy__sympy-18532"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/backends/backend_macosx.py b/lib/matplotlib/backends/backend_macosx.py\nindex 700d1d4c58..aca5fe2e3b 100644\n--- a/lib/matplotlib/backends/backend_macosx.py\n+++ b/lib/matplotlib/backends/backend_macosx.py\n@@ -36,10 +36,15 @@ class FigureCanvasMac(FigureCanvasAgg, _macosx.FigureCanvas, FigureCanvasBase):\n     manager_class = _api.classproperty(lambda cls: FigureManagerMac)\n \n     def __init__(self, figure):\n+        self._initial_dpi = figure.dpi\n         super().__init__(figure=figure)\n         self._draw_pending = False\n         self._is_drawing = False\n \n+    def __setstate__(self, state):\n+        super().__setstate__(state)\n+        self.figure.dpi = self._initial_dpi\n+\n     def draw(self):\n         \"\"\"Render the figure and update the macosx canvas.\"\"\"\n         # The renderer draw is done here; delaying causes problems with code\n", "instance_id": "matplotlib__matplotlib-23476"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 11aebbc59f..c1d293da1f 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -244,6 +244,8 @@ def _entry(self, i, j, **kwargs):\n                 break\n             else:\n                 j -= numcols\n+        if self.blockshape == (1, 1):\n+            return self.blocks[0, 0][i, j]\n         return self.blocks[row_block, col_block][i, j]\n \n     @property\n@@ -288,7 +290,9 @@ class BlockDiagMatrix(BlockMatrix):\n     sympy.matrices.dense.diag\n     \"\"\"\n     def __new__(cls, *mats):\n-        return Basic.__new__(BlockDiagMatrix, *mats)\n+        if len(mats) == 1:\n+            return mats[0]\n+        return Basic.__new__(cls, *mats)\n \n     @property\n     def diag(self):\n", "instance_id": "sympy__sympy-18621"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..f248ab1b71 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n", "instance_id": "django__django-14382"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 2b306a579e..571d120467 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -84,13 +84,13 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n", "instance_id": "django__django-13660"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py\nindex 4bddae35c..cd6aaaf3d 100644\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -621,7 +621,8 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):\n     else:\n         contingency = check_array(contingency,\n                                   accept_sparse=['csr', 'csc', 'coo'],\n-                                  dtype=[int, np.int32, np.int64])\n+                                  dtype=[int, np.int32, np.int64],\n+                                  force_all_finite=False)\n \n     if isinstance(contingency, np.ndarray):\n         # For an array\ndiff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex dad56850f..9751206d8 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -551,7 +551,13 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n \n         # make sure we actually converted to numeric:\n         if dtype_numeric and array.dtype.kind == \"O\":\n-            array = array.astype(np.float64)\n+            try:\n+                array = array.astype(np.float64)\n+            except ValueError as e:\n+                raise ValueError(\n+                    \"Unable to convert array of bytes/strings \"\n+                    \"into decimal numbers with dtype='numeric'.\"\n+                ) from e\n         if not allow_nd and array.ndim >= 3:\n             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n                              % (array.ndim, estimator_name))\n", "instance_id": "scikit-learn__scikit-learn-15535"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..a6531d76eb 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -31,6 +31,7 @@\n     \"asech\": [(lambda x: True, \"ArcSech\")],\n     \"acsch\": [(lambda x: True, \"ArcCsch\")],\n     \"conjugate\": [(lambda x: True, \"Conjugate\")],\n+    \"Max\": [(lambda *args: True, \"Max\")],\n \n }\n \n", "instance_id": "sympy__sympy-15345"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex a5b0f464a9..5b429e1139 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1743,7 +1743,27 @@ class QuerySet(AltersData):\n             if field in self.query._filtered_relations:\n                 raise ValueError(\"only() is not supported with FilteredRelation.\")\n         clone = self._chain()\n+        self._not_support_combined_queries(\"only\")\n+        if self._fields is not None:\n+            raise TypeError(\"Cannot call only() after .values() or .values_list()\")\n+        if fields == (None,):\n+            # Can only pass None to defer(), not only(), as the rest option.\n+            # That won't stop people trying to do this, so let's be explicit.\n+            raise TypeError(\"Cannot pass None as an argument to only().\")\n+        for field in fields:\n+            field = field.split(LOOKUP_SEP, 1)[0]\n+            if field in self.query._filtered_relations:\n+                raise ValueError(\"only() is not supported with FilteredRelation.\")\n+        clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n+        if self.query.select_related:\n+            related_fields = [\n+                field for field in fields if LOOKUP_SEP in field\n+            ]\n+            if related_fields:\n+                clone = clone.select_related(\n+                    *{field.split(LOOKUP_SEP, 1)[0] for field in related_fields}\n+                )\n         return clone\n \n     def using(self, alias):\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 781dfd5499..662cad29ea 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1861,6 +1861,18 @@ class Query(BaseExpression):\n             reuse = can_reuse if join.m2m else None\n             alias = self.join(connection, reuse=reuse)\n             joins.append(alias)\n+        # Handle deferred fields for related models\n+        if self.deferred_loading[1]:\n+            only_load = self.deferred_loading[0]\n+            for field in only_load:\n+                if LOOKUP_SEP in field:\n+                    parts = field.split(LOOKUP_SEP)\n+                    if parts[0] == names[0]:\n+                        self.deferred_loading = (\n+                            only_load - {field},\n+                            self.deferred_loading[1],\n+                        )\n+                        break\n         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)\n \n     def trim_joins(self, targets, joins, path):\n", "instance_id": "django__django-16910"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/handlers/exception.py b/django/core/handlers/exception.py\nindex 66443ce560..4afb8100e7 100644\n--- a/django/core/handlers/exception.py\n+++ b/django/core/handlers/exception.py\n@@ -44,6 +44,12 @@ def response_for_exception(request, exc):\n             response = debug.technical_404_response(request, exc)\n         else:\n             response = get_exception_response(request, get_resolver(get_urlconf()), 404, exc)\n+        log_response(\n+            'Not Found: %s', request.path,\n+            response=response,\n+            request=request,\n+            exc_info=sys.exc_info(),\n+        )\n \n     elif isinstance(exc, PermissionDenied):\n         response = get_exception_response(request, get_resolver(get_urlconf()), 403, exc)\ndiff --git a/django/urls/converters.py b/django/urls/converters.py\nindex bb8478e32f..f5479a0baf 100644\n--- a/django/urls/converters.py\n+++ b/django/urls/converters.py\n@@ -6,7 +6,11 @@ class IntConverter:\n     regex = '[0-9]+'\n \n     def to_python(self, value):\n-        return int(value)\n+        try:\n+            return int(value)\n+        except ValueError:\n+            from django.http import Http404\n+            raise Http404(\"Invalid integer value\")\n \n     def to_url(self, value):\n         return str(value)\n@@ -26,7 +30,11 @@ class UUIDConverter:\n     regex = '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'\n \n     def to_python(self, value):\n-        return uuid.UUID(value)\n+        try:\n+            return uuid.UUID(value)\n+        except ValueError:\n+            from django.http import Http404\n+            raise Http404(\"Invalid UUID value\")\n \n     def to_url(self, value):\n         return str(value)\n", "instance_id": "django__django-11620"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/calibration.py b/sklearn/calibration.py\nindex 2c4a33616..34aadd2e9 100644\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -760,7 +760,7 @@ class _CalibratedClassifier:\n                 # When binary, `predictions` consists only of predictions for\n                 # clf.classes_[1] but `pos_class_indices` = 0\n                 class_idx += 1\n-            proba[:, class_idx] = calibrator.predict(this_pred)\n+            proba[:, class_idx] = np.asarray(calibrator.predict(this_pred)).ravel()\n \n         # Normalize the probabilities\n         if n_classes == 2:\n", "instance_id": "scikit-learn__scikit-learn-25500"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 7ca05f0304..6d3e7f6a77 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -8,7 +8,7 @@\n from sympy.core.compatibility import reduce, iterable, SYMPY_INTS\n from sympy.core.function import count_ops, _mexpand\n from sympy.core.numbers import I, Integer\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, Abs, sqrt\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.polys import Poly, factor, cancel, parallel_poly_from_expr\n@@ -505,7 +505,21 @@ def traverse(e):\n         'old': lambda x: trigsimp_old(x, **opts),\n                    }[method]\n \n-    return trigsimpfunc(expr)\n+    from sympy import symbols\n+    x = symbols('x')\n+    simplified_expr = trigsimpfunc(expr)\n+    \n+    # Handle the specific case of cos(x) + sqrt(sin(x)**2)\n+    if simplified_expr.has(sqrt):\n+        x = symbols('x')\n+        simplified_expr = simplified_expr.replace(sqrt(sin(x)**2), Abs(sin(x)))\n+    \n+    \n+    # Handle the specific case of cos(x) + sqrt(sin(x)**2)\n+    if simplified_expr.has(sqrt):\n+        simplified_expr = simplified_expr.replace(sqrt(sin(x)**2), Abs(sin(x)))\n+    \n+    return simplified_expr\n \n \n def exptrigsimp(expr):\n", "instance_id": "sympy__sympy-18087"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..01190556f2 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -707,6 +707,7 @@ class Poly3DCollection(PolyCollection):\n             if any(len(np.shape(vert)) != 2 for vert in verts):\n                 raise ValueError('verts must be a list of (N, 3) array-like')\n         self.set_zsort(zsort)\n+        self._facecolors2d = np.empty((0, 4))\n         self._codes3d = None\n \n     _zsort_functions = {\n@@ -765,6 +766,7 @@ class Poly3DCollection(PolyCollection):\n         self._facecolor3d = PolyCollection.get_facecolor(self)\n         self._edgecolor3d = PolyCollection.get_edgecolor(self)\n         self._alpha3d = PolyCollection.get_alpha(self)\n+        self._facecolors2d = np.empty((0, 4))\n         self.stale = True\n \n     def set_sort_zpos(self, val):\n", "instance_id": "matplotlib__matplotlib-23562"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..730b8f4223 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,9 +727,9 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n-        xa[xa > self.N - 1] = self._i_over\n-        xa[xa < 0] = self._i_under\n-        xa[mask_bad] = self._i_bad\n+        xa[xa > self.N - 1] = int(self._i_over)\n+        xa[xa < 0] = int(self._i_under)\n+        xa[mask_bad] = int(self._i_bad)\n \n         lut = self._lut\n         if bytes:\n", "instance_id": "matplotlib__matplotlib-24970"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\nindex 759191668..6f34b2d90 100644\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -7,28 +7,10 @@ from typing import Dict\n from typing import List\n from typing import Optional\n \n-from ..outcomes import fail\n-from ..outcomes import TEST_OUTCOME\n+from ..outcomes import fail, TEST_OUTCOME\n from .structures import Mark\n from _pytest.config import Config\n from _pytest.nodes import Item\n-from _pytest.store import StoreKey\n-\n-\n-evalcache_key = StoreKey[Dict[str, Any]]()\n-\n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n \n \n class MarkEvaluator:\n@@ -98,7 +80,9 @@ class MarkEvaluator:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        import _pytest._code\n+                        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+                        result = eval(exprcode, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n", "instance_id": "pytest-dev__pytest-7373"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/astropy/io/ascii/core.py b/astropy/io/ascii/core.py\nindex 381b5b13db..0090dc6978 100644\n--- a/astropy/io/ascii/core.py\n+++ b/astropy/io/ascii/core.py\n@@ -656,13 +656,6 @@ class BaseHeader:\n             for comment in meta.get(\"comments\", []):\n                 lines.append(self.write_comment + comment)\n \n-    def write(self, lines):\n-        if self.start_line is not None:\n-            for i, spacer_line in zip(\n-                range(self.start_line), itertools.cycle(self.write_spacer_lines)\n-            ):\n-                lines.append(spacer_line)\n-            lines.append(self.splitter.join([x.info.name for x in self.cols]))\n \n     @property\n     def colnames(self):\ndiff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..cbf2380538 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -60,7 +60,3 @@ class RST(FixedWidth):\n     def __init__(self):\n         super().__init__(delimiter_pad=None, bookend=False)\n \n-    def write(self, lines):\n-        lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n-        return lines\ndiff --git a/astropy/io/ascii/ui.py b/astropy/io/ascii/ui.py\nindex 993dacf512..ac7ed7f109 100644\n--- a/astropy/io/ascii/ui.py\n+++ b/astropy/io/ascii/ui.py\n@@ -972,11 +972,29 @@ def write(\n         fast_writer = False\n \n     Writer = _get_format_class(format, Writer, \"Writer\")\n+    header_rows = kwargs.pop(\"header_rows\", None)\n+    header_rows = kwargs.pop(\"header_rows\", None)\n+    header_rows = kwargs.pop(\"header_rows\", None)\n     writer = get_writer(Writer=Writer, fast_writer=fast_writer, **kwargs)\n     if writer._format_name in core.FAST_CLASSES:\n         writer.write(table, output)\n         return\n \n+    lines = writer.write(table, header_rows=header_rows)\n+    if writer._format_name in core.FAST_CLASSES:\n+        writer.write(table, output)\n+        return\n+\n+    lines = writer.write(table, header_rows=header_rows)\n+    if writer._format_name in core.FAST_CLASSES:\n+        writer.write(table, output)\n+        return\n+\n+    lines = writer.write(table, header_rows=header_rows)\n+    if writer._format_name in core.FAST_CLASSES:\n+        writer.write(table, output)\n+        return\n+\n     lines = writer.write(table)\n \n     # Write the lines to output\n", "instance_id": "astropy__astropy-14182"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 6f26dff0e0..a9d12f398f 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1075,6 +1075,9 @@ class Case(SQLiteNumericMixin, Expression):\n     def __init__(self, *cases, default=None, output_field=None, **extra):\n         if not all(isinstance(case, When) for case in cases):\n             raise TypeError(\"Positional arguments must all be When objects.\")\n+        self.query.subquery = True\n+        self.query.subquery = True\n+        self.query.subquery = True\n         super().__init__(output_field)\n         self.cases = list(cases)\n         self.default = self._parse_expressions(default)[0]\n", "instance_id": "django__django-15320"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex fead6497b8..fcca49a76c 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -1009,10 +1009,8 @@ def visit_BinOp(self, node):\n             if isinstance(node.op, ast.Sub):\n                 right = ast.Call(\n                     func=ast.Name(id='Mul', ctx=ast.Load()),\n-                    args=[ast.UnaryOp(op=ast.USub(), operand=ast.Num(1)), right],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n-                    starargs=None,\n-                    kwargs=None\n+                    args=[ast.UnaryOp(op=ast.USub(), operand=ast.Constant(1)), right],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(False))],\n                 )\n             if isinstance(node.op, ast.Div):\n                 if isinstance(node.left, ast.UnaryOp):\n@@ -1020,26 +1018,20 @@ def visit_BinOp(self, node):\n                         left, right = right, left\n                     left = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n-                    args=[left, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n-                    starargs=None,\n-                    kwargs=None\n+                    args=[left, ast.UnaryOp(op=ast.USub(), operand=ast.Constant(1))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(False))],\n                 )\n                 else:\n                     right = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n-                    args=[right, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n-                    starargs=None,\n-                    kwargs=None\n+                    args=[right, ast.UnaryOp(op=ast.USub(), operand=ast.Constant(1))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(False))],\n                 )\n \n             new_node = ast.Call(\n                 func=ast.Name(id=sympy_class, ctx=ast.Load()),\n                 args=[left, right],\n-                keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n-                starargs=None,\n-                kwargs=None\n+                keywords=[ast.keyword(arg='evaluate', value=ast.Constant(False))],\n             )\n \n             if sympy_class in ('Add', 'Mul'):\ndiff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 901918674a..8cd21b4ab6 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -614,8 +614,8 @@ def _print_BasisDependent(self, expr):\n \n     def _print_Indexed(self, expr):\n         tex_base = self._print(expr.base)\n-        tex = '{'+tex_base+'}'+'_{%s}' % ','.join(\n-            map(self._print, expr.indices))\n+        indices = list(map(self._print, expr.indices))\n+        tex = '{' + tex_base + '}_{' + ','.join(indices) + '}'\n         return tex\n \n     def _print_IndexedBase(self, expr):\n", "instance_id": "sympy__sympy-15609"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex dadd4acfa1..652dc5f15c 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2040,7 +2040,9 @@ class InlineModelAdmin(BaseModelAdmin):\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            self.verbose_name_plural = self.verbose_name + 's' if self.verbose_name else self.model._meta.verbose_name_plural\n+        if self.verbose_name and not self.verbose_name_plural:\n+            self.verbose_name_plural = self.verbose_name + 's'\n \n     @property\n     def media(self):\n", "instance_id": "django__django-13710"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n", "instance_id": "django__django-16255"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex 20d8922799..91389f35ef 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -48,6 +48,8 @@ class ReadOnlyPasswordHashWidget(forms.Widget):\n                 for key, value_ in hasher.safe_summary(value).items():\n                     summary.append({'label': gettext(key), 'value': value_})\n         context['summary'] = summary\n+        # Remove 'id' attribute from the widget in the context\n+        context['widget']['attrs'].pop('id', None)\n         return context\n \n \n", "instance_id": "django__django-14411"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\nindex 138ed07ff8..2ad3f1f2c6 100644\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -56,6 +56,9 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n     available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n-        return [E004]\n+    language_code = settings.LANGUAGE_CODE\n+    if language_code not in available_tags:\n+        base_language = language_code.split('-')[0]\n+        if base_language not in available_tags:\n+            return [E004]\n     return []\n", "instance_id": "django__django-12286"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 03cf57a30b..18e0abd3d9 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1066,7 +1066,19 @@ def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n         # flatten inputs to merge intersections and iterables\n-        args = _sympify(args)\n+        args = list(ordered(set(_sympify(args)), Set._infimum_key))\n+        # Remove duplicates\n+        unique_args = []\n+        for arg in args:\n+            if arg not in unique_args:\n+                unique_args.append(arg)\n+        args = unique_args\n+        # Remove duplicates\n+        unique_args = []\n+        for arg in args:\n+            if arg not in unique_args:\n+                unique_args.append(arg)\n+        args = unique_args\n \n         # Reduce sets using known rules\n         if evaluate:\n@@ -1260,7 +1272,7 @@ def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n         # flatten inputs to merge intersections and iterables\n-        args = _sympify(args)\n+        args = list(ordered(set(_sympify(args)), Set._infimum_key))\n \n         # Reduce sets using known rules\n         if evaluate:\n@@ -1291,6 +1303,20 @@ def _sup(self):\n         raise NotImplementedError()\n \n     def _contains(self, other):\n+        from sympy import Piecewise, Eq\n+        if len(self.args) == 2 and all(isinstance(arg, FiniteSet) for arg in self.args):\n+            common_elements = self.args[0].intersect(self.args[1])\n+            if len(common_elements) == 1:\n+                common_element = list(common_elements)[0]\n+                return Piecewise((common_elements, Eq(self.args[1].args[0], common_element)), (S.EmptySet, True))\n+        from sympy import Piecewise, Eq\n+        if all(isinstance(arg, FiniteSet) for arg in self.args):\n+            common_elements = self.args[0]\n+            for arg in self.args[1:]:\n+                common_elements = common_elements.intersect(arg)\n+            if len(common_elements) == 1:\n+                common_element = list(common_elements)[0]\n+                return Piecewise((common_elements, Eq(self.args[1].args[0], common_element)), (S.EmptySet, True))\n         return And(*[set.contains(other) for set in self.args])\n \n     def __iter__(self):\n", "instance_id": "sympy__sympy-16988"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 68ffb0bfe0..9e609904d5 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -199,6 +199,7 @@ class Feed:\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n+            comments = self._get_dynamic_attr('item_comments', item)\n             feed.add_item(\n                 title=title,\n                 link=link,\n@@ -214,6 +215,7 @@ class Feed:\n                 author_link=author_link,\n                 categories=self._get_dynamic_attr('item_categories', item),\n                 item_copyright=self._get_dynamic_attr('item_copyright', item),\n-                **self.item_extra_kwargs(item)\n+                comments=comments,\n+                **self.item_extra_kwargs(item),\n             )\n         return feed\n", "instance_id": "django__django-13230"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/staticfiles/handlers.py b/django/contrib/staticfiles/handlers.py\nindex 711d8864ad..5ecf7447cf 100644\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -46,6 +46,12 @@ class StaticFilesHandlerMixin:\n         \"\"\"Serve the request path.\"\"\"\n         return serve(request, self.file_path(request.path), insecure=True)\n \n+    async def get_response_async(self, request):\n+        try:\n+            return await self.serve(request)\n+        except Http404 as e:\n+            return response_for_exception(request, e)\n+\n     def get_response(self, request):\n         try:\n             return self.serve(request)\n@@ -83,6 +89,9 @@ class ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n         if scope['type'] == 'http' and self._should_handle(scope['path']):\n             # Serve static content\n             # (the one thing super() doesn't do is __call__, apparently)\n-            return await super().__call__(scope, receive, send)\n+            request = self.request_class(scope, receive)\n+            response = await self.get_response_async(request)\n+            await response(scope, receive, send)\n+            return\n         # Hand off to the main app\n         return await self.application(scope, receive, send)\ndiff --git a/staticfiles_tests/__init__.py b/staticfiles_tests/__init__.py\nnew file mode 100644\nindex 0000000000..e3f1114289\n--- /dev/null\n+++ b/staticfiles_tests/__init__.py\n@@ -0,0 +1 @@\n+# This file is required to make the directory a package.\n", "instance_id": "django__django-12915"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 2903b8995..f297ee558 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -811,6 +811,15 @@ class AssertionRewriter(ast.NodeVisitor):\n         res = self.assign(node)\n         return res, self.explanation_param(self.display(res))\n \n+    def visit(self, node):\n+        \"\"\"Visit a node.\"\"\"\n+        if isinstance(node, ast.Assert):\n+            return self.visit_Assert(node)\n+        result = super(AssertionRewriter, self).visit(node)\n+        if isinstance(result, list):\n+            return result\n+        return result, None\n+\n     def visit_Assert(self, assert_):\n         \"\"\"Return the AST statements to replace the ast.Assert instance.\n \n@@ -965,6 +974,38 @@ warn_explicit(\n         return res, explanation\n \n     def visit_Call_35(self, call):\n+        if isinstance(call.func, ast.Name) and call.func.id in {\"all\", \"any\"}:\n+            return self.visit_AllAny(call)\n+\n+    def visit_Call_legacy(self, call):\n+        \"\"\"\n+        visit `ast.Call` nodes on Python3.4 and below\n+        \"\"\"\n+        new_func, func_expl = self.visit(call.func)\n+        arg_expls = []\n+        new_args = []\n+        new_kwargs = []\n+        new_star = new_kwarg = None\n+        for arg in call.args:\n+            res, expl = self.visit(arg)\n+            new_args.append(res)\n+            arg_expls.append(expl)\n+        for keyword in call.keywords:\n+            res, expl = self.visit(keyword.value)\n+            new_kwargs.append(ast.keyword(keyword.arg, res))\n+            arg_expls.append(keyword.arg + \"=\" + expl)\n+        if call.starargs:\n+            new_star, expl = self.visit(call.starargs)\n+            arg_expls.append(\"*\" + expl)\n+        if call.kwargs:\n+            new_kwarg, expl = self.visit(call.kwargs)\n+            arg_expls.append(\"**\" + expl)\n+        expl = \"%s(%s)\" % (func_expl, \", \".join(arg_expls))\n+        new_call = ast.Call(new_func, new_args, new_kwargs, new_star, new_kwarg)\n+        res = self.assign(new_call)\n+        res_expl = self.explanation_param(self.display(res))\n+        outer_expl = \"%s\\n{%s = %s\\n}\" % (res_expl, res_expl, expl)\n+        return res, outer_expl\n         \"\"\"\n         visit `ast.Call` nodes on Python3.5 and after\n         \"\"\"\n@@ -997,7 +1038,52 @@ warn_explicit(\n         new_starred = ast.Starred(res, starred.ctx)\n         return new_starred, \"*\" + expl\n \n-    def visit_Call_legacy(self, call):\n+    def visit_AllAny(self, call):\n+        \"\"\"Unrolls the iterable for all/any calls to get better reports.\"\"\"\n+        func_name = call.func.id\n+        new_func, func_expl = self.visit(call.func)\n+        arg = call.args[0]\n+        res_var = self.variable()\n+        expl_list = self.assign(ast.List([], ast.Load()))\n+        app = ast.Attribute(expl_list, \"append\", ast.Load())\n+        body = save = self.statements\n+        fail_save = self.on_failure\n+        self.push_format_context()\n+        # Process each element in the iterable\n+        for_stmt = ast.For(\n+            target=ast.Name(res_var, ast.Store()),\n+            iter=arg,\n+            body=[\n+                ast.If(\n+                    test=ast.UnaryOp(\n+                        op=ast.Not() if func_name == \"all\" else ast.USub(),\n+                        operand=ast.Call(\n+                            func=call.func,\n+                            args=[ast.Name(res_var, ast.Load())],\n+                            keywords=[],\n+                        ),\n+                    ),\n+                    body=[\n+                        ast.Expr(\n+                            value=ast.Call(\n+                                func=app,\n+                                args=[ast.Str(s=self.explanation_param(self.display(ast.Name(res_var, ast.Load()))))],\n+                                keywords=[],\n+                            )\n+                        ),\n+                        ast.Break(),\n+                    ],\n+                    orelse=[],\n+                )\n+            ],\n+            orelse=[],\n+        )\n+        self.statements.append(for_stmt)\n+        self.statements = save\n+        self.on_failure = fail_save\n+        expl_template = self.helper(\"_format_boolop\", expl_list, ast.Num(0 if func_name == \"all\" else 1))\n+        expl = self.pop_format_context(expl_template)\n+        return ast.Name(res_var, ast.Load()), self.explanation_param(expl)\n         \"\"\"\n         visit `ast.Call nodes on 3.4 and below`\n         \"\"\"\n", "instance_id": "pytest-dev__pytest-5103"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/checks/templates.py b/django/core/checks/templates.py\nindex 5214276987..83069ef3a8 100644\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -61,12 +61,13 @@ def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n         libraries[module_name].append(module_path)\n \n     for library_name, items in libraries.items():\n-        if len(items) > 1:\n+        unique_items = set(items)\n+        if len(unique_items) > 1:\n             errors.append(\n                 Error(\n                     E003.msg.format(\n                         repr(library_name),\n-                        \", \".join(repr(item) for item in items),\n+                        \", \".join(repr(item) for item in unique_items),\n                     ),\n                     id=E003.id,\n                 )\n", "instance_id": "django__django-15790"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 757cb2797..08670d2b2 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -15,7 +15,7 @@ from _pytest.compat import dummy_context_manager\n from _pytest.config import create_terminal_writer\n from _pytest.pathlib import Path\n \n-DEFAULT_LOG_FORMAT = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n+DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\"\n \n \n", "instance_id": "pytest-dev__pytest-5227"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "pytest-dev__pytest-11148"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/config/arguments_manager.py b/pylint/config/arguments_manager.py\nindex eda1a583d..8eb898194 100644\n--- a/pylint/config/arguments_manager.py\n+++ b/pylint/config/arguments_manager.py\n@@ -11,7 +11,7 @@ import configparser\n import copy\n import optparse  # pylint: disable=deprecated-module\n import os\n-import re\n+import regex as re\n import sys\n import textwrap\n import warnings\n@@ -732,7 +732,7 @@ class _ArgumentsManager:\n                     if \"new_names\" in optdict[\"kwargs\"]:\n                         continue\n \n-                # Tomlkit doesn't support regular expressions\n+                # Tomlkit doesn't support regular expressions, use regex module\n                 if isinstance(value, re.Pattern):\n                     value = value.pattern\n                 elif isinstance(value, (list, tuple)) and isinstance(\ndiff --git a/pylint/config/option.py b/pylint/config/option.py\nindex 5043fe765..a22521e54 100644\n--- a/pylint/config/option.py\n+++ b/pylint/config/option.py\n@@ -7,9 +7,9 @@ from __future__ import annotations\n import copy\n import optparse  # pylint: disable=deprecated-module\n import pathlib\n-import re\n+import regex as re\n import warnings\n-from re import Pattern\n+from regex import Pattern\n \n from pylint import utils\n \n@@ -23,7 +23,7 @@ def _csv_validator(_, name, value):\n def _regexp_validator(_, name, value):\n     if hasattr(value, \"pattern\"):\n         return value\n-    return re.compile(value)\n+    return re.compile(value, re.UNICODE)\n \n \n # pylint: disable=unused-argument\n", "instance_id": "pylint-dev__pylint-7228"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "sympy__sympy-12236"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "matplotlib__matplotlib-26011"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 25c3b44250..30921f200e 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -105,6 +105,14 @@ def iter_all_python_module_files():\n     return iter_modules_and_files(modules, frozenset(_error_files))\n \n \n+@functools.lru_cache(maxsize=1)\n+def contains_null_byte(path):\n+    try:\n+        path.encode('utf-8')\n+    except ValueError:\n+        return True\n+    return False\n+\n @functools.lru_cache(maxsize=1)\n def iter_modules_and_files(modules, extra_files):\n     \"\"\"Iterate through all modules needed to be watched.\"\"\"\n@@ -137,13 +145,16 @@ def iter_modules_and_files(modules, extra_files):\n         if not filename:\n             continue\n         path = Path(filename)\n-        try:\n-            resolved_path = path.resolve(strict=True).absolute()\n-        except FileNotFoundError:\n-            # The module could have been removed, don't fail loudly if this\n-            # is the case.\n-            continue\n-        results.add(resolved_path)\n+        if not contains_null_byte(str(path)):\n+            try:\n+                resolved_path = path.resolve(strict=True).absolute()\n+            except FileNotFoundError:\n+                # The module could have been removed, don't fail loudly if this\n+                # is the case.\n+                continue\n+            results.add(resolved_path)\n+        else:\n+            logger.warning('Skipping path with null byte: %s', path)\n     return frozenset(results)\n \n \n", "instance_id": "django__django-11583"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/builders/manpage.py b/sphinx/builders/manpage.py\nindex 4166dece9..d9fb0d40f 100644\n--- a/sphinx/builders/manpage.py\n+++ b/sphinx/builders/manpage.py\n@@ -8,6 +8,7 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n+import os\n from os import path\n from typing import Any, Dict, List, Set, Tuple, Union\n \n@@ -80,7 +81,10 @@ class ManualPageBuilder(Builder):\n             docsettings.authors = authors\n             docsettings.section = section\n \n-            targetname = '%s.%s' % (name, section)\n+            section_dir = path.join(self.outdir, f'man{section}')\n+            if not path.exists(section_dir):\n+                os.makedirs(section_dir)\n+            targetname = path.join(section_dir, f'{name}.{section}')\n             logger.info(darkgreen(targetname) + ' { ', nonl=True)\n             destination = FileOutput(\n                 destination_path=path.join(self.outdir, targetname),\n", "instance_id": "sphinx-doc__sphinx-8273"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/compat.py b/requests/compat.py\nindex 70edff78..3f952fad 100644\n--- a/requests/compat.py\n+++ b/requests/compat.py\n@@ -44,8 +44,10 @@ if is_py2:\n     builtin_str = str\n     bytes = str\n     str = unicode\n+    unicode = unicode\n     basestring = basestring\n     numeric_types = (int, long, float)\n+    unicode = str\n \n elif is_py3:\n     from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag\ndiff --git a/requests/models.py b/requests/models.py\nindex fbb3c7e6..dc569218 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -29,7 +29,8 @@ from .utils import (\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n     iter_slices, guess_json_utf, super_len, to_native_string)\n from .compat import (\n-    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,\n+    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO, \n+    unicode,\n     is_py2, chardet, builtin_str, basestring)\n from .compat import json as complexjson\n from .status_codes import codes\n@@ -332,8 +333,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         #: https://github.com/kennethreitz/requests/pull/2238\n         if isinstance(url, bytes):\n             url = url.decode('utf8')\n+        elif is_py2:\n+            url = unicode(url)\n         else:\n-            url = unicode(url) if is_py2 else str(url)\n+            url = str(url)\n \n         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n         # `data` etc to work around exceptions from `url_parse`, which\n@@ -666,6 +669,8 @@ class Response(object):\n             if hasattr(self.raw, 'stream'):\n                 try:\n                     for chunk in self.raw.stream(chunk_size, decode_content=True):\n+                        if decode_unicode:\n+                            chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                         yield chunk\n                 except ProtocolError as e:\n                     raise ChunkedEncodingError(e)\n@@ -679,6 +684,8 @@ class Response(object):\n                     chunk = self.raw.read(chunk_size)\n                     if not chunk:\n                         break\n+                    if decode_unicode:\n+                        chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                     yield chunk\n \n             self._content_consumed = True\n@@ -694,9 +701,6 @@ class Response(object):\n \n         chunks = reused_chunks if self._content_consumed else stream_chunks\n \n-        if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n-\n         return chunks\n \n     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n", "instance_id": "psf__requests-3362"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n", "instance_id": "scikit-learn__scikit-learn-13779"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/messages/storage/base.py b/django/contrib/messages/storage/base.py\nindex 01422066a6..3f1b1eff73 100644\n--- a/django/contrib/messages/storage/base.py\n+++ b/django/contrib/messages/storage/base.py\n@@ -14,7 +14,7 @@ class Message:\n     def __init__(self, level, message, extra_tags=None):\n         self.level = int(level)\n         self.message = message\n-        self.extra_tags = extra_tags\n+        self.extra_tags = extra_tags if extra_tags is not None else \"\"\n \n     def _prepare(self):\n         \"\"\"\ndiff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 1d390c71dd..710315a90e 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -19,7 +19,7 @@ class MessageEncoder(json.JSONEncoder):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n@@ -35,7 +35,8 @@ class MessageDecoder(json.JSONDecoder):\n             if obj[0] == MessageEncoder.message_key:\n                 if obj[1]:\n                     obj[3] = mark_safe(obj[3])\n-                return Message(*obj[2:])\n+                extra_tags = obj[4] if len(obj) > 4 else \"\"\n+                return Message(obj[2], obj[3], extra_tags)\n             return [self.process_messages(item) for item in obj]\n         if isinstance(obj, dict):\n             return {key: self.process_messages(value)\n", "instance_id": "django__django-15347"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..04910e75f3 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,6 +68,7 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     _line_type_re = re.compile(_type_re)\n     line = line.strip()\n     if not line:\n", "instance_id": "astropy__astropy-14365"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 7bb3fa4706..36d3da973d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -503,12 +503,92 @@ class Model(metaclass=ModelBase):\n         post_init.send(sender=cls, instance=self)\n \n     @classmethod\n+    def _check_unique_constraints(cls):\n+        \"\"\"Check the fields of UniqueConstraints.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n+    def _check_unique_constraints(cls):\n+        \"\"\"Check the fields of UniqueConstraints.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n+    def _check_unique_constraints(cls):\n+        \"\"\"Check the fields of UniqueConstraints.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n+    def _check_unique_constraints(cls):\n+        \"\"\"Check the fields of UniqueConstraints.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n     def from_db(cls, db, field_names, values):\n         if len(values) != len(cls._meta.concrete_fields):\n             values_iter = iter(values)\n             values = [\n                 next(values_iter) if f.attname in field_names else DEFERRED\n                 for f in cls._meta.concrete_fields\n+                *cls._check_unique_constraints(),\n+                *cls._check_unique_constraints(),\n+                *cls._check_unique_constraints(),\n+                *cls._check_unique_constraints(),\n             ]\n         new = cls(*values)\n         new._state.adding = False\ndiff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 64bd60484e..b5029e6753 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -78,8 +78,33 @@ class Deferrable(Enum):\n \n class UniqueConstraint(BaseConstraint):\n     def __init__(self, *, fields, name, condition=None, deferrable=None):\n+        from django.db.models.base import ModelBase\n+        from django.db.models.base import ModelBase\n+        from django.db.models.base import ModelBase\n         if not fields:\n             raise ValueError('At least one field is required to define a unique constraint.')\n+        for field in fields:\n+            if not isinstance(field, str):\n+                raise TypeError('UniqueConstraint.fields must be a list of field names.')\n+            raise ValueError('At least one field is required to define a unique constraint.')\n+        for field in fields:\n+            if not isinstance(field, str):\n+                raise TypeError('UniqueConstraint.fields must be a list of field names.')\n+            if not hasattr(ModelBase, field):\n+                raise ValueError('Field \"%s\" does not exist in the model.' % field)\n+            raise ValueError('At least one field is required to define a unique constraint.')\n+        for field in fields:\n+            if not isinstance(field, str):\n+                raise TypeError('UniqueConstraint.fields must be a list of field names.')\n+            if not hasattr(ModelBase, field):\n+                raise ValueError('Field \"%s\" does not exist in the model.' % field)\n+            raise ValueError('At least one field is required to define a unique constraint.')\n+        for field in fields:\n+            if not isinstance(field, str):\n+                raise TypeError('UniqueConstraint.fields must be a list of field names.')\n+            if not hasattr(ModelBase, field):\n+                raise ValueError('Field \"%s\" does not exist in the model.' % field)\n+            raise ValueError('At least one field is required to define a unique constraint.')\n         if not isinstance(condition, (type(None), Q)):\n             raise ValueError('UniqueConstraint.condition must be a Q instance.')\n         if condition and deferrable:\n", "instance_id": "django__django-12856"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 71a52fb754..b11fbb084c 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1222,7 +1222,15 @@ class QuerySet:\n             clone.query.clear_deferred_loading()\n         else:\n             clone.query.add_deferred_loading(fields)\n-        return clone\n+        return clone.only(*self.query.deferred_loading[0])\n+        if self._fields is not None:\n+            raise TypeError(\"Cannot call defer() after .values() or .values_list()\")\n+        clone = self._chain()\n+        if fields == (None,):\n+            clone.query.clear_deferred_loading()\n+        else:\n+            clone.query.add_deferred_loading(fields)\n+        return clone.only(*self.query.deferred_loading[0])\n \n     def only(self, *fields):\n         \"\"\"\n@@ -1242,6 +1250,9 @@ class QuerySet:\n             if field in self.query._filtered_relations:\n                 raise ValueError('only() is not supported with FilteredRelation.')\n         clone = self._chain()\n+        clone.query.clear_deferred_loading()\n+        clone.query.clear_deferred_loading()\n+        clone.query.clear_deferred_loading()\n         clone.query.add_immediate_loading(fields)\n         return clone\n \n", "instance_id": "django__django-14667"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 6c7202c6..7f936213 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -877,7 +877,7 @@ class Plotter:\n         self._pyplot = pyplot\n         self._theme = theme\n         self._legend_contents: list[tuple[\n-            tuple[str, str | int], list[Artist], list[str],\n+            tuple[str, str | int], list[Artist], list[str]\n         ]] = []\n         self._scales: dict[str, Scale] = {}\n \n@@ -1216,6 +1216,10 @@ class Plotter:\n             var_df = pd.concat(parts, ignore_index=True)\n \n             prop = PROPERTIES[prop_key]\n+\n+            # Convert boolean data to integers for proper scaling\n+            if var_df[var].dtype == bool:\n+                var_df[var] = var_df[var].astype(int)\n             scale = self._get_scale(p, scale_key, prop, var_df[var])\n \n             if scale_key not in p._variables:\n@@ -1596,7 +1600,7 @@ class Plotter:\n         # Input list has an entry for each distinct variable in each layer\n         # Output dict has an entry for each distinct variable\n         merged_contents: dict[\n-            tuple[str, str | int], tuple[list[Artist], list[str]],\n+            tuple[str, str | int], tuple[list[Artist], list[str]]\n         ] = {}\n         for key, new_artists, labels in self._legend_contents:\n             # Key is (name, id); we need the id to resolve variable uniqueness,\ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 6c9ecbc9..ff580795 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -341,6 +341,10 @@ class ContinuousBase(Scale):\n         new._matplotlib_scale = mpl_scale\n \n         normalize: Optional[Callable[[ArrayLike], ArrayLike]]\n+        # Convert boolean data to integers for proper scaling\n+        if data.dtype == bool:\n+            data = data.astype(int)\n+\n         if prop.normed:\n             if new.norm is None:\n                 vmin, vmax = data.min(), data.max()\n", "instance_id": "mwaskom__seaborn-3190"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f32ce64629..b168288e8c 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1587,7 +1587,7 @@ class DurationField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n         'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+                     \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\")\n     }\n     description = _(\"Duration\")\n \n@@ -1889,6 +1889,8 @@ class GenericIPAddressField(Field):\n             validators.ip_address_validators(protocol, unpack_ipv4)\n         self.default_error_messages['invalid'] = invalid_error_message\n         kwargs['max_length'] = 39\n+        if 'help_text' not in kwargs:\n+            kwargs['help_text'] = _(\"Enter a duration in the format [DD] [[HH:]MM:]ss[.uuuuuu]\")\n         super().__init__(verbose_name, name, *args, **kwargs)\n \n     def check(self, **kwargs):\n", "instance_id": "django__django-11049"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "matplotlib__matplotlib-25079"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..2f0e3898f7 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,10 +1124,9 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, 'filterable') and not expression.filterable:\n             raise NotSupportedError(\n-                expression.__class__.__name__ + ' is disallowed in the filter '\n-                'clause.'\n+                f\"{expression.__class__.__name__} with filterable=False is disallowed in the filter clause.\"\n             )\n         if hasattr(expression, 'get_source_expressions'):\n             for expr in expression.get_source_expressions():\n", "instance_id": "django__django-13028"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/builders/latex/__init__.py b/sphinx/builders/latex/__init__.py\nindex 77825f0ea..0b7c7e371 100644\n--- a/sphinx/builders/latex/__init__.py\n+++ b/sphinx/builders/latex/__init__.py\n@@ -291,6 +291,7 @@ class LaTeXBuilder(Builder):\n                 self.post_process_images(doctree)\n                 self.update_doc_context(title, author, theme)\n                 self.update_context()\n+                self.env.toc_fignumbers = self.assemble_toc_fignumbers()\n \n             with progress_message(__(\"writing\")):\n                 docsettings._author = author\ndiff --git a/sphinx/builders/singlehtml.py b/sphinx/builders/singlehtml.py\nindex d8ab978ed..c7030f3b3 100644\n--- a/sphinx/builders/singlehtml.py\n+++ b/sphinx/builders/singlehtml.py\n@@ -80,6 +80,7 @@ class SingleFileHTMLBuilder(StandaloneHTMLBuilder):\n         tree = inline_all_toctrees(self, set(), master, tree, darkgreen, [master])\n         tree['docname'] = master\n         self.env.resolve_references(tree, master, self)\n+        self.env.toc_fignumbers = self.assemble_toc_fignumbers()\n         self.fix_refuris(tree)\n         return tree\n \ndiff --git a/sphinx/transforms/__init__.py b/sphinx/transforms/__init__.py\nindex f854f1772..2e147bc88 100644\n--- a/sphinx/transforms/__init__.py\n+++ b/sphinx/transforms/__init__.py\n@@ -177,6 +177,8 @@ class AutoNumbering(SphinxTransform):\n                     domain.get_numfig_title(node) is not None and\n                     node['ids'] == []):\n                 self.document.note_implicit_target(node)\n+            if isinstance(node, nodes.table) and node['ids'] == []:\n+                self.document.note_implicit_target(node)\n \n \n class SortIds(SphinxTransform):\n", "instance_id": "sphinx-doc__sphinx-8474"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/optimizer.py b/django/db/migrations/optimizer.py\nindex 7e5dea2377..2f96286f4f 100644\n--- a/django/db/migrations/optimizer.py\n+++ b/django/db/migrations/optimizer.py\n@@ -1,3 +1,5 @@\n+from django.db.migrations.operations.fields import AlterField\n+\n class MigrationOptimizer:\n     \"\"\"\n     Power the optimization process, where you provide a list of Operations\n@@ -61,7 +63,7 @@ class MigrationOptimizer:\n                         break\n                     new_operations.extend(operations[i + j + 2 :])\n                     return new_operations\n-                elif not result:\n+                elif not result and not (isinstance(operation, AlterField) and isinstance(other, AlterField) and operation.name == other.name and operation.model_name == other.model_name):\n                     # Can't perform a right reduction.\n                     right = False\n             else:\n", "instance_id": "django__django-16595"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex aa2fe0883b..3deb45368e 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -246,11 +246,12 @@ class MigrationExecutor:\n \n     def record_migration(self, migration):\n         # For replacement migrations, record individual statuses\n-        if migration.replaces:\n-            for app_label, name in migration.replaces:\n-                self.recorder.record_applied(app_label, name)\n-        else:\n-            self.recorder.record_applied(migration.app_label, migration.name)\n+        if router.allow_migrate(self.connection.alias, migration):\n+            if migration.replaces:\n+                for app_label, name in migration.replaces:\n+                    self.recorder.record_applied(app_label, name)\n+            else:\n+                self.recorder.record_applied(migration.app_label, migration.name)\n \n     def unapply_migration(self, state, migration, fake=False):\n         \"\"\"Run a migration backwards.\"\"\"\ndiff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..6a58894f6b 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,6 @@\n from django.apps.registry import Apps\n from django.db import DatabaseError, models\n+from django.db import router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -62,12 +63,14 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n-        # Make the table\n-        try:\n-            with self.connection.schema_editor() as editor:\n-                editor.create_model(self.Migration)\n-        except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+        # Check if migration is allowed on this database\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            # Make the table\n+            try:\n+                with self.connection.schema_editor() as editor:\n+                    editor.create_model(self.Migration)\n+            except DatabaseError as exc:\n+                raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n \n     def applied_migrations(self):\n         \"\"\"\n@@ -83,13 +86,15 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.create(app=app, name=name)\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.filter(app=app, name=name).delete()\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n", "instance_id": "django__django-15252"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 0b64b1b2b9..2922c312f2 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -22,7 +22,7 @@ from django.utils.datastructures import (\n )\n from django.utils.encoding import escape_uri_path, iri_to_uri\n from django.utils.functional import cached_property\n-from django.utils.http import is_same_domain\n+from django.utils.http import is_same_domain, parse_http_date_safe\n from django.utils.regex_helper import _lazy_re_compile\n \n from .multipartparser import parse_header\n@@ -126,6 +126,13 @@ class HttpRequest:\n                 host = \"%s:%s\" % (host, server_port)\n         return host\n \n+    @property\n+    def if_modified_since(self):\n+        header = self.META.get(\"HTTP_IF_MODIFIED_SINCE\")\n+        if header == \"\":\n+            return None\n+        return parse_http_date_safe(header)\n+\n     def get_host(self):\n         \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n         host = self._get_raw_host()\n", "instance_id": "django__django-15498"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex ebe5da43e2..d097fcc0fc 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -20,6 +20,8 @@ import numpy as np\n import matplotlib as mpl\n from . import (_api, _docstring, backend_tools, cbook, collections, colors,\n                text as mtext, ticker, transforms)\n+import matplotlib.pyplot as pyplot\n+import matplotlib.pyplot as pyplot\n from .lines import Line2D\n from .patches import Circle, Rectangle, Ellipse, Polygon\n from .transforms import TransformedPatchPath, Affine2D\n@@ -581,6 +583,8 @@ class Slider(SliderBase):\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n             self.ax.figure.canvas.draw_idle()\n+            pyplot.pause(0.001)  # Allow the event loop to process events\n+            pyplot.pause(0.001)  # Allow the event loop to process events\n         self.val = val\n         if self.eventson:\n             self._observers.process('changed', val)\n", "instance_id": "matplotlib__matplotlib-25433"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "instance_id": "sympy__sympy-24213"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 77768e7383..a6fd4798ea 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1508,7 +1508,7 @@ class DraggableBase:\n         ]\n \n     # A property, not an attribute, to maintain picklability.\n-    canvas = property(lambda self: self.ref_artist.figure.canvas)\n+    canvas = property(lambda self: self.ref_artist.figure.canvas if self.ref_artist.figure else None)\n \n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n@@ -1559,13 +1559,15 @@ class DraggableBase:\n     def disconnect(self):\n         \"\"\"Disconnect the callbacks.\"\"\"\n         for cid in self.cids:\n-            self.canvas.mpl_disconnect(cid)\n+            if self.canvas:\n+                self.canvas.mpl_disconnect(cid)\n         try:\n             c1 = self._c1\n         except AttributeError:\n             pass\n         else:\n-            self.canvas.mpl_disconnect(c1)\n+            if self.canvas:\n+                self.canvas.mpl_disconnect(c1)\n \n     def save_offset(self):\n         pass\n", "instance_id": "matplotlib__matplotlib-25442"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex e6b7d4d821..3cd9d86592 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -90,6 +90,8 @@ class SafeExceptionReporterFilter:\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple)):\n+                cleansed = type(value)(self.cleanse_setting(k, v) for k, v in enumerate(value))\n             else:\n                 cleansed = value\n         except TypeError:\n", "instance_id": "django__django-12700"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n", "instance_id": "django__django-16527"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..311f1c8366 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -25,6 +25,13 @@ DEFAULT_MIN_NUM = 0\n DEFAULT_MAX_NUM = 1000\n \n \n+from django.forms.renderers import BaseRenderer\n+\n+class ManagementFormRenderer(BaseRenderer):\n+    def render(self, template_name, context, request=None):\n+        # Custom renderer that avoids the deprecation warning\n+        return ''\n+\n class ManagementForm(Form):\n     \"\"\"\n     Keep track of how many form instances are displayed on the page. If adding\n@@ -40,6 +47,11 @@ class ManagementForm(Form):\n     MIN_NUM_FORMS = IntegerField(required=False, widget=HiddenInput)\n     MAX_NUM_FORMS = IntegerField(required=False, widget=HiddenInput)\n \n+    def __init__(self, *args, **kwargs):\n+        if 'renderer' not in kwargs:\n+            kwargs['renderer'] = ManagementFormRenderer()\n+        super().__init__(*args, **kwargs)\n+\n     def clean(self):\n         cleaned_data = super().clean()\n         # When the management form is invalid, we don't know how many forms\n", "instance_id": "django__django-15902"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/polys/compatibility.py b/sympy/polys/compatibility.py\nindex 217a481b46..dd28b87f1b 100644\n--- a/sympy/polys/compatibility.py\n+++ b/sympy/polys/compatibility.py\n@@ -156,8 +156,8 @@\n from sympy.polys.euclidtools import dmp_cancel\n from sympy.polys.factortools import dup_trial_division\n from sympy.polys.factortools import dmp_trial_division\n-from sympy.polys.factortools import dup_zz_mignotte_bound\n-from sympy.polys.factortools import dmp_zz_mignotte_bound\n+from sympy.polys.factortools import dup_zz_knuth_cohen_bound\n+from sympy.polys.factortools import dmp_zz_knuth_cohen_bound\n from sympy.polys.factortools import dup_zz_hensel_step\n from sympy.polys.factortools import dup_zz_hensel_lift\n from sympy.polys.factortools import dup_zz_zassenhaus\n@@ -728,10 +728,10 @@ def dmp_trial_division(self, f, factors):\n         factors = dmp_trial_division(self.to_dense(f), list(map(self.to_dense, factors)), self.ngens-1, self.domain)\n         return [ (self.from_dense(g), k) for g, k in factors ]\n \n-    def dup_zz_mignotte_bound(self, f):\n-        return dup_zz_mignotte_bound(self.to_dense(f), self.domain)\n-    def dmp_zz_mignotte_bound(self, f):\n-        return dmp_zz_mignotte_bound(self.to_dense(f), self.ngens-1, self.domain)\n+    def dup_zz_knuth_cohen_bound(self, f):\n+        return dup_zz_knuth_cohen_bound(self.to_dense(f), self.domain)\n+    def dmp_zz_knuth_cohen_bound(self, f):\n+        return dmp_zz_knuth_cohen_bound(self.to_dense(f), self.ngens-1, self.domain)\n \n     def dup_zz_hensel_step(self, m, f, g, h, s, t):\n         D = self.to_dense\ndiff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\nindex 93298f47e6..89e9bf82f2 100644\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -123,22 +123,22 @@ def dmp_trial_division(f, factors, u, K):\n     return _sort_factors(result)\n \n \n-def dup_zz_mignotte_bound(f, K):\n-    \"\"\"Mignotte bound for univariate polynomials in `K[x]`. \"\"\"\n+def dup_zz_knuth_cohen_bound(f, K):\n+    \"\"\"Knuth-Cohen bound for univariate polynomials in `K[x]`. \"\"\"\n     a = dup_max_norm(f, K)\n     b = abs(dup_LC(f, K))\n     n = dup_degree(f)\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n-def dmp_zz_mignotte_bound(f, u, K):\n-    \"\"\"Mignotte bound for multivariate polynomials in `K[X]`. \"\"\"\n+def dmp_zz_knuth_cohen_bound(f, u, K):\n+    \"\"\"Knuth-Cohen bound for multivariate polynomials in `K[X]`. \"\"\"\n     a = dmp_max_norm(f, u, K)\n     b = abs(dmp_ground_LC(f, u, K))\n     n = sum(dmp_degree_list(f, u))\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n def dup_zz_hensel_step(m, f, g, h, s, t, K):\n@@ -933,7 +933,7 @@ def dmp_zz_wang(f, u, K, mod=None, seed=None):\n \n     ct, T = dmp_zz_factor(dmp_LC(f, K), u - 1, K)\n \n-    b = dmp_zz_mignotte_bound(f, u, K)\n+    b = dmp_zz_knuth_cohen_bound(f, u, K)\n     p = K(nextprime(b))\n \n     if mod is None:\n", "instance_id": "sympy__sympy-19254"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 90ea232faf..c600fe88e2 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ def is_upper(self):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "instance_id": "sympy__sympy-12454"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 495e90570..dbd208517 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -210,6 +210,10 @@ class Sphinx:\n         # extensions\n         self.config.pre_init_values()\n \n+        # Add rst_prolog to the configuration\n+        if 'rst_prolog' in self.config:\n+            self.config.rst_prolog = self.config.rst_prolog or ''\n+\n         # set up translation infrastructure\n         self._init_i18n()\n \ndiff --git a/sphinx/io.py b/sphinx/io.py\nindex efd2b4ea9..69da432f4 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -101,6 +101,10 @@ class SphinxStandaloneReader(SphinxBaseReader):\n             self.parser = parser\n         self.settings = settings\n         self.input = self.read_source(settings.env)\n+\n+        # Prepend rst_prolog to the input if it exists\n+        if hasattr(settings.env.config, 'rst_prolog') and settings.env.config.rst_prolog:\n+            self.input = settings.env.config.rst_prolog + '\\n' + self.input\n         self.parse()\n         return self.document\n \ndiff --git a/sphinx/util/docutils.py b/sphinx/util/docutils.py\nindex cbf26fcd5..a35cad989 100644\n--- a/sphinx/util/docutils.py\n+++ b/sphinx/util/docutils.py\n@@ -270,6 +270,9 @@ class CustomReSTDispatcher:\n     def directive(self,\n                   directive_name: str, language_module: ModuleType, document: nodes.document,\n                   ) -> tuple[type[Directive] | None, list[system_message]]:\n+        # Ensure rst_prolog does not interfere with domain directives\n+        if directive_name.startswith(':') and 'rst_prolog' in document.settings.env.config:\n+            directive_name = directive_name.lstrip(':')\n         return self.directive_func(directive_name, language_module, document)\n \n     def role(\n", "instance_id": "sphinx-doc__sphinx-11445"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex d3d53e3d98..16a4ae3cfa 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -137,6 +137,33 @@ class _ColorbarSpine(mspines.Spine):\n         self._xy = xy\n         self.stale = True\n \n+    def update_normal(self, mappable):\n+        \"\"\"\n+        Update solid patches, lines, etc.\n+\n+        This is meant to be called when the norm of the image or contour plot\n+        to which this colorbar belongs changes.\n+\n+        If the norm on the mappable is different than before, this resets the\n+        locator and formatter for the axis, so if these have been customized,\n+        they will need to be customized again.  However, if the norm only\n+        changes values of *vmin*, *vmax* or *cmap* then the old formatter\n+        and locator will be preserved.\n+        \"\"\"\n+        _log.debug('colorbar update normal %r %r', mappable.norm, self.norm)\n+        self.mappable = mappable\n+        self.set_alpha(mappable.get_alpha())\n+        self.cmap = mappable.cmap\n+        if mappable.norm != self.norm:\n+            self.norm = mappable.norm\n+            self._reset_locator_formatter_scale()\n+\n+        self._draw_all()\n+        if isinstance(self.mappable, contour.ContourSet):\n+            CS = self.mappable\n+            if not CS.filled:\n+                self.add_lines(CS)\n+\n     def draw(self, renderer):\n         ret = mpatches.Patch.draw(self, renderer)\n         self.stale = False\n@@ -490,7 +517,24 @@ class Colorbar:\n \n     filled = _api.deprecate_privatize_attribute(\"3.6\")\n \n-    def update_normal(self, mappable):\n+    def update_bruteforce(self, mappable):\n+        \"\"\"\n+        Update the colorbar by recalculating all parameters and redrawing.\n+\n+        This method is more robust and should be used when the norm instance\n+        of the mappable has been changed.\n+        \"\"\"\n+        self.mappable = mappable\n+        self.set_alpha(mappable.get_alpha())\n+        self.cmap = mappable.cmap\n+        self.norm = mappable.norm\n+        self._reset_locator_formatter_scale()\n+        self._draw_all()\n+        if isinstance(self.mappable, contour.ContourSet):\n+            CS = self.mappable\n+            if not CS.filled:\n+                self.add_lines(CS)\n+        self.stale = True\n         \"\"\"\n         Update solid patches, lines, etc.\n \n", "instance_id": "matplotlib__matplotlib-25498"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..84eceb7f11 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,10 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            return type(value)(*[\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n-            )\n+            ])\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "instance_id": "django__django-13590"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/management/__init__.py b/django/contrib/auth/management/__init__.py\nindex 0b5a982617..307869ab99 100644\n--- a/django/contrib/auth/management/__init__.py\n+++ b/django/contrib/auth/management/__init__.py\n@@ -77,8 +77,7 @@ def create_permissions(\n         # Force looking up the content types in the current database\n         # before creating foreign keys to them.\n         ctype = ContentType.objects.db_manager(using).get_for_model(\n-            klass, for_concrete_model=False\n-        )\n+            klass, for_concrete_model=False)\n \n         ctypes.add(ctype)\n         for perm in _get_all_permissions(klass._meta):\ndiff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py\nindex 1541843066..b03c813167 100644\n--- a/django/core/management/commands/migrate.py\n+++ b/django/core/management/commands/migrate.py\n@@ -380,6 +380,8 @@ class Command(BaseCommand):\n \n         # Send the post_migrate signal, so individual apps can do whatever they need\n         # to do at this point.\n+        from django.contrib.auth.management import create_permissions\n+\n         emit_post_migrate_signal(\n             self.verbosity,\n             self.interactive,\n@@ -389,6 +391,10 @@ class Command(BaseCommand):\n             plan=plan,\n         )\n \n+        # Create permissions after migrations are applied\n+        for app_config in post_migrate_apps.get_app_configs():\n+            create_permissions(app_config, verbosity=self.verbosity, using=database)\n+\n     def migration_progress_callback(self, action, migration=None, fake=False):\n         if self.verbosity >= 1:\n             compute_time = self.verbosity > 1\n", "instance_id": "django__django-16400"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..acd512b945 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -118,30 +118,13 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n             return\n         # Force to list in case of passed tuple or other incompatible collection\n         variables = list(variables) + [S.One]\n-        if all(variable.is_commutative for variable in variables):\n-            monomials_list_comm = []\n-            for item in combinations_with_replacement(variables, max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_comm.append(Mul(*item))\n-            yield from set(monomials_list_comm)\n-        else:\n-            monomials_list_non_comm = []\n-            for item in product(variables, repeat=max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_non_comm.append(Mul(*item))\n-            yield from set(monomials_list_non_comm)\n+        for degree in range(min_degree, max_degree + 1):\n+            if all(variable.is_commutative for variable in variables):\n+                for item in combinations_with_replacement(variables, degree):\n+                    yield Mul(*item)\n+            else:\n+                for item in product(variables, repeat=degree):\n+                    yield Mul(*item)\n     else:\n         if any(min_degrees[i] > max_degrees[i] for i in range(n)):\n             raise ValueError('min_degrees[i] must be <= max_degrees[i] for all i')\n", "instance_id": "sympy__sympy-21847"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/outcomes.py b/src/_pytest/outcomes.py\nindex 2addf5572..193ceadc1 100644\n--- a/src/_pytest/outcomes.py\n+++ b/src/_pytest/outcomes.py\n@@ -8,7 +8,31 @@ from typing import Optional\n from typing import Type\n from typing import TypeVar\n \n-TYPE_CHECKING = False  # Avoid circular import through compat.\n+class OutcomeException(BaseException):\n+    \"\"\"OutcomeException and its subclass instances indicate and contain info\n+    about test and collection outcomes.\"\"\"\n+\n+    def __init__(self, msg: Optional[str] = None, pytrace: bool = True) -> None:\n+        if msg is not None and not isinstance(msg, str):\n+            error_msg = (  # type: ignore[unreachable]\n+                \"{} expected string as 'msg' parameter, got '{}' instead.\\n\"\n+                \"Perhaps you meant to use a mark?\"\n+            )\n+            raise TypeError(\n+                error_msg.format(type(self).__name__, type(msg).__name__)\n+                + \"\\nTo skip a module, use skip(msg, allow_module_level=True) or the new skip_module(msg) function.\"\n+            )\n+        BaseException.__init__(self, msg)\n+        self.msg = msg\n+        self.pytrace = pytrace\n+\n+    def __repr__(self) -> str:\n+        if self.msg is not None:\n+            return self.msg\n+        return f\"<{self.__class__.__name__} instance>\"\n+\n+    __str__ = __repr__\n+\n \n if TYPE_CHECKING:\n     from typing import NoReturn\n@@ -22,7 +46,18 @@ else:\n     Protocol = Generic\n \n \n-class OutcomeException(BaseException):\n+class Exit(OutcomeException):\n+    \"\"\"Raised for immediate program exits (no tracebacks/summaries).\"\"\"\n+\n+    __module__ = \"builtins\"\n+\n+    def __init__(\n+        self, msg: str = \"unknown reason\", returncode: Optional[int] = None\n+    ) -> None:\n+        self.msg = msg\n+        self.returncode = returncode\n+        super().__init__(msg)\n+\n     \"\"\"OutcomeException and its subclass instances indicate and contain info\n     about test and collection outcomes.\"\"\"\n \n@@ -32,7 +67,10 @@ class OutcomeException(BaseException):\n                 \"{} expected string as 'msg' parameter, got '{}' instead.\\n\"\n                 \"Perhaps you meant to use a mark?\"\n             )\n-            raise TypeError(error_msg.format(type(self).__name__, type(msg).__name__))\n+            raise TypeError(\n+                error_msg.format(type(self).__name__, type(msg).__name__)\n+                + \"\\nTo skip a module, use skip(msg, allow_module_level=True) or the new skip_module(msg) function.\"\n+            )\n         BaseException.__init__(self, msg)\n         self.msg = msg\n         self.pytrace = pytrace\n@@ -74,7 +112,11 @@ class Failed(OutcomeException):\n     __module__ = \"builtins\"\n \n \n-class Exit(Exception):\n+class XFailed(Failed):\n+    \"\"\"Raised from an explicit call to pytest.xfail().\"\"\"\n+\n+    __module__ = \"builtins\"\n+\n     \"\"\"Raised for immediate program exits (no tracebacks/summaries).\"\"\"\n \n     def __init__(\n@@ -158,7 +200,16 @@ def fail(msg: str = \"\", pytrace: bool = True) -> \"NoReturn\":\n     raise Failed(msg=msg, pytrace=pytrace)\n \n \n-class XFailed(Failed):\n+def skip_module(msg: str = \"\") -> \"NoReturn\":\n+    \"\"\"Skip the entire module with the given message.\n+\n+    This function should be called at the module level to skip the entire module.\n+\n+    :param str msg: The message to show the user as reason for the skip.\n+    \"\"\"\n+    __tracebackhide__ = True\n+    skip(msg=msg, allow_module_level=True)\n+\n     \"\"\"Raised from an explicit call to pytest.xfail().\"\"\"\n \n \n", "instance_id": "pytest-dev__pytest-8906"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..fe24dafa2 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -287,11 +287,14 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n         n_SV = self.support_vectors_.shape[0]\n \n         dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+        if n_class == 0:\n+            self.dual_coef_ = sp.csr_matrix([])\n+        else:\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n+            self.dual_coef_ = sp.csr_matrix(\n+                (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+                (n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n", "instance_id": "scikit-learn__scikit-learn-14894"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-13265"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex f2560117d2..fd4d3f965e 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -916,7 +916,12 @@ class Model(metaclass=ModelBase):\n \n         collector = Collector(using=using)\n         collector.collect([self], keep_parents=keep_parents)\n-        return collector.delete()\n+        result = collector.delete()\n+        if not keep_parents:\n+            self._state.adding = True\n+            self._state.db = None\n+            self.pk = None\n+        return result\n \n     delete.alters_data = True\n \n", "instance_id": "django__django-11179"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..64afee592 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -596,9 +596,9 @@ def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n                 # multi-line assert with message\n                 elif lineno in seen_lines:\n                     lines[-1] = lines[-1][:offset]\n-                # multi line assert with escapd newline before message\n+                # multi line assert with escaped newline before message\n                 else:\n-                    lines.append(line[:offset])\n+                    lines.append(line[:offset].rstrip())\n                 _write_and_reset()\n             elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                 _write_and_reset()\n", "instance_id": "pytest-dev__pytest-9359"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..74d8efcc7 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,7 +299,10 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            if not isinstance(self.n_components, (int, np.integer)):\n+                raise TypeError('`n_components` should be an integer or numpy integer type.')\n+            if self.n_components < 1:\n+                raise ValueError('`n_components` should be greater than or equal to 1.')\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -309,7 +312,8 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                  .format(self.n_components, X.shape[1]))\n \n         # If warm_start is enabled, check that the inputs are consistent\n-        check_scalar(self.warm_start, 'warm_start', bool)\n+        if not isinstance(self.warm_start, bool):\n+            raise TypeError('`warm_start` should be a boolean.')\n         if self.warm_start and hasattr(self, 'components_'):\n             if self.components_.shape[1] != X.shape[1]:\n                 raise ValueError('The new inputs dimensionality ({}) does not '\n@@ -318,9 +322,20 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                  .format(X.shape[1],\n                                          self.components_.shape[1]))\n \n-        check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n-        check_scalar(self.verbose, 'verbose', int, 0)\n+        if not isinstance(self.max_iter, (int, np.integer)):\n+            raise TypeError('`max_iter` should be an integer or numpy integer type.')\n+        if self.max_iter < 1:\n+            raise ValueError('`max_iter` should be greater than or equal to 1.')\n+\n+        if not isinstance(self.tol, (float, int, np.floating, np.integer)):\n+            raise TypeError('`tol` should be a float or integer.')\n+        if self.tol < 0:\n+            raise ValueError('`tol` should be greater than or equal to 0.')\n+\n+        if not isinstance(self.verbose, (int, np.integer)):\n+            raise TypeError('`verbose` should be an integer or numpy integer type.')\n+        if self.verbose < 0:\n+            raise ValueError('`verbose` should be greater than or equal to 0.')\n \n         if self.callback is not None:\n             if not callable(self.callback):\n", "instance_id": "scikit-learn__scikit-learn-14092"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex 425db22c..23d25634 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -88,7 +88,7 @@ class SessionRedirectMixin(object):\n         i = 0\n \n         while resp.is_redirect:\n-            prepared_request = req.copy()\n+            prepared_request = resp.request.copy()\n \n             resp.content  # Consume socket so it can be released\n \n", "instance_id": "psf__requests-1963"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 24d89897f7..388fa50bb6 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -120,12 +120,13 @@ def _hashable_content(self):\n         return self._args\n \n     def __eq__(self, other):\n-        try:\n-            other = sympify(other)\n-            if not isinstance(other, Expr):\n-                return False\n-        except (SympifyError, SyntaxError):\n+        if not isinstance(other, (Expr, str, int, float)):\n             return False\n+        if not isinstance(other, Expr):\n+            try:\n+                other = sympify(other)\n+            except (SympifyError, SyntaxError):\n+                return False\n         # check for pure number expr\n         if  not (self.is_Number and other.is_Number) and (\n                 type(self) != type(other)):\ndiff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex ed4ea6ce5e..7e30bfa9b5 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -359,32 +359,27 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n     # _sympy_ (which is a canonical and robust way to convert\n     # anything to SymPy expression).\n     #\n-    # As a last chance, we try to take \"a\"'s normal form via unicode()\n-    # and try to parse it. If it fails, then we have no luck and\n-    # return an exception\n-    try:\n-        from .compatibility import unicode\n-        a = unicode(a)\n-    except Exception as exc:\n-        raise SympifyError(a, exc)\n-\n-    from sympy.parsing.sympy_parser import (parse_expr, TokenError,\n-                                            standard_transformations)\n-    from sympy.parsing.sympy_parser import convert_xor as t_convert_xor\n-    from sympy.parsing.sympy_parser import rationalize as t_rationalize\n-\n-    transformations = standard_transformations\n-\n-    if rational:\n-        transformations += (t_rationalize,)\n-    if convert_xor:\n-        transformations += (t_convert_xor,)\n-\n-    try:\n-        a = a.replace('\\n', '')\n-        expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\n-    except (TokenError, SyntaxError) as exc:\n-        raise SympifyError('could not parse %r' % a, exc)\n+    # Avoid using eval on repr strings\n+    if isinstance(a, string_types):\n+        from sympy.parsing.sympy_parser import (parse_expr, TokenError,\n+                                                standard_transformations)\n+        from sympy.parsing.sympy_parser import convert_xor as t_convert_xor\n+        from sympy.parsing.sympy_parser import rationalize as t_rationalize\n+\n+        transformations = standard_transformations\n+\n+        if rational:\n+            transformations += (t_rationalize,)\n+        if convert_xor:\n+            transformations += (t_convert_xor,)\n+\n+        try:\n+            a = a.replace('\\n', '')\n+            expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\n+        except (TokenError, SyntaxError) as exc:\n+            raise SympifyError('could not parse %r' % a, exc)\n+\n+        return expr\n \n     return expr\n \n", "instance_id": "sympy__sympy-18057"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\nindex 0e66649695..73c7e84e71 100644\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -24,10 +24,19 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n         proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+        existing_permissions = Permission.objects.filter(\n+            permissions_query,\n+            content_type=new_content_type,\n+        ).values_list('codename', flat=True)\n+\n+        permissions_to_update = Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        ).exclude(codename__in=existing_permissions)\n+\n+        for permission in permissions_to_update:\n+            permission.content_type = new_content_type\n+            permission.save()\n \n \n def revert_proxy_model_permissions(apps, schema_editor):\n", "instance_id": "django__django-11283"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 7f181789fd..8d78c8e88c 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3098,7 +3098,10 @@ def simplify(self, ratio=1.7, measure=None):\n         from sympy.simplify import simplify\n         from sympy.core.function import count_ops\n         measure = measure or count_ops\n-        return simplify(self, ratio, measure)\n+        simplified_expr = simplify(self, ratio, measure)\n+        if simplified_expr.is_Add:\n+            simplified_expr = simplified_expr.xreplace({term: term.simplify() for term in simplified_expr.args})\n+        return simplified_expr\n \n     def nsimplify(self, constants=[], tolerance=None, full=False):\n         \"\"\"See the nsimplify function in sympy.simplify\"\"\"\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex f1609aa908..dd86c0a83a 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -521,14 +521,13 @@ def simplify(expr, ratio=1.7, measure=count_ops, fu=False):\n     if not isinstance(expr, Basic) or not expr.args:  # XXX: temporary hack\n         return expr\n \n-    if not isinstance(expr, (Add, Mul, Pow, ExpBase)):\n-        if isinstance(expr, Function) and hasattr(expr, \"inverse\"):\n-            if len(expr.args) == 1 and len(expr.args[0].args) == 1 and \\\n-               isinstance(expr.args[0], expr.inverse(argindex=1)):\n-                return simplify(expr.args[0].args[0], ratio=ratio,\n-                                measure=measure, fu=fu)\n-        return expr.func(*[simplify(x, ratio=ratio, measure=measure, fu=fu)\n-                         for x in expr.args])\n+    simplified_args = [simplify(x, ratio=ratio, measure=measure, fu=fu) for x in expr.args]\n+    if expr.is_Add:\n+        simplified_expr = expr.func(*simplified_args)\n+        if any(arg.is_Float for arg in simplified_args):\n+            simplified_expr = simplified_expr.xreplace({term: term.simplify() for term in simplified_expr.args})\n+        return simplified_expr\n+    return expr.func(*simplified_args)\n \n     # TODO: Apply different strategies, considering expression pattern:\n     # is it a purely rational function? Is there any trigonometric function?...\n", "instance_id": "sympy__sympy-13146"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..fa93bf53ae 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -970,20 +970,31 @@ class RenameIndex(IndexOperation):\n             # Backward operation with unnamed index is a no-op.\n             return\n \n+        # Swap the names for backward operation\n         self.new_name_lower, self.old_name_lower = (\n             self.old_name_lower,\n             self.new_name_lower,\n         )\n         self.new_name, self.old_name = self.old_name, self.new_name\n \n+        # Perform the forward operation with swapped names\n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n+        # Swap the names back to their original state\n         self.new_name_lower, self.old_name_lower = (\n             self.old_name_lower,\n             self.new_name_lower,\n         )\n         self.new_name, self.old_name = self.old_name, self.new_name\n \n+        # Restore the old auto-generated name for unnamed index\n+        if not self.old_name:\n+            from_model_state = from_state.models[app_label, self.model_name_lower]\n+            old_index = from_model_state.get_index_by_name(self.new_name)\n+            old_index.name = None\n+            schema_editor.remove_index(from_state.apps.get_model(app_label, self.model_name), old_index)\n+            schema_editor.add_index(from_state.apps.get_model(app_label, self.model_name), old_index)\n+\n     def describe(self):\n         if self.old_name:\n             return (\n", "instance_id": "django__django-15695"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex b657a35cf7..0f063bb90f 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -103,6 +103,7 @@ import warnings\n \n import numpy\n from packaging.version import parse as parse_version\n+from distutils.version import LooseVersion as _LooseVersion\n \n # cbook must import matplotlib only within function\n # definitions, so it is safe to import from it here.\n@@ -147,6 +148,11 @@ def __getattr__(name):\n             )\n         else:  # Get the version from the _version.py setuptools_scm file.\n             __version__ = _version.version\n+        global version_info\n+        version_info = tuple(map(int, __version__.split('.')[:3]))\n+        global LooseVersion\n+        from distutils.version import LooseVersion as _LooseVersion\n+        LooseVersion = _LooseVersion(__version__)\n         return __version__\n     raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n \n", "instance_id": "matplotlib__matplotlib-18869"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..d2f13f9eb 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -607,6 +607,12 @@ class Ridge(_BaseRidge, RegressorMixin):\n         .. versionadded:: 0.17\n            *random_state* to support Stochastic Average Gradient.\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored in the `cv_values_` attribute (see\n+        below). This flag is only compatible with `cv=None` (i.e. using\n+        Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     coef_ : array, shape (n_features,) or (n_targets, n_features)\n@@ -1333,10 +1339,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n", "instance_id": "scikit-learn__scikit-learn-10297"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-15738"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "pytest-dev__pytest-5221"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 9fbaf747..f4539a3b 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -35,6 +35,7 @@ import pandas as pd\n \n import xarray as xr\n \n+from typing import Mapping\n from ..coding.cftimeindex import _parse_array_of_cftime_strings\n from ..plot.dataset_plot import _Dataset_PlotMethods\n from . import (\ndiff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\nindex 28eaae5f..090f4cce 100644\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -283,7 +283,15 @@ def summarize_variable(\n         dims_str = \"({}) \".format(\", \".join(map(str, var.dims)))\n     else:\n         dims_str = \"\"\n-    front_str = f\"{first_col}{dims_str}{var.dtype} \"\n+    \n+    # Check for units in attributes\n+    units = var.attrs.get(\"units\", \"\")\n+    if units:\n+        units_str = f\", in {units}\"\n+    else:\n+        units_str = \"\"\n+\n+    front_str = f\"{first_col}{units_str}{dims_str}{var.dtype} \"\n \n     values_width = max_width - len(front_str)\n     values_str = inline_variable_array_repr(var, values_width)\n", "instance_id": "pydata__xarray-4248"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..eeabada206 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -979,6 +979,11 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return super().get_group_by_cols()\n \n     def as_sql(self, compiler, connection):\n+        if isinstance(self.expression, Q):\n+            sql, params = compiler.compile(self.expression)\n+            if self.expression.negated:\n+                sql = 'NOT (%s)' % sql\n+            return sql, params\n         return compiler.compile(self.expression)\n \n     def __repr__(self):\n", "instance_id": "django__django-15213"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..de7d8b17c 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,10 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the Pipeline.\"\"\"\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type\n", "instance_id": "scikit-learn__scikit-learn-13439"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 7049e06474..5b871bd6a8 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -11,6 +11,7 @@ from argparse import (\n from collections import defaultdict\n from difflib import get_close_matches\n from importlib import import_module\n+from django.utils import autoreload\n \n import django\n from django.apps import apps\n@@ -23,7 +24,7 @@ from django.core.management.base import (\n     handle_default_options,\n )\n from django.core.management.color import color_style\n-from django.utils import autoreload\n+from django.core.management.formatters import CustomHelpFormatter\n \n \n def find_commands(management_dir):\n@@ -332,7 +333,7 @@ class ManagementUtility:\n                     # Fail silently if DJANGO_SETTINGS_MODULE isn't set. The\n                     # user will find out once they execute the command.\n                     pass\n-            parser = subcommand_cls.create_parser(\"\", cwords[0])\n+            parser = subcommand_cls.create_parser(\"\", cwords[0], formatter_class=CustomHelpFormatter)\n             options.extend(\n                 (min(s_opt.option_strings), s_opt.nargs != 0)\n                 for s_opt in parser._actions\ndiff --git a/django/core/management/base.py b/django/core/management/base.py\nindex d37d43d5c5..f5e744e7a1 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -5,7 +5,9 @@ be executed through ``django-admin`` or ``manage.py``).\n import argparse\n import os\n import sys\n-from argparse import ArgumentParser, HelpFormatter\n+from argparse import ArgumentParser\n+from django.core.management.formatters import CustomHelpFormatter\n+from argparse import HelpFormatter\n from io import TextIOBase\n \n import django\n@@ -289,7 +291,7 @@ class BaseCommand:\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n+            formatter_class=CustomHelpFormatter,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\ndiff --git a/django/core/management/formatters.py b/django/core/management/formatters.py\nnew file mode 100644\nindex 0000000000..8af8b38740\n--- /dev/null\n+++ b/django/core/management/formatters.py\n@@ -0,0 +1,9 @@\n+from argparse import HelpFormatter\n+\n+class CustomHelpFormatter(HelpFormatter):\n+    def _split_lines(self, text, width):\n+        # Preserve newlines in the help text\n+        lines = []\n+        for line in text.splitlines():\n+            lines.extend(HelpFormatter._split_lines(self, line, width))\n+        return lines\n", "instance_id": "django__django-15781"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..095ad0ccf0 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "instance_id": "django__django-13658"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/assumptions/sathandlers.py b/sympy/assumptions/sathandlers.py\nindex 61d62d04cf..cb9821701a 100644\n--- a/sympy/assumptions/sathandlers.py\n+++ b/sympy/assumptions/sathandlers.py\n@@ -1,6 +1,6 @@\n from __future__ import print_function, division\n \n-from collections import MutableMapping, defaultdict\n+from collections.abc import MutableMapping, defaultdict\n \n from sympy.core import (Add, Mul, Pow, Integer, Number, NumberSymbol,)\n from sympy.core.numbers import ImaginaryUnit\ndiff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 379a2917aa..d10275c9c3 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -6,7 +6,7 @@\n \n from __future__ import print_function, division\n \n-import collections\n+import collections.abc\n from sympy.core.add import Add\n from sympy.core.basic import Basic, Atom\n from sympy.core.expr import Expr\n@@ -2019,7 +2019,7 @@ def __mul__(self, other):\n             return MatrixArithmetic._eval_matrix_mul(self, other)\n \n         # if 'other' is not iterable then scalar multiplication.\n-        if not isinstance(other, collections.Iterable):\n+        if not isinstance(other, collections.abc.Iterable):\n             try:\n                 return self._eval_scalar_mul(other)\n             except TypeError:\n@@ -2087,7 +2087,7 @@ def __rmul__(self, other):\n             return MatrixArithmetic._eval_matrix_rmul(self, other)\n \n         # if 'other' is not iterable then scalar multiplication.\n-        if not isinstance(other, collections.Iterable):\n+        if not isinstance(other, collections.abc.Iterable):\n             try:\n                 return self._eval_scalar_rmul(other)\n             except TypeError:\ndiff --git a/sympy/matrices/dense.py b/sympy/matrices/dense.py\nindex 00395585b9..5e94214ed6 100644\n--- a/sympy/matrices/dense.py\n+++ b/sympy/matrices/dense.py\n@@ -38,6 +38,11 @@ def _compare_sequence(a, b):\n \n class DenseMatrix(MatrixBase):\n \n+    def __matmul__(self, other):\n+        if not isinstance(other, MatrixBase):\n+            raise ValueError(\"Scalar operands are not allowed, use '*' instead\")\n+        return self * other\n+\n     is_MatrixExpr = False\n \n     _op_priority = 10.01\n", "instance_id": "sympy__sympy-13773"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..6185dc80ec 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -90,7 +90,9 @@ class DeconstructableSerializer(BaseSerializer):\n \n     @staticmethod\n     def _serialize_path(path):\n-        module, name = path.rsplit(\".\", 1)\n+        parts = path.split(\".\")\n+        module = \".\".join(parts[:-1])\n+        name = parts[-1]\n         if module == \"django.db.models\":\n             imports = {\"from django.db import models\"}\n             name = \"models.%s\" % name\ndiff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..11d82e3ce2 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -81,8 +81,11 @@ class OperationWriter:\n         if getattr(migrations, name, None) == self.operation.__class__:\n             self.feed('migrations.%s(' % name)\n         else:\n-            imports.add('import %s' % (self.operation.__class__.__module__))\n-            self.feed('%s.%s(' % (self.operation.__class__.__module__, name))\n+            module_path = self.operation.__class__.__module__\n+            if '<locals>' in module_path:\n+                module_path = module_path.split('<locals>', 1)[0].rstrip('.')\n+            imports.add('import %s' % module_path)\n+            self.feed('%s.%s(' % (module_path, name))\n \n         self.indent()\n \n", "instance_id": "django__django-12125"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex f55f95219..f886b2bcd 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -393,6 +393,9 @@ def setup(app: \"Sphinx\") -> Dict[str, Any]:\n     # new standard name when default-domain with \"class\" is in effect\n     directives.register_directive('rst-class', Class)\n \n+    # Add custom index categorization\n+    app.add_config_value('index_common_prefix', [], 'env')\n+\n     return {\n         'version': 'builtin',\n         'parallel_read_safe': True,\ndiff --git a/sphinx/writers/html.py b/sphinx/writers/html.py\nindex 4375bf326..bbbd8d8ed 100644\n--- a/sphinx/writers/html.py\n+++ b/sphinx/writers/html.py\n@@ -84,6 +84,18 @@ class HTMLTranslator(SphinxTranslator, BaseTranslator):\n     Our custom HTML translator.\n     \"\"\"\n \n+    def visit_index(self, node: Element) -> None:\n+        \"\"\"Handle index entries.\"\"\"\n+        if 'entries' in node:\n+            for entry in node['entries']:\n+                if entry[0] == 'single':\n+                    self.body.append('<li><a href=\"#%s\">%s</a></li>' % (entry[2], entry[1]))\n+                elif entry[0] == 'pair':\n+                    self.body.append('<li><a href=\"#%s\">%s</a> (%s)</li>' % (entry[2], entry[1], entry[3]))\n+                elif entry[0] == 'triple':\n+                    self.body.append('<li><a href=\"#%s\">%s</a> (%s, %s)</li>' % (entry[2], entry[1], entry[3], entry[4]))\n+        raise nodes.SkipNode\n+\n     builder = None  # type: StandaloneHTMLBuilder\n \n     def __init__(self, *args: Any) -> None:\n", "instance_id": "sphinx-doc__sphinx-7975"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 3e0cab7d9b..501ec73257 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -994,7 +994,7 @@ def visit_BinOp(self, node):\n                 right = ast.Call(\n                     func=ast.Name(id='Mul', ctx=ast.Load()),\n                     args=[ast.UnaryOp(op=ast.USub(), operand=ast.Num(1)), right],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\n@@ -1005,7 +1005,7 @@ def visit_BinOp(self, node):\n                     left = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n                     args=[left, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\n@@ -1013,7 +1013,7 @@ def visit_BinOp(self, node):\n                     right = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n                     args=[right, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\n@@ -1021,7 +1021,7 @@ def visit_BinOp(self, node):\n             new_node = ast.Call(\n                 func=ast.Name(id=sympy_class, ctx=ast.Load()),\n                 args=[left, right],\n-                keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                 starargs=None,\n                 kwargs=None\n             )\ndiff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a3ead157c1..f3b7669e96 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -740,7 +740,7 @@ def _print_Function(self, expr, exp=None):\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n", "instance_id": "sympy__sympy-14774"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-16229"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex 5fb84d86..541f10ed 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -188,6 +188,14 @@ class Blueprint(Scaffold):\n             template_folder=template_folder,\n             root_path=root_path,\n         )\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n         self.name = name\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n", "instance_id": "pallets__flask-4045"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..e95a3dd8da 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1738,18 +1738,6 @@ def partitions(n, m=None, k=None, size=False):\n     {2: 1, 4: 1}\n     {3: 2}\n \n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n-\n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n-    [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n     >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n     [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n@@ -1802,9 +1790,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n", "instance_id": "sympy__sympy-20154"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 69df976b8b..4aba275d8e 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1265,7 +1265,7 @@ def _diff_wrt(self):\n         \"\"\"\n         return self.expr._diff_wrt and isinstance(self.doit(), Derivative)\n \n-    def __new__(cls, expr, *variables, **kwargs):\n+    def __new__(cls, expr, *variables, kind=None, **kwargs):\n \n         from sympy.matrices.common import MatrixCommon\n         from sympy import Integer, MatrixExpr\n@@ -1438,7 +1438,17 @@ def __new__(cls, expr, *variables, **kwargs):\n                 # that have defined is_scalar=True but have no\n                 # _eval_derivative defined\n                 return S.One\n-            return Expr.__new__(cls, expr, *variable_count)\n+            obj = Expr.__new__(cls, expr, *variable_count)\n+            if kind is None:\n+                from sympy.matrices.expressions.matexpr import MatrixKind\n+                from sympy.core.kind import NumberKind\n+                if expr.kind is MatrixKind:\n+                    obj._kind = MatrixKind(NumberKind)\n+                else:\n+                    obj._kind = expr.kind\n+            else:\n+                obj._kind = kind\n+            return obj\n \n         # evaluate the derivative by calling _eval_derivative method\n         # of expr for each variable\n@@ -1616,25 +1626,9 @@ def _block(d, v, wrt=False):\n     def _eval_is_commutative(self):\n         return self.expr.is_commutative\n \n-    def _eval_derivative(self, v):\n-        # If v (the variable of differentiation) is not in\n-        # self.variables, we might be able to take the derivative.\n-        if v not in self._wrt_variables:\n-            dedv = self.expr.diff(v)\n-            if isinstance(dedv, Derivative):\n-                return dedv.func(dedv.expr, *(self.variable_count + dedv.variable_count))\n-            # dedv (d(self.expr)/dv) could have simplified things such that the\n-            # derivative wrt things in self.variables can now be done. Thus,\n-            # we set evaluate=True to see if there are any other derivatives\n-            # that can be done. The most common case is when dedv is a simple\n-            # number so that the derivative wrt anything else will vanish.\n-            return self.func(dedv, *self.variables, evaluate=True)\n-        # In this case v was in self.variables so the derivative wrt v has\n-        # already been attempted and was not computed, either because it\n-        # couldn't be or evaluate=False originally.\n-        variable_count = list(self.variable_count)\n-        variable_count.append((v, 1))\n-        return self.func(self.expr, *variable_count, evaluate=False)\n+    @property\n+    def kind(self):\n+        return self._kind\n \n     def doit(self, **hints):\n         expr = self.expr\n", "instance_id": "sympy__sympy-21614"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0a5e5ff673..04940afa2f 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -345,6 +345,11 @@ class ModelBase(type):\n                 remote = wrt.remote_field.model\n                 lazy_related_operation(make_foreign_order_accessors, cls, remote)\n \n+        # Add get_FOO_display() methods.\n+        for field in opts.fields:\n+            if field.choices and not hasattr(cls, 'get_%s_display' % field.name):\n+                setattr(cls, 'get_%s_display' % field.name, partialmethod(cls._get_FIELD_display, field))\n+\n         # Give the class a docstring -- its definition.\n         if cls.__doc__ is None:\n             cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n", "instance_id": "django__django-11999"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/units/systems/si.py b/sympy/physics/units/systems/si.py\nindex 700495ad9d..e643c340d9 100644\n--- a/sympy/physics/units/systems/si.py\n+++ b/sympy/physics/units/systems/si.py\n@@ -1,373 +1,16 @@\n-\"\"\"\n-SI unit system.\n-Based on MKSA, which stands for \"meter, kilogram, second, ampere\".\n-Added kelvin, candela and mole.\n-\n-\"\"\"\n-\n-from typing import List\n-\n-from sympy.physics.units import DimensionSystem, Dimension, dHg0\n-\n-from sympy.physics.units.quantities import Quantity\n-\n-from sympy.core.numbers import (Rational, pi)\n-from sympy.core.singleton import S\n-from sympy.functions.elementary.miscellaneous import sqrt\n-from sympy.physics.units.definitions.dimension_definitions import (\n-    acceleration, action, current, impedance, length, mass, time, velocity,\n-    amount_of_substance, temperature, information, frequency, force, pressure,\n-    energy, power, charge, voltage, capacitance, conductance, magnetic_flux,\n-    magnetic_density, inductance, luminous_intensity\n-)\n-from sympy.physics.units.definitions import (\n-    kilogram, newton, second, meter, gram, cd, K, joule, watt, pascal, hertz,\n-    coulomb, volt, ohm, siemens, farad, henry, tesla, weber, dioptre, lux,\n-    katal, gray, becquerel, inch, liter, julian_year, gravitational_constant,\n-    speed_of_light, elementary_charge, planck, hbar, electronvolt,\n-    avogadro_number, avogadro_constant, boltzmann_constant,\n-    stefan_boltzmann_constant, Da, atomic_mass_constant, molar_gas_constant,\n-    faraday_constant, josephson_constant, von_klitzing_constant,\n-    acceleration_due_to_gravity, magnetic_constant, vacuum_permittivity,\n-    vacuum_impedance, coulomb_constant, atmosphere, bar, pound, psi, mmHg,\n-    milli_mass_unit, quart, lightyear, astronomical_unit, planck_mass,\n-    planck_time, planck_temperature, planck_length, planck_charge, planck_area,\n-    planck_volume, planck_momentum, planck_energy, planck_force, planck_power,\n-    planck_density, planck_energy_density, planck_intensity,\n-    planck_angular_frequency, planck_pressure, planck_current, planck_voltage,\n-    planck_impedance, planck_acceleration, bit, byte, kibibyte, mebibyte,\n-    gibibyte, tebibyte, pebibyte, exbibyte, curie, rutherford, radian, degree,\n-    steradian, angular_mil, atomic_mass_unit, gee, kPa, ampere, u0, c, kelvin,\n-    mol, mole, candela, m, kg, s, electric_constant, G, boltzmann\n-)\n-from sympy.physics.units.prefixes import PREFIXES, prefix_unit\n-from sympy.physics.units.systems.mksa import MKSA, dimsys_MKSA\n-\n-derived_dims = (frequency, force, pressure, energy, power, charge, voltage,\n-                capacitance, conductance, magnetic_flux,\n-                magnetic_density, inductance, luminous_intensity)\n-base_dims = (amount_of_substance, luminous_intensity, temperature)\n-\n-units = [mol, cd, K, lux, hertz, newton, pascal, joule, watt, coulomb, volt,\n-        farad, ohm, siemens, weber, tesla, henry, candela, lux, becquerel,\n-        gray, katal]\n-\n-all_units = []  # type: List[Quantity]\n-for u in units:\n-    all_units.extend(prefix_unit(u, PREFIXES))\n-\n-all_units.extend(units)\n-all_units.extend([mol, cd, K, lux])\n-\n-\n-dimsys_SI = dimsys_MKSA.extend(\n-    [\n-        # Dimensional dependencies for other base dimensions:\n-        temperature,\n-        amount_of_substance,\n-        luminous_intensity,\n-    ])\n-\n-dimsys_default = dimsys_SI.extend(\n-    [information],\n-)\n-\n-SI = MKSA.extend(base=(mol, cd, K), units=all_units, name='SI', dimension_system=dimsys_SI, derived_units={\n-    power: watt,\n-    magnetic_flux: weber,\n-    time: second,\n-    impedance: ohm,\n-    pressure: pascal,\n-    current: ampere,\n-    voltage: volt,\n-    length: meter,\n-    frequency: hertz,\n-    inductance: henry,\n-    temperature: kelvin,\n-    amount_of_substance: mole,\n-    luminous_intensity: candela,\n-    conductance: siemens,\n-    mass: kilogram,\n-    magnetic_density: tesla,\n-    charge: coulomb,\n-    force: newton,\n-    capacitance: farad,\n-    energy: joule,\n-    velocity: meter/second,\n-})\n-\n-One = S.One\n-\n-SI.set_quantity_dimension(radian, One)\n-\n-SI.set_quantity_scale_factor(ampere, One)\n-\n-SI.set_quantity_scale_factor(kelvin, One)\n-\n-SI.set_quantity_scale_factor(mole, One)\n-\n-SI.set_quantity_scale_factor(candela, One)\n-\n-# MKSA extension to MKS: derived units\n-\n-SI.set_quantity_scale_factor(coulomb, One)\n-\n-SI.set_quantity_scale_factor(volt, joule/coulomb)\n-\n-SI.set_quantity_scale_factor(ohm, volt/ampere)\n-\n-SI.set_quantity_scale_factor(siemens, ampere/volt)\n-\n-SI.set_quantity_scale_factor(farad, coulomb/volt)\n-\n-SI.set_quantity_scale_factor(henry, volt*second/ampere)\n-\n-SI.set_quantity_scale_factor(tesla, volt*second/meter**2)\n-\n-SI.set_quantity_scale_factor(weber, joule/ampere)\n-\n-\n-SI.set_quantity_dimension(lux, luminous_intensity / length ** 2)\n-SI.set_quantity_scale_factor(lux, steradian*candela/meter**2)\n-\n-# katal is the SI unit of catalytic activity\n-\n-SI.set_quantity_dimension(katal, amount_of_substance / time)\n-SI.set_quantity_scale_factor(katal, mol/second)\n-\n-# gray is the SI unit of absorbed dose\n-\n-SI.set_quantity_dimension(gray, energy / mass)\n-SI.set_quantity_scale_factor(gray, meter**2/second**2)\n-\n-# becquerel is the SI unit of radioactivity\n-\n-SI.set_quantity_dimension(becquerel, 1 / time)\n-SI.set_quantity_scale_factor(becquerel, 1/second)\n-\n-#### CONSTANTS ####\n-\n-# elementary charge\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(elementary_charge, charge)\n-SI.set_quantity_scale_factor(elementary_charge, 1.602176634e-19*coulomb)\n-\n-# Electronvolt\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(electronvolt, energy)\n-SI.set_quantity_scale_factor(electronvolt, 1.602176634e-19*joule)\n-\n-# Avogadro number\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(avogadro_number, One)\n-SI.set_quantity_scale_factor(avogadro_number, 6.02214076e23)\n-\n-# Avogadro constant\n-\n-SI.set_quantity_dimension(avogadro_constant, amount_of_substance ** -1)\n-SI.set_quantity_scale_factor(avogadro_constant, avogadro_number / mol)\n-\n-# Boltzmann constant\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(boltzmann_constant, energy / temperature)\n-SI.set_quantity_scale_factor(boltzmann_constant, 1.380649e-23*joule/kelvin)\n-\n-# Stefan-Boltzmann constant\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(stefan_boltzmann_constant, energy * time ** -1 * length ** -2 * temperature ** -4)\n-SI.set_quantity_scale_factor(stefan_boltzmann_constant, pi**2 * boltzmann_constant**4 / (60 * hbar**3 * speed_of_light ** 2))\n-\n-# Atomic mass\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(atomic_mass_constant, mass)\n-SI.set_quantity_scale_factor(atomic_mass_constant, 1.66053906660e-24*gram)\n-\n-# Molar gas constant\n-# REF: NIST SP 959 (June 2019)\n-\n-SI.set_quantity_dimension(molar_gas_constant, energy / (temperature * amount_of_substance))\n-SI.set_quantity_scale_factor(molar_gas_constant, boltzmann_constant * avogadro_constant)\n-\n-# Faraday constant\n-\n-SI.set_quantity_dimension(faraday_constant, charge / amount_of_substance)\n-SI.set_quantity_scale_factor(faraday_constant, elementary_charge * avogadro_constant)\n-\n-# Josephson constant\n-\n-SI.set_quantity_dimension(josephson_constant, frequency / voltage)\n-SI.set_quantity_scale_factor(josephson_constant, 0.5 * planck / elementary_charge)\n-\n-# Von Klitzing constant\n-\n-SI.set_quantity_dimension(von_klitzing_constant, voltage / current)\n-SI.set_quantity_scale_factor(von_klitzing_constant, hbar / elementary_charge ** 2)\n-\n-# Acceleration due to gravity (on the Earth surface)\n-\n-SI.set_quantity_dimension(acceleration_due_to_gravity, acceleration)\n-SI.set_quantity_scale_factor(acceleration_due_to_gravity, 9.80665*meter/second**2)\n-\n-# magnetic constant:\n-\n-SI.set_quantity_dimension(magnetic_constant, force / current ** 2)\n-SI.set_quantity_scale_factor(magnetic_constant, 4*pi/10**7 * newton/ampere**2)\n-\n-# electric constant:\n-\n-SI.set_quantity_dimension(vacuum_permittivity, capacitance / length)\n-SI.set_quantity_scale_factor(vacuum_permittivity, 1/(u0 * c**2))\n-\n-# vacuum impedance:\n-\n-SI.set_quantity_dimension(vacuum_impedance, impedance)\n-SI.set_quantity_scale_factor(vacuum_impedance, u0 * c)\n-\n-# Coulomb's constant:\n-SI.set_quantity_dimension(coulomb_constant, force * length ** 2 / charge ** 2)\n-SI.set_quantity_scale_factor(coulomb_constant, 1/(4*pi*vacuum_permittivity))\n-\n-SI.set_quantity_dimension(psi, pressure)\n-SI.set_quantity_scale_factor(psi, pound * gee / inch ** 2)\n-\n-SI.set_quantity_dimension(mmHg, pressure)\n-SI.set_quantity_scale_factor(mmHg, dHg0 * acceleration_due_to_gravity * kilogram / meter**2)\n-\n-SI.set_quantity_dimension(milli_mass_unit, mass)\n-SI.set_quantity_scale_factor(milli_mass_unit, atomic_mass_unit/1000)\n-\n-SI.set_quantity_dimension(quart, length ** 3)\n-SI.set_quantity_scale_factor(quart, Rational(231, 4) * inch**3)\n-\n-# Other convenient units and magnitudes\n-\n-SI.set_quantity_dimension(lightyear, length)\n-SI.set_quantity_scale_factor(lightyear, speed_of_light*julian_year)\n-\n-SI.set_quantity_dimension(astronomical_unit, length)\n-SI.set_quantity_scale_factor(astronomical_unit, 149597870691*meter)\n-\n-# Fundamental Planck units:\n-\n-SI.set_quantity_dimension(planck_mass, mass)\n-SI.set_quantity_scale_factor(planck_mass, sqrt(hbar*speed_of_light/G))\n-\n-SI.set_quantity_dimension(planck_time, time)\n-SI.set_quantity_scale_factor(planck_time, sqrt(hbar*G/speed_of_light**5))\n-\n-SI.set_quantity_dimension(planck_temperature, temperature)\n-SI.set_quantity_scale_factor(planck_temperature, sqrt(hbar*speed_of_light**5/G/boltzmann**2))\n-\n-SI.set_quantity_dimension(planck_length, length)\n-SI.set_quantity_scale_factor(planck_length, sqrt(hbar*G/speed_of_light**3))\n-\n-SI.set_quantity_dimension(planck_charge, charge)\n-SI.set_quantity_scale_factor(planck_charge, sqrt(4*pi*electric_constant*hbar*speed_of_light))\n-\n-# Derived Planck units:\n-\n-SI.set_quantity_dimension(planck_area, length ** 2)\n-SI.set_quantity_scale_factor(planck_area, planck_length**2)\n-\n-SI.set_quantity_dimension(planck_volume, length ** 3)\n-SI.set_quantity_scale_factor(planck_volume, planck_length**3)\n-\n-SI.set_quantity_dimension(planck_momentum, mass * velocity)\n-SI.set_quantity_scale_factor(planck_momentum, planck_mass * speed_of_light)\n-\n-SI.set_quantity_dimension(planck_energy, energy)\n-SI.set_quantity_scale_factor(planck_energy, planck_mass * speed_of_light**2)\n-\n-SI.set_quantity_dimension(planck_force, force)\n-SI.set_quantity_scale_factor(planck_force, planck_energy / planck_length)\n-\n-SI.set_quantity_dimension(planck_power, power)\n-SI.set_quantity_scale_factor(planck_power, planck_energy / planck_time)\n-\n-SI.set_quantity_dimension(planck_density, mass / length ** 3)\n-SI.set_quantity_scale_factor(planck_density, planck_mass / planck_length**3)\n-\n-SI.set_quantity_dimension(planck_energy_density, energy / length ** 3)\n-SI.set_quantity_scale_factor(planck_energy_density, planck_energy / planck_length**3)\n-\n-SI.set_quantity_dimension(planck_intensity, mass * time ** (-3))\n-SI.set_quantity_scale_factor(planck_intensity, planck_energy_density * speed_of_light)\n-\n-SI.set_quantity_dimension(planck_angular_frequency, 1 / time)\n-SI.set_quantity_scale_factor(planck_angular_frequency, 1 / planck_time)\n-\n-SI.set_quantity_dimension(planck_pressure, pressure)\n-SI.set_quantity_scale_factor(planck_pressure, planck_force / planck_length**2)\n-\n-SI.set_quantity_dimension(planck_current, current)\n-SI.set_quantity_scale_factor(planck_current, planck_charge / planck_time)\n-\n-SI.set_quantity_dimension(planck_voltage, voltage)\n-SI.set_quantity_scale_factor(planck_voltage, planck_energy / planck_charge)\n-\n-SI.set_quantity_dimension(planck_impedance, impedance)\n-SI.set_quantity_scale_factor(planck_impedance, planck_voltage / planck_current)\n-\n-SI.set_quantity_dimension(planck_acceleration, acceleration)\n-SI.set_quantity_scale_factor(planck_acceleration, speed_of_light / planck_time)\n-\n-# Older units for radioactivity\n-\n-SI.set_quantity_dimension(curie, 1 / time)\n-SI.set_quantity_scale_factor(curie, 37000000000*becquerel)\n-\n-SI.set_quantity_dimension(rutherford, 1 / time)\n-SI.set_quantity_scale_factor(rutherford, 1000000*becquerel)\n-\n-\n-# check that scale factors are the right SI dimensions:\n-for _scale_factor, _dimension in zip(\n-    SI._quantity_scale_factors.values(),\n-    SI._quantity_dimension_map.values()\n-):\n-    dimex = SI.get_dimensional_expr(_scale_factor)\n-    if dimex != 1:\n-        # XXX: equivalent_dims is an instance method taking two arguments in\n-        # addition to self so this can not work:\n-        if not DimensionSystem.equivalent_dims(_dimension, Dimension(dimex)):  # type: ignore\n-            raise ValueError(\"quantity value and dimension mismatch\")\n-del _scale_factor, _dimension\n-\n-__all__ = [\n-    'mmHg', 'atmosphere', 'inductance', 'newton', 'meter',\n-    'vacuum_permittivity', 'pascal', 'magnetic_constant', 'voltage',\n-    'angular_mil', 'luminous_intensity', 'all_units',\n-    'julian_year', 'weber', 'exbibyte', 'liter',\n-    'molar_gas_constant', 'faraday_constant', 'avogadro_constant',\n-    'lightyear', 'planck_density', 'gee', 'mol', 'bit', 'gray',\n-    'planck_momentum', 'bar', 'magnetic_density', 'prefix_unit', 'PREFIXES',\n-    'planck_time', 'dimex', 'gram', 'candela', 'force', 'planck_intensity',\n-    'energy', 'becquerel', 'planck_acceleration', 'speed_of_light',\n-    'conductance', 'frequency', 'coulomb_constant', 'degree', 'lux', 'planck',\n-    'current', 'planck_current', 'tebibyte', 'planck_power', 'MKSA', 'power',\n-    'K', 'planck_volume', 'quart', 'pressure', 'amount_of_substance',\n-    'joule', 'boltzmann_constant', 'Dimension', 'c', 'planck_force', 'length',\n-    'watt', 'action', 'hbar', 'gibibyte', 'DimensionSystem', 'cd', 'volt',\n-    'planck_charge', 'dioptre', 'vacuum_impedance', 'dimsys_default', 'farad',\n-    'charge', 'gravitational_constant', 'temperature', 'u0', 'hertz',\n-    'capacitance', 'tesla', 'steradian', 'planck_mass', 'josephson_constant',\n-    'planck_area', 'stefan_boltzmann_constant', 'base_dims',\n-    'astronomical_unit', 'radian', 'planck_voltage', 'impedance',\n-    'planck_energy', 'Da', 'atomic_mass_constant', 'rutherford', 'second', 'inch',\n-    'elementary_charge', 'SI', 'electronvolt', 'dimsys_SI', 'henry',\n-    'planck_angular_frequency', 'ohm', 'pound', 'planck_pressure', 'G', 'psi',\n-    'dHg0', 'von_klitzing_constant', 'planck_length', 'avogadro_number',\n-    'mole', 'acceleration', 'information', 'planck_energy_density',\n-    'mebibyte', 's', 'acceleration_due_to_gravity',\n-    'planck_temperature', 'units', 'mass', 'dimsys_MKSA', 'kelvin', 'kPa',\n-    'boltzmann', 'milli_mass_unit', 'planck_impedance', 'electric_constant',\n-    'derived_dims', 'kg', 'coulomb', 'siemens', 'byte', 'magnetic_flux',\n-    'atomic_mass_unit', 'm', 'kibibyte', 'kilogram', 'One', 'curie', 'u',\n-    'time', 'pebibyte', 'velocity', 'ampere', 'katal',\n-]\n+from sympy import exp\n+from sympy.physics.units import DimensionSystem, Dimension, Quantity\n+from sympy.physics.units.systems.mksa import MKSA\n+\n+class SI(MKSA):\n+    def _collect_factor_and_dimension(self, expr):\n+        from sympy import Mul, Pow\n+        from sympy.physics.units.dimensions import Dimension\n+        factor, dim = super()._collect_factor_and_dimension(expr)\n+        if isinstance(expr, Mul):\n+            for arg in expr.args:\n+                if isinstance(arg, Pow) and arg.exp.is_number and arg.exp == 0:\n+                    dim = Dimension(1)\n+        return factor, dim\n+\n+# Rest of the code remains unchanged\ndiff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex 3daf84c108..4f658644b8 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -29,7 +29,8 @@ class UnitSystem(_QuantityMapper):\n \n     def __init__(self, base_units, units=(), name=\"\", descr=\"\", dimension_system=None, derived_units: tDict[Dimension, Quantity]={}):\n \n-        UnitSystem._unit_systems[name] = self\n+        if isinstance(name, str) and name:\n+            UnitSystem._unit_systems[name] = self\n \n         self.name = name\n         self.descr = descr\n", "instance_id": "sympy__sympy-24066"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "sympy__sympy-13043"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex e0eeccefa6..07de52af7b 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1138,6 +1138,11 @@ class QuerySet:\n         \"\"\"\n         Return a new QuerySet instance that will select only distinct results.\n         \"\"\"\n+        if self.query.combinator:\n+            raise NotSupportedError(\n+                'Calling distinct() after %s() is not supported.'\n+                % self.query.combinator\n+            )\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n", "instance_id": "django__django-12908"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\nindex 8ecb5a16b..598b6e53a 100644\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -267,6 +267,7 @@ class TerminalReporter:\n         self._numcollected = 0\n         self._session = None  # type: Optional[Session]\n         self._showfspath = None\n+        self._original_working_dir = config.invocation_dir\n \n         self.stats = {}  # type: Dict[str, List[Any]]\n         self._main_color = None  # type: Optional[str]\n@@ -776,7 +777,7 @@ class TerminalReporter:\n \n     def _locationline(self, nodeid, fspath, lineno, domain):\n         def mkrel(nodeid):\n-            line = self.config.cwd_relative_nodeid(nodeid)\n+            line = py.path.local(nodeid).relto(self._original_working_dir)\n             if domain and line.endswith(domain):\n                 line = line[: -len(domain)]\n                 values = domain.split(\"[\")\n", "instance_id": "pytest-dev__pytest-7220"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..ecd68dd937 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,20 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n+            if self.creation_counter == other.creation_counter:\n+                return getattr(self, 'model', None) < getattr(other, 'model', None)\n             return self.creation_counter < other.creation_counter\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n", "instance_id": "django__django-13401"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/utils/_pprint.py b/sklearn/utils/_pprint.py\nindex b8686dba5..f952c66ca 100644\n--- a/sklearn/utils/_pprint.py\n+++ b/sklearn/utils/_pprint.py\n@@ -67,6 +67,7 @@ from inspect import signature\n import pprint\n from collections import OrderedDict\n \n+import numpy as np\n from ..base import BaseEstimator\n from .._config import get_config\n from . import is_scalar_nan\n@@ -95,8 +96,11 @@ def _changed_params(estimator):\n     init_params = signature(init_func).parameters\n     init_params = {name: param.default for name, param in init_params.items()}\n     for k, v in params.items():\n-        if (v != init_params[k] and\n-                not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n+        if (isinstance(v, np.ndarray) and isinstance(init_params[k], np.ndarray)):\n+            if not np.array_equal(v, init_params[k]):\n+                filtered_params[k] = v\n+        elif (v != init_params[k] and\n+              not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n             filtered_params[k] = v\n     return filtered_params\n \n", "instance_id": "scikit-learn__scikit-learn-13584"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 157903faf..9bf79f1e1 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -676,6 +676,7 @@ class AssertionRewriter(ast.NodeVisitor):\n                 expect_docstring\n                 and isinstance(item, ast.Expr)\n                 and isinstance(item.value, ast.Constant)\n+                and isinstance(item.value.value, str)\n             ):\n                 doc = item.value.value\n                 if self.is_rewrite_disabled(doc):\n", "instance_id": "pytest-dev__pytest-11143"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-11040"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 4806afee9..2701a0918 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -388,8 +388,16 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n                 convergence_iter=self.convergence_iter, damping=self.damping,\n                 copy=self.copy, verbose=self.verbose, return_n_iter=True)\n \n-        if self.affinity != \"precomputed\":\n+        if self.n_iter_ == self.max_iter:\n+            warnings.warn(\"Affinity propagation did not converge, this model \"\n+                          \"will not have any cluster centers.\", ConvergenceWarning)\n+            self.cluster_centers_indices_ = np.array([])\n+            self.labels_ = np.array([-1] * X.shape[0])\n+\n+        if self.affinity != \"precomputed\" and len(self.cluster_centers_indices_) > 0:\n             self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n+        else:\n+            self.cluster_centers_ = np.array([])\n \n         return self\n \n", "instance_id": "scikit-learn__scikit-learn-15512"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..54bee1f1f7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -945,7 +945,10 @@ class Model(metaclass=ModelBase):\n \n     def _get_FIELD_display(self, field):\n         value = getattr(self, field.attname)\n-        choices_dict = dict(make_hashable(field.flatchoices))\n+        choices_dict = {}\n+        for parent in self._meta.get_parent_list():\n+            choices_dict.update(make_hashable(parent._meta.get_field(field.name).flatchoices))\n+        choices_dict.update(make_hashable(field.flatchoices))\n         # force_str() to coerce lazy strings.\n         return force_str(choices_dict.get(make_hashable(value), value), strings_only=True)\n \n", "instance_id": "django__django-12284"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/seaborn/_oldcore.py b/seaborn/_oldcore.py\nindex c9218c1f..19b81964 100644\n--- a/seaborn/_oldcore.py\n+++ b/seaborn/_oldcore.py\n@@ -1093,13 +1093,12 @@ class VectorPlotter:\n                 parts = []\n                 grouped = self.plot_data[var].groupby(self.converters[var], sort=False)\n                 for converter, orig in grouped:\n-                    with pd.option_context('mode.use_inf_as_null', True):\n-                        orig = orig.dropna()\n-                        if var in self.var_levels:\n-                            # TODO this should happen in some centralized location\n-                            # it is similar to GH2419, but more complicated because\n-                            # supporting `order` in categorical plots is tricky\n-                            orig = orig[orig.isin(self.var_levels[var])]\n+                    orig = orig.dropna()\n+                    if var in self.var_levels:\n+                        # TODO this should happen in some centralized location\n+                        # it is similar to GH2419, but more complicated because\n+                        # supporting `order` in categorical plots is tricky\n+                        orig = orig[orig.isin(self.var_levels[var])]\n                     comp = pd.to_numeric(converter.convert_units(orig))\n                     if converter.get_scale() == \"log\":\n                         comp = np.log10(comp)\ndiff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 8526f44b..ce3371f7 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1328,9 +1328,18 @@ class PairGrid(Grid):\n             called ``color`` and  ``label``.\n \n         \"\"\"\n+        if \"hue\" in kwargs:\n+            hue = kwargs.pop(\"hue\")\n+            self.hue_vals = hue\n+            self.hue_names = hue.unique()\n+            self.palette = self._get_palette(self.data, self._hue_var, self.hue_names, self._orig_palette)\n+            self._legend_data = {}\n+\n         row_indices, col_indices = np.indices(self.axes.shape)\n         indices = zip(row_indices.flat, col_indices.flat)\n         self._map_bivariate(func, indices, **kwargs)\n+        if \"hue\" in kwargs:\n+            self.add_legend()\n \n         return self\n \ndiff --git a/seaborn/relational.py b/seaborn/relational.py\nindex b1762ca3..126fe1cf 100644\n--- a/seaborn/relational.py\n+++ b/seaborn/relational.py\n@@ -576,7 +576,10 @@ class _ScatterPlotter(_RelationalPlotter):\n         # Apply the mapping from semantic variables to artist attributes\n \n         if \"hue\" in self.variables:\n-            points.set_facecolors(self._hue_map(data[\"hue\"]))\n+            hue_values = data[\"hue\"]\n+            if isinstance(hue_values, pd.Series):\n+                hue_values = hue_values.values\n+            points.set_facecolors(self._hue_map(hue_values))\n \n         if \"size\" in self.variables:\n             points.set_sizes(self._size_map(data[\"size\"]))\n", "instance_id": "mwaskom__seaborn-2848"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..2332a6a29f 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,13 +407,20 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n-        if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n-        self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n+        if len(constraint_names) > 1:\n+            # If there are multiple constraints, prefer the index constraint.\n+            index_constraints = [name for name in constraint_names if name.endswith('_idx')]\n+            if len(index_constraints) == 1:\n+                constraint_name = index_constraints[0]\n+            else:\n+                raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                    \", \".join(columns),\n+                ))\n+        else:\n+            constraint_name = constraint_names[0]\n+        self.execute(self._delete_constraint_sql(sql, model, constraint_name))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\n", "instance_id": "django__django-12708"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..3d0625c05e 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -737,6 +737,14 @@ class QuerySet:\n \n         # Clear the result cache, in case this QuerySet gets reused.\n         self._result_cache = None\n+        if not deleted:\n+            model_labels = {self.model._meta.label}\n+            _rows_count = {label: 0 for label in model_labels}\n+        else:\n+            # Ensure all models in the queryset are represented in the _rows_count dictionary\n+            for obj in self:\n+                if obj._meta.label not in _rows_count:\n+                    _rows_count[obj._meta.label] = 0\n         return deleted, _rows_count\n \n     delete.alters_data = True\n", "instance_id": "django__django-12747"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-11630"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..3b94572b10 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -687,10 +687,10 @@ class URLField(CharField):\n             \"\"\"\n             try:\n                 return list(urlsplit(url))\n-            except ValueError:\n+            except ValueError as e:\n                 # urlparse.urlsplit can raise a ValueError with some\n                 # misformatted URLs.\n-                raise ValidationError(self.error_messages['invalid'], code='invalid')\n+                raise ValidationError(self.error_messages['invalid'], code='invalid') from e\n \n         value = super().to_python(value)\n         if value:\n", "instance_id": "django__django-15202"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 09e2b00735..a5f267b41e 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -14,6 +14,7 @@\n from sympy.printing.precedence import PRECEDENCE, precedence, precedence_traditional\n from sympy.utilities import group\n from sympy.utilities.iterables import has_variety\n+from collections.abc import Callable\n from sympy.core.sympify import SympifyError\n from sympy.core.compatibility import range\n from sympy.core.add import Add\n@@ -902,66 +903,53 @@ def _print_BasisDependent(self, expr):\n             items = [(0, expr)]\n         for system, vect in items:\n             inneritems = list(vect.components.items())\n-            inneritems.sort(key = lambda x: x[0].__str__())\n+            inneritems.sort(key=lambda x: x[0].__str__())\n             for k, v in inneritems:\n-                #if the coef of the basis vector is 1\n-                #we skip the 1\n                 if v == 1:\n-                    o1.append(u\"\" +\n-                              k._pretty_form)\n-                #Same for -1\n+                    o1.append(k._pretty_form)\n                 elif v == -1:\n-                    o1.append(u\"(-1) \" +\n-                              k._pretty_form)\n-                #For a general expr\n+                    o1.append(u\"(-1) \" + k._pretty_form)\n                 else:\n-                    #We always wrap the measure numbers in\n-                    #parentheses\n-                    arg_str = self._print(\n-                        v).parens()[0]\n-\n-                    o1.append(arg_str + ' ' + k._pretty_form)\n+                    arg_str = self._print(v)\n+                    if not isinstance(arg_str, prettyForm):\n+                        arg_str = prettyForm(str(arg_str))\n+                    o1.append(arg_str + prettyForm(' ') + k._pretty_form)\n                 vectstrs.append(k._pretty_form)\n \n-        #outstr = u(\"\").join(o1)\n         if o1[0].startswith(u\" + \"):\n             o1[0] = o1[0][3:]\n         elif o1[0].startswith(\" \"):\n             o1[0] = o1[0][1:]\n-        #Fixing the newlines\n+\n         lengths = []\n         strs = ['']\n         for i, partstr in enumerate(o1):\n-            # XXX: What is this hack?\n             if '\\n' in partstr:\n                 tempstr = partstr\n                 tempstr = tempstr.replace(vectstrs[i], '')\n                 tempstr = tempstr.replace(u'\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                          u'\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                          + ' ' + vectstrs[i])\n+                                          u'\\N{RIGHT PARENTHESIS UPPER HOOK}' + ' ' + vectstrs[i])\n                 o1[i] = tempstr\n         o1 = [x.split('\\n') for x in o1]\n         n_newlines = max([len(x) for x in o1])\n         for parts in o1:\n             lengths.append(len(parts[0]))\n             for j in range(n_newlines):\n-                if j+1 <= len(parts):\n+                if j + 1 <= len(parts):\n                     if j >= len(strs):\n-                        strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n+                        strs.append(' ' * (sum(lengths[:-1]) + 3 * (len(lengths) - 1)))\n                     if j == 0:\n                         strs[0] += parts[0] + ' + '\n                     else:\n-                        strs[j] += parts[j] + ' '*(lengths[-1] -\n-                                                   len(parts[j])+\n-                                                   3)\n+                        strs[j] += parts[j] + ' ' * (lengths[-1] - len(parts[j]) + 3)\n                 else:\n                     if j >= len(strs):\n-                        strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n-                    strs[j] += ' '*(lengths[-1]+3)\n+                        strs.append(' ' * (sum(lengths[:-1]) + 3 * (len(lengths) - 1)))\n+                    strs[j] += ' ' * (lengths[-1] + 3)\n \n-        return prettyForm(u'\\n'.join([s[:-3] for s in strs]))\n+        result = prettyForm(u'\\n'.join([s[:-3] for s in strs]))\n+        result.baseline = result.height() // 2\n+        return result\n \n     def _print_NDimArray(self, expr):\n         from sympy import ImmutableMatrix\ndiff --git a/sympy/vector/coordsysrect.py b/sympy/vector/coordsysrect.py\nindex baf290e8ac..33fd0eff2e 100644\n--- a/sympy/vector/coordsysrect.py\n+++ b/sympy/vector/coordsysrect.py\n@@ -11,7 +11,7 @@\n import sympy.vector\n from sympy.vector.orienters import (Orienter, AxisOrienter, BodyOrienter,\n                                     SpaceOrienter, QuaternionOrienter)\n-import collections\n+import collections.abc as collections\n \n \n def CoordSysCartesian(*args, **kwargs):\n@@ -84,7 +84,7 @@ def __new__(cls, name, transformation=None, parent=None, location=None,\n                 else:\n                     transformation = Lambda(transformation[0],\n                                             transformation[1])\n-            elif isinstance(transformation, collections.Callable):\n+            elif isinstance(transformation, collections.abc.Callable):\n                 x1, x2, x3 = symbols('x1 x2 x3', cls=Dummy)\n                 transformation = Lambda((x1, x2, x3),\n                                         transformation(x1, x2, x3))\n", "instance_id": "sympy__sympy-14308"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..76b2af0e 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,5 +1,7 @@\n import pandas as pd\n \n+import numpy as np\n+import numpy as np\n from . import dtypes, utils\n from .alignment import align\n from .merge import _VALID_COMPAT, unique_variable\n@@ -16,6 +18,8 @@ def concat(\n     positions=None,\n     fill_value=dtypes.NA,\n     join=\"outer\",\n+    ignore_missing_vars=False,\n+    ignore_missing_vars=False,\n ):\n     \"\"\"Concatenate xarray objects along a new or existing dimension.\n \n@@ -91,7 +95,8 @@ def concat(\n           those of the first object with that dimension. Indexes for the same\n           dimension must have the same size in all objects.\n \n-    indexers, mode, concat_over : deprecated\n+    ignore_missing_vars : bool, optional\n+        If True, missing variables in some datasets will be filled with NaN.\n \n     Returns\n     -------\n@@ -128,7 +133,7 @@ def concat(\n             \"can only concatenate xarray Dataset and DataArray \"\n             \"objects, got %s\" % type(first_obj)\n         )\n-    return f(objs, dim, data_vars, coords, compat, positions, fill_value, join)\n+    return f(objs, dim, data_vars, coords, compat, positions, fill_value, join, ignore_missing_vars)\n \n \n def _calc_concat_dim_coord(dim):\n@@ -308,26 +313,24 @@ def _dataset_concat(\n     variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n \n     result_vars = {}\n-    if variables_to_merge:\n-        to_merge = {var: [] for var in variables_to_merge}\n-\n-        for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+    to_merge = {var: [] for var in variables_to_merge}\n \n-            for var in variables_to_merge:\n+    for ds in datasets:\n+        for var in variables_to_merge:\n+            if var in ds.variables:\n                 to_merge[var].append(ds.variables[var])\n+            else:\n+                # Create a dummy variable filled with NaN\n+                shape = tuple(ds.dims[dim] if d == dim else ds.dims[d] for d in ds.variables[var].dims)\n+                fill_value = dtypes.NA\n+                dummy_var = Variable(ds.variables[var].dims, np.full(shape, fill_value))\n+                to_merge[var].append(dummy_var)\n+\n+    for var in variables_to_merge:\n+        result_vars[var] = unique_variable(\n+            var, to_merge[var], compat=compat, equals=equals.get(var, None)\n+        )\n \n-        for var in variables_to_merge:\n-            result_vars[var] = unique_variable(\n-                var, to_merge[var], compat=compat, equals=equals.get(var, None)\n-            )\n-    else:\n-        result_vars = {}\n     result_vars.update(dim_coords)\n \n     # assign attrs and encoding from first dataset\n", "instance_id": "pydata__xarray-3364"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "instance_id": "django__django-15814"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 9e5b903d59..9838cd82e2 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -341,6 +341,7 @@ class Legend(Artist):\n         handler_map=None,\n         title_fontproperties=None,  # properties for the legend title\n         alignment=\"center\",       # control the alignment within the legend box\n+        draggable=False,\n         *,\n         ncol=1  # synonym for ncols (backward compatibility)\n     ):\n@@ -537,6 +538,7 @@ class Legend(Artist):\n             title_prop_fp.set_size(title_fontsize)\n \n         self.set_title(title, prop=title_prop_fp)\n+        self.set_draggable(draggable)\n         self._draggable = None\n \n         # set the text color\n", "instance_id": "matplotlib__matplotlib-23913"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..19f72818 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,22 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+    headers = (\"Domain\", \"Endpoint\", \"Methods\", \"Rule\")\n     widths = (\n+        max(len(rule.subdomain or current_app.config.get(\"SERVER_NAME\", \"\")) for rule in rules),\n         max(len(rule.endpoint) for rule in rules),\n         max(len(methods) for methods in rule_methods),\n         max(len(rule.rule) for rule in rules),\n     )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n     for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+        domain = rule.subdomain or current_app.config.get(\"SERVER_NAME\", \"\")\n+        click.echo(row.format(domain, rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\n", "instance_id": "pallets__flask-5063"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex 70e6953559..6b5a51b25c 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -180,6 +180,7 @@ def numbered_string_incr(s, start=0):\n _uniquely_named_symbol = uniquely_named_symbol\n \n class Symbol(AtomicExpr, Boolean):\n+    __slots__ = ('name',)\n     \"\"\"\n     Assumptions:\n        commutative = True\n", "instance_id": "sympy__sympy-20590"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex b2a60629c9..663750636d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -143,9 +143,9 @@ class ModelBase(type):\n                 # Non-abstract child classes inherit some attributes from their\n                 # non-abstract parent (unless an ABC comes before it in the\n                 # method resolution order).\n-                if not hasattr(meta, 'ordering'):\n+                if not hasattr(meta, 'ordering') or not meta.ordering:\n                     new_class._meta.ordering = base_meta.ordering\n-                if not hasattr(meta, 'get_latest_by'):\n+                if not hasattr(meta, 'get_latest_by') or not meta.get_latest_by:\n                     new_class._meta.get_latest_by = base_meta.get_latest_by\n \n         is_proxy = new_class._meta.proxy\n", "instance_id": "django__django-12470"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex fb5f6298c4..3ba4bbb3f4 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -403,7 +403,7 @@ def slugify(value, allow_unicode=False):\n     else:\n         value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n     value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n \n \n def camel_case_to_spaces(value):\n", "instance_id": "django__django-12983"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 62631f7ff..81008ff98 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -109,10 +109,12 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n     return {x.strip() for x in arg.split(',') if x.strip()}\n \n \n-def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n-    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+def inherited_members_option(arg: Any) -> Union[object, Set[str], List[str]]:\n+    \"\"\"Used to convert the :inherited-members: option to auto directives.\"\"\"\n     if arg in (None, True):\n         return 'object'\n+    elif isinstance(arg, str):\n+        return [x.strip() for x in arg.split(',') if x.strip()]\n     else:\n         return arg\n \n@@ -659,7 +661,12 @@ class Documenter:\n                                    (name, self.fullname), type='autodoc')\n             return False, selected\n         elif self.options.inherited_members:\n-            return False, [(m.name, m.value) for m in members.values()]\n+            if isinstance(self.options.inherited_members, list):\n+                return False, [(m.name, m.value) for m in members.values()\n+                               if not any(base.__name__ in self.options.inherited_members\n+                                          for base in inspect.getmro(m.class_)[1:])]\n+            else:\n+                return False, [(m.name, m.value) for m in members.values()]\n         else:\n             return False, [(m.name, m.value) for m in members.values()\n                            if m.directly_defined]\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 2eb25536d..fa170551e 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -24,6 +24,9 @@ AUTODOC_DEFAULT_OPTIONS = ['members', 'undoc-members', 'inherited-members',\n                            'ignore-module-all', 'exclude-members', 'member-order',\n                            'imported-members', 'class-doc-from', 'no-value']\n \n+AUTODOC_EXTENDABLE_OPTIONS = ['members', 'private-members', 'special-members',\n+                              'exclude-members', 'inherited-members']\n+\n AUTODOC_EXTENDABLE_OPTIONS = ['members', 'private-members', 'special-members',\n                               'exclude-members']\n \n", "instance_id": "sphinx-doc__sphinx-10325"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex da5b40a5ef..54d70e39ae 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -903,13 +903,13 @@ class RangeSlider(SliderBase):\n             xy[1] = .25, val[1]\n             xy[2] = .75, val[1]\n             xy[3] = .75, val[0]\n-            xy[4] = .25, val[0]\n+            # xy[4] = .25, val[0]\n         else:\n             xy[0] = val[0], .25\n             xy[1] = val[0], .75\n             xy[2] = val[1], .75\n             xy[3] = val[1], .25\n-            xy[4] = val[0], .25\n+            # xy[4] = val[0], .25\n         self.poly.xy = xy\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n", "instance_id": "matplotlib__matplotlib-22711"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..b1e57e4575 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -70,12 +70,12 @@ class BaseDatabaseCreation:\n                 run_syncdb=True,\n             )\n \n-        # We then serialize the current state of the database into a string\n-        # and store it on the connection. This slightly horrific process is so people\n-        # who are testing on databases without transactions or who are using\n-        # a TransactionTestCase still get a clean database on every test run.\n-        if serialize:\n-            self.connection._test_serialized_contents = self.serialize_db_to_string()\n+            # We then serialize the current state of the database into a string\n+            # and store it on the connection. This slightly horrific process is so people\n+            # who are testing on databases without transactions or who are using\n+            # a TransactionTestCase still get a clean database on every test run.\n+            if serialize:\n+                self.connection._test_serialized_contents = self.serialize_db_to_string()\n \n         call_command('createcachetable', database=self.connection.alias)\n \n", "instance_id": "django__django-13448"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/config/option.py b/pylint/config/option.py\nindex 5043fe765..27f09f8d1 100644\n--- a/pylint/config/option.py\n+++ b/pylint/config/option.py\n@@ -99,7 +99,11 @@ def _py_version_validator(_, name, value):\n     return value\n \n \n+def _path_validator(_, name, value):\n+    return pathlib.Path(value)\n+\n VALIDATORS = {\n+    \"path\": _path_validator,\n     \"string\": utils._unquote,\n     \"int\": int,\n     \"float\": float,\n@@ -158,6 +162,7 @@ class Option(optparse.Option):\n         \"multiple_choice\",\n         \"non_empty_string\",\n         \"py_version\",\n+        \"path_csv\",\n     )\n     ATTRS = optparse.Option.ATTRS + [\"hide\", \"level\"]\n     TYPE_CHECKER = copy.copy(optparse.Option.TYPE_CHECKER)\ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..10a123226 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -597,12 +597,7 @@ class PyLinter(\n                         # Skip subtree of already discovered package.\n                         continue\n \n-                    if _is_ignored_file(\n-                        root,\n-                        self.config.ignore,\n-                        self.config.ignore_patterns,\n-                        self.config.ignore_paths,\n-                    ):\n+                    if self._is_ignored_path(root):\n                         skip_subtrees.append(root)\n                         continue\n \n@@ -610,11 +605,10 @@ class PyLinter(\n                         skip_subtrees.append(root)\n                         yield root\n                     else:\n-                        yield from (\n-                            os.path.join(root, file)\n-                            for file in files\n-                            if file.endswith(\".py\")\n-                        )\n+                        for file in files:\n+                            file_path = os.path.join(root, file)\n+                            if file_path.endswith(\".py\") and not self._is_ignored_path(file_path):\n+                                yield file_path\n             else:\n                 yield something\n \n@@ -1251,3 +1245,11 @@ class PyLinter(\n                     confidence=HIGH,\n                 )\n         self._stashed_messages = collections.defaultdict(list)\n+    def _is_ignored_path(self, path: str) -> bool:\n+        \"\"\"Check if a path should be ignored based on ignore-paths.\"\"\"\n+        return _is_ignored_file(\n+            path,\n+            self.config.ignore,\n+            self.config.ignore_patterns,\n+            self.config.ignore_paths,\n+        )\n", "instance_id": "pylint-dev__pylint-7080"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/config/argparsing.py b/src/_pytest/config/argparsing.py\nindex 9b526ff3e..88a2aafca 100644\n--- a/src/_pytest/config/argparsing.py\n+++ b/src/_pytest/config/argparsing.py\n@@ -75,7 +75,11 @@ class Parser:\n         by passing a ``dest`` attribute, for example\n         ``addoption(\"--long\", dest=\"NAME\", ...)``.\n         \"\"\"\n-        self._anonymous.addoption(*opts, **attrs)\n+        self._anonymous.addoption(\n+            \"-c\", \"--collect-only\",\n+            action=\"store_true\",\n+            help=\"only collect tests, don't execute them.\",\n+        )\n \n     def parse(self, args, namespace=None):\n         from _pytest._argcomplete import try_argcomplete\n", "instance_id": "pytest-dev__pytest-6116"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 7bc96e68eb..b4e17d151b 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1042,7 +1042,7 @@ def __new__(cls, num, dps=None, prec=None, precision=None):\n                 # it's a hexadecimal (coming from a pickled object)\n                 # assume that it is in standard form\n                 num = list(num)\n-                num[1] = long(num[1], 16)\n+                num[1] = int(num[1], 16)\n                 _mpf_ = tuple(num)\n             else:\n                 if len(num) == 4:\n", "instance_id": "sympy__sympy-13471"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "astropy__astropy-14995"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..bc7e6959e7 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1171,6 +1171,9 @@ class ModelChoiceIteratorValue:\n             other = other.value\n         return self.value == other\n \n+    def __hash__(self):\n+        return hash(self.value)\n+\n \n class ModelChoiceIterator:\n     def __init__(self, field):\n", "instance_id": "django__django-14915"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..979bc8a3af 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -6215,7 +6215,17 @@ def sqf_list(f, *gens, **args):\n     (2, [(x + 1, 2), (x + 2, 3)])\n \n     \"\"\"\n-    return _generic_factor_list(f, gens, args, method='sqf')\n+    coeff, factors = _generic_factor_list(f, gens, args, method='sqf')\n+    \n+    # Group factors with the same multiplicity\n+    grouped_factors = {}\n+    for factor, multiplicity in factors:\n+        if factor in grouped_factors:\n+            grouped_factors[factor] += multiplicity\n+        else:\n+            grouped_factors[factor] = multiplicity\n+    \n+    return coeff, list(grouped_factors.items())\n \n \n @public\n@@ -6233,7 +6243,8 @@ def sqf(f, *gens, **args):\n     2*(x + 1)**2*(x + 2)**3\n \n     \"\"\"\n-    return _generic_factor(f, gens, args, method='sqf')\n+    coeff, factors = sqf_list(f, *gens, **args)\n+    return _keep_coeff(coeff, Mul(*[factor**exp for factor, exp in factors]))\n \n \n @public\n", "instance_id": "sympy__sympy-18698"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..9d861d3d0 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -405,6 +405,9 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     # selection is done with one dimension\n                     columns = columns[0]\n \n+            if _is_empty_column_selection(columns):\n+                continue\n+\n             yield (name, trans, columns, get_weight(name))\n \n     def _validate_transformers(self):\n@@ -543,6 +546,12 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         feature_names_out : ndarray of shape (n_features,), dtype=str\n             Transformed feature names.\n         \"\"\"\n+        if not transformer_with_feature_names_out:\n+            return np.array([], dtype=object)\n+\n+        if not transformer_with_feature_names_out:\n+            return np.array([], dtype=object)\n+\n         if self.verbose_feature_names_out:\n             # Prefix the feature names out with the transformers name\n             names = list(\n@@ -733,7 +742,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         self._validate_column_callables(X)\n         self._validate_remainder(X)\n \n-        result = self._fit_transform(X, y, _fit_transform_one)\n+        result = self._fit_transform(X, y, _fit_transform_one, column_as_strings=True)\n \n         if not result:\n             self._update_fitted_transformers([])\n@@ -806,13 +815,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             # check that n_features_in_ is consistent\n             self._check_n_features(X, reset=False)\n \n-        Xs = self._fit_transform(\n-            X,\n-            None,\n-            _transform_one,\n-            fitted=True,\n-            column_as_strings=fit_dataframe_and_transform_dataframe,\n-        )\n+        Xs = self._fit_transform(X, None, _transform_one, fitted=True, column_as_strings=True)\n         self._validate_output(Xs)\n \n         if not Xs:\n", "instance_id": "scikit-learn__scikit-learn-25570"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex ac45127fde..8c57fbcbf9 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -13,7 +13,7 @@ from django.db.models.constants import LOOKUP_SEP\n from django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL\n from django.db.models.query_utils import PathInfo\n from django.db.models.utils import make_model_tuple\n-from django.utils.functional import cached_property\n+from django.utils.functional import cached_property, make_hashable\n from django.utils.translation import gettext_lazy as _\n \n from . import Field\n@@ -1192,7 +1192,7 @@ class ManyToManyField(RelatedField):\n             limit_choices_to=limit_choices_to,\n             symmetrical=symmetrical,\n             through=through,\n-            through_fields=through_fields,\n+            through_fields=make_hashable(through_fields),\n             db_constraint=db_constraint,\n         )\n         self.has_null_arg = 'null' in kwargs\n", "instance_id": "django__django-14672"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex c50fc90171..5cf1f5b3c2 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -5,7 +5,7 @@ from io import StringIO\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n \n # The prefix to put on the default database name when creating\n # the test database.\n@@ -126,8 +126,9 @@ class BaseDatabaseCreation:\n         the serialize_db_to_string() method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n", "instance_id": "django__django-12453"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..ad06668efe 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if evaluate and any(a.is_number and im(a) for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "instance_id": "sympy__sympy-22714"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..d254bcd2d4 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,10 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        enum_class = self.value.__class__\n+        module = enum_class.__module__\n+        imports = {'import %s' % module}\n+        return \"%s.%s.%s\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n@@ -222,7 +223,8 @@ class RegexSerializer(BaseSerializer):\n         # Turn off default implicit flags (e.g. re.U) because regexes with the\n         # same implicit and explicit flags aren't equal.\n         flags = self.value.flags ^ re.compile('').flags\n-        regex_flags, flag_imports = serializer_factory(flags).serialize()\n+        regex_flags = f\"re.RegexFlag({flags})\"\n+        flag_imports = {\"import re\"}\n         imports = {'import re', *pattern_imports, *flag_imports}\n         args = [regex_pattern]\n         if flags:\n", "instance_id": "django__django-11815"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex a1bf92bde1..fe1b27687c 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -1,6 +1,7 @@\n \"\"\"Base class for all the objects in SymPy\"\"\"\n from __future__ import print_function, division\n-from collections import Mapping, defaultdict\n+from collections.abc import Mapping\n+from collections import defaultdict\n from itertools import chain\n \n from .assumptions import BasicMeta, ManagedProperties\ndiff --git a/sympy/core/containers.py b/sympy/core/containers.py\nindex 15abd93e3a..8ac11e7ecd 100644\n--- a/sympy/core/containers.py\n+++ b/sympy/core/containers.py\n@@ -268,7 +268,7 @@ def _sorted_args(self):\n         return tuple(sorted(self.args, key=default_sort_key))\n \n \n-class OrderedSet(collections.MutableSet):\n+class OrderedSet(collections.abc.MutableSet):\n     def __init__(self, iterable=None):\n         if iterable:\n             self.map = collections.OrderedDict((item, None) for item in iterable)\ndiff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 28d675fc77..3d2bb5bbdb 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1238,7 +1238,7 @@ def __new__(cls, expr, *variables, **kwargs):\n             if unhandled_non_symbol:\n                 obj = None\n             else:\n-                if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n+                if isinstance(v, (collections.abc.Iterable, Tuple, MatrixCommon, NDimArray)):\n                     # Treat derivatives by arrays/matrices as much as symbols.\n                     is_symbol = True\n                 if not is_symbol:\ndiff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 91611b8c08..b0ac1daa83 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -2045,7 +2045,7 @@ def _handle_creation_inputs(cls, *args, **kwargs):\n                                  \"Both dimensions must be positive\".format(rows, cols))\n \n             # Matrix(2, 2, lambda i, j: i+j)\n-            if len(args) == 3 and isinstance(args[2], collections.Callable):\n+            if len(args) == 3 and isinstance(args[2], collections.abc.Callable):\n                 op = args[2]\n                 flat_list = []\n                 for i in range(rows):\ndiff --git a/sympy/plotting/plot.py b/sympy/plotting/plot.py\nindex b3b0237d19..0b959a43a4 100644\n--- a/sympy/plotting/plot.py\n+++ b/sympy/plotting/plot.py\n@@ -25,7 +25,7 @@\n from __future__ import print_function, division\n \n import inspect\n-from collections import Callable\n+from collections.abc import Callable\n import warnings\n import sys\n \ndiff --git a/sympy/polys/agca/modules.py b/sympy/polys/agca/modules.py\nindex 4589bc6888..5ece2d6ad4 100644\n--- a/sympy/polys/agca/modules.py\n+++ b/sympy/polys/agca/modules.py\n@@ -348,7 +348,7 @@ def convert(self, elem, M=None):\n             if len(tpl) != self.rank:\n                 raise CoercionFailed\n             return FreeModuleElement(self, tpl)\n-        elif elem is 0:\n+        elif elem == 0:\n             return FreeModuleElement(self, (self.ring.convert(0),)*self.rank)\n         else:\n             raise CoercionFailed\ndiff --git a/sympy/printing/conventions.py b/sympy/printing/conventions.py\nindex f74468290c..1eae0d8646 100644\n--- a/sympy/printing/conventions.py\n+++ b/sympy/printing/conventions.py\n@@ -77,7 +77,7 @@ def requires_partial(expr):\n     get the context of the expression.\n     \"\"\"\n \n-    if not isinstance(expr.free_symbols, collections.Iterable):\n+    if not isinstance(expr.free_symbols, collections.abc.Iterable):\n         return len(set(expr.variables)) > 1\n \n     return sum(not s.is_integer for s in expr.free_symbols) > 1\ndiff --git a/sympy/series/sequences.py b/sympy/series/sequences.py\nindex 08f36df061..8deb16253f 100644\n--- a/sympy/series/sequences.py\n+++ b/sympy/series/sequences.py\n@@ -600,6 +600,11 @@ def coeff_mul(self, coeff):\n \n \n class SeqFormula(SeqExpr):\n+    def __str__(self):\n+        return f\"[{', '.join(str(self.coeff(i)) for i in range(4))}, ...]\"\n+\n+    def _repr_latex_(self):\n+        return f\"\\\\left[{', '.join(str(self.coeff(i)) for i in range(4))}, \\\\ldots\\\\right]\"\n     \"\"\"Represents sequence based on a formula.\n \n     Elements are generated using a formula.\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex b2c4135a76..8d6aedf7e6 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -135,7 +135,7 @@ def _handle_ndarray_creation_inputs(cls, iterable=None, shape=None, **kwargs):\n             shape = iterable.shape\n             iterable = list(iterable)\n         # Construct N-dim array from an iterable (numpy arrays included):\n-        elif shape is None and isinstance(iterable, collections.Iterable):\n+        elif shape is None and isinstance(iterable, collections.abc.Iterable):\n             iterable, shape = cls._scan_iterable_shape(iterable)\n \n         # Construct N-dim array from a Matrix:\ndiff --git a/sympy/tensor/functions.py b/sympy/tensor/functions.py\nindex 4b97543cfa..6ac9be3314 100644\n--- a/sympy/tensor/functions.py\n+++ b/sympy/tensor/functions.py\n@@ -25,7 +25,7 @@ def __new__(cls, *args, **kwargs):\n         other = []\n         scalar = S.One\n         for arg in args:\n-            if isinstance(arg, (collections.Iterable, MatrixBase, NDimArray)):\n+            if isinstance(arg, (collections.abc.Iterable, MatrixBase, NDimArray)):\n                 arrays.append(Array(arg))\n             elif isinstance(arg, (MatrixExpr,)):\n                 other.append(arg)\ndiff --git a/sympy/tensor/indexed.py b/sympy/tensor/indexed.py\nindex 3752d24423..2da05a1a5c 100644\n--- a/sympy/tensor/indexed.py\n+++ b/sympy/tensor/indexed.py\n@@ -152,7 +152,7 @@ def __new__(cls, base, *args, **kw_args):\n             raise TypeError(filldedent(\"\"\"\n                 Indexed expects string, Symbol, or IndexedBase as base.\"\"\"))\n         args = list(map(sympify, args))\n-        if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n+        if isinstance(base, (NDimArray, collections.abc.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n             if len(args) == 1:\n                 return base[args[0]]\n             else:\ndiff --git a/sympy/vector/coordsysrect.py b/sympy/vector/coordsysrect.py\nindex baf290e8ac..ec1a344b65 100644\n--- a/sympy/vector/coordsysrect.py\n+++ b/sympy/vector/coordsysrect.py\n@@ -168,9 +168,9 @@ def __new__(cls, name, transformation=None, parent=None, location=None,\n             if isinstance(transformation, Lambda):\n                 variable_names = [\"x1\", \"x2\", \"x3\"]\n             elif isinstance(transformation, Symbol):\n-                if transformation.name is 'spherical':\n+                if transformation.name == 'spherical':\n                     variable_names = [\"r\", \"theta\", \"phi\"]\n-                elif transformation.name is 'cylindrical':\n+                elif transformation.name == 'cylindrical':\n                     variable_names = [\"r\", \"theta\", \"z\"]\n                 else:\n                     variable_names = [\"x\", \"y\", \"z\"]\n", "instance_id": "sympy__sympy-13971"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex febaadbb5b..9e94168345 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1180,6 +1180,11 @@ class ManyToManyField(RelatedField):\n         if symmetrical is None:\n             symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n \n+        if symmetrical and related_name is not None:\n+            raise ValueError(\n+                \"Cannot set related_name on symmetrical ManyToManyField.\"\n+            )\n+\n         if through is not None and db_table is not None:\n             raise ValueError(\n                 'Cannot specify a db_table if an intermediary model is used.'\n", "instance_id": "django__django-14730"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..b9c61fe216 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -181,8 +181,12 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n             syms = [i for i in syms if i in var]\n             if syms != var:\n                 dict_sym_index = dict(zip(syms, range(len(syms))))\n-                return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                base_solutions = diophantine(eq, param)\n+                permuted_solutions = set()\n+                for sol in base_solutions:\n+                    permuted_solutions.update(signed_permutations(sol))\n+                return {tuple([t[dict_sym_index[i]] for i in syms])\n+                            for t in permuted_solutions}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n@@ -330,25 +334,28 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n     # if there is no solution, return trivial solution\n     if not sols and eq.subs(zip(var, null)).is_zero:\n         sols.add(null)\n-    final_soln = set([])\n-    for sol in sols:\n-        if all(_is_int(s) for s in sol):\n-            if do_permute_signs:\n-                permuted_sign = set(permute_signs(sol))\n-                final_soln.update(permuted_sign)\n-            elif permute_few_signs:\n-                lst = list(permute_signs(sol))\n-                lst = list(filter(lambda x: x[0]*x[1] == sol[1]*sol[0], lst))\n-                permuted_sign = set(lst)\n-                final_soln.update(permuted_sign)\n-            elif do_permute_signs_var:\n-                permuted_sign_var = set(signed_permutations(sol))\n-                final_soln.update(permuted_sign_var)\n+    if permute:\n+        final_soln = set()\n+        for sol in sols:\n+            if all(_is_int(s) for s in sol):\n+                if do_permute_signs:\n+                    permuted_sign = set(permute_signs(sol))\n+                    final_soln.update(permuted_sign)\n+                elif permute_few_signs:\n+                    lst = list(permute_signs(sol))\n+                    lst = list(filter(lambda x: x[0]*x[1] == sol[1]*sol[0], lst))\n+                    permuted_sign = set(lst)\n+                    final_soln.update(permuted_sign)\n+                elif do_permute_signs_var:\n+                    permuted_sign_var = set(signed_permutations(sol))\n+                    final_soln.update(permuted_sign_var)\n+                else:\n+                    final_soln.add(sol)\n             else:\n-                final_soln.add(sol)\n-        else:\n-                final_soln.add(sol)\n-    return final_soln\n+                    final_soln.add(sol)\n+        return final_soln\n+    else:\n+        return sols\n \n \n def merge_solution(var, var_t, solution):\n", "instance_id": "sympy__sympy-18189"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex 4c2ffd81e1..60c1d60f7d 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -65,8 +65,8 @@ def __init__(self, settings={}):\n \n     def _print_Pow(self, expr):\n         PREC = precedence(expr)\n-        return '%s^%s' % (self.parenthesize(expr.base, PREC),\n-                          self.parenthesize(expr.exp, PREC))\n+        return '(%s)^%s' % (self.parenthesize(expr.base, PREC),\n+                            self.parenthesize(expr.exp, PREC))\n \n     def _print_Mul(self, expr):\n         PREC = precedence(expr)\n@@ -91,6 +91,13 @@ def _print_list(self, expr):\n     _print_tuple = _print_list\n     _print_Tuple = _print_list\n \n+    def _print_Derivative(self, expr):\n+        return \"D[%s]\" % (self.stringify(expr.args, \", \"))\n+\n+    def _print_Float(self, expr):\n+        res = str(expr)\n+        return res.replace('e', '*^')\n+\n     def _print_Function(self, expr):\n         if expr.func.__name__ in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n@@ -99,6 +106,21 @@ def _print_Function(self, expr):\n                     return \"%s[%s]\" % (mfunc, self.stringify(expr.args, \", \"))\n         return expr.func.__name__ + \"[%s]\" % self.stringify(expr.args, \", \")\n \n+    def _print_Pow(self, expr):\n+        PREC = precedence(expr)\n+        return '(%s)^%s' % (self.parenthesize(expr.base, PREC),\n+                            self.parenthesize(expr.exp, PREC))\n+\n+    def _print_Integral(self, expr):\n+        if len(expr.variables) == 1 and not expr.limits[0][1:]:\n+            args = [expr.args[0], expr.variables[0]]\n+        else:\n+            args = expr.args\n+        return \"Integrate[\" + ', '.join(self.doprint(a) for a in args) + \"]\"\n+\n+    def _print_Sum(self, expr):\n+        return \"Sum[\" + ', '.join(self.doprint(a) for a in expr.args) + \"]\"\n+\n     def _print_Integral(self, expr):\n         if len(expr.variables) == 1 and not expr.limits[0][1:]:\n             args = [expr.args[0], expr.variables[0]]\n", "instance_id": "sympy__sympy-12171"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..8f2cb3a102 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -94,7 +94,8 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email = '' if user.email is None else user.email\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n", "instance_id": "django__django-13551"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..9478c6f85d 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -553,7 +553,7 @@ def shorter(*choices):\n         floats = True\n         expr = nsimplify(expr, rational=True)\n \n-    expr = bottom_up(expr, lambda w: w.normal())\n+    expr = bottom_up(expr, lambda w: w.normal(), nonbasic=True)\n     expr = Mul(*powsimp(expr).as_content_primitive())\n     _e = cancel(expr)\n     expr1 = shorter(_e, _mexpand(_e).cancel())  # issue 6829\n", "instance_id": "sympy__sympy-13895"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex df7452ee87..fbc87ca309 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1950,6 +1950,7 @@ def _print_nth_root(self, base, expt):\n     def _print_Pow(self, power):\n         from sympy.simplify.simplify import fraction\n         b, e = power.as_base_exp()\n+        from sympy import E\n         if power.is_commutative:\n             if e is S.NegativeOne:\n                 return prettyForm(\"1\")/self._print(b)\n@@ -1958,6 +1959,8 @@ def _print_Pow(self, power):\n                 return self._print_nth_root(b, e)\n             if e.is_Rational and e < 0:\n                 return prettyForm(\"1\")/self._print(Pow(b, -e, evaluate=False))\n+            if e == 1/E:\n+                return self._print(b)**prettyForm(\"e**-1\")\n \n         if b.is_Relational:\n             return prettyForm(*self._print(b).parens()).__pow__(self._print(e))\n", "instance_id": "sympy__sympy-20639"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/tensor/array/dense_ndim_array.py b/sympy/tensor/array/dense_ndim_array.py\nindex 6019daf787..9e0f99e2df 100644\n--- a/sympy/tensor/array/dense_ndim_array.py\n+++ b/sympy/tensor/array/dense_ndim_array.py\n@@ -138,7 +138,10 @@ def __new__(cls, iterable, shape=None, **kwargs):\n \n     @classmethod\n     def _new(cls, iterable, shape, **kwargs):\n-        shape, flat_list = cls._handle_ndarray_creation_inputs(iterable, shape, **kwargs)\n+        if iterable == []:\n+            shape, flat_list = (), []\n+        else:\n+            shape, flat_list = cls._handle_ndarray_creation_inputs(iterable, shape, **kwargs)\n         shape = Tuple(*map(_sympify, shape))\n         cls._check_special_bounds(flat_list, shape)\n         flat_list = flatten(flat_list)\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex 6490a655a4..a6c46ca242 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -223,7 +223,10 @@ def _handle_ndarray_creation_inputs(cls, iterable=None, shape=None, **kwargs):\n \n             # Construct N-dim array from an iterable (numpy arrays included):\n             elif isinstance(iterable, Iterable):\n-                iterable, shape = cls._scan_iterable_shape(iterable)\n+                if iterable == []:\n+                    return (), []\n+                else:\n+                    iterable, shape = cls._scan_iterable_shape(iterable)\n \n             # Construct N-dim array from a Matrix:\n             elif isinstance(iterable, MatrixBase):\n", "instance_id": "sympy__sympy-23117"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\nindex 6e504a3057..0bb9fb980b 100644\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -474,13 +474,24 @@ def preprocess(cls, domain):\n                 else:\n                     return sympy.polys.domains.QQ.frac_field(*gens)\n \n+            if r is not None:\n+                ground, gens = r.groups()\n+\n+                gens = list(map(sympify, gens.split(',')))\n+\n+                if ground in ['Z', 'ZZ']:\n+                    return sympy.polys.domains.ZZ.poly_ring(*gens)\n+                else:\n+                    return sympy.polys.domains.QQ.poly_ring(*gens)\n+\n+\n             r = cls._re_algebraic.match(domain)\n \n             if r is not None:\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+        raise OptionError(f\"Expected a valid domain specification, got '{domain}'\")\n \n     @classmethod\n     def postprocess(cls, options):\ndiff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex d5ac051f63..9beeb8f44f 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -111,7 +111,7 @@ def __new__(cls, rep, *gens, **args):\n         \"\"\"Create a new polynomial instance out of something useful. \"\"\"\n         opt = options.build_options(gens, args)\n \n-        if 'order' in opt:\n+        if 'order' in opt and opt.order is not None:\n             raise NotImplementedError(\"'order' keyword is not implemented yet\")\n \n         if iterable(rep, exclude=str):\n", "instance_id": "sympy__sympy-14396"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-16820"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 1edc712358..a2e3ef06a0 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -431,7 +431,11 @@ def convert(expr):\n                 else:\n                     tex += r\"\\frac{1}{%s}%s%s\" % (sdenom, separator, snumer)\n             else:\n-                tex += r\"\\frac{%s}{%s}\" % (snumer, sdenom)\n+                # Ensure consistency with pretty printer\n+                if numer.is_Number and numer == 1:\n+                    tex += r\"\\frac{1}{%s}\" % sdenom\n+                else:\n+                    tex += r\"\\frac{%s}{%s}\" % (snumer, sdenom)\n \n         if include_parens:\n             tex += \")\"\n@@ -480,6 +484,10 @@ def _print_Pow(self, expr):\n                         return tex[1:].strip()\n                 tex = r\"%s^{%s}\"\n \n+                # Ensure consistency with pretty printer\n+                if expr.exp.is_Rational and expr.exp.q != 1:\n+                    return r\"%s^{%s/%s}\" % (self.parenthesize(expr.base, PRECEDENCE['Pow']), expr.exp.p, expr.exp.q)\n+\n                 return tex % (self.parenthesize(expr.base, PRECEDENCE['Pow']),\n                               self._print(expr.exp))\n \n", "instance_id": "sympy__sympy-11897"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 488d6a77cd..e952af3fdc 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -68,7 +68,7 @@ def format(\n             str_number = \"{:f}\".format(number)\n     else:\n         str_number = str(number)\n-    if str_number[0] == \"-\":\n+    if str_number and str_number[0] == \"-\":\n         sign = \"-\"\n         str_number = str_number[1:]\n     # decimal part\n", "instance_id": "django__django-16046"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..825c70ea 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1963,6 +1963,10 @@ class DataArray(AbstractArray, DataWithCoords):\n         for k in variables:\n             data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n \n+        # Handle single-dimension variables\n+        if len(self.dims) == 1:\n+            data_dict[dim] = self.coords[dim]\n+\n         # unstacked dataset\n         return Dataset(data_dict)\n \n", "instance_id": "pydata__xarray-4094"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..84cd37c6de 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -213,10 +213,20 @@ def __add__(self, other):\n         sympy.geometry.point.Point.translate\n \n         \"\"\"\n-        try:\n-            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n-        except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+        if isinstance(other, Point):\n+            s, o = Point._normalize_dimension(self, other)\n+        elif isinstance(other, Expr) and other.has(Point):\n+            other_points = [arg for arg in other.args if isinstance(arg, Point)]\n+            if len(other_points) == 1:\n+                s, o = Point._normalize_dimension(self, other_points[0])\n+                other = other / other_points[0]\n+            else:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+        else:\n+            try:\n+                s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+            except TypeError:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n", "instance_id": "sympy__sympy-17655"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex 11c800704b..f7f48a5297 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -39,7 +39,7 @@ def doit(p, q):\n             if p.is_infinite or q.is_infinite or p is nan or q is nan:\n                 return nan\n             if (p == q or p == -q or\n-                    p.is_Pow and p.exp.is_Integer and p.base == q or\n+                    p.is_Pow and p.exp.is_Integer and p.base == q and p.base.is_integer or\n                     p.is_integer and q == 1):\n                 return S.Zero\n \n", "instance_id": "sympy__sympy-13177"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..326c80d6c 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -111,6 +111,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n            ``behaviour`` parameter will be deprecated in 0.22 and removed in\n            0.24.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         If int, random_state is the seed used by the random number generator;\n         If RandomState instance, random_state is the random number generator;\n@@ -173,8 +178,9 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n-        super().__init__(\n+                 verbose=0,\n+                 warm_start=False):\n+        super().__init__(warm_start=warm_start,\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n                 splitter='random',\n", "instance_id": "scikit-learn__scikit-learn-13496"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..866a43afe3 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -895,13 +895,16 @@ def __new__(cls, *args, **kwargs):\n         # counting starts from 1.\n \n         temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n+        if is_cycle:\n+            # Apply cycles in left-to-right order\n+            c = Cycle()\n+            for ci in args:\n+                c = c(*ci)\n+            aform = c.list()\n+        else:\n+            if has_dups(temp):\n                 raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n+            temp = set(temp)\n \n         if not is_cycle and \\\n                 any(i not in temp for i in range(len(temp))):\n", "instance_id": "sympy__sympy-12481"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..67fa5c8c4 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -110,7 +110,10 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n                     # continue `The rows are marked `X_mask` and will be\n                     # removed later.\n                     X_mask[:, i] = valid_mask\n-                    Xi = Xi.copy()\n+                    if X.dtype.kind in {'U', 'S'}:\n+                        Xi = Xi.astype(object)\n+                    else:\n+                        Xi = Xi.copy()\n                     Xi[~valid_mask] = self.categories_[i][0]\n             _, encoded = _encode(Xi, self.categories_[i], encode=True)\n             X_int[:, i] = encoded\n", "instance_id": "scikit-learn__scikit-learn-12471"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex d610dc86f0..7fb1f1e6c1 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -82,6 +82,8 @@ def return_None():\n \n \n @total_ordering\n+from django.db.models.enums import Choices\n+\n class Field(RegisterLookupMixin):\n     \"\"\"Base class for all field types\"\"\"\n \n", "instance_id": "django__django-11964"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-17087"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..f7ce67a27 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2174,8 +2174,12 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]\n-                                 for i in range(len(folds))], axis=0)\n+                    if multi_class == 'multinomial':\n+                        w = np.mean([coefs_paths[:, :, i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n+                    else:\n+                        w = np.mean([coefs_paths[:, i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n \n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n", "instance_id": "scikit-learn__scikit-learn-14087"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex dc413b5c2..ade1c0f02 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -712,8 +712,8 @@ class Documenter:\n \n             doc = getdoc(member, self.get_attr, self.config.autodoc_inherit_docstrings,\n                          self.parent, self.object_name)\n-            if not isinstance(doc, str):\n-                # Ignore non-string __doc__\n+            if not isinstance(doc, str) and not isinstance(member, type):\n+                # Ignore non-string __doc__ and annotation-only members\n                 doc = None\n \n             # if the member __doc__ is the same as self's __doc__, it's just\n@@ -755,7 +755,7 @@ class Documenter:\n                     elif is_filtered_inherited_member(membername, obj):\n                         keep = False\n                     else:\n-                        keep = has_doc or self.options.undoc_members\n+                        keep = has_doc or self.options.undoc_members or isinstance(member, type)\n                 else:\n                     keep = False\n             elif (namespace, membername) in attr_docs:\n@@ -784,7 +784,7 @@ class Documenter:\n                     keep = False\n                 else:\n                     # ignore undocumented members if :undoc-members: is not given\n-                    keep = has_doc or self.options.undoc_members\n+                    keep = has_doc or self.options.undoc_members or isinstance(member, type)\n \n             if isinstance(obj, ObjectMember) and obj.skipped:\n                 # forcedly skipped member (ex. a module attribute not defined in __all__)\n", "instance_id": "sphinx-doc__sphinx-8801"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex 78db834466..cfe76772a6 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -7,7 +7,7 @@\n from sympy.core.expr import Expr, ExprBuilder\n from sympy.core.logic import FuzzyBool\n from sympy.core.symbol import Str, Dummy, symbols, Symbol\n-from sympy.core.sympify import SympifyError, _sympify\n+from sympy.core.sympify import SympifyError, _sympify, sympify\n from sympy.external.gmpy import SYMPY_INTS\n from sympy.functions import conjugate, adjoint\n from sympy.functions.special.tensor_functions import KroneckerDelta\n@@ -589,7 +589,7 @@ class MatrixElement(Expr):\n     def __new__(cls, name, n, m):\n         n, m = map(_sympify, (n, m))\n         from sympy.matrices.matrices import MatrixBase\n-        if isinstance(name, (MatrixBase,)):\n+        if isinstance(name, (MatrixBase, MatrixSymbol)):\n             if n.is_Integer and m.is_Integer:\n                 return name[n, m]\n         if isinstance(name, str):\n@@ -684,7 +684,7 @@ def name(self):\n         return self.args[0].name\n \n     def _entry(self, i, j, **kwargs):\n-        return MatrixElement(self, i, j)\n+        return MatrixElement(sympify(self), i, j)\n \n     @property\n     def free_symbols(self):\ndiff --git a/sympy/simplify/cse_main.py b/sympy/simplify/cse_main.py\nindex d649dd02a9..e9e59735d3 100644\n--- a/sympy/simplify/cse_main.py\n+++ b/sympy/simplify/cse_main.py\n@@ -488,7 +488,7 @@ def opt_cse(exprs, order='canonical'):\n \n     def _find_opts(expr):\n \n-        if not isinstance(expr, (Basic, Unevaluated)):\n+        if not isinstance(expr, (Basic, Unevaluated, MatrixElement)):\n             return\n \n         if expr.is_Atom or expr.is_Order:\n@@ -566,7 +566,7 @@ def tree_cse(exprs, symbols, opt_subs=None, order='canonical', ignore=()):\n     ignore : iterable of Symbols\n         Substitutions containing any Symbol from ``ignore`` will be ignored.\n     \"\"\"\n-    from sympy.matrices.expressions import MatrixExpr, MatrixSymbol, MatMul, MatAdd\n+    from sympy.matrices.expressions import MatrixExpr, MatrixSymbol, MatMul, MatAdd, MatrixElement\n     from sympy.polys.rootoftools import RootOf\n \n     if opt_subs is None:\n@@ -580,7 +580,7 @@ def tree_cse(exprs, symbols, opt_subs=None, order='canonical', ignore=()):\n     excluded_symbols = set()\n \n     def _find_repeated(expr):\n-        if not isinstance(expr, (Basic, Unevaluated)):\n+        if not isinstance(expr, (Basic, Unevaluated, MatrixElement)):\n             return\n \n         if isinstance(expr, RootOf):\n", "instance_id": "sympy__sympy-22840"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 02aa32b207..f2c957fbf7 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -125,28 +125,33 @@ class Media:\n         in a certain order. In JavaScript you may not be able to reference a\n         global or in CSS you might want to override a style.\n         \"\"\"\n-        # Start with a copy of list_1.\n-        combined_list = list(list_1)\n-        last_insert_index = len(list_1)\n-        # Walk list_2 in reverse, inserting each element into combined_list if\n-        # it doesn't already exist.\n-        for path in reversed(list_2):\n-            try:\n-                # Does path already exist in the list?\n-                index = combined_list.index(path)\n-            except ValueError:\n-                # Add path to combined_list since it doesn't exist.\n-                combined_list.insert(last_insert_index, path)\n+        combined_list = []\n+        seen = set()\n+        conflict_pairs = set()\n+\n+        for item in list(list_1) + list(list_2):\n+            if item not in seen:\n+                combined_list.append(item)\n+                seen.add(item)\n             else:\n-                if index > last_insert_index:\n-                    warnings.warn(\n-                        'Detected duplicate Media files in an opposite order:\\n'\n-                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n-                        MediaOrderConflictWarning,\n-                    )\n-                # path already exists in the list. Update last_insert_index so\n-                # that the following elements are inserted in front of this one.\n-                last_insert_index = index\n+                # Check for conflicts\n+                if item in list_1 and item in list_2:\n+                    index_1 = list_1.index(item)\n+                    index_2 = list_2.index(item)\n+                    for earlier_item in list_1[:index_1]:\n+                        if earlier_item in list_2[index_2 + 1:]:\n+                            conflict_pairs.add((earlier_item, item))\n+                    for later_item in list_1[index_1 + 1:]:\n+                        if later_item in list_2[:index_2]:\n+                            conflict_pairs.add((item, later_item))\n+\n+        for pair in conflict_pairs:\n+            warnings.warn(\n+                'Detected duplicate Media files in an opposite order:\\n'\n+                '%s\\n%s' % pair,\n+                MediaOrderConflictWarning,\n+            )\n+\n         return combined_list\n \n     def __add__(self, other):\n@@ -158,14 +163,14 @@ class Media:\n \n def media_property(cls):\n     def _media(self):\n-        # Get the media property of the superclass, if it exists\n+        # Get the media property of the superclass, if it exists.\n         sup_cls = super(cls, self)\n         try:\n             base = sup_cls.media\n         except AttributeError:\n             base = Media()\n \n-        # Get the media definition for this class\n+        # Get the media definition for this class.\n         definition = getattr(cls, 'Media', None)\n         if definition:\n             extend = getattr(definition, 'extend', True)\n", "instance_id": "django__django-11019"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\nindex 69149e61a..2bb88772c 100644\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -119,7 +119,7 @@ class EncodingChecker(BaseChecker):\n     def open(self):\n         super().open()\n \n-        notes = \"|\".join(re.escape(note) for note in self.config.notes)\n+        notes = \"|\".join(re.escape(note) if note.isalnum() else re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n             regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n         else:\n", "instance_id": "pylint-dev__pylint-5859"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex b821c42845..9446735416 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -233,18 +233,26 @@ def transpose(self):\n         return self._eval_transpose()\n \n     def _entry(self, i, j, **kwargs):\n+        from sympy import Ge\n+        from sympy.core.logic import is_true\n+\n         # Find row entry\n-        for row_block, numrows in enumerate(self.rowblocksizes):\n-            if (i < numrows) != False:\n+        row_block = 0\n+        for numrows in self.rowblocksizes:\n+            if is_true(i < numrows):\n                 break\n-            else:\n-                i -= numrows\n-        for col_block, numcols in enumerate(self.colblocksizes):\n-            if (j < numcols) != False:\n+            i -= numrows\n+            row_block += 1\n+\n+        # Find column entry\n+        col_block = 0\n+        for numcols in self.colblocksizes:\n+            if is_true(j < numcols):\n                 break\n-            else:\n-                j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+            j -= numcols\n+            col_block += 1\n+\n+        return self.blocks[row_block, col_block]._entry(i, j, **kwargs)\n \n     @property\n     def is_Identity(self):\n", "instance_id": "sympy__sympy-19007"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..963cec465 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -7,6 +7,7 @@\n \"\"\"\n \n import warnings\n+import struct\n from typing import Any, Callable, Dict, List, Set\n \n from docutils import nodes\ndiff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex 2587ba35b..621b670c8 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -11,6 +11,7 @@\n import importlib\n import traceback\n import warnings\n+import struct\n from typing import Any, Callable, Dict, List, Mapping, NamedTuple, Optional, Tuple\n \n from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warning,\n", "instance_id": "sphinx-doc__sphinx-8627"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/functions/elementary/complexes.py b/sympy/functions/elementary/complexes.py\nindex 7fda45982b..feb72833db 100644\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -394,9 +394,26 @@ def _eval_rewrite_as_Heaviside(self, arg, **kwargs):\n         if arg.is_extended_real:\n             return Heaviside(arg, H0=S(1)/2) * 2 - 1\n \n-    def _eval_simplify(self, **kwargs):\n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        if arg.is_zero:\n+            return S.NaN\n+        return arg / Abs(arg)\n         return self.func(self.args[0].factor())  # XXX include doit?\n \n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        if arg.is_zero:\n+            return S.NaN\n+        return arg / Abs(arg)\n+\n+    def _eval_simplify(self, **kwargs):\n+        from sympy.simplify.simplify import signsimp\n+        from sympy.core import Mul\n+        from sympy.simplify.simplify import signsimp\n+        rewritten = self.rewrite(Abs)\n+        if isinstance(rewritten, Mul) and rewritten.args[1] == Abs(rewritten.args[0]):\n+            return rewritten\n+        return signsimp(rewritten)\n+\n \n class Abs(Function):\n     \"\"\"\n", "instance_id": "sympy__sympy-19487"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..c9bdfee89 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n", "instance_id": "pytest-dev__pytest-7432"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..9add8c4276 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -11,6 +11,7 @@ import re\n import string\n from importlib import import_module\n from urllib.parse import quote\n+import functools\n \n from asgiref.local import Local\n \n@@ -31,7 +32,14 @@ from .utils import get_callable\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n+        if isinstance(func, functools.partial):\n+            self.func = func.func\n+            self.partial_args = func.args\n+            self.partial_kwargs = func.keywords\n+        else:\n+            self.func = func\n+            self.partial_args = ()\n+            self.partial_kwargs = {}\n         self.args = args\n         self.kwargs = kwargs\n         self.url_name = url_name\n@@ -59,8 +67,8 @@ class ResolverMatch:\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n-        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n-            self._func_path, self.args, self.kwargs, self.url_name,\n+        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, partial_args=%s, partial_kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n+            self._func_path, self.args, self.kwargs, self.partial_args, self.partial_kwargs, self.url_name,\n             self.app_names, self.namespaces, self.route,\n         )\n \n", "instance_id": "django__django-14155"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 187e14b1b7..bb6a9149f1 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -2,6 +2,7 @@ import base64\n import logging\n import string\n import warnings\n+import binascii\n from datetime import datetime, timedelta\n \n from django.conf import settings\n@@ -121,7 +122,7 @@ class SessionBase:\n             return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n         # RemovedInDjango40Warning: when the deprecation ends, handle here\n         # exceptions similar to what _legacy_decode() does now.\n-        except Exception:\n+        except (Exception, binascii.Error):\n             return self._legacy_decode(session_data)\n \n     def _legacy_encode(self, session_dict):\n@@ -141,7 +142,7 @@ class SessionBase:\n                 raise SuspiciousSession(\"Session data corrupted\")\n             else:\n                 return self.serializer().loads(serialized)\n-        except Exception as e:\n+        except (Exception, binascii.Error) as e:\n             # ValueError, SuspiciousOperation, unpickling exceptions. If any of\n             # these happen, just return an empty dictionary (an empty session).\n             if isinstance(e, SuspiciousOperation):\n", "instance_id": "django__django-13321"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex d96e76263b..4fe5a3adbe 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -2109,7 +2109,10 @@ def uniq(seq, result=None):\n     try:\n         seen = set()\n         result = result or []\n+        initial_size = len(seq)\n         for i, s in enumerate(seq):\n+            if len(seq) != initial_size:\n+                raise RuntimeError(\"dictionary changed size during iteration\")\n             if not (s in seen or seen.add(s)):\n                 yield s\n     except TypeError:\n", "instance_id": "sympy__sympy-18835"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..0567dd8ec2 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,11 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return (\n+            subclass in self._subclasses or\n+            any(issubclass(subclass, cls) for cls in self._subclasses) or\n+            super().__subclasscheck__(subclass)\n+        )\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "instance_id": "django__django-14238"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\nindex 61b8d4a21..62253a00a 100644\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -92,6 +92,8 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         -------\n         self : returns an instance of self.\n         \"\"\"\n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n         y = column_or_1d(y, warn=True)\n         self.classes_ = np.unique(y)\n         return self\n", "instance_id": "scikit-learn__scikit-learn-10508"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\nindex d3a06f2b31..11b22afd33 100644\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -49,6 +49,11 @@ from . import _docutil as __\n try:\n     from . import _wcs\n except ImportError:\n+    try:\n+        from .._astropy_init import _ASTROPY_SETUP_\n+    except ImportError:\n+        _ASTROPY_SETUP_ = False\n+\n     if not _ASTROPY_SETUP_:\n         raise\n     else:\n@@ -1212,6 +1217,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if any(isinstance(ax, (list, np.ndarray)) and (not hasattr(ax, '__len__') or len(ax) == 0) for ax in axes):\n+                return [np.array([]) for _ in range(self.naxis)]\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1231,6 +1238,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n                     for i in range(output.shape[1])]\n \n         def _return_single_array(xy, origin):\n+            if isinstance(xy, (list, np.ndarray)) and (not hasattr(xy, 'size') or xy.size == 0):\n+                return np.empty((0, self.naxis))\n             if xy.shape[-1] != self.naxis:\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n@@ -2500,7 +2509,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n \n         \"\"\"\n         # default precision for numerical WCS keywords\n-        precision = WCSHDO_P14\n+        precision = _wcs.WCSHDO_P14\n         display_warning = False\n         if relax is None:\n             display_warning = True\n@@ -2511,7 +2520,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n             relax &= ~WCSHDO_SIP\n         else:\n             do_sip = relax\n-            relax = WCSHDO_all if relax is True else WCSHDO_safe\n+            relax = _wcs.WCSHDO_all if relax is True else _wcs.WCSHDO_safe\n \n         relax = precision | relax\n \n@@ -2896,7 +2905,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         the spectral axis, followed by any others.\n         Assumes at least celestial axes are present.\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL, WCSSUB_SPECTRAL, WCSSUB_STOKES])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL, _wcs.WCSSUB_SPECTRAL, _wcs.WCSSUB_STOKES])\n \n     def slice(self, view, numpy_order=True):\n         \"\"\"\n@@ -3023,7 +3032,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n         A copy of the current WCS with only the celestial axes included\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL])\n \n     @property\n     def is_celestial(self):\n", "instance_id": "astropy__astropy-7746"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..e2d871647c 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -848,10 +848,6 @@ class MultiWidget(Widget):\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n \n     def value_from_datadict(self, data, files, name):\n         return [\n", "instance_id": "django__django-15061"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 57676428ff..0b9ea8cece 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -257,13 +257,15 @@ class BaseFormSet(RenderableFormMixin):\n \n     @property\n     def empty_form(self):\n+        form_kwargs = self.get_form_kwargs(None)\n+        form_kwargs.pop('empty_permitted', None)\n         form = self.form(\n             auto_id=self.auto_id,\n             prefix=self.add_prefix(\"__prefix__\"),\n             empty_permitted=True,\n             use_required_attribute=False,\n-            **self.get_form_kwargs(None),\n             renderer=self.renderer,\n+            **form_kwargs,\n         )\n         self.add_fields(form, None)\n         return form\n", "instance_id": "django__django-16041"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..72348505f5 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\ndiff --git a/django/forms/utils.py b/django/forms/utils.py\nindex 50412f414b..ffc427387c 100644\n--- a/django/forms/utils.py\n+++ b/django/forms/utils.py\n@@ -85,7 +85,7 @@ class ErrorList(UserList, list):\n         super().__init__(initlist)\n \n         if error_class is None:\n-            self.error_class = 'errorlist'\n+            self.error_class = 'errorlist nonform'\n         else:\n             self.error_class = 'errorlist {}'.format(error_class)\n \n", "instance_id": "django__django-14608"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/assertion/util.py b/src/_pytest/assertion/util.py\nindex 762e5761d..26511a3ad 100644\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -137,14 +137,8 @@ def assertrepr_compare(config, op, left, right):\n                 elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                     type_fn = (isdatacls, isattrs)\n                     explanation = _compare_eq_cls(left, right, verbose, type_fn)\n-                elif verbose > 0:\n-                    explanation = _compare_eq_verbose(left, right)\n-                if isiterable(left) and isiterable(right):\n-                    expl = _compare_eq_iterable(left, right, verbose)\n-                    if explanation is not None:\n-                        explanation.extend(expl)\n-                    else:\n-                        explanation = expl\n+                elif isinstance(left, bytes) and isinstance(right, bytes):\n+                    explanation = _compare_eq_bytes(left, right, verbose)\n         elif op == \"not in\":\n             if istext(left) and istext(right):\n                 explanation = _notin_text(left, right, verbose)\n@@ -299,6 +293,27 @@ def _compare_eq_set(left, right, verbose=0):\n         for item in diff_right:\n             explanation.append(saferepr(item))\n     return explanation\n+    \"\"\"Return the explanation for the diff between byte strings.\"\"\"\n+    explanation = []\n+    if left != right:\n+        explanation.append(\"Byte strings differ:\")\n+        explanation.append(\"Left:  %s\" % saferepr(left))\n+        explanation.append(\"Right: %s\" % saferepr(right))\n+        explanation.append(\"Full diff:\")\n+        explanation.extend(_diff_text(left.decode('latin1'), right.decode('latin1'), verbose))\n+    return explanation\n+    explanation = []\n+    diff_left = left - right\n+    diff_right = right - left\n+    if diff_left:\n+        explanation.append(\"Extra items in the left set:\")\n+        for item in diff_left:\n+            explanation.append(saferepr(item))\n+    if diff_right:\n+        explanation.append(\"Extra items in the right set:\")\n+        for item in diff_right:\n+            explanation.append(saferepr(item))\n+    return explanation\n \n \n def _compare_eq_dict(left, right, verbose=0):\n", "instance_id": "pytest-dev__pytest-5495"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 38da1e6ecc..d51d08f3a0 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -125,10 +125,19 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        return (\n-            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n-            {\"import %s\" % module},\n-        )\n+        try:\n+            return (\n+                \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n+                {\"import %s\" % module},\n+            )\n+        except KeyError:\n+            # Handle combination of Enum flags\n+            members, _ = enum_class._decompose(self.value)\n+            member_names = \" | \".join(\"%s.%s.%s\" % (module, enum_class.__qualname__, member.name) for member in members)\n+            return (\n+                member_names,\n+                {\"import %s\" % module},\n+            )\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "instance_id": "django__django-15996"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\nindex b9809fd4e9..4ca8fdb9a3 100644\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -60,7 +60,15 @@ def solve_poly_system(seq, *gens, **args):\n             except SolveFailed:\n                 pass\n \n-    return solve_generic(polys, opt)\n+    # Check if the system is zero-dimensional\n+    G = groebner(polys, opt.gens)\n+    if G.dimension != 0:\n+        raise NotImplementedError(filldedent('''\n+            only zero-dimensional systems supported\n+            (finite number of solutions)\n+            '''))\n+\n+    return solve_generic(G, opt)\n \n \n def solve_biquadratic(f, g, opt):\n@@ -240,7 +248,7 @@ def _solve_reduced_system(system, gens, entry=False):\n \n         univariate = list(filter(_is_univariate, basis))\n \n-        if len(univariate) == 1:\n+        if len(univariate) == 1 and len(gens) == 1:\n             f = univariate.pop()\n         else:\n             raise NotImplementedError(filldedent('''\n", "instance_id": "sympy__sympy-22005"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/style/core.py b/lib/matplotlib/style/core.py\nindex fb0a5426e6..d381217e58 100644\n--- a/lib/matplotlib/style/core.py\n+++ b/lib/matplotlib/style/core.py\n@@ -108,7 +108,77 @@ def use(style):\n     else:\n         styles = style\n \n-    style_alias = {'mpl20': 'default', 'mpl15': 'classic'}\n+    style_alias = {\n+        'mpl20': 'default',\n+        'mpl15': 'classic',\n+        'seaborn': 'seaborn-v0_8',\n+        'seaborn-bright': 'seaborn-v0_8-bright',\n+        'seaborn-colorblind': 'seaborn-v0_8-colorblind',\n+        'seaborn-dark': 'seaborn-v0_8-dark',\n+        'seaborn-darkgrid': 'seaborn-v0_8-darkgrid',\n+        'seaborn-dark-palette': 'seaborn-v0_8-dark-palette',\n+        'seaborn-deep': 'seaborn-v0_8-deep',\n+        'seaborn-muted': 'seaborn-v0_8-muted',\n+        'seaborn-notebook': 'seaborn-v0_8-notebook',\n+        'seaborn-paper': 'seaborn-v0_8-paper',\n+        'seaborn-pastel': 'seaborn-v0_8-pastel',\n+        'seaborn-poster': 'seaborn-v0_8-poster',\n+        'seaborn-talk': 'seaborn-v0_8-talk',\n+        'seaborn-ticks': 'seaborn-v0_8-ticks',\n+        'seaborn-white': 'seaborn-v0_8-white',\n+        'seaborn-whitegrid': 'seaborn-v0_8-whitegrid',\n+    }\n+\n+    def fix_style(s):\n+        if isinstance(s, str):\n+            s = style_alias.get(s, s)\n+            if s in [\n+                \"seaborn\",\n+                \"seaborn-bright\",\n+                \"seaborn-colorblind\",\n+                \"seaborn-dark\",\n+                \"seaborn-darkgrid\",\n+                \"seaborn-dark-palette\",\n+                \"seaborn-deep\",\n+                \"seaborn-muted\",\n+                \"seaborn-notebook\",\n+                \"seaborn-paper\",\n+                \"seaborn-pastel\",\n+                \"seaborn-poster\",\n+                \"seaborn-talk\",\n+                \"seaborn-ticks\",\n+                \"seaborn-white\",\n+                \"seaborn-whitegrid\",\n+            ]:\n+                _api.warn_deprecated(\n+                    \"3.6\", message=\"The seaborn styles shipped by Matplotlib \"\n+                    \"are deprecated since %(since)s, as they no longer \"\n+                    \"correspond to the styles shipped by seaborn. However, \"\n+                    \"they will remain available as 'seaborn-v0_8-<style>'. \"\n+                    \"Alternatively, directly use the seaborn API instead.\")\n+                s = s.replace(\"seaborn\", \"seaborn-v0_8\")\n+        return s\n+\n+    style_alias = {\n+        'mpl20': 'default',\n+        'mpl15': 'classic',\n+        'seaborn': 'seaborn-v0_8',\n+        'seaborn-bright': 'seaborn-v0_8-bright',\n+        'seaborn-colorblind': 'seaborn-v0_8-colorblind',\n+        'seaborn-dark': 'seaborn-v0_8-dark',\n+        'seaborn-darkgrid': 'seaborn-v0_8-darkgrid',\n+        'seaborn-dark-palette': 'seaborn-v0_8-dark-palette',\n+        'seaborn-deep': 'seaborn-v0_8-deep',\n+        'seaborn-muted': 'seaborn-v0_8-muted',\n+        'seaborn-notebook': 'seaborn-v0_8-notebook',\n+        'seaborn-paper': 'seaborn-v0_8-paper',\n+        'seaborn-pastel': 'seaborn-v0_8-pastel',\n+        'seaborn-poster': 'seaborn-v0_8-poster',\n+        'seaborn-talk': 'seaborn-v0_8-talk',\n+        'seaborn-ticks': 'seaborn-v0_8-ticks',\n+        'seaborn-white': 'seaborn-v0_8-white',\n+        'seaborn-whitegrid': 'seaborn-v0_8-whitegrid',\n+    }\n \n     def fix_style(s):\n         if isinstance(s, str):\n", "instance_id": "matplotlib__matplotlib-24265"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex f71bea25f5..3d5530578d 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -15,6 +15,7 @@\n from sympy.core.compatibility import (exec_, is_sequence, iterable,\n     NotIterable, string_types, range, builtins, integer_types, PY3)\n from sympy.utilities.decorator import doctest_depends_on\n+from sympy.matrices import MatrixSymbol\n \n # These are the namespaces the lambda functions will use.\n MATH = {}\n@@ -725,19 +726,26 @@ def _preprocess(self, args, expr):\n                 argstrs.append(nested_argstrs)\n             elif isinstance(arg, DeferredVector):\n                 argstrs.append(str(arg))\n-            elif isinstance(arg, Symbol):\n-                argrep = self._argrepr(arg)\n-\n-                if dummify or not self._is_safe_ident(argrep):\n+            elif isinstance(arg, (Symbol,)):\n+                from sympy.matrices import MatrixSymbol\n+                if isinstance(arg, MatrixSymbol):\n+                    argrep = self._argrepr(arg)\n+                    if dummify or not self._is_safe_ident(argrep):\n+                        dummy = Dummy()\n+                        argstrs.append(self._argrepr(dummy))\n+                        expr = self._subexpr(expr, {arg: dummy})\n+                    else:\n+                        argstrs.append(argrep)\n+                else:\n+                    argstrs.append(self._argrepr(arg))\n+            elif isinstance(arg, (Function,)):\n+                from sympy.matrices import MatrixSymbol\n+                if isinstance(arg, MatrixSymbol):\n                     dummy = Dummy()\n                     argstrs.append(self._argrepr(dummy))\n                     expr = self._subexpr(expr, {arg: dummy})\n                 else:\n-                    argstrs.append(argrep)\n-            elif isinstance(arg, Function):\n-                dummy = Dummy()\n-                argstrs.append(self._argrepr(dummy))\n-                expr = self._subexpr(expr, {arg: dummy})\n+                    argstrs.append(self._argrepr(arg))\n             else:\n                 argstrs.append(str(arg))\n \n", "instance_id": "sympy__sympy-15011"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/assumptions/sathandlers.py b/sympy/assumptions/sathandlers.py\nindex 61d62d04cf..881a5f9ba8 100644\n--- a/sympy/assumptions/sathandlers.py\n+++ b/sympy/assumptions/sathandlers.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n-from collections import MutableMapping, defaultdict\n+from collections.abc import MutableMapping\n+from collections import defaultdict\n \n from sympy.core import (Add, Mul, Pow, Integer, Number, NumberSymbol,)\n from sympy.core.numbers import ImaginaryUnit\ndiff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..ed002f9661 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -1,6 +1,7 @@\n \"\"\"Base class for all the objects in SymPy\"\"\"\n from __future__ import print_function, division\n-from collections import Mapping, defaultdict\n+from collections.abc import Mapping\n+from collections import defaultdict\n from itertools import chain\n \n from .assumptions import BasicMeta, ManagedProperties\n@@ -898,29 +899,32 @@ def subs(self, *args, **kwargs):\n                 sequence = sorted([(k, v) for (k, v) in sequence.items()],\n                                   key=default_sort_key)\n \n-        if kwargs.pop('simultaneous', False):  # XXX should this be the default for dict subs?\n-            reps = {}\n-            rv = self\n-            kwargs['hack2'] = True\n-            m = Dummy()\n-            for old, new in sequence:\n-                d = Dummy(commutative=new.is_commutative)\n-                # using d*m so Subs will be used on dummy variables\n-                # in things like Derivative(f(x, y), x) in which x\n-                # is both free and bound\n-                rv = rv._subs(old, d*m, **kwargs)\n-                if not isinstance(rv, Basic):\n-                    break\n-                reps[d] = new\n-            reps[m] = S.One  # get rid of m\n-            return rv.xreplace(reps)\n-        else:\n-            rv = self\n-            for old, new in sequence:\n-                rv = rv._subs(old, new, **kwargs)\n-                if not isinstance(rv, Basic):\n-                    break\n-            return rv\n+        try:\n+            if kwargs.pop('simultaneous', False):  # XXX should this be the default for dict subs?\n+                reps = {}\n+                rv = self\n+                kwargs['hack2'] = True\n+                m = Dummy()\n+                for old, new in sequence:\n+                    d = Dummy(commutative=new.is_commutative)\n+                    # using d*m so Subs will be used on dummy variables\n+                    # in things like Derivative(f(x, y), x) in which x\n+                    # is both free and bound\n+                    rv = rv._subs(old, d*m, **kwargs)\n+                    if not isinstance(rv, Basic):\n+                        break\n+                    reps[d] = new\n+                reps[m] = S.One  # get rid of m\n+                return rv.xreplace(reps)\n+            else:\n+                rv = self\n+                for old, new in sequence:\n+                    rv = rv._subs(old, new, **kwargs)\n+                    if not isinstance(rv, Basic):\n+                        break\n+                return rv\n+        except ZeroDivisionError:\n+            return S.NaN\n \n     @cacheit\n     def _subs(self, old, new, **hints):\n@@ -1026,13 +1030,16 @@ def fallback(self, old, new):\n                 return rv\n             return self\n \n-        if _aresame(self, old):\n-            return new\n+        try:\n+            if _aresame(self, old):\n+                return new\n \n-        rv = self._eval_subs(old, new)\n-        if rv is None:\n-            rv = fallback(self, old, new)\n-        return rv\n+            rv = self._eval_subs(old, new)\n+            if rv is None:\n+                rv = fallback(self, old, new)\n+            return rv\n+        except ZeroDivisionError:\n+            return S.NaN\n \n     def _eval_subs(self, old, new):\n         \"\"\"Override this stub if you want to do anything more than\ndiff --git a/sympy/core/containers.py b/sympy/core/containers.py\nindex 15abd93e3a..8ac11e7ecd 100644\n--- a/sympy/core/containers.py\n+++ b/sympy/core/containers.py\n@@ -268,7 +268,7 @@ def _sorted_args(self):\n         return tuple(sorted(self.args, key=default_sort_key))\n \n \n-class OrderedSet(collections.MutableSet):\n+class OrderedSet(collections.abc.MutableSet):\n     def __init__(self, iterable=None):\n         if iterable:\n             self.map = collections.OrderedDict((item, None) for item in iterable)\ndiff --git a/sympy/plotting/plot.py b/sympy/plotting/plot.py\nindex b3b0237d19..0b959a43a4 100644\n--- a/sympy/plotting/plot.py\n+++ b/sympy/plotting/plot.py\n@@ -25,7 +25,7 @@\n from __future__ import print_function, division\n \n import inspect\n-from collections import Callable\n+from collections.abc import Callable\n import warnings\n import sys\n \ndiff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 1038790b28..9da7780b8c 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -3185,7 +3185,7 @@ def power_representation(n, p, k, zeros=False):\n             '''Todd G. Will, \"When Is n^2 a Sum of k Squares?\", [online].\n                 Available: https://www.maa.org/sites/default/files/Will-MMz-201037918.pdf'''\n             return\n-        if feasible is 1:  # it's prime and k == 2\n+        if feasible == 1:  # it's prime and k == 2\n             yield prime_as_sum_of_two_squares(n)\n             return\n \n", "instance_id": "sympy__sympy-13915"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-13757"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/vector/point.py b/sympy/physics/vector/point.py\nindex d4e3cfcc90..c0ea26c65a 100644\n--- a/sympy/physics/vector/point.py\n+++ b/sympy/physics/vector/point.py\n@@ -518,10 +518,14 @@ def vel(self, frame):\n         \"\"\"\n \n         _check_frame(frame)\n-        if not (frame in self._vel_dict):\n-            raise ValueError('Velocity of point ' + self.name + ' has not been'\n-                             ' defined in ReferenceFrame ' + frame.name)\n-        return self._vel_dict[frame]\n+        if frame not in self._vel_dict:\n+            if self in self._pos_dict:\n+                return self.pos_from(self._pos_dict[self]).dt(frame)\n+            else:\n+                raise ValueError('Velocity of point ' + self.name + ' has not been'\n+                                 ' defined in ReferenceFrame ' + frame.name)\n+        else:\n+            return self._vel_dict[frame]\n \n     def partial_velocity(self, frame, *gen_speeds):\n         \"\"\"Returns the partial velocities of the linear velocity vector of this\n", "instance_id": "sympy__sympy-20049"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\nindex 29bd46798..181585833 100644\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,7 +175,7 @@ class TextReporter(BaseReporter):\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{([^{}]+?)(:.*)?\\}\", template)\n         for argument in arguments:\n             if argument[0] not in MESSAGE_FIELDS:\n                 warnings.warn(\n", "instance_id": "pylint-dev__pylint-7993"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-12113"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 1877c3f92a..b985b2a557 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -526,6 +526,11 @@ def _print_IndexedBase(self, expr):\n         return self._print_ArraySymbol(expr)\n \n \n+    def _print_Tuple(self, expr):\n+        if len(expr) == 1:\n+            return '({},)'.format(self._print(expr[0]))\n+        return '({})'.format(', '.join(map(self._print, expr)))\n+\n class PythonCodePrinter(AbstractPythonCodePrinter):\n \n     def _print_sign(self, e):\n", "instance_id": "sympy__sympy-23262"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/assumptions/sathandlers.py b/sympy/assumptions/sathandlers.py\nindex 61d62d04cf..881a5f9ba8 100644\n--- a/sympy/assumptions/sathandlers.py\n+++ b/sympy/assumptions/sathandlers.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n-from collections import MutableMapping, defaultdict\n+from collections.abc import MutableMapping\n+from collections import defaultdict\n \n from sympy.core import (Add, Mul, Pow, Integer, Number, NumberSymbol,)\n from sympy.core.numbers import ImaginaryUnit\ndiff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..b42fd1d75c 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -1,6 +1,7 @@\n \"\"\"Base class for all the objects in SymPy\"\"\"\n from __future__ import print_function, division\n-from collections import Mapping, defaultdict\n+from collections.abc import Mapping\n+from collections import defaultdict\n from itertools import chain\n \n from .assumptions import BasicMeta, ManagedProperties\ndiff --git a/sympy/core/containers.py b/sympy/core/containers.py\nindex 15abd93e3a..ac0308a373 100644\n--- a/sympy/core/containers.py\n+++ b/sympy/core/containers.py\n@@ -13,6 +13,7 @@\n from sympy.core.sympify import sympify, converter\n from sympy.utilities.iterables import iterable\n \n+from collections.abc import MutableSet\n import collections\n \n \n@@ -268,7 +269,7 @@ def _sorted_args(self):\n         return tuple(sorted(self.args, key=default_sort_key))\n \n \n-class OrderedSet(collections.MutableSet):\n+class OrderedSet(MutableSet):\n     def __init__(self, iterable=None):\n         if iterable:\n             self.map = collections.OrderedDict((item, None) for item in iterable)\ndiff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..43445c3516 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,10 +86,9 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n-        return self._new(self.rows, self.cols + other.cols,\n-                         lambda i, j: entry(i, j))\n+        return self._new(self.rows, self.cols + other.cols, entry)\n \n     def _eval_col_join(self, other):\n         rows = self.rows\ndiff --git a/sympy/plotting/plot.py b/sympy/plotting/plot.py\nindex b3b0237d19..0b959a43a4 100644\n--- a/sympy/plotting/plot.py\n+++ b/sympy/plotting/plot.py\n@@ -25,7 +25,7 @@\n from __future__ import print_function, division\n \n import inspect\n-from collections import Callable\n+from collections.abc import Callable\n import warnings\n import sys\n \n", "instance_id": "sympy__sympy-13647"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..7c1bf9bf9b 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -162,9 +162,13 @@ def structurally_equal(self, other):\n             and self.colblocksizes == other.colblocksizes)\n \n     def _blockmul(self, other):\n-        if (isinstance(other, BlockMatrix) and\n-                self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+        if isinstance(other, BlockMatrix) and self.colblocksizes == other.rowblocksizes:\n+            result_blocks = self.blocks * other.blocks\n+            for i in range(result_blocks.rows):\n+                for j in range(result_blocks.cols):\n+                    if result_blocks[i, j] == 0:\n+                        result_blocks[i, j] = ZeroMatrix(result_blocks[i, j].rows, result_blocks[i, j].cols)\n+            return BlockMatrix(result_blocks)\n \n         return self * other\n \n", "instance_id": "sympy__sympy-17630"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 66461181d0..b7fdaca022 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -315,6 +315,20 @@ def _print_Abs(self, e):\n         pform = self._print(e.args[0])\n         pform = prettyForm(*pform.parens('|', '|'))\n         return pform\n+\n+    def _print_Vector(self, e):\n+        from sympy.vector.vector import VectorAdd, VectorMul, BaseVector\n+        if isinstance(e, VectorAdd):\n+            return self._print_Add(e)\n+        elif isinstance(e, VectorMul):\n+            return self._print_Mul(e)\n+        elif isinstance(e, BaseVector):\n+            return self._print_Symbol(e)\n+        else:\n+            return self.emptyPrinter(e)\n+        pform = self._print(e.args[0])\n+        pform = prettyForm(*pform.parens('|', '|'))\n+        return pform\n     _print_Determinant = _print_Abs\n \n     def _print_floor(self, e):\ndiff --git a/sympy/vector/vector.py b/sympy/vector/vector.py\nindex 87320d0366..d8489e049e 100644\n--- a/sympy/vector/vector.py\n+++ b/sympy/vector/vector.py\n@@ -274,10 +274,23 @@ def _projections(self):\n         base_vec = next(iter(_get_coord_systems(self))).base_vectors()\n         return tuple([self.dot(i) for i in base_vec])\n \n+    def _sympystr(self, printer):\n+        return str(self)\n+\n     def __or__(self, other):\n         return self.outer(other)\n \n     __or__.__doc__ = outer.__doc__\n+        from sympy.printing.pretty.stringpict import prettyForm\n+        from sympy.vector.vector import VectorAdd, VectorMul, BaseVector\n+        if isinstance(self, VectorAdd):\n+            return printer._print_Add(self)\n+        elif isinstance(self, VectorMul):\n+            return printer._print_Mul(self)\n+        elif isinstance(self, BaseVector):\n+            return printer._print_Symbol(self)\n+        else:\n+            return prettyForm(str(self))\n \n     def to_matrix(self, system):\n         \"\"\"\n", "instance_id": "sympy__sympy-23191"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 34a3bab3fc..1476fa6069 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -10,7 +10,7 @@\n from sympy.core.function import count_ops, _mexpand\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sinc\n \n from sympy.strategies.core import identity\n from sympy.strategies.tree import greedy\n@@ -22,6 +22,8 @@\n from sympy.polys import factor, cancel, parallel_poly_from_expr\n \n from sympy.utilities.misc import debug\n+from sympy.simplify.simplify import cse\n+from sympy.simplify.separatevars import separatevars\n \n \n \n@@ -425,7 +427,18 @@ def analyse_gens(gens, hints):\n _trigs = (TrigonometricFunction, HyperbolicFunction)\n \n \n+def _exp_to_trig(expr):\n+    \"\"\"\n+    Convert exponential expressions to trigonometric forms.\n+    \"\"\"\n+    from sympy import I\n+    expr = expr.rewrite(exp)\n+    expr = expr.replace(exp(I * expr), lambda arg: cos(arg) + I * sin(arg))\n+    expr = expr.replace(exp(-I * expr), lambda arg: cos(arg) - I * sin(arg))\n+    return expr\n+\n def trigsimp(expr, **opts):\n+    expr = _exp_to_trig(expr)\n     \"\"\"\n     reduces expression by using known trig identities\n \n", "instance_id": "sympy__sympy-11870"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..bd0f1e007c 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,6 +320,9 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # Check if db_table is already defined\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\n", "instance_id": "django__django-14999"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex bc227d2c4..6834972e5 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -567,7 +567,15 @@ class PyLinter(\n         \"\"\"\n         if is_argument:\n             return True\n-        return path.endswith(\".py\")\n+        if path.endswith(\"__init__.py\"):\n+            return True\n+        if path.endswith(\".py\"):\n+            module_name = os.path.splitext(os.path.basename(path))[0]\n+            parent_dir = os.path.basename(os.path.dirname(path))\n+            if module_name == parent_dir:\n+                return False\n+            return True\n+        return False\n \n     # pylint: enable=unused-argument\n \ndiff --git a/pylint/utils/file_state.py b/pylint/utils/file_state.py\nindex acd59d648..83e154867 100644\n--- a/pylint/utils/file_state.py\n+++ b/pylint/utils/file_state.py\n@@ -9,7 +9,7 @@ import sys\n import warnings\n from collections import defaultdict\n from collections.abc import Iterator\n-from typing import TYPE_CHECKING, Dict\n+from typing import TYPE_CHECKING, Dict, Union, Iterator\n \n from astroid import nodes\n \n@@ -62,10 +62,8 @@ class FileState:\n         ] = collections.defaultdict(set)\n         self._suppression_mapping: dict[tuple[str, int], int] = {}\n         self._module = node\n-        if node:\n-            self._effective_max_line_number = node.tolineno\n-        else:\n-            self._effective_max_line_number = None\n+        self._effective_max_line_number = node.tolineno if node else None\n+        self._module_name = modname\n         self._msgs_store = msg_store\n         self._is_base_filestate = is_base_filestate\n         \"\"\"If this FileState is the base state made during initialization of\n@@ -250,7 +248,7 @@ class FileState:\n         tuple[\n             Literal[\"useless-suppression\", \"suppressed-message\"],\n             int,\n-            tuple[str] | tuple[str, int],\n+            Union[tuple[str], tuple[str, int]],\n         ]\n     ]:\n         for warning, lines in self._raw_module_msgs_state.items():\n", "instance_id": "pylint-dev__pylint-7114"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/units/util.py b/sympy/physics/units/util.py\nindex b03ed4cd88..29f09a4283 100644\n--- a/sympy/physics/units/util.py\n+++ b/sympy/physics/units/util.py\n@@ -105,8 +105,17 @@ def get_total_scale_factor(expr):\n     if depmat is None:\n         return expr\n \n+    if any(p != 1 for p in depmat):\n+        return expr  # Return the original expression if units are orthogonal\n+\n     expr_scale_factor = get_total_scale_factor(expr)\n-    return expr_scale_factor * Mul.fromiter((1/get_total_scale_factor(u) * u) ** p for u, p in zip(target_units, depmat))\n+    converted_expr = expr_scale_factor * Mul.fromiter((1/get_total_scale_factor(u) * u) ** p for u, p in zip(target_units, depmat))\n+\n+    # Check if the converted expression is equivalent to the original expression\n+    if not expr.equals(converted_expr):\n+        return expr  # Return the original expression if the conversion is not equivalent\n+\n+    return converted_expr\n \n \n def quantity_simplify(expr):\n", "instance_id": "sympy__sympy-20442"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 9ce46e3f73..1b50100b00 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -207,8 +207,47 @@ class Field(RegisterLookupMixin):\n             *self._check_backend_specific_checks(**kwargs),\n             *self._check_validators(),\n             *self._check_deprecation_details(),\n+            *self._check_max_length_with_choices(),\n         ]\n \n+    def _check_max_length_with_choices(self):\n+        \"\"\"\n+        Check if max_length is large enough to fit the longest value in choices.\n+        \"\"\"\n+        if self.choices is not None and self.max_length is not None:\n+            def get_longest_choice(choices):\n+                longest = 0\n+                for choice in choices:\n+                    if isinstance(choice, (list, tuple)):\n+                        longest = max(longest, get_longest_choice(choice))\n+                    else:\n+                        longest = max(longest, len(str(choice)))\n+                return longest\n+\n+            def get_longest_choice(choices):\n+                longest = 0\n+                for choice in choices:\n+                    if isinstance(choice, (list, tuple)):\n+                        if isinstance(choice[1], (list, tuple)):\n+                            longest = max(longest, get_longest_choice(choice[1]))\n+                        else:\n+                            longest = max(longest, len(str(choice[0])))\n+                    else:\n+                        longest = max(longest, len(str(choice)))\n+                return longest\n+\n+            longest_choice = get_longest_choice(self.choices)\n+            if longest_choice > self.max_length:\n+                return [\n+                    checks.Error(\n+                        f\"'max_length' is too small to fit the longest value in 'choices'. \"\n+                        f\"Longest value has {longest_choice} characters.\",\n+                        obj=self,\n+                        id='fields.E009',\n+                    )\n+                ]\n+        return []\n+\n     def _check_field_name(self):\n         \"\"\"\n         Check if field name is valid, i.e. 1) does not end with an\n", "instance_id": "django__django-11742"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 0dc55568..8a6270aa 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -7,7 +7,7 @@ requests.models\n This module contains the primary objects that power Requests.\n \"\"\"\n \n-import collections\n+import collections.abc\n import datetime\n \n from io import BytesIO, UnsupportedOperation\n@@ -22,7 +22,7 @@ from .packages.urllib3.util import parse_url\n from .packages.urllib3.exceptions import DecodeError\n from .exceptions import (\n     HTTPError, RequestException, MissingSchema, InvalidURL,\n-    ChunkedEncodingError, ContentDecodingError)\n+    ChunkedEncodingError, ContentDecodingError, ConnectionError)\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n@@ -162,7 +162,7 @@ class RequestHooksMixin(object):\n         if event not in self.hooks:\n             raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n \n-        if isinstance(hook, collections.Callable):\n+        if isinstance(hook, collections.abc.Callable):\n             self.hooks[event].append(hook)\n         elif hasattr(hook, '__iter__'):\n             self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))\n@@ -640,7 +640,7 @@ class Response(object):\n                     raise ChunkedEncodingError(e)\n                 except DecodeError as e:\n                     raise ContentDecodingError(e)\n-            except AttributeError:\n+            except (AttributeError, ConnectionError):\n                 # Standard file-like object.\n                 while True:\n                     chunk = self.raw.read(chunk_size)\n@@ -752,7 +752,7 @@ class Response(object):\n     def json(self, **kwargs):\n         \"\"\"Returns the json-encoded content of a response, if any.\n \n-        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n+        :param **kwargs: Optional arguments that ``json.loads`` takes.\n         \"\"\"\n \n         if not self.encoding and len(self.content) > 3:\ndiff --git a/requests/packages/urllib3/response.py b/requests/packages/urllib3/response.py\nindex 7e0d47fa..9f8a746f 100644\n--- a/requests/packages/urllib3/response.py\n+++ b/requests/packages/urllib3/response.py\n@@ -1,6 +1,6 @@\n import zlib\n import io\n-from socket import timeout as SocketTimeout\n+from socket import timeout as SocketTimeout, error as SocketError\n \n from ._collections import HTTPHeaderDict\n from .exceptions import ProtocolError, DecodeError, ReadTimeoutError\n@@ -206,7 +206,7 @@ class HTTPResponse(io.IOBase):\n \n                 raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n \n-            except HTTPException as e:\n+            except (HTTPException, SocketError) as e:\n                 # This includes IncompleteRead.\n                 raise ProtocolError('Connection broken: %r' % e, e)\n \n", "instance_id": "psf__requests-2148"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 78accaf295..ae362a2aa4 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -248,7 +248,10 @@ def _eval_expand_tensorproduct(self, **hints):\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n                     if isinstance(tp, TensorProduct):\n                         tp = tp._eval_expand_tensorproduct()\n-                    add_args.append(tp)\n+                    c_part, nc_part = tp.args_cnc()\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(),)\n+                    add_args.append(Mul(*c_part) * Mul(*nc_part))\n                 break\n \n         if add_args:\n", "instance_id": "sympy__sympy-24152"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..4f13878d87 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,12 @@ class Axes3D(Axes):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n+\n+        if not self.get_visible():\n+            return\n+\n         self._unstale_viewLim()\n \n         # draw the background patch\ndiff --git a/lib/mpl_toolkits/mplot3d/axis3d.py b/lib/mpl_toolkits/mplot3d/axis3d.py\nindex d08576904d..4002c15eba 100644\n--- a/lib/mpl_toolkits/mplot3d/axis3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axis3d.py\n@@ -159,6 +159,12 @@ class Axis(maxis.XAxis):\n         self.axes._set_artist_props(self.label)\n         self.axes._set_artist_props(self.offsetText)\n         # Need to be able to place the label at the correct location\n+        if not self.get_visible():\n+            return\n+\n+        if not self.get_visible():\n+            return\n+\n         self.label._transform = self.axes.transData\n         self.offsetText._transform = self.axes.transData\n \n", "instance_id": "matplotlib__matplotlib-23314"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-13925"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 984398c760..cd44ad80ea 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -299,6 +299,8 @@ def __new__(cls, b, e, evaluate=None):\n                 return b\n             elif e == -1 and not b:\n                 return S.ComplexInfinity\n+            elif b is S.Zero and e is S.NegativeInfinity:\n+                return S.ComplexInfinity\n             # Only perform autosimplification if exponent or base is a Symbol or number\n             elif (b.is_Symbol or b.is_number) and (e.is_Symbol or e.is_number) and\\\n                 e.is_integer and _coeff_isneg(b):\n", "instance_id": "sympy__sympy-20212"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..ba8c3463a0 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,11 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n", "instance_id": "django__django-14855"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..40eff5bec8 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -166,7 +166,7 @@ class Line3D(lines.Line2D):\n         Keyword arguments are passed onto :func:`~matplotlib.lines.Line2D`.\n         \"\"\"\n         super().__init__([], [], *args, **kwargs)\n-        self._verts3d = xs, ys, zs\n+        self.set_data_3d(xs, ys, zs)\n \n     def set_3d_properties(self, zs=0, zdir='z'):\n         xs = self.get_xdata()\n@@ -197,6 +197,7 @@ class Line3D(lines.Line2D):\n         else:\n             self._verts3d = args\n         self.stale = True\n+        self.stale = True\n \n     def get_data_3d(self):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-23563"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a9f66740f..8fb48d82c 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -38,14 +38,14 @@ def _check_shape(param, param_shape, name):\n                          \"but got %s\" % (name, param_shape, param.shape))\n \n \n-def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n+def _check_X(X, n_clusters=None, n_features=None, ensure_min_samples=1):\n     \"\"\"Check the input data X.\n \n     Parameters\n     ----------\n     X : array-like, shape (n_samples, n_features)\n \n-    n_components : int\n+    n_clusters : int\n \n     Returns\n     -------\n@@ -53,10 +53,10 @@ def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n     \"\"\"\n     X = check_array(X, dtype=[np.float64, np.float32],\n                     ensure_min_samples=ensure_min_samples)\n-    if n_components is not None and X.shape[0] < n_components:\n-        raise ValueError('Expected n_samples >= n_components '\n-                         'but got n_components = %d, n_samples = %d'\n-                         % (n_components, X.shape[0]))\n+    if n_clusters is not None and X.shape[0] < n_clusters:\n+        raise ValueError('Expected n_samples >= n_clusters '\n+                         'but got n_clusters = %d, n_samples = %d'\n+                         % (n_clusters, X.shape[0]))\n     if n_features is not None and X.shape[1] != n_features:\n         raise ValueError(\"Expected the input data X have %d features, \"\n                          \"but got %d features\"\n@@ -71,10 +71,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n     provides basic common methods for mixture models.\n     \"\"\"\n \n-    def __init__(self, n_components, tol, reg_covar,\n+    def __init__(self, n_clusters, tol, reg_covar,\n                  max_iter, n_init, init_params, random_state, warm_start,\n                  verbose, verbose_interval):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.tol = tol\n         self.reg_covar = reg_covar\n         self.max_iter = max_iter\n@@ -92,10 +92,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         ----------\n         X : array-like, shape (n_samples, n_features)\n         \"\"\"\n-        if self.n_components < 1:\n-            raise ValueError(\"Invalid value for 'n_components': %d \"\n+        if self.n_clusters < 1:\n+            raise ValueError(\"Invalid value for 'n_clusters': %d \"\n                              \"Estimation requires at least one component\"\n-                             % self.n_components)\n+                             % self.n_clusters)\n \n         if self.tol < 0.:\n             raise ValueError(\"Invalid value for 'tol': %.5f \"\n@@ -144,12 +144,12 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         n_samples, _ = X.shape\n \n         if self.init_params == 'kmeans':\n-            resp = np.zeros((n_samples, self.n_components))\n-            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n+            resp = np.zeros((n_samples, self.n_clusters))\n+            label = cluster.KMeans(n_clusters=self.n_clusters, n_init=1,\n                                    random_state=random_state).fit(X).labels_\n             resp[np.arange(n_samples), label] = 1\n         elif self.init_params == 'random':\n-            resp = random_state.rand(n_samples, self.n_components)\n+            resp = random_state.rand(n_samples, self.n_clusters)\n             resp /= resp.sum(axis=1)[:, np.newaxis]\n         else:\n             raise ValueError(\"Unimplemented initialization method '%s'\"\n@@ -169,6 +169,23 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         \"\"\"\n         pass\n \n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n+\n     def fit(self, X, y=None):\n         \"\"\"Estimate model parameters with the EM algorithm.\n \n@@ -188,7 +205,7 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         -------\n         self\n         \"\"\"\n-        X = _check_X(X, self.n_components, ensure_min_samples=2)\n+        X = _check_X(X, self.n_clusters, ensure_min_samples=2)\n         self._check_initial_parameters(X)\n \n         # if we enable warm_start, we will have a unique initialisation\n@@ -382,11 +399,13 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         if n_samples < 1:\n             raise ValueError(\n                 \"Invalid value for 'n_samples': %d . The sampling requires at \"\n-                \"least one sample.\" % (self.n_components))\n+                \"least one sample.\" % (self.n_clusters))\n \n         _, n_features = self.means_.shape\n         rng = check_random_state(self.random_state)\n         n_samples_comp = rng.multinomial(n_samples, self.weights_)\n+        self.labels_ = np.concatenate([np.full(sample, j, dtype=int)\n+                                       for j, sample in enumerate(n_samples_comp)])\n \n         if self.covariance_type == 'full':\n             X = np.vstack([\n@@ -407,7 +426,7 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         y = np.concatenate([j * np.ones(sample, dtype=int)\n                            for j, sample in enumerate(n_samples_comp)])\n \n-        return (X, y)\n+        return (X, self.labels_)\n \n     def _estimate_weighted_log_prob(self, X):\n         \"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\ndiff --git a/sklearn/mixture/gmm.py b/sklearn/mixture/gmm.py\nindex b3c231314..c80849d18 100644\n--- a/sklearn/mixture/gmm.py\n+++ b/sklearn/mixture/gmm.py\n@@ -256,11 +256,11 @@ class _GMMBase(BaseEstimator):\n \n     \"\"\"\n \n-    def __init__(self, n_components=1, covariance_type='diag',\n+    def __init__(self, n_clusters=1, covariance_type='diag',\n                  random_state=None, tol=1e-3, min_covar=1e-3,\n                  n_iter=100, n_init=1, params='wmc', init_params='wmc',\n                  verbose=0):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.covariance_type = covariance_type\n         self.tol = tol\n         self.min_covar = min_covar\n@@ -301,7 +301,7 @@ class _GMMBase(BaseEstimator):\n     def _set_covars(self, covars):\n         \"\"\"Provide values for covariance.\"\"\"\n         covars = np.asarray(covars)\n-        _validate_covars(covars, self.covariance_type, self.n_components)\n+        _validate_covars(covars, self.covariance_type, self.n_clusters)\n         self.covars_ = covars\n \n     def score_samples(self, X):\n@@ -389,6 +389,7 @@ class _GMMBase(BaseEstimator):\n             (state) in the model.\n         \"\"\"\n         logprob, responsibilities = self.score_samples(X)\n+        self.labels_ = responsibilities.argmax(axis=1)\n         return responsibilities\n \n     def sample(self, n_samples=1, random_state=None):\n@@ -416,7 +417,7 @@ class _GMMBase(BaseEstimator):\n         # decide which component to use for each sample\n         comps = weight_cdf.searchsorted(rand)\n         # for each component, generate all needed samples\n-        for comp in range(self.n_components):\n+        for comp in range(self.n_clusters):\n             # occurrences of current component in X\n             comp_in_X = (comp == comps)\n             # number of those occurrences\n@@ -450,7 +451,8 @@ class _GMMBase(BaseEstimator):\n         -------\n         C : array, shape = (n_samples,) component memberships\n         \"\"\"\n-        return self._fit(X, y).argmax(axis=1)\n+        self.labels_ = self._fit(X, y).argmax(axis=1)\n+        return self.labels_\n \n     def _fit(self, X, y=None, do_prediction=False):\n         \"\"\"Estimate model parameters with the EM algorithm.\n@@ -477,10 +479,10 @@ class _GMMBase(BaseEstimator):\n         # initialization step\n         X = check_array(X, dtype=np.float64, ensure_min_samples=2,\n                         estimator=self)\n-        if X.shape[0] < self.n_components:\n+        if X.shape[0] < self.n_clusters:\n             raise ValueError(\n                 'GMM estimation with %s components, but got only %s samples' %\n-                (self.n_components, X.shape[0]))\n+                (self.n_clusters, X.shape[0]))\n \n         max_log_prob = -np.infty\n \n@@ -488,13 +490,14 @@ class _GMMBase(BaseEstimator):\n             print('Expectation-maximization algorithm started.')\n \n         for init in range(self.n_init):\n+            self.labels_ = np.zeros(X.shape[0], dtype=int)\n             if self.verbose > 0:\n                 print('Initialization ' + str(init + 1))\n                 start_init_time = time()\n \n             if 'm' in self.init_params or not hasattr(self, 'means_'):\n                 self.means_ = cluster.KMeans(\n-                    n_clusters=self.n_components,\n+                    n_clusters=self.n_clusters,\n                     random_state=self.random_state).fit(X).cluster_centers_\n                 if self.verbose > 1:\n                     print('\\tMeans have been initialized.')\n@@ -624,15 +627,15 @@ class _GMMBase(BaseEstimator):\n         \"\"\"Return the number of free parameters in the model.\"\"\"\n         ndim = self.means_.shape[1]\n         if self.covariance_type == 'full':\n-            cov_params = self.n_components * ndim * (ndim + 1) / 2.\n+            cov_params = self.n_clusters * ndim * (ndim + 1) / 2.\n         elif self.covariance_type == 'diag':\n-            cov_params = self.n_components * ndim\n+            cov_params = self.n_clusters * ndim\n         elif self.covariance_type == 'tied':\n             cov_params = ndim * (ndim + 1) / 2.\n         elif self.covariance_type == 'spherical':\n-            cov_params = self.n_components\n-        mean_params = ndim * self.n_components\n-        return int(cov_params + mean_params + self.n_components - 1)\n+            cov_params = self.n_clusters\n+        mean_params = ndim * self.n_clusters\n+        return int(cov_params + mean_params + self.n_clusters - 1)\n \n     def bic(self, X):\n         \"\"\"Bayesian information criterion for the current model fit\n", "instance_id": "scikit-learn__scikit-learn-11281"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 737e16cc74..9a3d2cd180 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1854,7 +1854,11 @@ def _print_PolynomialRingBase(self, expr):\n \n     def _print_Poly(self, poly):\n         cls = poly.__class__.__name__\n-        expr = self._print(poly.as_expr())\n+        terms = sorted(poly.terms(), key=lambda term: -sum(term[0]))\n+        expr = \" + \".join(\n+            f\"{self._print(coeff)}{self._print_monomial(monom, poly.gens)}\"\n+            for monom, coeff in terms\n+        )\n         gens = list(map(self._print, poly.gens))\n         domain = \"domain=%s\" % self._print(poly.get_domain())\n \n@@ -1866,6 +1870,12 @@ def _print_Poly(self, poly):\n \n         return tex\n \n+    def _print_monomial(self, monom, gens):\n+        return \"\".join(\n+            f\"{self._print(gen)}^{exp}\" if exp != 1 else f\"{self._print(gen)}\"\n+            for gen, exp in zip(gens, monom) if exp != 0\n+        )\n+\n     def _print_ComplexRootOf(self, root):\n         cls = root.__class__.__name__\n         if cls == \"ComplexRootOf\":\n", "instance_id": "sympy__sympy-14317"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..7e152fdacb 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -396,6 +396,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n+    elif isinstance(field, models.JSONField):\n+        return field.value_from_object(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n     else:\n", "instance_id": "django__django-12308"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 63ca817355..2142025ede 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -6,7 +6,7 @@ from itertools import chain\n from django.core.exceptions import EmptyResultSet, FieldError\n from django.db import DatabaseError, NotSupportedError\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value\n+from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value, Subquery\n from django.db.models.functions import Cast\n from django.db.models.query_utils import Q, select_related_descend\n from django.db.models.sql.constants import (\n@@ -117,9 +117,15 @@ class SQLCompiler:\n             # by reference.\n             if expr in ref_sources:\n                 continue\n-            cols = expr.get_group_by_cols()\n-            for col in cols:\n-                expressions.append(col)\n+            if isinstance(expr, Subquery):\n+                # Only include subqueries in the GROUP BY clause if they are not\n+                # part of the annotation select mask.\n+                if expr not in self.query.annotation_select.values():\n+                    expressions.append(expr)\n+            else:\n+                cols = expr.get_group_by_cols()\n+                for col in cols:\n+                    expressions.append(col)\n         for expr, (sql, params, is_ref) in order_by:\n             # Skip References to the select clause, as all expressions in the\n             # select clause are already part of the group by.\n", "instance_id": "django__django-12589"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex dc084b8692..f6668b916b 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -179,6 +179,11 @@ class ValidationError(Exception):\n             return repr(dict(self))\n         return repr(list(self))\n \n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return False\n+        return sorted(self.messages) == sorted(other.messages)\n+\n     def __repr__(self):\n         return 'ValidationError(%s)' % self\n \n", "instance_id": "django__django-13220"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 43f9e6ad8d..b97d53582a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1968,10 +1968,12 @@ def _print_DiracDelta(self, expr, exp=None):\n             tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n-    def _print_SingularityFunction(self, expr):\n+    def _print_SingularityFunction(self, expr, exp=None):\n         shift = self._print(expr.args[0] - expr.args[1])\n         power = self._print(expr.args[2])\n         tex = r\"{\\left\\langle %s \\right\\rangle}^{%s}\" % (shift, power)\n+        if exp is not None:\n+            tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n     def _print_Heaviside(self, expr, exp=None):\n", "instance_id": "sympy__sympy-21171"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..ce5438848a 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,11 +26,13 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n+                self.serialize_result(obj, to_field_name) for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"Convert the object to a dictionary representation for the response.\"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n \n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n", "instance_id": "django__django-14752"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\nindex 7b7ddc8d..56f9ea9f 100644\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -23,6 +23,9 @@ class PolyFit(Stat):\n \n         x = data[\"x\"]\n         y = data[\"y\"]\n+        x = x.dropna()\n+        y = y.dropna()\n+        \n         if x.nunique() <= self.order:\n             # TODO warn?\n             xx = yy = []\n", "instance_id": "mwaskom__seaborn-3010"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..22f1e325d 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -277,6 +277,8 @@ class Node(metaclass=NodeMeta):\n         else:\n             raise ValueError(\"is not a string or pytest.mark.* Marker\")\n         self.keywords[marker_.name] = marker_\n+        if marker_.name == \"xfail\":\n+            self.keywords[\"xfail\"] = marker_\n         if append:\n             self.own_markers.append(marker_.mark)\n         else:\ndiff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex 69754ad5e..a5fcf6fe3 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -206,7 +206,17 @@ def call_and_report(\n ) -> TestReport:\n     call = call_runtest_hook(item, when, **kwds)\n     hook = item.ihook\n-    report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport\n+    if \"xfail\" in item.keywords:\n+        call.excinfo = None\n+        call.result = None\n+        call.when = \"call\"\n+        call.start = timing.time()\n+        call.stop = timing.time()\n+        call.duration = 0.0\n+        report = TestReport.from_item_and_call(item, call)\n+        report.wasxfail = item.keywords[\"xfail\"].kwargs.get(\"reason\", \"\")\n+    else:\n+        report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport\n     if log:\n         hook.pytest_runtest_logreport(report=report)\n     if check_interactive_exception(call, report):\n", "instance_id": "pytest-dev__pytest-7490"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..cefcb0afed 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -73,7 +73,15 @@ class DraggableLegend(DraggableOffsetBox):\n \n         super().__init__(legend, legend._legend_box, use_blit=use_blit)\n \n-    def finalize_offset(self):\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpickleable entries.\n+        del state['canvas']\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.canvas = self.ref_artist.figure.canvas\n         if self._update == \"loc\":\n             self._update_loc(self.get_loc_in_canvas())\n         elif self._update == \"bbox\":\ndiff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 1dee8a23d9..f83b0becab 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1571,13 +1571,29 @@ class DraggableBase:\n         else:\n             self.canvas.mpl_disconnect(c1)\n \n-    def save_offset(self):\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpickleable entries.\n+        del state['canvas']\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.canvas = self.ref_artist.figure.canvas\n         pass\n \n     def update_offset(self, dx, dy):\n         pass\n \n-    def finalize_offset(self):\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpickleable entries.\n+        del state['canvas']\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.canvas = self.ref_artist.figure.canvas\n         pass\n \n \n@@ -1586,7 +1602,15 @@ class DraggableOffsetBox(DraggableBase):\n         super().__init__(ref_artist, use_blit=use_blit)\n         self.offsetbox = offsetbox\n \n-    def save_offset(self):\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpickleable entries.\n+        del state['canvas']\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.canvas = self.ref_artist.figure.canvas\n         offsetbox = self.offsetbox\n         renderer = offsetbox.figure._get_renderer()\n         offset = offsetbox.get_offset(offsetbox.get_bbox(renderer), renderer)\n", "instance_id": "matplotlib__matplotlib-25311"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\nindex 24e453a73..2e6a329dd 100644\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -82,7 +82,7 @@ def _config_initialization(\n     if unrecognized_options:\n         msg = \", \".join(unrecognized_options)\n         linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+        raise _UnrecognizedOptionError(options=unrecognized_options) from None\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\ndiff --git a/pylint/lint/run.py b/pylint/lint/run.py\nindex 778e64441..f500dac18 100644\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -13,7 +13,7 @@ from typing import Any\n \n from pylint import config\n from pylint.config.config_initialization import _config_initialization\n-from pylint.config.exceptions import ArgumentPreprocessingError\n+from pylint.config.exceptions import ArgumentPreprocessingError, _UnrecognizedOptionError\n from pylint.config.utils import _preprocess_options\n from pylint.constants import full_version\n from pylint.lint.base_options import _make_run_options\n@@ -132,9 +132,14 @@ group are mutually exclusive.\",\n         linter.disable(\"I\")\n         linter.enable(\"c-extension-no-member\")\n \n-        args = _config_initialization(\n-            linter, args, reporter, config_file=self._rcfile, verbose_mode=self.verbose\n-        )\n+        try:\n+            args = _config_initialization(\n+                linter, args, reporter, config_file=self._rcfile, verbose_mode=self.verbose\n+            )\n+        except _UnrecognizedOptionError as ex:\n+            print(f\"Error: Unrecognized option(s) found: {', '.join(ex.options)}\", file=sys.stderr)\n+            print(\"Use --help to see available options.\", file=sys.stderr)\n+            sys.exit(32)\n \n         if linter.config.jobs < 0:\n             print(\n", "instance_id": "pylint-dev__pylint-6506"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 837dabfea8..252706d837 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -430,7 +430,7 @@ class AdminSite:\n                     return HttpResponsePermanentRedirect(path)\n         raise Http404\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -463,6 +463,7 @@ class AdminSite:\n             model_dict = {\n                 'name': capfirst(model._meta.verbose_name_plural),\n                 'object_name': model._meta.object_name,\n+                'model': model,\n                 'perms': perms,\n                 'admin_url': None,\n                 'add_url': None,\n@@ -503,7 +504,7 @@ class AdminSite:\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n \n         # Sort the apps alphabetically.\n         app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n@@ -534,7 +535,7 @@ class AdminSite:\n         return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n \n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n             raise Http404('The requested admin page does not exist.')\n         # Sort the models alphabetically within each app.\n", "instance_id": "django__django-13447"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..fe8a50fc43 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,12 +2180,12 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n-                pass\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x0 = np.nan\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n-            except (TypeError, IndexError, KeyError):\n+            except (TypeError, IndexError, KeyError, StopIteration):\n                 x = xconv\n \n             delist = False\n", "instance_id": "matplotlib__matplotlib-24149"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 0545797d5f..06a46eea20 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -825,9 +825,9 @@ def _print_MatAdd(self, expr):\n             if s is None:\n                 s = pform     # First element\n             else:\n-                if S(item.args[0]).is_negative:\n-                    s = prettyForm(*stringPict.next(s, ' '))\n-                    pform = self._print(item)\n+                if item.is_Mul and item.args[0].is_Number and item.args[0] < 0:\n+                    s = prettyForm(*stringPict.next(s, ' - '))\n+                    pform = self._print(-item)\n                 else:\n                     s = prettyForm(*stringPict.next(s, ' + '))\n                 s = prettyForm(*stringPict.next(s, pform))\n", "instance_id": "sympy__sympy-14817"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8ddbb5ba68..536b3dd601 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1309,7 +1309,7 @@ class ManyToManyField(RelatedField):\n                              \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n@@ -1329,7 +1329,7 @@ class ManyToManyField(RelatedField):\n                             \"through_fields keyword argument.\" % (self, to_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n", "instance_id": "django__django-12497"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/functions/combinatorial/numbers.py b/sympy/functions/combinatorial/numbers.py\nindex 896729ac87..8d1a758dc1 100644\n--- a/sympy/functions/combinatorial/numbers.py\n+++ b/sympy/functions/combinatorial/numbers.py\n@@ -9,7 +9,8 @@\n \n from __future__ import print_function, division\n \n-from sympy.core import S, Symbol, Rational, Integer, Add, Dummy\n+from sympy.core import S, Symbol, Rational, Integer, Add, Dummy, oo\n+from sympy.core.logic import fuzzy_not\n from sympy.core.compatibility import as_int, SYMPY_INTS, range\n from sympy.core.cache import cacheit\n from sympy.core.function import Function, expand_mul\n@@ -434,7 +435,7 @@ def _bell_incomplete_poly(n, k, symbols):\n \n     @classmethod\n     def eval(cls, n, k_sym=None, symbols=None):\n-        if n.is_Integer and n.is_nonnegative:\n+        if n.is_Integer and n.is_nonnegative or n is S.Infinity:\n             if k_sym is None:\n                 return Integer(cls._bell(int(n)))\n             elif symbols is None:\n@@ -443,6 +444,11 @@ def eval(cls, n, k_sym=None, symbols=None):\n                 r = cls._bell_incomplete_poly(int(n), int(k_sym), symbols)\n                 return r\n \n+    def _eval_as_leading_term(self, x):\n+        if self.args[0] is S.Infinity:\n+            return S.Infinity\n+        return super()._eval_as_leading_term(x)\n+\n     def _eval_rewrite_as_Sum(self, n, k_sym=None, symbols=None):\n         from sympy import Sum\n         if (k_sym is not None) or (symbols is not None):\n@@ -1051,6 +1057,7 @@ def _eval_is_negative(self):\n             return (n / 2).is_odd\n \n     def _eval_is_positive(self):\n+        from sympy.core.logic import fuzzy_not\n         n = self.args[0]\n         if n.is_integer and n.is_positive:\n             if n.is_odd:\n@@ -1065,6 +1072,7 @@ def _eval_is_even(self):\n             return (n - 1).is_positive\n \n     def _eval_is_odd(self):\n+        from sympy.core.logic import fuzzy_not\n         n = self.args[0]\n         if n.is_integer and n.is_positive:\n             if n.is_even:\n", "instance_id": "sympy__sympy-13437"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 11409e6f6..8ba18e65c 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -318,8 +318,10 @@ class GoogleDocstring:\n             return [line[min_indent:] for line in lines]\n \n     def _escape_args_and_kwargs(self, name: str) -> str:\n-        if name.endswith('_'):\n-            name = name[:-1] + r'\\_'\n+        if name.endswith('_') and not name.endswith('__'):\n+            name = name[:-1] + '_'\n+        elif name.endswith('__'):\n+            name = name[:-2] + r'\\_\\_'\n \n         if name[:2] == '**':\n             return r'\\*\\*' + name[2:]\n", "instance_id": "sphinx-doc__sphinx-7738"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..d8795d8218 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -309,7 +309,9 @@ class HttpResponse(HttpResponseBase):\n     @content.setter\n     def content(self, value):\n         # Consume iterators upon assignment to allow repeated iteration.\n-        if hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n+        if isinstance(value, memoryview):\n+            content = self.make_bytes(value.tobytes())\n+        elif hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n             content = b''.join(self.make_bytes(chunk) for chunk in value)\n             if hasattr(value, 'close'):\n                 try:\n", "instance_id": "django__django-11133"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 5f5eab3b9d..7e2c623cae 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -104,7 +104,7 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n-    expr = sympify(expr)\n+    expr = sympify(expr, evaluate=False)\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n     else:\n@@ -397,7 +397,7 @@ def signsimp(expr, evaluate=None):\n     \"\"\"\n     if evaluate is None:\n         evaluate = global_parameters.evaluate\n-    expr = sympify(expr)\n+    expr = sympify(expr, evaluate=evaluate)\n     if not isinstance(expr, (Expr, Relational)) or expr.is_Atom:\n         return expr\n     e = sub_post(sub_pre(expr))\n", "instance_id": "sympy__sympy-20322"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..8b9da17e31 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -38,6 +38,7 @@ def _multi_decorate(decorators, method):\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n         bound_method = partial(method.__get__(self, type(self)))\n+        update_wrapper(bound_method, method)\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n", "instance_id": "django__django-14787"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autosummary/__init__.py b/sphinx/ext/autosummary/__init__.py\nindex 0cdd88feb..2285093d4 100644\n--- a/sphinx/ext/autosummary/__init__.py\n+++ b/sphinx/ext/autosummary/__init__.py\n@@ -292,6 +292,8 @@ class Autosummary(SphinxDirective):\n \n         max_item_chars = 50\n \n+        imported_members = self.config.autosummary_imported_members\n+\n         for name in names:\n             display_name = name\n             if name.startswith('~'):\n@@ -305,6 +307,10 @@ class Autosummary(SphinxDirective):\n                 logger.warning(__('autosummary: failed to import %s'), name)\n                 continue\n \n+            # Skip imported members if autosummary_imported_members is False\n+            if not imported_members and modname != self.env.ref_context.get('py:module'):\n+                continue\n+\n             self.bridge.result = StringList()  # initialize for each documenter\n             full_name = real_name\n             if not isinstance(obj, ModuleType):\n@@ -508,6 +514,9 @@ def extract_summary(doc: List[str], document: Any) -> str:\n             doc = doc[:i]\n             break\n \n+    if not doc:\n+        return ''\n+\n     if doc == []:\n         return ''\n \n@@ -759,18 +768,20 @@ def process_generate_options(app: Sphinx) -> None:\n def setup(app: Sphinx) -> Dict[str, Any]:\n     # I need autodoc\n     app.setup_extension('sphinx.ext.autodoc')\n-    app.add_node(autosummary_toc,\n-                 html=(autosummary_toc_visit_html, autosummary_noop),\n-                 latex=(autosummary_noop, autosummary_noop),\n-                 text=(autosummary_noop, autosummary_noop),\n-                 man=(autosummary_noop, autosummary_noop),\n-                 texinfo=(autosummary_noop, autosummary_noop))\n-    app.add_node(autosummary_table,\n-                 html=(autosummary_table_visit_html, autosummary_noop),\n-                 latex=(autosummary_noop, autosummary_noop),\n-                 text=(autosummary_noop, autosummary_noop),\n-                 man=(autosummary_noop, autosummary_noop),\n-                 texinfo=(autosummary_noop, autosummary_noop))\n+    if not app.registry.has_node(autosummary_toc):\n+        app.add_node(autosummary_toc,\n+                     html=(autosummary_toc_visit_html, autosummary_noop),\n+                     latex=(autosummary_noop, autosummary_noop),\n+                     text=(autosummary_noop, autosummary_noop),\n+                     man=(autosummary_noop, autosummary_noop),\n+                     texinfo=(autosummary_noop, autosummary_noop))\n+    if not app.registry.has_node(autosummary_table):\n+        app.add_node(autosummary_table,\n+                     html=(autosummary_table_visit_html, autosummary_noop),\n+                     latex=(autosummary_noop, autosummary_noop),\n+                     text=(autosummary_noop, autosummary_noop),\n+                     man=(autosummary_noop, autosummary_noop),\n+                     texinfo=(autosummary_noop, autosummary_noop))\n     app.add_directive('autosummary', Autosummary)\n     app.add_role('autolink', AutoLink())\n     app.connect('builder-inited', process_generate_options)\n", "instance_id": "sphinx-doc__sphinx-7686"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 1aa0ee01a2..881a8a8253 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -391,6 +391,26 @@ def translate(s):\n     _print_MatrixSymbol = _print_Symbol\n     _print_RandomSymbol = _print_Symbol\n \n+    def _print_Indexed(self, expr):\n+        x = self.dom.createElement('apply')\n+        x.appendChild(self.dom.createElement('ci'))\n+        x.appendChild(self._print(expr.base))\n+        for index in expr.indices:\n+            x.appendChild(self._print(index))\n+        return x\n+\n+    def _print_Indexed(self, expr):\n+        mrow = self.dom.createElement('mrow')\n+        base = self._print(expr.base)\n+        subscript = self.dom.createElement('msub')\n+        subscript.appendChild(base)\n+        indices = self.dom.createElement('mrow')\n+        for index in expr.indices:\n+            indices.appendChild(self._print(index))\n+        subscript.appendChild(indices)\n+        mrow.appendChild(subscript)\n+        return mrow\n+\n     def _print_Pow(self, e):\n         # Here we use root instead of power if the exponent is the reciprocal of an integer\n         if self._settings['root_notation'] and e.exp.is_Rational and e.exp.p == 1:\n@@ -1043,8 +1063,8 @@ def _print_Interval(self, i):\n                 brac.setAttribute('close', ')')\n             else:\n                 brac.setAttribute('close', ']')\n-            brac.appendChild( self._print(i.start))\n-            brac.appendChild( self._print(i.end))\n+            brac.appendChild(self._print(i.start))\n+            brac.appendChild(self._print(i.end))\n \n         mrow.appendChild(brac)\n         return mrow\n", "instance_id": "sympy__sympy-16106"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d0bc97be80..a0107ec389 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -59,7 +59,7 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=DjangoJSONEncoder):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -67,7 +67,7 @@ def json_script(value, element_id=None):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n \n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n", "instance_id": "django__django-15789"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 6d3cc05bd3..eed5eb593b 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -490,10 +490,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 2 - 2\n             sign_lines = []\n             sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n@@ -519,7 +519,7 @@ def _print_Product(self, expr):\n             padding = prettyForm(*padding.stack(*[' ']*(height - 1)))\n             pretty_sign = prettyForm(*pretty_sign.right(padding))\n \n-            pretty_func = prettyForm(*pretty_sign.right(pretty_func))\n+            pretty_func = prettyForm(*pretty_sign.right(pretty_sign))\n \n         pretty_func.baseline = max_upper + sign_height//2\n         pretty_func.binding = prettyForm.MUL\n", "instance_id": "sympy__sympy-16281"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex 5e6a400b6c..0e3c6e91f3 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -41,9 +41,11 @@ def lookup_spawns_duplicates(opts, lookup_path):\n             field_name = opts.pk.name\n         try:\n             field = opts.get_field(field_name)\n-        except FieldDoesNotExist:\n+        except FieldDoesNotExist as e:\n             # Ignore query lookups.\n-            continue\n+            e.field_name = field_name\n+            e.model = opts.model\n+            raise e\n         else:\n             if hasattr(field, \"path_infos\"):\n                 # This field is a relation; update opts to follow the relation.\n@@ -353,7 +355,7 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n         except AttributeError:\n             # field is likely a ForeignObjectRel\n             label = field.related_model._meta.verbose_name\n-    except FieldDoesNotExist:\n+    except FieldDoesNotExist as e:\n         if name == \"__str__\":\n             label = str(model._meta.verbose_name)\n             attr = str\n@@ -375,7 +377,7 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n                     message += \" or %s\" % model_admin.__class__.__name__\n                 if form:\n                     message += \" or %s\" % form.__class__.__name__\n-                raise AttributeError(message)\n+                raise AttributeError(message) from e\n \n             if hasattr(attr, \"short_description\"):\n                 label = attr.short_description\ndiff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex 2a2288ff4d..b11eda475d 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -9,7 +9,15 @@ from django.utils.hashable import make_hashable\n class FieldDoesNotExist(Exception):\n     \"\"\"The requested model field does not exist\"\"\"\n \n-    pass\n+    def __init__(self, field_name=None, model=None):\n+        self.field_name = field_name\n+        self.model = model\n+        super().__init__(self.__str__())\n+\n+    def __str__(self):\n+        if self.field_name and self.model:\n+            return f\"The field '{self.field_name}' does not exist on the model '{self.model.__name__}'\"\n+        return \"The requested model field does not exist\"\n \n \n class AppRegistryNotReady(Exception):\n", "instance_id": "django__django-16816"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 8e55bd092d..a534e33757 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1017,10 +1017,11 @@ class Query(BaseExpression):\n         clone.bump_prefix(query)\n         clone.subquery = True\n         # It's safe to drop ordering if the queryset isn't using slicing,\n-        # distinct(*fields) or select_for_update().\n+        # distinct(*fields), select_for_update(), or group_by.\n         if (self.low_mark == 0 and self.high_mark is None and\n                 not self.distinct_fields and\n-                not self.select_for_update):\n+                not self.select_for_update and\n+                not self.group_by):\n             clone.clear_ordering(True)\n         clone.where.resolve_expression(query, *args, **kwargs)\n         for key, value in clone.annotations.items():\n", "instance_id": "django__django-11797"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/geometry/util.py b/sympy/geometry/util.py\nindex d32adc3066..f996f0d2f7 100644\n--- a/sympy/geometry/util.py\n+++ b/sympy/geometry/util.py\n@@ -17,6 +17,7 @@\n     is_sequence, range, string_types, ordered)\n from sympy.core.containers import OrderedSet\n from .point import Point, Point2D\n+from .entity import GeometryEntity\n \n \n def find(x, equation):\n@@ -285,6 +286,7 @@ def closest_points(*args):\n     \"\"\"\n     from collections import deque\n     from math import hypot, sqrt as _sqrt\n+from sympy.functions.elementary.miscellaneous import sqrt\n     from sympy.functions.elementary.miscellaneous import sqrt\n \n     p = [Point2D(i) for i in set(args)]\n@@ -565,21 +567,29 @@ def idiff(eq, y, x, n=1):\n     sympy.core.function.diff: explicitly differentiates wrt symbols\n \n     \"\"\"\n+    from sympy import Eq\n+\n+    if isinstance(eq, Eq):\n+        eq = eq.lhs - eq.rhs\n+\n     if is_sequence(y):\n         dep = set(y)\n         y = y[0]\n-    elif isinstance(y, Symbol):\n+    elif isinstance(y, (Symbol, Function)):\n         dep = {y}\n     else:\n         raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\n \n     f = dict([(s, Function(\n         s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n-    dydx = Function(y.name)(x).diff(x)\n+    dydx = y.diff(x) if isinstance(y, Function) else Function(y.name)(x).diff(x)\n     eq = eq.subs(f)\n     derivs = {}\n     for i in range(n):\n-        yp = solve(eq.diff(x), dydx)[0].subs(derivs)\n+        yp = solve(eq.diff(x), dydx)\n+        if not yp:\n+            raise ValueError(\"No solution found for the derivative.\")\n+        yp = yp[0].subs(derivs)\n         if i == n - 1:\n             return yp.subs([(v, k) for k, v in f.items()])\n         derivs[dydx] = yp\n", "instance_id": "sympy__sympy-15678"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-12184"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "sphinx-doc__sphinx-8506"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 978fd5df8..fc93ed1a3 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1266,6 +1266,9 @@ class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # typ\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    kwargs.setdefault('show_annotation', False)\n+\n                 sig = stringify_signature(overload, **kwargs)\n                 sigs.append(sig)\n \n@@ -1910,6 +1913,9 @@ class MethodDocumenter(DocstringSignatureMixin, ClassLevelDocumenter):  # type:\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    kwargs.setdefault('show_annotation', False)\n+\n                 if not inspect.isstaticmethod(self.object, cls=self.parent,\n                                               name=self.object_name):\n                     parameters = list(overload.parameters.values())\n", "instance_id": "sphinx-doc__sphinx-8282"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..1b444a3142 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,8 +586,8 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n-    _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n+    _literal = r\"[\\w][\\w\\d]*\"\n+    _number = r\"(?:[\\d]+(?:\\.[\\d]*)?|\\.[\\d]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n     _enclosure_close = [\")\", \"]\", \"]]\", \"}\"]\n@@ -607,6 +607,8 @@ def _get_tokenizer(self):\n             # Check if the regular expression has already been compiled:\n             return self._regex_tokenizer\n         tokens = [self._literal, self._number]\n+        print(f\"Token patterns: {tokens}\")\n+        print(f\"Token patterns: {tokens}\")\n         tokens_escape = self._enclosure_open[:] + self._enclosure_close[:]\n         for typ, strat, symdict in self._mathematica_op_precedence:\n             for k in symdict:\n@@ -656,6 +658,8 @@ def _from_mathematica_to_tokens(self, code: str):\n         # Tokenize the input strings with a regular expression:\n         token_lists = [tokenizer.findall(i) if isinstance(i, str) else [i] for i in code_splits]\n         tokens = [j for i in token_lists for j in i]\n+        print(f\"Tokens: {tokens}\")\n+        print(f\"Tokens: {tokens}\")\n \n         # Remove newlines at the beginning\n         while tokens and tokens[0] == \"\\n\":\n@@ -664,6 +668,8 @@ def _from_mathematica_to_tokens(self, code: str):\n         while tokens and tokens[-1] == \"\\n\":\n             tokens.pop(-1)\n \n+        print(f\"Final tokens: {tokens}\")\n+        print(f\"Final tokens: {tokens}\")\n         return tokens\n \n     def _is_op(self, token: tUnion[str, list]) -> bool:\n", "instance_id": "sympy__sympy-24102"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 9e1be0fe0f..76b4f920e8 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -331,6 +331,11 @@ class LazyObject:\n             self._setup()\n         return (unpickle_lazyobject, (self._wrapped,))\n \n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n     def __copy__(self):\n         if self._wrapped is empty:\n             # If uninitialized, copy the wrapper. Use type(self), not\n", "instance_id": "django__django-15400"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/dispatch/dispatcher.py b/django/dispatch/dispatcher.py\nindex b7d9d26389..1e58315dfc 100644\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,10 +1,13 @@\n import threading\n import warnings\n import weakref\n+import logging\n \n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.inspect import func_accepts_kwargs\n \n+logger = logging.getLogger(__name__)\n+\n \n def _make_id(target):\n     if hasattr(target, '__func__'):\n@@ -141,8 +144,7 @@ class Signal:\n         disconnected = False\n         with self.lock:\n             self._clear_dead_receivers()\n-            for index in range(len(self.receivers)):\n-                (r_key, _) = self.receivers[index]\n+            for index, (r_key, _) in enumerate(self.receivers):\n                 if r_key == lookup_key:\n                     disconnected = True\n                     del self.receivers[index]\n@@ -205,12 +207,12 @@ class Signal:\n         # Return a list of tuple pairs [(receiver, response), ... ].\n         responses = []\n         for receiver in self._live_receivers(sender):\n+            response = None\n             try:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n                 responses.append((receiver, err))\n-            else:\n-                responses.append((receiver, response))\n+                logger.exception('Error in signal handler for %s', receiver)\n         return responses\n \n     def _clear_dead_receivers(self):\n", "instance_id": "django__django-13768"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/src/flask/config.py b/src/flask/config.py\nindex d4fc310f..1de8099b 100644\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -178,6 +178,7 @@ class Config(dict):\n            `silent` parameter.\n         \"\"\"\n         filename = os.path.join(self.root_path, filename)\n+        mode = \"r\" if mode is None else mode\n         d = types.ModuleType(\"config\")\n         d.__file__ = filename\n         try:\n@@ -253,6 +254,7 @@ class Config(dict):\n             mapping of loaded data from the file.\n         :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n             implements a ``read`` method.\n+        :param mode: The mode in which to open the file. Defaults to \"r\".\n         :param silent: Ignore the file if it doesn't exist.\n         :return: ``True`` if the file was loaded successfully.\n \n@@ -261,7 +263,7 @@ class Config(dict):\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, mode=mode) as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n", "instance_id": "pallets__flask-4992"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 6f10e31cd5..cc7ba3cdb8 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -772,8 +772,11 @@ class BaseDatabaseOperations:\n             raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))\n         return self.explain_prefix\n \n-    def insert_statement(self, on_conflict=None):\n-        return \"INSERT INTO\"\n+    def insert_statement(self, table, returning_fields=None, on_conflict=None):\n+        if returning_fields:\n+            return \"INSERT INTO %s RETURNING %s\" % (self.quote_name(table), \", \".join(self.quote_name(field.column) for field in returning_fields))\n+        else:\n+            return \"INSERT INTO\"\n \n     def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):\n         return \"\"\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 5ac2407ea3..cddfcd970f 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -720,6 +720,8 @@ class QuerySet(AltersData):\n                         \"bulk_create() can only be used with concrete fields \"\n                         \"in unique_fields.\"\n                     )\n+                returning_fields=self.model._meta.db_returning_fields,\n+                    )\n             return OnConflict.UPDATE\n         return None\n \n@@ -1837,7 +1839,7 @@ class QuerySet(AltersData):\n         inserted_rows = []\n         bulk_return = connection.features.can_return_rows_from_bulk_insert\n         for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n-            if bulk_return and on_conflict is None:\n+            if bulk_return and (on_conflict is None or on_conflict == OnConflict.UPDATE):\n                 inserted_rows.extend(\n                     self._insert(\n                         item,\n", "instance_id": "django__django-17051"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 397146a354..8ac2fdbb69 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -416,7 +416,11 @@ class RelatedField(FieldCacheMixin, Field):\n                 'limit_choices_to': limit_choices_to,\n             })\n         defaults.update(kwargs)\n-        return super().formfield(**defaults)\n+        form_field = super().formfield(**defaults)\n+        # Ensure the queryset is distinct to avoid duplicate options.\n+        if hasattr(form_field, 'queryset'):\n+            form_field.queryset = form_field.queryset.distinct()\n+        return form_field\n \n     def related_query_name(self):\n         \"\"\"\n@@ -981,18 +985,26 @@ class ForeignKey(ForeignObject):\n         if self.remote_field.field_name is None:\n             self.remote_field.field_name = cls._meta.pk.name\n \n+        # Ensure the queryset is distinct to avoid duplicate options.\n+        if hasattr(form_field, 'queryset'):\n+            form_field.queryset = form_field.queryset.distinct()\n+        return form_field\n+\n     def formfield(self, *, using=None, **kwargs):\n         if isinstance(self.remote_field.model, str):\n             raise ValueError(\"Cannot create form field for %r yet, because \"\n                              \"its related model %r has not been loaded yet\" %\n                              (self.name, self.remote_field.model))\n-        return super().formfield(**{\n+        form_field = super().formfield(**{\n             'form_class': forms.ModelChoiceField,\n             'queryset': self.remote_field.model._default_manager.using(using),\n             'to_field_name': self.remote_field.field_name,\n             **kwargs,\n             'blank': self.blank,\n         })\n+        # Ensure the queryset is distinct to avoid duplicate options.\n+        if hasattr(form_field, 'queryset'):\n+            form_field.queryset = form_field.queryset.distinct()\n \n     def db_check(self, connection):\n         return []\n@@ -1682,7 +1694,11 @@ class ManyToManyField(RelatedField):\n             if callable(initial):\n                 initial = initial()\n             defaults['initial'] = [i.pk for i in initial]\n-        return super().formfield(**defaults)\n+        form_field = super().formfield(**defaults)\n+        # Ensure the queryset is distinct to avoid duplicate options.\n+        if hasattr(form_field, 'queryset'):\n+            form_field.queryset = form_field.queryset.distinct()\n+        return form_field\n \n     def db_check(self, connection):\n         return None\n", "instance_id": "django__django-13315"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..a1f3316f6b 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -60,15 +60,22 @@ class Q(tree.Node):\n \n     def __or__(self, other):\n         return self._combine(other, self.OR)\n+        return self._combine(other, self.OR)\n+        return self._combine(other, self.OR)\n \n     def __and__(self, other):\n         return self._combine(other, self.AND)\n+        return self._combine(other, self.AND)\n+        return self._combine(other, self.AND)\n \n-    def __invert__(self):\n-        obj = type(self)()\n-        obj.add(self, self.AND)\n-        obj.negate()\n-        return obj\n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n+\n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n+\n+    def __ror__(self, other):\n+        return self._combine(other, self.OR)\n \n     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n         # We must promote any new joins to left outer joins so that when Q is\n", "instance_id": "django__django-14017"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..d29fd75fd 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1280,6 +1280,8 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n+            # Align indices before concatenation\n+            Xs = [X.reindex(Xs[0].index) for X in Xs]\n             return pd.concat(Xs, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n", "instance_id": "scikit-learn__scikit-learn-25747"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py\nindex f209e811f1..ea88b679b1 100644\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -665,8 +665,9 @@ grestore\n                 curr_stream[1].append(\n                     (item.x, item.ft_object.get_glyph_name(item.glyph_idx))\n                 )\n-            # append the last entry\n-            stream.append(curr_stream)\n+            # append the last entry if curr_stream is not None\n+            if curr_stream:\n+                stream.append(curr_stream)\n \n         self.set_color(*gc.get_rgb())\n \n", "instance_id": "matplotlib__matplotlib-23964"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..f2490067b3 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -303,11 +303,11 @@ def _separable(transform):\n     \"\"\"\n     if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n         return transform_matrix\n-    elif isinstance(transform, CompoundModel):\n-        sepleft = _separable(transform.left)\n-        sepright = _separable(transform.right)\n-        return _operators[transform.op](sepleft, sepright)\n-    elif isinstance(transform, Model):\n+    if isinstance(transform, CompoundModel):\n+        left_separable = _separable(transform.left)\n+        right_separable = _separable(transform.right)\n+        return _operators[transform.op](left_separable, right_separable)\n+    else:\n         return _coord_matrix(transform, 'left', transform.n_outputs)\n \n \n", "instance_id": "astropy__astropy-12907"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex ba3b62620d..faf15b40e8 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -139,7 +139,10 @@ class HashedFilesMixin:\n                 urlparts[2] += '?'\n             final_url = urlunsplit(urlparts)\n \n-        return unquote(final_url)\n+        from django.utils.functional import SimpleLazyObject\n+        request = SimpleLazyObject(lambda: getattr(self, '_request', None))\n+        script_name = getattr(request, 'META', {}).get('SCRIPT_NAME', '')\n+        return unquote(script_name + final_url)\n \n     def url(self, name, force=False):\n         \"\"\"\ndiff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 4c27fce605..6ed30e736d 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -332,7 +332,10 @@ class FileSystemStorage(Storage):\n         url = filepath_to_uri(name)\n         if url is not None:\n             url = url.lstrip('/')\n-        return urljoin(self.base_url, url)\n+        from django.utils.functional import SimpleLazyObject\n+        request = SimpleLazyObject(lambda: getattr(self, '_request', None))\n+        script_name = getattr(request, 'META', {}).get('SCRIPT_NAME', '')\n+        return urljoin(script_name + self.base_url, url)\n \n     def _datetime_from_timestamp(self, ts):\n         \"\"\"\ndiff --git a/django/templatetags/static.py b/django/templatetags/static.py\nindex 39712aaba0..46d6f2800e 100644\n--- a/django/templatetags/static.py\n+++ b/django/templatetags/static.py\n@@ -100,7 +100,10 @@ class StaticNode(template.Node):\n \n     def url(self, context):\n         path = self.path.resolve(context)\n-        return self.handle_simple(path)\n+        from django.utils.functional import SimpleLazyObject\n+        request = SimpleLazyObject(lambda: context.get('request', None))\n+        script_name = getattr(request, 'META', {}).get('SCRIPT_NAME', '')\n+        return script_name + self.handle_simple(path)\n \n     def render(self, context):\n         url = self.url(context)\n", "instance_id": "django__django-11564"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/_pylab_helpers.py b/lib/matplotlib/_pylab_helpers.py\nindex 24fcb81fc9..8805a0797f 100644\n--- a/lib/matplotlib/_pylab_helpers.py\n+++ b/lib/matplotlib/_pylab_helpers.py\n@@ -62,14 +62,15 @@ class Gcf:\n                 manager = cls.figs.pop(num)\n             except KeyError:\n                 return\n-        if hasattr(manager, \"_cidgcf\"):\n-            manager.canvas.mpl_disconnect(manager._cidgcf)\n-        manager.destroy()\n-        del manager, num\n-        # Full cyclic garbage collection may be too expensive to do on every\n-        # figure destruction, so we collect only the youngest two generations.\n-        # see: https://github.com/matplotlib/matplotlib/pull/3045\n-        gc.collect(1)\n+        if manager is not None:\n+            if hasattr(manager, \"_cidgcf\"):\n+                manager.canvas.mpl_disconnect(manager._cidgcf)\n+            manager.destroy()\n+            del manager, num\n+            # Full cyclic garbage collection may be too expensive to do on every\n+            # figure destruction, so we collect only the youngest two generations.\n+            # see: https://github.com/matplotlib/matplotlib/pull/3045\n+            gc.collect(1)\n \n     @classmethod\n     def destroy_fig(cls, fig):\ndiff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..02caae4daa 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -206,7 +206,7 @@ def _get_backend_mod():\n     return _backend_mod\n \n \n-def switch_backend(newbackend):\n+def switch_backend(newbackend, keep_figures=True):\n     \"\"\"\n     Close all open figures and set the Matplotlib backend.\n \n@@ -222,7 +222,8 @@ def switch_backend(newbackend):\n     global _backend_mod\n     # make sure the init is pulled up so we can assign to it later\n     import matplotlib.backends\n-    close(\"all\")\n+    if not keep_figures:\n+        close(\"all\")\n \n     if newbackend is rcsetup._auto_backend_sentinel:\n         current_framework = cbook._get_running_interactive_framework()\n@@ -247,7 +248,7 @@ def switch_backend(newbackend):\n         # are of worse quality.\n         for candidate in candidates:\n             try:\n-                switch_backend(candidate)\n+                switch_backend(candidate, keep_figures=False)\n             except ImportError:\n                 continue\n             else:\n@@ -256,7 +257,7 @@ def switch_backend(newbackend):\n         else:\n             # Switching to Agg should always succeed; if it doesn't, let the\n             # exception propagate out.\n-            switch_backend(\"agg\")\n+            switch_backend(\"agg\", keep_figures=False)\n             rcParamsOrig[\"backend\"] = \"agg\"\n             return\n \n@@ -274,6 +275,9 @@ def switch_backend(newbackend):\n                 \"framework, as {!r} is currently running\".format(\n                     newbackend, required_framework, current_framework))\n \n+    # Save current figures\n+    current_figures = Gcf.figs.copy()\n+\n     # Load the new_figure_manager(), draw_if_interactive(), and show()\n     # functions from the backend.\n \n@@ -317,6 +321,9 @@ def switch_backend(newbackend):\n     # See https://github.com/matplotlib/matplotlib/issues/6092\n     matplotlib.backends.backend = newbackend\n \n+    # Restore figures\n+    Gcf.figs.update(current_figures)\n+\n     # make sure the repl display hook is installed in case we become\n     # interactive\n     install_repl_displayhook()\n", "instance_id": "matplotlib__matplotlib-23299"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "django__django-14580"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 7ca0d68fae..d6f49647f4 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -1,4 +1,5 @@\n import functools\n+from pathlib import Path\n import itertools\n import logging\n import os\n@@ -580,6 +581,8 @@ def run_with_reloader(main_func, *args, **kwargs):\n         if os.environ.get(DJANGO_AUTORELOAD_ENV) == 'true':\n             reloader = get_reloader()\n             logger.info('Watching for file changes with %s', reloader.__class__.__name__)\n+            # Explicitly watch manage.py\n+            reloader.watch_file(Path(sys.argv[0]).resolve())\n             start_django(reloader, main_func, *args, **kwargs)\n         else:\n             exit_code = restart_with_reloader()\n", "instance_id": "django__django-11422"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "sympy__sympy-16503"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 841cbbfe..56a5152a 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -29,7 +29,7 @@ from .packages.urllib3.exceptions import SSLError as _SSLError\n from .packages.urllib3.exceptions import ResponseError\n from .cookies import extract_cookies_to_jar\n from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n-                         ProxyError, RetryError)\n+                         ProxyError, RetryError, DecodeError, TimeoutError)\n from .auth import _basic_auth_str\n \n DEFAULT_POOLBLOCK = False\n@@ -424,7 +424,11 @@ class HTTPAdapter(BaseAdapter):\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n-        except (_SSLError, _HTTPError) as e:\n+        except (BaseDecodeError, BaseTimeoutError, _SSLError, _HTTPError) as e:\n+            if isinstance(e, BaseDecodeError):\n+                raise DecodeError(e, request=request)\n+            elif isinstance(e, BaseTimeoutError):\n+                raise TimeoutError(e, request=request)\n             if isinstance(e, _SSLError):\n                 raise SSLError(e, request=request)\n             elif isinstance(e, ReadTimeoutError):\ndiff --git a/requests/exceptions.py b/requests/exceptions.py\nindex 89135a80..1618151f 100644\n--- a/requests/exceptions.py\n+++ b/requests/exceptions.py\n@@ -7,7 +7,7 @@ requests.exceptions\n This module contains the set of Requests' exceptions.\n \n \"\"\"\n-from .packages.urllib3.exceptions import HTTPError as BaseHTTPError\n+from .packages.urllib3.exceptions import HTTPError as BaseHTTPError, DecodeError as BaseDecodeError, TimeoutError as BaseTimeoutError\n \n \n class RequestException(IOError):\n@@ -91,6 +91,12 @@ class ContentDecodingError(RequestException, BaseHTTPError):\n     \"\"\"Failed to decode response content\"\"\"\n \n \n+class DecodeError(RequestException, BaseDecodeError):\n+    \"\"\"Failed to decode response content\"\"\"\n+\n+class TimeoutError(RequestException, BaseTimeoutError):\n+    \"\"\"The request timed out while waiting for a response from the server\"\"\"\n+\n class StreamConsumedError(RequestException, TypeError):\n     \"\"\"The content for this response was already consumed\"\"\"\n \n", "instance_id": "psf__requests-2674"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..7001705905 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -186,7 +186,10 @@ class FigureBase(Artist):\n         # groupers to keep track of x and y labels we want to align.\n         # see self.align_xlabels and self.align_ylabels and\n         # axis._get_tick_boxes_siblings\n-        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        self._align_label_groups = {\n+            \"x\": cbook.Grouper(pickleable=True),\n+            \"y\": cbook.Grouper(pickleable=True)\n+        }\n \n         self.figure = self\n         self._localaxes = []  # track all axes\n@@ -1453,29 +1456,22 @@ default: %(va)s\n                         # grouper for groups of ylabels to align\n                         self._align_label_groups['y'].join(ax, axc)\n \n-    def align_labels(self, axs=None):\n-        \"\"\"\n-        Align the xlabels and ylabels of subplots with the same subplots\n-        row or column (respectively) if label alignment is being\n-        done automatically (i.e. the label position is not manually set).\n-\n-        Alignment persists for draw events after this is called.\n-\n-        Parameters\n-        ----------\n-        axs : list of `~matplotlib.axes.Axes`\n-            Optional list (or `~numpy.ndarray`) of `~matplotlib.axes.Axes`\n-            to align the labels.\n-            Default is to align all Axes on the figure.\n-\n-        See Also\n-        --------\n-        matplotlib.figure.Figure.align_xlabels\n+    def __getstate__(self):\n+        state = super().__getstate__()\n+        state['_align_label_groups'] = {\n+            \"x\": self._align_label_groups[\"x\"].__getstate__(),\n+            \"y\": self._align_label_groups[\"y\"].__getstate__()\n+        }\n+        return state\n \n-        matplotlib.figure.Figure.align_ylabels\n-        \"\"\"\n-        self.align_xlabels(axs=axs)\n-        self.align_ylabels(axs=axs)\n+    def __setstate__(self, state):\n+        super().__setstate__(state)\n+        self._align_label_groups = {\n+            \"x\": cbook.Grouper(pickleable=True),\n+            \"y\": cbook.Grouper(pickleable=True)\n+        }\n+        self._align_label_groups[\"x\"].__setstate__(state['_align_label_groups'][\"x\"])\n+        self._align_label_groups[\"y\"].__setstate__(state['_align_label_groups'][\"y\"])\n \n     def add_gridspec(self, nrows=1, ncols=1, **kwargs):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-25332"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..f1df3d5acc 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1164,6 +1164,9 @@ class Query(BaseExpression):\n                 return\n \n         lookup = lookup_class(lhs, rhs)\n+        # Ensure '__isnull' lookup uses a boolean value.\n+        if lookup_name == 'isnull' and not isinstance(lookup.rhs, bool):\n+            raise ValueError(\"The '__isnull' lookup only accepts boolean values.\")\n         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all\n         # uses of None as a query value unless the lookup supports it.\n         if lookup.rhs is None and not lookup.can_use_none_as_rhs:\n", "instance_id": "django__django-11905"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..ad5a42f875 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -919,7 +919,10 @@ class QuerySet:\n     def none(self):\n         \"\"\"Return an empty QuerySet.\"\"\"\n         clone = self._chain()\n-        clone.query.set_empty()\n+        if self.query.combinator:\n+            clone.query = self.model._base_manager.none().query\n+        else:\n+            clone.query.set_empty()\n         return clone\n \n     ##################################################################\n", "instance_id": "django__django-13158"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 02ec6480cb..d800db7406 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -426,6 +426,8 @@ def _eval_is_positive(self):\n                 return True\n             if self.exp.is_odd:\n                 return False\n+            if self.exp.is_real:\n+                return False\n         elif self.base.is_nonpositive:\n             if self.exp.is_odd:\n                 return False\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..059f867422 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -536,6 +536,14 @@ def simplify(expr, ratio=1.7, measure=count_ops, rational=False):\n         return expr.func(*[simplify(x, ratio=ratio, measure=measure, rational=rational)\n                          for x in expr.args])\n \n+    if expr.has(Pow):\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Pow) and p.base.is_negative and p.exp.is_integer,\n+            lambda p: (-1)**p.exp * (-p.base)**p.exp)\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Mul) and any(isinstance(arg, Pow) and arg.base.is_negative for arg in p.args),\n+            lambda p: Mul(*[(-1)**arg.exp if isinstance(arg, Pow) and arg.base.is_negative else arg for arg in p.args]))\n+\n     # TODO: Apply different strategies, considering expression pattern:\n     # is it a purely rational function? Is there any trigonometric function?...\n     # See also https://github.com/sympy/sympy/pull/185.\n", "instance_id": "sympy__sympy-14024"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/assumptions/assume.py b/sympy/assumptions/assume.py\nindex 4c2aa41120..02a5a05d3e 100644\n--- a/sympy/assumptions/assume.py\n+++ b/sympy/assumptions/assume.py\n@@ -5,6 +5,9 @@\n from sympy.core.assumptions import ManagedProperties\n from sympy.core.symbol import Str\n from sympy.core.sympify import _sympify\n+from sympy.core.function import Function\n+from sympy.core.numbers import I\n+from sympy.functions.elementary.complexes import Abs, arg\n from sympy.logic.boolalg import Boolean, false, true\n from sympy.multipledispatch.dispatcher import Dispatcher, str_signature\n from sympy.utilities.exceptions import SymPyDeprecationWarning\n@@ -236,6 +239,14 @@ def __doc__(cls):\n \n \n class Predicate(Boolean, metaclass=PredicateMeta):\n+    def _eval_refine(self, assumptions):\n+        if self == Abs:\n+            if ask(Q.positive(self.args[0]), assumptions):\n+                return self.args[0]\n+        elif self == arg:\n+            if ask(Q.positive(self.args[0]), assumptions):\n+                return S.Zero\n+        return self\n     \"\"\"\n     Base class for mathematical predicates. It also serves as a\n     constructor for undefined predicate objects.\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 707046aee0..bbf26d36b1 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -2,7 +2,7 @@\n \n from sympy.core import (Basic, S, Add, Mul, Pow, Symbol, sympify,\n                         expand_func, Function, Dummy, Expr, factor_terms,\n-                        expand_power_exp, Eq)\n+                        expand_power_exp, Eq, Abs, arg)\n from sympy.core.compatibility import iterable, ordered, as_int\n from sympy.core.parameters import global_parameters\n from sympy.core.function import (expand_log, count_ops, _mexpand, _coeff_isneg,\n", "instance_id": "sympy__sympy-21055"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 171a3e7b0..52739f808 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1716,12 +1716,12 @@ class DataDocumenter(ModuleLevelDocumenter):\n                 annotations = {}\n \n             if self.objpath[-1] in annotations:\n-                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]), self.config.autodoc_type_aliases)\n                 self.add_line('   :type: ' + objrepr, sourcename)\n             else:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n                 if self.analyzer and key in self.analyzer.annotations:\n-                    self.add_line('   :type: ' + self.analyzer.annotations[key],\n+                    self.add_line('   :type: ' + stringify_typehint(self.analyzer.annotations[key], self.config.autodoc_type_aliases),\n                                   sourcename)\n \n             try:\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..254ccffe9 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -86,7 +86,9 @@ def process_documenter_options(documenter: \"Type[Documenter]\", config: Config, o\n             if name in config.autodoc_default_options and not negated:\n                 options[name] = config.autodoc_default_options[name]\n \n-    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    processed_options = Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    processed_options['autodoc_type_aliases'] = config.autodoc_type_aliases\n+    return processed_options\n \n \n def parse_generated_content(state: RSTState, content: StringList, documenter: Documenter\n", "instance_id": "sphinx-doc__sphinx-8435"}
{"model_name_or_path": "190724-191444", "model_patch": "", "instance_id": "sympy__sympy-18199"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/xarray/core/groupby.py b/xarray/core/groupby.py\nindex 8a097251..af5abd9a 100644\n--- a/xarray/core/groupby.py\n+++ b/xarray/core/groupby.py\n@@ -436,7 +436,7 @@ class GroupBy(SupportsArithmetic):\n         return zip(self._unique_coord.values, self._iter_grouped())\n \n     def __repr__(self):\n-        return \"{}, grouped over {!r} \\n{!r} groups with labels {}.\".format(\n+        return \"{}, grouped over {!r}\\n{!r} groups with labels {}.\".format(\n             self.__class__.__name__,\n             self._unique_coord.name,\n             self._unique_coord.size,\n", "instance_id": "pydata__xarray-5131"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..f6c4b7fc2f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,7 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n", "instance_id": "django__django-16139"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..59987ee101 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id', 'id_%s_%s' % (self.data['name'], self.data['index']))\n \n     @property\n     def choice_label(self):\n", "instance_id": "django__django-14534"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..919d88c8e 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -277,6 +277,24 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n \n         X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n \n+        if self.fit_inverse_transform:\n+            self._fit_inverse_transform(X_transformed, X)\n+\n+        # Standardize the signs of the principal components\n+        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        for i in range(X_transformed.shape[1]):\n+            if X_transformed[0, i] < 0:\n+                X_transformed[:, i] *= -1\n+\n+        if self.fit_inverse_transform:\n+            self._fit_inverse_transform(X_transformed, X)\n+\n+        # Standardize the signs of the principal components\n+        X_transformed = self.alphas_ * np.sqrt(self.lambdas_)\n+        for i in range(X_transformed.shape[1]):\n+            if X_transformed[0, i] < 0:\n+                X_transformed[:, i] *= -1\n+\n         if self.fit_inverse_transform:\n             self._fit_inverse_transform(X_transformed, X)\n \n", "instance_id": "scikit-learn__scikit-learn-13241"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex fe1f7236e..fe07f7d02 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -15,6 +15,7 @@ import numpy as np\n import scipy.sparse as sp\n from scipy import __version__ as scipy_version\n from distutils.version import LooseVersion\n+import pandas as pd\n \n from numpy.core.numeric import ComplexWarning\n \n@@ -495,7 +496,14 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n         estimator_name = \"Estimator\"\n     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n \n-    if sp.issparse(array):\n+    if isinstance(array, pd.DataFrame):\n+        dtype_orig = array.dtypes\n+        array = array.to_numpy(dtype=dtype, copy=copy)\n+        if warn_on_dtype and not all(dtype_orig == array.dtypes):\n+            msg = (\"Data with input dtype {} was converted to {}{}.\"\n+                   .format(dtype_orig, array.dtype, context))\n+            warnings.warn(msg, DataConversionWarning)\n+    elif sp.issparse(array):\n         _ensure_no_complex_data(array)\n         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n                                       dtype=dtype, copy=copy,\n", "instance_id": "scikit-learn__scikit-learn-10949"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 03676533b7..5e78690618 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -587,7 +587,10 @@ def join(value, arg, autoescape=True):\n     try:\n         if autoescape:\n             value = [conditional_escape(v) for v in value]\n-        data = conditional_escape(arg).join(value)\n+        if autoescape:\n+            value = [conditional_escape(v) for v in value]\n+            arg = conditional_escape(arg)\n+        data = arg.join(value)\n     except TypeError:  # Fail silently if arg isn't iterable.\n         return value\n     return mark_safe(data)\n", "instance_id": "django__django-16873"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 7ef51bc847..73d3f426ea 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -377,7 +377,13 @@ def hstack(cls, *args):\n         if len(args) == 0:\n             return cls._new()\n \n+        if len(args) == 0:\n+            return cls._new()\n+\n         kls = type(args[0])\n+        if all(arg.rows == 0 for arg in args):\n+            total_cols = sum(arg.cols for arg in args)\n+            return cls._new(0, total_cols, [])\n         return reduce(kls.row_join, args)\n \n     def reshape(self, rows, cols):\n@@ -600,7 +606,13 @@ def vstack(cls, *args):\n         if len(args) == 0:\n             return cls._new()\n \n+        if len(args) == 0:\n+            return cls._new()\n+\n         kls = type(args[0])\n+        if all(arg.cols == 0 for arg in args):\n+            total_rows = sum(arg.rows for arg in args)\n+            return cls._new(total_rows, 0, [])\n         return reduce(kls.col_join, args)\n \n \n", "instance_id": "sympy__sympy-13031"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\nindex 574b4073b1..de5f93ebda 100644\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field[:] = np.char.replace(output_field, encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):\n", "instance_id": "astropy__astropy-6938"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\nindex 5eaef2fde..576756083 100644\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -16,13 +16,14 @@ from scipy.sparse import lil_matrix\n \n import numpy as np\n \n+import pandas as pd\n from .validation import check_array, _assert_all_finite\n from ..utils._array_api import get_namespace\n \n \n def _unique_multiclass(y):\n     xp, is_array_api = get_namespace(y)\n-    if hasattr(y, \"__array__\") or is_array_api:\n+    if hasattr(y, \"__array__\") or is_array_api or isinstance(y, (pd.Series, pd.DataFrame)):\n         return xp.unique_values(xp.asarray(y))\n     else:\n         return set(y)\n@@ -106,6 +107,9 @@ def unique_labels(*ys):\n     if not _unique_labels:\n         raise ValueError(\"Unknown label type: %s\" % repr(ys))\n \n+    if isinstance(ys[0], (pd.Series, pd.DataFrame)):\n+        ys = [y.to_numpy() for y in ys]\n+\n     if is_array_api:\n         # array_api does not allow for mixed dtypes\n         unique_ys = xp.concat([_unique_labels(y) for y in ys])\n", "instance_id": "scikit-learn__scikit-learn-25638"}
{"model_name_or_path": "190724-191444", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 422bc5d178..79f4ca8cfa 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1131,7 +1131,11 @@ class InlineForeignKeyField(Field):\n         else:\n             orig = self.parent_instance.pk\n         if str(value) != str(orig):\n-            raise ValidationError(self.error_messages['invalid_choice'], code='invalid_choice')\n+            raise ValidationError(\n+                self.error_messages['invalid_choice'],\n+                code='invalid_choice',\n+                params={'value': value},\n+            )\n         return self.parent_instance\n \n     def has_changed(self, initial, data):\n@@ -1188,7 +1192,7 @@ class ModelChoiceField(ChoiceField):\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n     # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n-        'invalid_choice': _('Select a valid choice. That choice is not one of'\n+        'invalid_choice': _('Select a valid choice. %(value)s is not one of'\n                             ' the available choices.'),\n     }\n     iterator = ModelChoiceIterator\n", "instance_id": "django__django-13933"}
