{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 892e19cabb..02e5feb268 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -268,6 +268,8 @@ def _eval_is_zero(self):\n         arg = self.args[0]\n         if arg.is_zero:\n             return True\n+        if isinstance(arg, cosh):\n+            return False\n \n \n class cosh(HyperbolicFunction):\n", "instance_id": "sympy__sympy-21627"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-13925"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/series/sequences.py b/sympy/series/sequences.py\nindex 08f36df061..3b3777f9d8 100644\n--- a/sympy/series/sequences.py\n+++ b/sympy/series/sequences.py\n@@ -105,7 +105,9 @@ def coeff(self, pt):\n             raise IndexError(\"Index %s out of bounds %s\" % (pt, self.interval))\n         return self._eval_coeff(pt)\n \n-    def _eval_coeff(self, pt):\n+    def _repr_latex_(self):\n+        from sympy.printing.latex import latex\n+        return r\"$\\left[\" + \", \".join([latex(self.coeff(i)) for i in range(4)]) + r\", \\ldots \\right]$\"\n         raise NotImplementedError(\"The _eval_coeff method should be added to\"\n                                   \"%s to return coefficient so it is available\"\n                                   \"when coeff calls it.\"\n", "instance_id": "sympy__sympy-13971"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..095ad0ccf0 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "instance_id": "django__django-13658"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex b821c42845..6a550e7e48 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -7,7 +7,7 @@\n from sympy.utilities import sift\n from sympy.utilities.misc import filldedent\n \n-from sympy.matrices.expressions.matexpr import MatrixExpr, ZeroMatrix, Identity\n+from sympy.matrices.expressions.matexpr import MatrixExpr, ZeroMatrix, Identity, MatrixElement\n from sympy.matrices.expressions.matmul import MatMul\n from sympy.matrices.expressions.matadd import MatAdd\n from sympy.matrices.expressions.matpow import MatPow\n@@ -244,7 +244,10 @@ def _entry(self, i, j, **kwargs):\n                 break\n             else:\n                 j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+        if i.is_Integer and j.is_Integer:\n+            return self.blocks[row_block, col_block][i, j]\n+        else:\n+            return MatrixElement(self, i, j)\n \n     @property\n     def is_Identity(self):\n", "instance_id": "sympy__sympy-19007"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-15738"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 757cb2797..08670d2b2 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -15,7 +15,7 @@ from _pytest.compat import dummy_context_manager\n from _pytest.config import create_terminal_writer\n from _pytest.pathlib import Path\n \n-DEFAULT_LOG_FORMAT = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n+DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\"\n \n \n", "instance_id": "pytest-dev__pytest-5227"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 0545797d5f..06a46eea20 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -825,9 +825,9 @@ def _print_MatAdd(self, expr):\n             if s is None:\n                 s = pform     # First element\n             else:\n-                if S(item.args[0]).is_negative:\n-                    s = prettyForm(*stringPict.next(s, ' '))\n-                    pform = self._print(item)\n+                if item.is_Mul and item.args[0].is_Number and item.args[0] < 0:\n+                    s = prettyForm(*stringPict.next(s, ' - '))\n+                    pform = self._print(-item)\n                 else:\n                     s = prettyForm(*stringPict.next(s, ' + '))\n                 s = prettyForm(*stringPict.next(s, pform))\n", "instance_id": "sympy__sympy-14817"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex c50fc90171..5cf1f5b3c2 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -5,7 +5,7 @@ from io import StringIO\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n \n # The prefix to put on the default database name when creating\n # the test database.\n@@ -126,8 +126,9 @@ class BaseDatabaseCreation:\n         the serialize_db_to_string() method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n", "instance_id": "django__django-12453"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 71a52fb754..6bde412a50 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1221,6 +1221,11 @@ class QuerySet:\n         if fields == (None,):\n             clone.query.clear_deferred_loading()\n         else:\n+            if clone.query.deferred_loading[0]:\n+                # If there are already deferred fields, remove them if they are in the only fields.\n+                existing_deferred = set(clone.query.deferred_loading[1])\n+                fields_set = set(fields)\n+                clone.query.set_deferred_loading(existing_deferred - fields_set)\n             clone.query.add_deferred_loading(fields)\n         return clone\n \n@@ -1242,6 +1247,11 @@ class QuerySet:\n             if field in self.query._filtered_relations:\n                 raise ValueError('only() is not supported with FilteredRelation.')\n         clone = self._chain()\n+        if clone.query.deferred_loading[0]:\n+            # If there are already deferred fields, remove them if they are in the only fields.\n+            existing_deferred = set(clone.query.deferred_loading[1])\n+            fields_set = set(fields)\n+            clone.query.set_deferred_loading(existing_deferred - fields_set)\n         clone.query.add_immediate_loading(fields)\n         return clone\n \n", "instance_id": "django__django-14667"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 66461181d0..1436fd0f4a 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -18,6 +18,7 @@\n from sympy.utilities.exceptions import sympy_deprecation_warning\n \n from sympy.printing.pretty.stringpict import prettyForm, stringPict\n+from sympy.vector.vector import Vector\n from sympy.printing.pretty.pretty_symbology import hobj, vobj, xobj, \\\n     xsym, pretty_symbol, pretty_atom, pretty_use_unicode, greek_unicode, U, \\\n     pretty_try_use_unicode,  annotated\n@@ -81,7 +82,16 @@ def _print_Symbol(self, e, bold_name=False):\n         symb = pretty_symbol(e.name, bold_name)\n         return prettyForm(symb)\n     _print_RandomSymbol = _print_Symbol\n-    def _print_MatrixSymbol(self, e):\n+    def _print_Vector(self, e):\n+        from sympy.vector.vector import VectorMul, VectorAdd, BaseVector\n+        if isinstance(e, VectorAdd):\n+            return self._print_Add(e)\n+        elif isinstance(e, VectorMul):\n+            return self._print_Mul(e)\n+        elif isinstance(e, BaseVector):\n+            return self._print_Symbol(e)\n+        else:\n+            return self.emptyPrinter(e)\n         return self._print_Symbol(e, self._settings['mat_symbol_style'] == \"bold\")\n \n     def _print_Float(self, e):\n", "instance_id": "sympy__sympy-23191"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..d21a0149f7 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -95,8 +95,15 @@ class DeconstructableSerializer(BaseSerializer):\n             imports = {\"from django.db import models\"}\n             name = \"models.%s\" % name\n         else:\n-            imports = {\"import %s\" % module}\n-            name = path\n+            # Handle inner classes\n+            if '.' in name:\n+                outer_class, inner_class = name.split('.', 1)\n+                imports = {\"import %s\" % module}\n+                name = \"%s.%s\" % (module, outer_class)\n+                name = \"%s.%s\" % (name, inner_class)\n+            else:\n+                imports = {\"import %s\" % module}\n+                name = path\n         return name, imports\n \n     def serialize(self):\ndiff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..5e3ca20d3f 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -81,8 +81,15 @@ class OperationWriter:\n         if getattr(migrations, name, None) == self.operation.__class__:\n             self.feed('migrations.%s(' % name)\n         else:\n-            imports.add('import %s' % (self.operation.__class__.__module__))\n-            self.feed('%s.%s(' % (self.operation.__class__.__module__, name))\n+            module_path = self.operation.__class__.__module__\n+            class_name = self.operation.__class__.__name__\n+            if '.' in class_name:\n+                outer_class, inner_class = class_name.split('.', 1)\n+                imports.add('import %s' % module_path)\n+                self.feed('%s.%s.%s(' % (module_path, outer_class, inner_class))\n+            else:\n+                imports.add('import %s' % module_path)\n+                self.feed('%s.%s(' % (module_path, name))\n \n         self.indent()\n \n", "instance_id": "django__django-12125"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 1877c3f92a..fe2f0cc519 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -528,6 +528,11 @@ def _print_IndexedBase(self, expr):\n \n class PythonCodePrinter(AbstractPythonCodePrinter):\n \n+    def _print_Tuple(self, expr):\n+        if len(expr) == 1:\n+            return '({},)'.format(self._print(expr[0]))\n+        return '({})'.format(', '.join(map(self._print, expr)))\n+\n     def _print_sign(self, e):\n         return '(0.0 if {e} == 0 else {f}(1, {e}))'.format(\n             f=self._module_format('math.copysign'), e=self._print(e.args[0]))\n", "instance_id": "sympy__sympy-23262"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..76b6031507 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -64,7 +64,8 @@ class Q(tree.Node):\n     def __and__(self, other):\n         return self._combine(other, self.AND)\n \n-    def __invert__(self):\n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n         obj = type(self)()\n         obj.add(self, self.AND)\n         obj.negate()\n", "instance_id": "django__django-14017"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 157903faf..1369f34f6 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -667,7 +667,7 @@ class AssertionRewriter(ast.NodeVisitor):\n         # docstrings and __future__ imports, so first figure out where that is.\n         doc = getattr(mod, \"docstring\", None)\n         expect_docstring = doc is None\n-        if doc is not None and self.is_rewrite_disabled(doc):\n+        if doc is not None and isinstance(doc, str) and self.is_rewrite_disabled(doc):\n             return\n         pos = 0\n         item = None\n@@ -743,7 +743,7 @@ class AssertionRewriter(ast.NodeVisitor):\n \n     @staticmethod\n     def is_rewrite_disabled(docstring: str) -> bool:\n-        return \"PYTEST_DONT_REWRITE\" in docstring\n+        return isinstance(docstring, str) and \"PYTEST_DONT_REWRITE\" in docstring\n \n     def variable(self) -> str:\n         \"\"\"Get a new variable.\"\"\"\n", "instance_id": "pytest-dev__pytest-11143"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex da5b40a5ef..54d70e39ae 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -903,13 +903,13 @@ class RangeSlider(SliderBase):\n             xy[1] = .25, val[1]\n             xy[2] = .75, val[1]\n             xy[3] = .75, val[0]\n-            xy[4] = .25, val[0]\n+            # xy[4] = .25, val[0]\n         else:\n             xy[0] = val[0], .25\n             xy[1] = val[0], .75\n             xy[2] = val[1], .75\n             xy[3] = val[1], .25\n-            xy[4] = val[0], .25\n+            # xy[4] = val[0], .25\n         self.poly.xy = xy\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n", "instance_id": "matplotlib__matplotlib-22711"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex af0815d41d..8d27e8f04b 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -1892,6 +1892,12 @@ class Axis(martist.Artist):\n         else:\n             formatter = mticker.FixedFormatter(ticklabels)\n \n+        if kwargs:\n+            valid_text_kwargs = mtext.Text().properties()\n+            for kwarg in kwargs:\n+                if kwarg not in valid_text_kwargs:\n+                    raise TypeError(f\"'{kwarg}' is not a valid Text property\")\n+\n         if minor:\n             self.set_minor_formatter(formatter)\n             locs = self.get_minorticklocs()\n@@ -2022,7 +2028,11 @@ class Axis(martist.Artist):\n         ticks.\n         \"\"\"\n         result = self._set_tick_locations(ticks, minor=minor)\n-        if labels is not None:\n+        if kwargs:\n+            valid_text_kwargs = mtext.Text().properties()\n+            for kwarg in kwargs:\n+                if kwarg not in valid_text_kwargs:\n+                    raise TypeError(f\"'{kwarg}' is not a valid Text property\")\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n         return result\n \n", "instance_id": "matplotlib__matplotlib-24334"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\nindex 759191668..0b8d6ee47 100644\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -15,20 +15,6 @@ from _pytest.nodes import Item\n from _pytest.store import StoreKey\n \n \n-evalcache_key = StoreKey[Dict[str, Any]]()\n-\n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n \n \n class MarkEvaluator:\n@@ -98,7 +84,9 @@ class MarkEvaluator:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        import _pytest._code\n+                        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+                        result = eval(exprcode, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n", "instance_id": "pytest-dev__pytest-7373"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex f50d8200e..ddfc855e5 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -363,6 +363,9 @@ def _format_assertmsg(obj):\n     for r1, r2 in replaces:\n         obj = obj.replace(r1, r2)\n \n+    if isinstance(obj, str):\n+        obj = obj.replace(\"b'\", \"\").replace(\"'\", \"\")\n+\n     return obj\n \n \n", "instance_id": "pytest-dev__pytest-5495"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 7649c39262..687b773587 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -353,7 +353,8 @@ class SQLCompiler:\n             # not taken into account so we strip it. When this entire method\n             # is refactored into expressions, then we can check each part as we\n             # generate it.\n-            without_ordering = self.ordering_parts.search(sql).group(1)\n+            sql_oneline = ' '.join(sql.split('\\n'))\n+            without_ordering = self.ordering_parts.search(sql_oneline).group(1)\n             params_hash = make_hashable(params)\n             if (without_ordering, params_hash) in seen:\n                 continue\n", "instance_id": "django__django-11001"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 7ca0d68fae..0cca06a3e3 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -103,7 +103,8 @@ def iter_all_python_module_files():\n     # aren't loaded on the fly.\n     keys = sorted(sys.modules)\n     modules = tuple(m for m in map(sys.modules.__getitem__, keys) if not isinstance(m, weakref.ProxyTypes))\n-    return iter_modules_and_files(modules, frozenset(_error_files))\n+    manage_py = Path(__file__).resolve().parent.parent.parent / 'manage.py'\n+    return iter_modules_and_files(modules, frozenset(_error_files).union({manage_py}))\n \n \n @functools.lru_cache(maxsize=1)\n", "instance_id": "django__django-11422"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex 872a4c98dc..7dc321a12e 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -251,8 +251,10 @@ class ForwardManyToOneDescriptor:\n             for lh_field, rh_field in self.field.related_fields:\n                 setattr(instance, lh_field.attname, None)\n \n-        # Set the values of the related field.\n+        # Ensure the primary key is set before saving the parent object.\n         else:\n+            if value._state.adding and value._meta.pk.attname in value.__dict__:\n+                value.save()\n             for lh_field, rh_field in self.field.related_fields:\n                 setattr(instance, lh_field.attname, getattr(value, rh_field.attname))\n \n@@ -307,6 +309,8 @@ class ForwardOneToOneDescriptor(ForwardManyToOneDescriptor):\n         return super().get_object(instance)\n \n     def __set__(self, instance, value):\n+        if value is not None and value._state.adding and value._meta.pk.attname in value.__dict__:\n+            value.save()\n         super().__set__(instance, value)\n         # If the primary key is a link to a parent model and a parent instance\n         # is being set, update the value of the inherited pk(s).\n", "instance_id": "django__django-13964"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex f71bea25f5..8e2bc56b94 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -707,7 +707,7 @@ def _preprocess(self, args, expr):\n \n         Returns string form of args, and updated expr.\n         \"\"\"\n-        from sympy import Dummy, Symbol, Function, flatten\n+        from sympy import Dummy, Symbol, Function, flatten, MatrixSymbol\n         from sympy.matrices import DeferredVector\n \n         dummify = self._dummify\n@@ -725,7 +725,7 @@ def _preprocess(self, args, expr):\n                 argstrs.append(nested_argstrs)\n             elif isinstance(arg, DeferredVector):\n                 argstrs.append(str(arg))\n-            elif isinstance(arg, Symbol):\n+            elif isinstance(arg, (Symbol, MatrixSymbol)):\n                 argrep = self._argrepr(arg)\n \n                 if dummify or not self._is_safe_ident(argrep):\n@@ -734,7 +734,7 @@ def _preprocess(self, args, expr):\n                     expr = self._subexpr(expr, {arg: dummy})\n                 else:\n                     argstrs.append(argrep)\n-            elif isinstance(arg, Function):\n+            elif isinstance(arg, (Function, MatrixSymbol)):\n                 dummy = Dummy()\n                 argstrs.append(self._argrepr(dummy))\n                 expr = self._subexpr(expr, {arg: dummy})\n", "instance_id": "sympy__sympy-15011"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/builders/manpage.py b/sphinx/builders/manpage.py\nindex 4166dece9..548388804 100644\n--- a/sphinx/builders/manpage.py\n+++ b/sphinx/builders/manpage.py\n@@ -8,7 +8,8 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n-from os import path\n+import os\n+from os import path, makedirs\n from typing import Any, Dict, List, Set, Tuple, Union\n \n from docutils.frontend import OptionParser\n@@ -80,7 +81,10 @@ class ManualPageBuilder(Builder):\n             docsettings.authors = authors\n             docsettings.section = section\n \n-            targetname = '%s.%s' % (name, section)\n+            section_dir = path.join(self.outdir, f'man{section}')\n+            if not path.exists(section_dir):\n+                os.makedirs(section_dir)\n+            targetname = path.join(section_dir, f'{name}.{section}')\n             logger.info(darkgreen(targetname) + ' { ', nonl=True)\n             destination = FileOutput(\n                 destination_path=path.join(self.outdir, targetname),\n", "instance_id": "sphinx-doc__sphinx-8273"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 978fd5df8..fc93ed1a3 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1266,6 +1266,9 @@ class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # typ\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    kwargs.setdefault('show_annotation', False)\n+\n                 sig = stringify_signature(overload, **kwargs)\n                 sigs.append(sig)\n \n@@ -1910,6 +1913,9 @@ class MethodDocumenter(DocstringSignatureMixin, ClassLevelDocumenter):  # type:\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    kwargs.setdefault('show_annotation', False)\n+\n                 if not inspect.isstaticmethod(self.object, cls=self.parent,\n                                               name=self.object_name):\n                     parameters = list(overload.parameters.values())\n", "instance_id": "sphinx-doc__sphinx-8282"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/dispatch/dispatcher.py b/django/dispatch/dispatcher.py\nindex b7d9d26389..4c3ad4dfd2 100644\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,3 +1,4 @@\n+import logging\n import threading\n import warnings\n import weakref\n@@ -5,6 +6,8 @@ import weakref\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.inspect import func_accepts_kwargs\n \n+logger = logging.getLogger(__name__)\n+\n \n def _make_id(target):\n     if hasattr(target, '__func__'):\n@@ -201,13 +204,12 @@ class Signal:\n         if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n             return []\n \n-        # Call each receiver with whatever arguments it can accept.\n-        # Return a list of tuple pairs [(receiver, response), ... ].\n         responses = []\n         for receiver in self._live_receivers(sender):\n             try:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n+                logger.exception('Error in signal handler for %s', receiver)\n                 responses.append((receiver, err))\n             else:\n                 responses.append((receiver, response))\n", "instance_id": "django__django-13768"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\nindex 69149e61a..2bb88772c 100644\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -119,7 +119,7 @@ class EncodingChecker(BaseChecker):\n     def open(self):\n         super().open()\n \n-        notes = \"|\".join(re.escape(note) for note in self.config.notes)\n+        notes = \"|\".join(re.escape(note) if note.isalnum() else re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n             regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n         else:\n", "instance_id": "pylint-dev__pylint-5859"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 6c7202c6..2990c90c 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -877,7 +877,7 @@ class Plotter:\n         self._pyplot = pyplot\n         self._theme = theme\n         self._legend_contents: list[tuple[\n-            tuple[str, str | int], list[Artist], list[str],\n+            tuple[str, str | int], list[Artist], list[str]\n         ]] = []\n         self._scales: dict[str, Scale] = {}\n \n@@ -1215,6 +1215,10 @@ class Plotter:\n                     parts.append(df.filter(cols))\n             var_df = pd.concat(parts, ignore_index=True)\n \n+            # Convert boolean data to integers\n+            if var_df[var].dtype == bool:\n+                var_df[var] = var_df[var].astype(int)\n+\n             prop = PROPERTIES[prop_key]\n             scale = self._get_scale(p, scale_key, prop, var_df[var])\n \n@@ -1596,7 +1600,7 @@ class Plotter:\n         # Input list has an entry for each distinct variable in each layer\n         # Output dict has an entry for each distinct variable\n         merged_contents: dict[\n-            tuple[str, str | int], tuple[list[Artist], list[str]],\n+            tuple[str, str | int], tuple[list[Artist], list[str]]\n         ] = {}\n         for key, new_artists, labels in self._legend_contents:\n             # Key is (name, id); we need the id to resolve variable uniqueness,\ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 6c9ecbc9..f931b14f 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -156,6 +156,10 @@ class Nominal(Scale):\n         self, data: Series, prop: Property, axis: Axis | None = None,\n     ) -> Scale:\n \n+        # Convert boolean data to integers\n+        if data.dtype == bool:\n+            data = data.astype(int)\n+\n         new = copy(self)\n         if new._tick_params is None:\n             new = new.tick()\n", "instance_id": "mwaskom__seaborn-3190"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..139c42587 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -51,6 +51,12 @@ class BaseCrossValidator(metaclass=ABCMeta):\n     Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n     \"\"\"\n \n+    def __repr__(self):\n+        return _build_repr(self)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n+\n     def split(self, X, y=None, groups=None):\n         \"\"\"Generate indices to split data into training and test set.\n \n", "instance_id": "scikit-learn__scikit-learn-14983"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 860989f7c1..8eccf46531 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -110,7 +110,9 @@ def eval(cls, arg):\n \n         arg = sympify(arg)\n \n-        if arg.is_Number:\n+        if isinstance(arg, Piecewise):\n+            return Piecewise(*[(cls.eval(e), c) for e, c in arg.args])\n+        elif arg.is_Number:\n             if arg is S.NaN:\n                 return S.NaN\n             elif arg is S.Infinity:\n", "instance_id": "sympy__sympy-21379"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "instance_id": "django__django-15814"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/handlers/exception.py b/django/core/handlers/exception.py\nindex 66443ce560..4afb8100e7 100644\n--- a/django/core/handlers/exception.py\n+++ b/django/core/handlers/exception.py\n@@ -44,6 +44,12 @@ def response_for_exception(request, exc):\n             response = debug.technical_404_response(request, exc)\n         else:\n             response = get_exception_response(request, get_resolver(get_urlconf()), 404, exc)\n+        log_response(\n+            'Not Found: %s', request.path,\n+            response=response,\n+            request=request,\n+            exc_info=sys.exc_info(),\n+        )\n \n     elif isinstance(exc, PermissionDenied):\n         response = get_exception_response(request, get_resolver(get_urlconf()), 403, exc)\ndiff --git a/django/urls/converters.py b/django/urls/converters.py\nindex bb8478e32f..ddc3a79317 100644\n--- a/django/urls/converters.py\n+++ b/django/urls/converters.py\n@@ -6,7 +6,11 @@ class IntConverter:\n     regex = '[0-9]+'\n \n     def to_python(self, value):\n-        return int(value)\n+        from django.http import Http404\n+        try:\n+            return int(value)\n+        except ValueError:\n+            raise Http404(f\"Invalid value '{value}' for path converter 'int'\")\n \n     def to_url(self, value):\n         return str(value)\n@@ -26,7 +30,11 @@ class UUIDConverter:\n     regex = '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'\n \n     def to_python(self, value):\n-        return uuid.UUID(value)\n+        from django.http import Http404\n+        try:\n+            return uuid.UUID(value)\n+        except ValueError:\n+            raise Http404(f\"Invalid value '{value}' for path converter 'uuid'\")\n \n     def to_url(self, value):\n         return str(value)\n", "instance_id": "django__django-11620"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..e113a8b9aa 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -164,6 +164,9 @@ class BaseFormSet(RenderableFormMixin):\n                 },\n                 renderer=self.renderer,\n             )\n+        # Special-case to avoid deprecation warning for default.html\n+        form.use_required_attribute = False\n+        form.empty_permitted = True\n         return form\n \n     def total_form_count(self):\n", "instance_id": "django__django-15902"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..f07e7f8842 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -979,7 +979,10 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return super().get_group_by_cols()\n \n     def as_sql(self, compiler, connection):\n-        return compiler.compile(self.expression)\n+        sql, params = compiler.compile(self.expression)\n+        if sql == '':\n+            sql = '0'\n+        return sql, params\n \n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n", "instance_id": "django__django-15213"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 78accaf295..ae362a2aa4 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -248,7 +248,10 @@ def _eval_expand_tensorproduct(self, **hints):\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n                     if isinstance(tp, TensorProduct):\n                         tp = tp._eval_expand_tensorproduct()\n-                    add_args.append(tp)\n+                    c_part, nc_part = tp.args_cnc()\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(),)\n+                    add_args.append(Mul(*c_part) * Mul(*nc_part))\n                 break\n \n         if add_args:\n", "instance_id": "sympy__sympy-24152"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-13933"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..a3cb359720 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -72,7 +72,7 @@ def _line_type(line, delimiter=None):\n     line = line.strip()\n     if not line:\n         return \"comment\"\n-    match = _line_type_re.match(line)\n+    match = _line_type_re.match(line.upper())\n \n     if match is None:\n         raise ValueError(f\"Unrecognized QDP line: {line}\")\n", "instance_id": "astropy__astropy-14365"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py\nindex f209e811f1..de8cb802ee 100644\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -665,8 +665,9 @@ grestore\n                 curr_stream[1].append(\n                     (item.x, item.ft_object.get_glyph_name(item.glyph_idx))\n                 )\n-            # append the last entry\n-            stream.append(curr_stream)\n+            # append the last entry if it exists\n+            if curr_stream:\n+                stream.append(curr_stream)\n \n         self.set_color(*gc.get_rgb())\n \n", "instance_id": "matplotlib__matplotlib-23964"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a3ead157c1..f3b7669e96 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -740,7 +740,7 @@ def _print_Function(self, expr, exp=None):\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n", "instance_id": "sympy__sympy-14774"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..7f115dd3e 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -280,7 +280,12 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         if self.fit_inverse_transform:\n             self._fit_inverse_transform(X_transformed, X)\n \n-        return X_transformed\n+        # Ensure consistent sign for the eigenvectors\n+        signs = np.sign(self.alphas_[0, :])\n+        self.alphas_ *= signs\n+        self.lambdas_ *= signs\n+\n+        return self.alphas_ * np.sqrt(self.lambdas_)\n \n     def transform(self, X):\n         \"\"\"Transform X.\n", "instance_id": "scikit-learn__scikit-learn-13241"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 1ce54470..7dd6396b 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -387,7 +387,7 @@ class HTTPAdapter(BaseAdapter):\n                     conn._put_conn(low_conn)\n \n         except socket.error as sockerr:\n-            raise ConnectionError(sockerr, request=request)\n+            raise ConnectionError(f\"Socket error: {sockerr}\", request=request)\n \n         except MaxRetryError as e:\n             raise ConnectionError(e, request=request)\n", "instance_id": "psf__requests-2148"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/elementary/complexes.py b/sympy/functions/elementary/complexes.py\nindex 7fda45982b..4b92661282 100644\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -290,7 +290,7 @@ class sign(Function):\n     def doit(self, **hints):\n         if self.args[0].is_zero is False:\n             return self.args[0] / Abs(self.args[0])\n-        return self\n+        return S.NaN\n \n     @classmethod\n     def eval(cls, arg):\n@@ -394,7 +394,10 @@ def _eval_rewrite_as_Heaviside(self, arg, **kwargs):\n         if arg.is_extended_real:\n             return Heaviside(arg, H0=S(1)/2) * 2 - 1\n \n-    def _eval_simplify(self, **kwargs):\n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        if arg.is_zero:\n+            return S.NaN\n+        return arg / Abs(arg)\n         return self.func(self.args[0].factor())  # XXX include doit?\n \n \n", "instance_id": "sympy__sympy-19487"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex 11c800704b..f0df4d1af1 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -39,7 +39,7 @@ def doit(p, q):\n             if p.is_infinite or q.is_infinite or p is nan or q is nan:\n                 return nan\n             if (p == q or p == -q or\n-                    p.is_Pow and p.exp.is_Integer and p.base == q or\n+                    (p.is_Pow and p.exp.is_Integer and p.base == q and p.base.is_integer) or\n                     p.is_integer and q == 1):\n                 return S.Zero\n \n", "instance_id": "sympy__sympy-13177"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 7049e06474..d78f02c6ca 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -195,7 +195,7 @@ def call_command(command_name, *args, **options):\n     if \"skip_checks\" not in options:\n         defaults[\"skip_checks\"] = True\n \n-    return command.execute(*args, **defaults)\n+    return command.execute(*args, **defaults, help_formatter=command.help_formatter)\n \n \n class ManagementUtility:\ndiff --git a/django/core/management/base.py b/django/core/management/base.py\nindex d37d43d5c5..88359a8475 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -257,7 +257,8 @@ class BaseCommand:\n     stealth_options = ()\n     suppressed_base_arguments = set()\n \n-    def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False):\n+    def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False, help_formatter=None):\n+        self.help_formatter = help_formatter or DjangoHelpFormatter\n         self.stdout = OutputWrapper(stdout or sys.stdout)\n         self.stderr = OutputWrapper(stderr or sys.stderr)\n         if no_color and force_color:\n@@ -289,7 +290,7 @@ class BaseCommand:\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n+            formatter_class=self.help_formatter,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n@@ -418,7 +419,9 @@ class BaseCommand:\n                 # configured settings).\n                 pass\n \n-    def execute(self, *args, **options):\n+    def execute(self, *args, help_formatter=None, **options):\n+        if help_formatter:\n+            self.help_formatter = help_formatter\n         \"\"\"\n         Try to execute this command, performing system checks if needed (as\n         controlled by the ``requires_system_checks`` attribute, except if\n", "instance_id": "django__django-15781"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 6d3cc05bd3..37edb9cda9 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -490,10 +490,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 3 - 2\n             sign_lines = []\n             sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n@@ -516,7 +516,7 @@ def _print_Product(self, expr):\n \n             height = pretty_sign.height()\n             padding = stringPict('')\n-            padding = prettyForm(*padding.stack(*[' ']*(height - 1)))\n+            padding = prettyForm(*padding.stack(*[' ']*(height)))\n             pretty_sign = prettyForm(*pretty_sign.right(padding))\n \n             pretty_func = prettyForm(*pretty_sign.right(pretty_func))\n", "instance_id": "sympy__sympy-16281"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..eea30100b3 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -898,6 +898,7 @@ def subs(self, *args, **kwargs):\n                 sequence = sorted([(k, v) for (k, v) in sequence.items()],\n                                   key=default_sort_key)\n \n+        from sympy import S, nan\n         if kwargs.pop('simultaneous', False):  # XXX should this be the default for dict subs?\n             reps = {}\n             rv = self\n@@ -913,14 +914,19 @@ def subs(self, *args, **kwargs):\n                     break\n                 reps[d] = new\n             reps[m] = S.One  # get rid of m\n-            return rv.xreplace(reps)\n+            rv = rv.xreplace(reps)\n         else:\n             rv = self\n             for old, new in sequence:\n                 rv = rv._subs(old, new, **kwargs)\n                 if not isinstance(rv, Basic):\n                     break\n-            return rv\n+\n+        # Check for undefined expressions\n+        if rv.has(S.ComplexInfinity, S.NaN, S.Infinity, S.NegativeInfinity):\n+            return nan\n+\n+        return rv\n \n     @cacheit\n     def _subs(self, old, new, **hints):\n@@ -1026,12 +1032,18 @@ def fallback(self, old, new):\n                 return rv\n             return self\n \n+        from sympy import S, nan\n         if _aresame(self, old):\n             return new\n \n         rv = self._eval_subs(old, new)\n         if rv is None:\n             rv = fallback(self, old, new)\n+\n+        # Check for undefined expressions\n+        if rv.has(S.ComplexInfinity, S.NaN, S.Infinity, S.NegativeInfinity):\n+            return nan\n+\n         return rv\n \n     def _eval_subs(self, old, new):\n", "instance_id": "sympy__sympy-13915"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex 4c2ffd81e1..3405c51db8 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -91,6 +91,13 @@ def _print_list(self, expr):\n     _print_tuple = _print_list\n     _print_Tuple = _print_list\n \n+    def _print_Derivative(self, expr):\n+        return \"D[%s]\" % (self.stringify(expr.args, \", \"))\n+\n+    def _print_Float(self, expr):\n+        res = str(expr)\n+        return res.replace('e', '*^')\n+\n     def _print_Function(self, expr):\n         if expr.func.__name__ in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n", "instance_id": "sympy__sympy-12171"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/builders/latex/__init__.py b/sphinx/builders/latex/__init__.py\nindex 77825f0ea..4a21c698f 100644\n--- a/sphinx/builders/latex/__init__.py\n+++ b/sphinx/builders/latex/__init__.py\n@@ -347,6 +347,8 @@ class LaTeXBuilder(Builder):\n         logger.info('')\n         logger.info(__(\"resolving references...\"))\n         self.env.resolve_references(largetree, indexfile, self)\n+        self.env.assign_section_numbers(largetree)\n+        self.env.assign_figure_numbers(largetree)\n         # resolve :ref:s to distant tex files -- we can't add a cross-reference,\n         # but append the document name\n         for pendingnode in largetree.traverse(addnodes.pending_xref):\ndiff --git a/sphinx/builders/singlehtml.py b/sphinx/builders/singlehtml.py\nindex d8ab978ed..a8c95f611 100644\n--- a/sphinx/builders/singlehtml.py\n+++ b/sphinx/builders/singlehtml.py\n@@ -81,6 +81,8 @@ class SingleFileHTMLBuilder(StandaloneHTMLBuilder):\n         tree['docname'] = master\n         self.env.resolve_references(tree, master, self)\n         self.fix_refuris(tree)\n+        self.env.assign_section_numbers(tree)\n+        self.env.assign_figure_numbers(tree)\n         return tree\n \n     def assemble_toc_secnumbers(self) -> Dict[str, Dict[str, Tuple[int, ...]]]:\n", "instance_id": "sphinx-doc__sphinx-8474"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..d29fd75fd 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1280,6 +1280,8 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         config = _get_output_config(\"transform\", self)\n         if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n             pd = check_pandas_support(\"transform\")\n+            # Align indices before concatenation\n+            Xs = [X.reindex(Xs[0].index) for X in Xs]\n             return pd.concat(Xs, axis=1)\n \n         if any(sparse.issparse(f) for f in Xs):\n", "instance_id": "scikit-learn__scikit-learn-25747"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..a18791c54 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -111,6 +111,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n            ``behaviour`` parameter will be deprecated in 0.22 and removed in\n            0.24.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         If int, random_state is the seed used by the random number generator;\n         If RandomState instance, random_state is the random number generator;\n@@ -173,8 +178,9 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n-        super().__init__(\n+                 verbose=0,\n+                 warm_start=False):\n+        super().__init__( \n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n                 splitter='random',\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n", "instance_id": "scikit-learn__scikit-learn-13496"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 737e16cc74..1ffe4f6d32 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1854,7 +1854,7 @@ def _print_PolynomialRingBase(self, expr):\n \n     def _print_Poly(self, poly):\n         cls = poly.__class__.__name__\n-        expr = self._print(poly.as_expr())\n+        expr = self._print(poly.as_expr(order='lex'))\n         gens = list(map(self._print, poly.gens))\n         domain = \"domain=%s\" % self._print(poly.get_domain())\n \n", "instance_id": "sympy__sympy-14317"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d65141b834..2945d1e506 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -641,7 +641,10 @@ class Query(BaseExpression):\n \n         # Ordering uses the 'rhs' ordering, unless it has none, in which case\n         # the current ordering is used.\n-        self.order_by = rhs.order_by or self.order_by\n+        if rhs.order_by:\n+            self.order_by = rhs.order_by\n+        else:\n+            self.order_by = self.order_by or self.get_meta().ordering\n         self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n \n     def deferred_to_data(self, target, callback):\n@@ -2309,8 +2312,8 @@ def get_order_dir(field, default='ASC'):\n     \"\"\"\n     dirn = ORDER_DIR[default]\n     if field[0] == '-':\n-        return field[1:], dirn[1]\n-    return field, dirn[0]\n+        return field[1:], 'DESC'\n+    return field, 'ASC'\n \n \n def add_to_dict(data, key, value):\n", "instance_id": "django__django-13033"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..2d690c4d 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1958,10 +1958,13 @@ class DataArray(AbstractArray, DataWithCoords):\n         variables = idx.levels[level_number]\n         variable_dim = idx.names[level_number]\n \n-        # pull variables out of datarray\n+        # pull variables out of dataarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            data_dict[k] = self.sel({variable_dim: k})\n+            if data_dict[k].ndim == 0:\n+                data_dict[k] = data_dict[k].expand_dims(variable_dim)\n+            data_dict[k] = data_dict[k].squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n", "instance_id": "pydata__xarray-4094"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..43f7745abc 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -180,9 +180,9 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n                     'syms should be given as a sequence, e.g. a list')\n             syms = [i for i in syms if i in var]\n             if syms != var:\n-                dict_sym_index = dict(zip(syms, range(len(syms))))\n-                return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                dict_sym_index = dict(zip(var, range(len(var))))\n+                return {tuple([t[dict_sym_index[i]] for i in syms])\n+                            for t in diophantine(eq, param, permute=permute)}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n@@ -330,7 +330,7 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n     # if there is no solution, return trivial solution\n     if not sols and eq.subs(zip(var, null)).is_zero:\n         sols.add(null)\n-    final_soln = set([])\n+    final_soln = set()\n     for sol in sols:\n         if all(_is_int(s) for s in sol):\n             if do_permute_signs:\n@@ -345,7 +345,10 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n                 permuted_sign_var = set(signed_permutations(sol))\n                 final_soln.update(permuted_sign_var)\n             else:\n-                final_soln.add(sol)\n+                if syms:\n+                    final_soln.add(tuple(sol[syms.index(v)] for v in var))\n+                else:\n+                    final_soln.add(sol)\n         else:\n                 final_soln.add(sol)\n     return final_soln\n", "instance_id": "sympy__sympy-18189"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 2b306a579e..571d120467 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -84,13 +84,13 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n", "instance_id": "django__django-13660"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex 425db22c..23d25634 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -88,7 +88,7 @@ class SessionRedirectMixin(object):\n         i = 0\n \n         while resp.is_redirect:\n-            prepared_request = req.copy()\n+            prepared_request = resp.request.copy()\n \n             resp.content  # Consume socket so it can be released\n \n", "instance_id": "psf__requests-1963"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 837dabfea8..336dfbc695 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -430,7 +430,7 @@ class AdminSite:\n                     return HttpResponsePermanentRedirect(path)\n         raise Http404\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -479,6 +479,8 @@ class AdminSite:\n                 except NoReverseMatch:\n                     pass\n \n+            model_dict['model'] = model  # Add model class to the dictionary\n+\n             if app_label in app_dict:\n                 app_dict[app_label]['models'].append(model_dict)\n             else:\n@@ -503,7 +505,7 @@ class AdminSite:\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n \n         # Sort the apps alphabetically.\n         app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n@@ -534,7 +536,7 @@ class AdminSite:\n         return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n \n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n             raise Http404('The requested admin page does not exist.')\n         # Sort the models alphabetically within each app.\n", "instance_id": "django__django-13447"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..1de7795427 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -2309,14 +2309,22 @@ def frac(self):\n             self.state = 306\n             self.match(LaTeXParser.L_BRACE)\n             self.state = 307\n-            localctx.upper = self.expr()\n+            self.match(LaTeXParser.L_PAREN)\n             self.state = 308\n-            self.match(LaTeXParser.R_BRACE)\n+            localctx.upper = self.expr()\n             self.state = 309\n-            self.match(LaTeXParser.L_BRACE)\n+            self.match(LaTeXParser.R_PAREN)\n             self.state = 310\n-            localctx.lower = self.expr()\n+            self.match(LaTeXParser.R_BRACE)\n             self.state = 311\n+            self.match(LaTeXParser.L_BRACE)\n+            self.state = 312\n+            self.match(LaTeXParser.L_PAREN)\n+            self.state = 313\n+            localctx.lower = self.expr()\n+            self.state = 314\n+            self.match(LaTeXParser.R_PAREN)\n+            self.state = 315\n             self.match(LaTeXParser.R_BRACE)\n         except RecognitionException as re:\n             localctx.exception = re\n", "instance_id": "sympy__sympy-21612"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..ceed093cf9 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -967,23 +967,27 @@ class RenameIndex(IndexOperation):\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n-            return\n-\n-        self.new_name_lower, self.old_name_lower = (\n-            self.old_name_lower,\n-            self.new_name_lower,\n-        )\n-        self.new_name, self.old_name = self.old_name, self.new_name\n+            from_model = from_state.apps.get_model(app_label, self.model_name)\n+            columns = [\n+                from_model._meta.get_field(field).column for field in self.old_fields\n+            ]\n+            matching_index_name = schema_editor._constraint_names(\n+                from_model, column_names=columns, index=True\n+            )\n+            if len(matching_index_name) != 1:\n+                raise ValueError(\n+                    \"Found wrong number (%s) of indexes for %s(%s).\"\n+                    % (\n+                        len(matching_index_name),\n+                        from_model._meta.db_table,\n+                        \", \".join(columns),\n+                    )\n+                )\n+            self.old_name = matching_index_name[0]\n+            self.old_name_lower = self.old_name.lower()\n \n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n-        self.new_name_lower, self.old_name_lower = (\n-            self.old_name_lower,\n-            self.new_name_lower,\n-        )\n-        self.new_name, self.old_name = self.old_name, self.new_name\n-\n     def describe(self):\n         if self.old_name:\n             return (\n", "instance_id": "django__django-15695"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 901918674a..874568a58a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -614,8 +614,8 @@ def _print_BasisDependent(self, expr):\n \n     def _print_Indexed(self, expr):\n         tex_base = self._print(expr.base)\n-        tex = '{'+tex_base+'}'+'_{%s}' % ','.join(\n-            map(self._print, expr.indices))\n+        indices = [self._print(index) for index in expr.indices]\n+        tex = '{' + tex_base + '}' + '_{' + ','.join(indices) + '}'\n         return tex\n \n     def _print_IndexedBase(self, expr):\n", "instance_id": "sympy__sympy-15609"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\nindex 1f33b9d3ec..af4a722a2e 100644\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -1304,13 +1304,14 @@ class Artist:\n             normed = self.norm(data)\n             if np.isfinite(normed):\n                 # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n-                g_sig_digits = cbook._g_sig_digits(data, delta)\n-            else:\n-                g_sig_digits = 3  # Consistent with default below.\n-            return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n+                try:\n+                    neighbors = self.norm.inverse(\n+                        (int(self.norm(data) * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n+                    g_sig_digits = cbook._g_sig_digits(data, delta)\n+                except ValueError:\n+                    g_sig_digits = 3  # Consistent with default below.\n+                return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n         else:\n             try:\n                 data[0]\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2e51914952..7072620632 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1909,7 +1909,7 @@ class BoundaryNorm(Normalize):\n             BoundaryNorm is not invertible, so calling this method will always\n             raise an error\n         \"\"\"\n-        raise ValueError(\"BoundaryNorm is not invertible\")\n+        raise ValueError(\"BoundaryNorm is not invertible. Consider using a different normalization method.\")\n \n \n class NoNorm(Normalize):\n", "instance_id": "matplotlib__matplotlib-22835"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 7f181789fd..41a08a492e 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -238,6 +238,11 @@ def __float__(self):\n             raise TypeError(\"can't convert complex to float\")\n         raise TypeError(\"can't convert expression to float\")\n \n+    def evalf(self, n=15, subs=None, maxn=100, chop=False, strict=False, quad=None, verbose=False):\n+        from sympy import simplify\n+        result = super().evalf(n, subs, maxn, chop, strict, quad, verbose)\n+        return simplify(result)\n+\n     def __complex__(self):\n         result = self.evalf()\n         re, im = result.as_real_imag()\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex f1609aa908..6032a162f8 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -610,6 +610,9 @@ def shorter(*choices):\n     if measure(expr) > ratio*measure(original_expr):\n         expr = original_expr\n \n+    # Additional simplification to handle cases like x**2.5 - x**(5/2)\n+    expr = expr.simplify()\n+\n     return expr\n \n \n", "instance_id": "sympy__sympy-13146"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/combinatorial/numbers.py b/sympy/functions/combinatorial/numbers.py\nindex 896729ac87..5e302f795c 100644\n--- a/sympy/functions/combinatorial/numbers.py\n+++ b/sympy/functions/combinatorial/numbers.py\n@@ -11,6 +11,7 @@\n \n from sympy.core import S, Symbol, Rational, Integer, Add, Dummy\n from sympy.core.compatibility import as_int, SYMPY_INTS, range\n+from sympy.core.logic import fuzzy_not\n from sympy.core.cache import cacheit\n from sympy.core.function import Function, expand_mul\n from sympy.core.numbers import E, pi\n@@ -443,6 +444,10 @@ def eval(cls, n, k_sym=None, symbols=None):\n                 r = cls._bell_incomplete_poly(int(n), int(k_sym), symbols)\n                 return r\n \n+    def _eval_as_leading_term(self, x):\n+        from sympy import oo\n+        return oo if x.is_unbounded else self\n+\n     def _eval_rewrite_as_Sum(self, n, k_sym=None, symbols=None):\n         from sympy import Sum\n         if (k_sym is not None) or (symbols is not None):\n", "instance_id": "sympy__sympy-13437"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-16229"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..d386aae3 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -313,11 +313,8 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                to_merge[var].append(Variable((), fill_value))\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\ndiff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex 012898ac..7a2d189c 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -154,6 +154,7 @@ def merge_collected(\n     grouped: Dict[Hashable, List[MergeElement]],\n     prioritized: Mapping[Hashable, MergeElement] = None,\n     compat: str = \"minimal\",\n+    ignore_missing_vars: bool = True,\n ) -> Tuple[Dict[Hashable, Variable], Dict[Hashable, pd.Index]]:\n     \"\"\"Merge dicts of variables, while resolving conflicts appropriately.\n \n@@ -442,7 +443,25 @@ def merge_coords(\n     )\n     collected = collect_variables_and_indexes(aligned)\n     prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)\n-    variables, out_indexes = merge_collected(collected, prioritized, compat=compat)\n+    variables, out_indexes = merge_collected(collected, prioritized, compat=compat, ignore_missing_vars=ignore_missing_vars)\n+\n+    if ignore_missing_vars:\n+        all_vars = set().union(*[set(obj.keys()) for obj in objects])\n+        for var in all_vars:\n+            if var not in variables:\n+                variables[var] = Variable((), fill_value)\n+\n+    if ignore_missing_vars:\n+        all_vars = set().union(*[set(obj.keys()) for obj in objects])\n+        for var in all_vars:\n+            if var not in variables:\n+                variables[var] = Variable((), fill_value)\n+\n+    if ignore_missing_vars:\n+        all_vars = set().union(*[set(obj.keys()) for obj in objects])\n+        for var in all_vars:\n+            if var not in variables:\n+                variables[var] = Variable((), fill_value)\n     assert_unique_multiindex_level_names(variables)\n     return variables, out_indexes\n \n@@ -495,6 +514,7 @@ def merge_core(\n     explicit_coords: Optional[Sequence] = None,\n     indexes: Optional[Mapping[Hashable, pd.Index]] = None,\n     fill_value: object = dtypes.NA,\n+    ignore_missing_vars: bool = True,\n ) -> _MergeResult:\n     \"\"\"Core logic for merging labeled objects.\n \n@@ -541,7 +561,7 @@ def merge_core(\n     collected = collect_variables_and_indexes(aligned)\n \n     prioritized = _get_priority_vars_and_indexes(aligned, priority_arg, compat=compat)\n-    variables, out_indexes = merge_collected(collected, prioritized, compat=compat)\n+    variables, out_indexes = merge_collected(collected, prioritized, compat=compat, ignore_missing_vars=ignore_missing_vars)\n     assert_unique_multiindex_level_names(variables)\n \n     dims = calculate_dimensions(variables)\n", "instance_id": "pydata__xarray-3364"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\nindex 28eaae5f..51a5c804 100644\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -283,7 +283,15 @@ def summarize_variable(\n         dims_str = \"({}) \".format(\", \".join(map(str, var.dims)))\n     else:\n         dims_str = \"\"\n-    front_str = f\"{first_col}{dims_str}{var.dtype} \"\n+    \n+    # Check for units in attributes\n+    units = var.attrs.get(\"units\", \"\")\n+    if units:\n+        units_str = f\", in {units}\"\n+    else:\n+        units_str = \"\"\n+\n+    front_str = f\"{first_col}{units_str} {dims_str}{var.dtype} \"\n \n     values_width = max_width - len(front_str)\n     values_str = inline_variable_array_repr(var, values_width)\n", "instance_id": "pydata__xarray-4248"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 755088ca5..cc7486d19 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -682,7 +682,11 @@ class GoogleDocstring:\n         return self._parse_generic_section(_('Notes'), use_admonition)\n \n     def _parse_other_parameters_section(self, section: str) -> List[str]:\n-        return self._format_fields(_('Other Parameters'), self._consume_fields())\n+        fields = self._consume_fields()\n+        if self._config.napoleon_use_param:\n+            return self._format_docutils_params(fields)\n+        else:\n+            return self._format_fields(_('Other Parameters'), fields)\n \n     def _parse_parameters_section(self, section: str) -> List[str]:\n         if self._config.napoleon_use_param:\n", "instance_id": "sphinx-doc__sphinx-8713"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/assumptions/assume.py b/sympy/assumptions/assume.py\nindex 4c2aa41120..6fe1c01055 100644\n--- a/sympy/assumptions/assume.py\n+++ b/sympy/assumptions/assume.py\n@@ -494,3 +494,10 @@ def assuming(*assumptions):\n     finally:\n         global_assumptions.clear()\n         global_assumptions.update(old_global_assumptions)\n+@Q.positive.register(Abs)\n+def _(expr, assumptions):\n+    return ask(Q.positive(expr.args[0]), assumptions)\n+\n+@Q.zero.register(arg)\n+def _(expr, assumptions):\n+    return ask(Q.positive(expr.args[0]), assumptions)\ndiff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 38c423a70f..5a276cdb4b 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3,6 +3,7 @@\n from functools import reduce\n \n from .sympify import sympify, _sympify, SympifyError\n+from sympy.assumptions import Q, ask\n from .basic import Basic, Atom\n from .singleton import S\n from .evalf import EvalfMixin, pure_complex\n", "instance_id": "sympy__sympy-21055"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..b5f65db9b7 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -85,8 +85,8 @@ class PasswordResetTokenGenerator:\n            same password is chosen, due to password salting).\n         2. The last_login field will usually be updated very shortly after\n            a password reset.\n-        Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n-        invalidates the token.\n+        3. The email field will change if the user updates their email address.\n+        Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually invalidates the token.\n \n         Running this data through salted_hmac() prevents password cracking\n         attempts using the reset token, provided the secret isn't compromised.\n@@ -94,7 +94,8 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email_timestamp = '' if user.email is None else user.email\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email_timestamp\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n", "instance_id": "django__django-13551"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\nindex 93298f47e6..7d38f1553c 100644\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -123,22 +123,22 @@ def dmp_trial_division(f, factors, u, K):\n     return _sort_factors(result)\n \n \n-def dup_zz_mignotte_bound(f, K):\n-    \"\"\"Mignotte bound for univariate polynomials in `K[x]`. \"\"\"\n+def dup_zz_knuth_cohen_bound(f, K):\n+    \"\"\"Knuth-Cohen bound for univariate polynomials in `K[x]`. \"\"\"\n     a = dup_max_norm(f, K)\n     b = abs(dup_LC(f, K))\n     n = dup_degree(f)\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n-def dmp_zz_mignotte_bound(f, u, K):\n-    \"\"\"Mignotte bound for multivariate polynomials in `K[X]`. \"\"\"\n+def dmp_zz_knuth_cohen_bound(f, u, K):\n+    \"\"\"Knuth-Cohen bound for multivariate polynomials in `K[X]`. \"\"\"\n     a = dmp_max_norm(f, u, K)\n     b = abs(dmp_ground_LC(f, u, K))\n     n = sum(dmp_degree_list(f, u))\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n def dup_zz_hensel_step(m, f, g, h, s, t, K):\n@@ -272,7 +272,7 @@ def dup_zz_zassenhaus(f, K):\n     fc = f[-1]\n     A = dup_max_norm(f, K)\n     b = dup_LC(f, K)\n-    B = int(abs(K.sqrt(K(n + 1))*2**n*A*b))\n+    B = int(dup_zz_knuth_cohen_bound(f, K))\n     C = int((n + 1)**(2*n)*A**(2*n - 1))\n     gamma = int(_ceil(2*_log(C, 2)))\n     bound = int(2*gamma*_log(gamma))\n@@ -933,7 +933,7 @@ def dmp_zz_wang(f, u, K, mod=None, seed=None):\n \n     ct, T = dmp_zz_factor(dmp_LC(f, K), u - 1, K)\n \n-    b = dmp_zz_mignotte_bound(f, u, K)\n+    b = dmp_zz_knuth_cohen_bound(f, u, K)\n     p = K(nextprime(b))\n \n     if mod is None:\n", "instance_id": "sympy__sympy-19254"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..72348505f5 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\ndiff --git a/django/forms/utils.py b/django/forms/utils.py\nindex 50412f414b..a67940f17a 100644\n--- a/django/forms/utils.py\n+++ b/django/forms/utils.py\n@@ -84,10 +84,9 @@ class ErrorList(UserList, list):\n     def __init__(self, initlist=None, error_class=None):\n         super().__init__(initlist)\n \n-        if error_class is None:\n-            self.error_class = 'errorlist'\n-        else:\n-            self.error_class = 'errorlist {}'.format(error_class)\n+        self.error_class = 'errorlist'\n+        if error_class:\n+            self.error_class += ' {}'.format(error_class)\n \n     def as_data(self):\n         return ValidationError(self.data).error_list\n", "instance_id": "django__django-14608"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex f0c81c123b..cb72b335e1 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -236,7 +236,11 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n                 if delete_field.name not in index.fields\n             ]\n \n-        constraints = list(model._meta.constraints)\n+        constraints = [\n+            constraint for constraint in model._meta.constraints\n+            if not isinstance(constraint, UniqueConstraint) or\n+               not constraint.contains_expressions\n+        ]\n \n         # Provide isolated instances of the fields to the new model body so\n         # that the existing model's internals aren't interfered with when\n", "instance_id": "django__django-14997"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "matplotlib__matplotlib-26011"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex dc084b8692..fb44ff2707 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -179,7 +179,10 @@ class ValidationError(Exception):\n             return repr(dict(self))\n         return repr(list(self))\n \n-    def __repr__(self):\n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return False\n+        return sorted(self.messages) == sorted(other.messages)\n         return 'ValidationError(%s)' % self\n \n \n", "instance_id": "django__django-13220"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..7015eba6 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,6 +425,8 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n         method = builtin_str(method)\n \n         # Create the Request.\n", "instance_id": "psf__requests-2317"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..ecd68dd937 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,20 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n+            if self.creation_counter == other.creation_counter:\n+                return getattr(self, 'model', None) < getattr(other, 'model', None)\n             return self.creation_counter < other.creation_counter\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n", "instance_id": "django__django-13401"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n", "instance_id": "django__django-16527"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/python_api.py b/src/_pytest/python_api.py\nindex 011181a40..521c9f2f5 100644\n--- a/src/_pytest/python_api.py\n+++ b/src/_pytest/python_api.py\n@@ -713,6 +713,9 @@ class RaisesContext:\n         self.match_expr = match_expr\n         self.excinfo = None\n \n+    def __str__(self):\n+        return str(self.excinfo.value) if self.excinfo else \"\"\n+\n     def __enter__(self):\n         self.excinfo = _pytest._code.ExceptionInfo.for_later()\n         return self.excinfo\n", "instance_id": "pytest-dev__pytest-5413"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..e2d871647c 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -848,10 +848,6 @@ class MultiWidget(Widget):\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n \n     def value_from_datadict(self, data, files, name):\n         return [\n", "instance_id": "django__django-15061"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\nindex 29bd46798..c3c91e8e4 100644\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,14 +175,15 @@ class TextReporter(BaseReporter):\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{(.+?)(:.*?)?\\}\", template)\n         for argument in arguments:\n-            if argument[0] not in MESSAGE_FIELDS:\n+            arg_name = argument[0].strip()\n+            if arg_name not in MESSAGE_FIELDS:\n                 warnings.warn(\n-                    f\"Don't recognize the argument '{argument[0]}' in the --msg-template. \"\n+                    f\"Don't recognize the argument '{arg_name}' in the --msg-template. \"\n                     \"Are you sure it is supported on the current version of pylint?\"\n                 )\n-                template = re.sub(r\"\\{\" + argument[0] + r\"(:.*?)?\\}\", \"\", template)\n+                template = re.sub(r\"\\{\" + re.escape(argument[0]) + r\"(:.*?)?\\}\", \"\", template)\n         self._fixed_template = template\n \n     def write_message(self, msg: Message) -> None:\n", "instance_id": "pylint-dev__pylint-7993"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 6f26dff0e0..ac9568594a 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1075,6 +1075,7 @@ class Case(SQLiteNumericMixin, Expression):\n     def __init__(self, *cases, default=None, output_field=None, **extra):\n         if not all(isinstance(case, When) for case in cases):\n             raise TypeError(\"Positional arguments must all be When objects.\")\n+        self.query.subquery = True\n         super().__init__(output_field)\n         self.cases = list(cases)\n         self.default = self._parse_expressions(default)[0]\n", "instance_id": "django__django-15320"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..743a2a67f 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -111,6 +111,8 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n                     # removed later.\n                     X_mask[:, i] = valid_mask\n                     Xi = Xi.copy()\n+                    if X.dtype.kind in 'UO' and isinstance(self.categories_[i][0], str):\n+                        Xi = Xi.astype(object)\n                     Xi[~valid_mask] = self.categories_[i][0]\n             _, encoded = _encode(Xi, self.categories_[i], encode=True)\n             X_int[:, i] = encoded\n", "instance_id": "scikit-learn__scikit-learn-12471"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/calibration.py b/sklearn/calibration.py\nindex 2c4a33616..91ba70167 100644\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -760,6 +760,8 @@ class _CalibratedClassifier:\n                 # When binary, `predictions` consists only of predictions for\n                 # clf.classes_[1] but `pos_class_indices` = 0\n                 class_idx += 1\n+            # Ensure this_pred is a NumPy array\n+            this_pred = np.asarray(this_pred)\n             proba[:, class_idx] = calibrator.predict(this_pred)\n \n         # Normalize the probabilities\n", "instance_id": "scikit-learn__scikit-learn-25500"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/_io/saferepr.py b/src/_pytest/_io/saferepr.py\nindex 23af4d0bb..a0460dad4 100644\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -8,8 +8,8 @@ def _try_repr_or_str(obj):\n         return repr(obj)\n     except (KeyboardInterrupt, SystemExit):\n         raise\n-    except BaseException:\n-        return '{}(\"{}\")'.format(type(obj).__name__, obj)\n+    except BaseException as exc:\n+        return _format_repr_exception(exc, obj)\n \n \n def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n@@ -20,7 +20,7 @@ def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n     except BaseException as exc:\n         exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc))\n     return \"<[{} raised in repr()] {} object at 0x{:x}>\".format(\n-        exc_info, obj.__class__.__name__, id(obj)\n+        exc_info, type(obj).__name__, id(obj)\n     )\n \n \n@@ -60,6 +60,15 @@ class SafeRepr(reprlib.Repr):\n             s = _format_repr_exception(exc, x)\n         return _ellipsize(s, self.maxsize)\n \n+    def repr_instance(self, x: Any, level: int) -> str:\n+        try:\n+            s = repr(x)\n+        except (KeyboardInterrupt, SystemExit):\n+            raise\n+        except BaseException as exc:\n+            s = _format_repr_exception(exc, x)\n+        return _ellipsize(s, self.maxsize)\n+\n \n def safeformat(obj: Any) -> str:\n     \"\"\"return a pretty printed string for the given object.\n", "instance_id": "pytest-dev__pytest-7168"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0a5e5ff673..e4f5a6a8c2 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -345,6 +345,12 @@ class ModelBase(type):\n                 remote = wrt.remote_field.model\n                 lazy_related_operation(make_foreign_order_accessors, cls, remote)\n \n+        # Add get_FOO_display() methods for each field with choices.\n+        for field in opts.fields:\n+            if field.choices and not hasattr(cls, 'get_%s_display' % field.name):\n+                setattr(cls, 'get_%s_display' % field.name,\n+                        partialmethod(cls._get_FIELD_display, field))\n+\n         # Give the class a docstring -- its definition.\n         if cls.__doc__ is None:\n             cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n", "instance_id": "django__django-11999"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..515ec689e9 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -173,9 +173,8 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                addend_factor, addend_dim = self._collect_factor_and_dimension(addend)\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "instance_id": "sympy__sympy-24213"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 583c2be647..90ab81c466 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -18,6 +18,7 @@ import django\n from django.apps import apps\n from django.core.signals import request_finished\n from django.dispatch import Signal\n+from django.conf import settings\n from django.utils.functional import cached_property\n from django.utils.version import get_version_tuple\n \n@@ -252,6 +253,55 @@ def get_child_arguments():\n         args += sys.argv\n     return args\n \n+    \"\"\"\n+    Extract directories from the TEMPLATES setting.\n+    \"\"\"\n+    template_dirs = []\n+    for config in settings.TEMPLATES:\n+        template_dirs.extend(config.get('DIRS', []))\n+    return template_dirs\n+\n+    \"\"\"\n+    Return the executable. This contains a workaround for Windows if the\n+    executable is reported to not have the .exe extension which can cause bugs\n+    on reloading.\n+    \"\"\"\n+    import __main__\n+    py_script = Path(sys.argv[0])\n+\n+    args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n+    if sys.implementation.name == 'cpython':\n+        args.extend(\n+            f'-X{key}' if value is True else f'-X{key}={value}'\n+            for key, value in sys._xoptions.items()\n+        )\n+    # __spec__ is set when the server was started with the `-m` option,\n+    # see https://docs.python.org/3/reference/import.html#main-spec\n+    # __spec__ may not exist, e.g. when running in a Conda env.\n+    if getattr(__main__, '__spec__', None) is not None:\n+        spec = __main__.__spec__\n+        if (spec.name == '__main__' or spec.name.endswith('.__main__')) and spec.parent:\n+            name = spec.parent\n+        else:\n+            name = spec.name\n+        args += ['-m', name]\n+        args += sys.argv[1:]\n+    elif not py_script.exists():\n+        # sys.argv[0] may not exist for several reasons on Windows.\n+        # It may exist with a .exe extension or have a -script.py suffix.\n+        exe_entrypoint = py_script.with_suffix('.exe')\n+        if exe_entrypoint.exists():\n+            # Should be executed directly, ignoring sys.executable.\n+            return [exe_entrypoint, *sys.argv[1:]]\n+        script_entrypoint = py_script.with_name('%s-script.py' % py_script.name)\n+        if script_entrypoint.exists():\n+            # Should be executed as usual.\n+            return [*args, script_entrypoint, *sys.argv[1:]]\n+        raise RuntimeError('Script %s does not exist.' % py_script)\n+    else:\n+        args += sys.argv\n+    return args\n+\n \n def trigger_reload(filename):\n     logger.info('%s changed, reloading.', filename)\n@@ -294,7 +344,8 @@ class BaseReloader:\n         \"\"\"\n         yield from iter_all_python_module_files()\n         yield from self.extra_files\n-        if include_globs:\n+        for template_dir in get_template_dirs():\n+            yield Path(template_dir).resolve().absolute()\n             for directory, patterns in self.directory_globs.items():\n                 for pattern in patterns:\n                     yield from directory.glob(pattern)\n", "instance_id": "django__django-15388"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..948ef210c6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[\\w][\\w\\d]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n", "instance_id": "sympy__sympy-24102"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\nindex 0e66649695..e206f0de53 100644\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -24,10 +24,17 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n         proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+        existing_permissions = Permission.objects.filter(\n+            permissions_query,\n+            content_type=new_content_type,\n+        ).values_list('codename', flat=True)\n+\n+        permissions_to_update = Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        ).exclude(codename__in=existing_permissions)\n+\n+        permissions_to_update.update(content_type=new_content_type)\n \n \n def revert_proxy_model_permissions(apps, schema_editor):\n", "instance_id": "django__django-11283"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 397146a354..50b6ccd925 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -14,6 +14,7 @@ from django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL\n from django.db.models.query_utils import PathInfo\n from django.db.models.utils import make_model_tuple\n from django.utils.functional import cached_property\n+from django.forms.models import apply_limit_choices_to_to_formfield\n from django.utils.translation import gettext_lazy as _\n \n from . import Field\n@@ -528,6 +529,16 @@ class ForeignObject(RelatedField):\n             frozenset(ut)\n             for ut in self.remote_field.model._meta.unique_together\n         })\n+\n+        if self.remote_field.limit_choices_to:\n+            apply_limit_choices_to_to_formfield(form_field)\n+\n+        return form_field\n+\n+        if self.remote_field.limit_choices_to:\n+            apply_limit_choices_to_to_formfield(form_field)\n+\n+        return form_field\n         unique_foreign_fields.update({\n             frozenset(uc.fields)\n             for uc in self.remote_field.model._meta.total_unique_constraints\n@@ -986,7 +997,7 @@ class ForeignKey(ForeignObject):\n             raise ValueError(\"Cannot create form field for %r yet, because \"\n                              \"its related model %r has not been loaded yet\" %\n                              (self.name, self.remote_field.model))\n-        return super().formfield(**{\n+        form_field = super().formfield(**{\n             'form_class': forms.ModelChoiceField,\n             'queryset': self.remote_field.model._default_manager.using(using),\n             'to_field_name': self.remote_field.field_name,\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..c279bf81ad 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,7 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.filter(limit_choices_to).distinct()\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n", "instance_id": "django__django-13315"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "matplotlib__matplotlib-23314"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8ddbb5ba68..c54767f592 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1309,7 +1309,7 @@ class ManyToManyField(RelatedField):\n                              \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n", "instance_id": "django__django-12497"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex d610dc86f0..beea21d11e 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -6,6 +6,7 @@ import operator\n import uuid\n import warnings\n from base64 import b64decode, b64encode\n+import enum\n from functools import partialmethod, total_ordering\n \n from django import forms\n@@ -916,7 +917,13 @@ class Field(RegisterLookupMixin):\n \n     def value_from_object(self, obj):\n         \"\"\"Return the value of this field in the given model instance.\"\"\"\n-        return getattr(obj, self.attname)\n+        value = getattr(obj, self.attname)\n+        if isinstance(value, enum.Enum):\n+            return value.value\n+        return value\n+        if isinstance(value, enum.Enum):\n+            return value.value\n+        return value\n \n \n class BooleanField(Field):\n", "instance_id": "django__django-11964"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/flask/config.py b/src/flask/config.py\nindex d4fc310f..c7ae9f74 100644\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -234,6 +234,7 @@ class Config(dict):\n         filename: str,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n+        mode: str = \"r\",\n     ) -> bool:\n         \"\"\"Update the values in the config from a file that is loaded\n         using the ``load`` parameter. The loaded data is passed to the\n@@ -261,7 +262,7 @@ class Config(dict):\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, mode) as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n", "instance_id": "pallets__flask-4992"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c2623f099f..695e9e48f1 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -9,6 +9,7 @@ import copy\n import functools\n import inspect\n from collections import namedtuple\n+from collections.abc import dict_keys, dict_values\n \n from django.core.exceptions import FieldError\n from django.db.models.constants import LOOKUP_SEP\n@@ -38,7 +39,10 @@ class Q(tree.Node):\n     conditional = True\n \n     def __init__(self, *args, _connector=None, _negated=False, **kwargs):\n-        super().__init__(children=[*args, *sorted(kwargs.items())], connector=_connector, negated=_negated)\n+        # Convert non-pickleable types to list\n+        children = [*args, *sorted((k, list(v) if isinstance(v, (dict_keys, dict_values)) else v) for k, v in kwargs.items())]\n+        super().__init__(children=children, connector=_connector, negated=_negated)\n+        super().__init__(children=children, connector=_connector, negated=_negated)\n \n     def _combine(self, other, conn):\n         if not isinstance(other, Q):\n", "instance_id": "django__django-14016"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..c93959b1e3 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs']['id']\n \n     @property\n     def choice_label(self):\n", "instance_id": "django__django-14534"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex c99b0771e2..8d51a956ec 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -304,7 +304,8 @@ class Axes(_AxesBase):\n                 **kwargs)\n         if len(extra_args):\n             raise TypeError('legend only accepts two non-keyword arguments')\n-        self.legend_ = mlegend.Legend(self, handles, labels, **kwargs)\n+        draggable = kwargs.pop('draggable', False)\n+        self.legend_ = mlegend.Legend(self, handles, labels, draggable=draggable, **kwargs)\n         self.legend_._remove_method = self._remove_legend\n         return self.legend_\n \ndiff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 9e5b903d59..b6dad0d664 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -342,7 +342,8 @@ class Legend(Artist):\n         title_fontproperties=None,  # properties for the legend title\n         alignment=\"center\",       # control the alignment within the legend box\n         *,\n-        ncol=1  # synonym for ncols (backward compatibility)\n+        ncol=1,  # synonym for ncols (backward compatibility)\n+        draggable=False  # make legend draggable if True\n     ):\n         \"\"\"\n         Parameters\n@@ -538,6 +539,8 @@ class Legend(Artist):\n \n         self.set_title(title, prop=title_prop_fp)\n         self._draggable = None\n+        if draggable:\n+            self.set_draggable(True)\n \n         # set the text color\n \n", "instance_id": "matplotlib__matplotlib-23913"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/operations/special.py b/django/db/migrations/operations/special.py\nindex 94a6ec72de..ebe58a35dc 100644\n--- a/django/db/migrations/operations/special.py\n+++ b/django/db/migrations/operations/special.py\n@@ -190,7 +190,7 @@ class RunPython(Operation):\n             # object, representing the versioned models as an app registry.\n             # We could try to override the global cache, but then people will still\n             # use direct imports, so we go with a documentation approach instead.\n-            self.code(from_state.apps, schema_editor)\n+            self.code(from_state.apps, schema_editor, schema_editor.connection.alias)\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.reverse_code is None:\n@@ -198,7 +198,7 @@ class RunPython(Operation):\n         if router.allow_migrate(\n             schema_editor.connection.alias, app_label, **self.hints\n         ):\n-            self.reverse_code(from_state.apps, schema_editor)\n+            self.reverse_code(from_state.apps, schema_editor, schema_editor.connection.alias)\n \n     def describe(self):\n         return \"Raw Python operation\"\n", "instance_id": "django__django-16400"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sympy__sympy-12236"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 7ef51bc847..5443d8ddc7 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -378,6 +378,9 @@ def hstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.rows == 0 for arg in args):\n+            total_cols = sum(arg.cols for arg in args)\n+            return cls._new(0, total_cols, [])\n         return reduce(kls.row_join, args)\n \n     def reshape(self, rows, cols):\n@@ -601,6 +604,9 @@ def vstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.cols == 0 for arg in args):\n+            total_rows = sum(arg.rows for arg in args)\n+            return cls._new(total_rows, 0, [])\n         return reduce(kls.col_join, args)\n \n \n", "instance_id": "sympy__sympy-13031"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 03676533b7..aeb8f80b34 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -587,7 +587,9 @@ def join(value, arg, autoescape=True):\n     try:\n         if autoescape:\n             value = [conditional_escape(v) for v in value]\n-        data = conditional_escape(arg).join(value)\n+        if autoescape:\n+            arg = conditional_escape(arg)\n+        data = arg.join(value)\n     except TypeError:  # Fail silently if arg isn't iterable.\n         return value\n     return mark_safe(data)\n", "instance_id": "django__django-16873"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..1304f20a60 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n", "instance_id": "django__django-11099"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 90ea232faf..c600fe88e2 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ def is_upper(self):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "instance_id": "sympy__sympy-12454"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 8526f44b..36054eaa 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1566,9 +1566,10 @@ class PairGrid(Grid):\n             hue = data.get(self._hue_var)\n \n         if \"hue\" not in kwargs:\n-            kwargs.update({\n-                \"hue\": hue, \"hue_order\": self._hue_order, \"palette\": self._orig_palette,\n-            })\n+            if hue is not None:\n+                kwargs.update({\n+                    \"hue\": hue, \"hue_order\": self._hue_order, \"palette\": self._orig_palette,\n+                })\n         func(x=x, y=y, **kwargs)\n \n         self._update_legend_data(ax)\ndiff --git a/seaborn/relational.py b/seaborn/relational.py\nindex b1762ca3..1ee96fd7 100644\n--- a/seaborn/relational.py\n+++ b/seaborn/relational.py\n@@ -575,7 +575,7 @@ class _ScatterPlotter(_RelationalPlotter):\n \n         # Apply the mapping from semantic variables to artist attributes\n \n-        if \"hue\" in self.variables:\n+        if \"hue\" in self.variables and \"hue\" in data:\n             points.set_facecolors(self._hue_map(data[\"hue\"]))\n \n         if \"size\" in self.variables:\n", "instance_id": "mwaskom__seaborn-2848"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex a5b0f464a9..acd4ade904 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1744,6 +1744,13 @@ class QuerySet(AltersData):\n                 raise ValueError(\"only() is not supported with FilteredRelation.\")\n         clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n+        if clone._fields is None:\n+            clone._fields = set()\n+        for field in fields:\n+            if LOOKUP_SEP in field:\n+                related_field, related_field_name = field.split(LOOKUP_SEP, 1)\n+                if related_field in clone.query.select_related:\n+                    clone._fields.add(field)\n         return clone\n \n     def using(self, alias):\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 781dfd5499..2fdec76c19 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1861,6 +1861,13 @@ class Query(BaseExpression):\n             reuse = can_reuse if join.m2m else None\n             alias = self.join(connection, reuse=reuse)\n             joins.append(alias)\n+        if self.deferred_loading[0]:\n+            only_load = self.deferred_loading[0]\n+            for field in only_load:\n+                if LOOKUP_SEP in field:\n+                    related_field, related_field_name = field.split(LOOKUP_SEP, 1)\n+                    if related_field in self.select_related:\n+                        self.add_deferred_loading([related_field_name])\n         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)\n \n     def trim_joins(self, targets, joins, path):\n", "instance_id": "django__django-16910"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex dc413b5c2..f509cac25 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -728,6 +728,12 @@ class Documenter:\n                 # hack for ClassDocumenter to inject docstring via ObjectMember\n                 doc = obj.docstring\n \n+            # Check if the member is an annotation-only member in the superclass\n+            if not doc and isinstance(self.parent, type):\n+                annotations = get_type_hints(self.parent, None, self.config.autodoc_type_aliases)\n+                if membername in annotations:\n+                    doc = \"Annotation-only member\"\n+\n             has_doc = bool(doc)\n \n             metadata = extract_metadata(doc)\n", "instance_id": "sphinx-doc__sphinx-8801"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/config/argparsing.py b/src/_pytest/config/argparsing.py\nindex cc48ed337..ff9ca3ec2 100644\n--- a/src/_pytest/config/argparsing.py\n+++ b/src/_pytest/config/argparsing.py\n@@ -72,6 +72,10 @@ class Parser(object):\n         self._anonymous.addoption(*opts, **attrs)\n \n     def parse(self, args, namespace=None):\n+        if \"--fixtures\" in args:\n+            self._print_fixtures = True\n+        else:\n+            self._print_fixtures = False\n         from _pytest._argcomplete import try_argcomplete\n \n         self.optparser = self._getparser()\ndiff --git a/src/_pytest/fixtures.py b/src/_pytest/fixtures.py\nindex 902904457..748f5f6d3 100644\n--- a/src/_pytest/fixtures.py\n+++ b/src/_pytest/fixtures.py\n@@ -633,6 +633,9 @@ class FixtureRequest(FuncargnamesCompatAttr):\n         )\n         return node\n \n+    def get_scope(self):\n+        return self.scope\n+\n     def __repr__(self):\n         return \"<FixtureRequest for %r>\" % (self.node)\n \ndiff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\nindex 7f348e823..452dfd64f 100644\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -620,6 +620,15 @@ class TerminalReporter(object):\n                 for rep in self.stats.get(\"failed\"):\n                     rep.toterminal(self._tw)\n \n+    def _printfixtures(self, fixtures):\n+        if not fixtures:\n+            self.write_line(\"No fixtures found.\")\n+            return\n+        for fixturedef in fixtures:\n+            self.write_line(\n+                \"{} -- scope: {}\".format(fixturedef.argname, fixturedef.get_scope())\n+            )\n+\n     def _printcollecteditems(self, items):\n         # to print out items and their parent collectors\n         # we take care to leave out Instances aka ()\n", "instance_id": "pytest-dev__pytest-5221"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..0c30cae54a 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -233,7 +233,8 @@ class HttpResponseBase:\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n-        # Handle non-string types.\n+        if isinstance(value, memoryview):\n+            return value.tobytes()\n         return str(value).encode(self.charset)\n \n     # These methods partially implement the file-like object interface.\n", "instance_id": "django__django-11133"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 984398c760..8a3bc3003b 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -299,6 +299,8 @@ def __new__(cls, b, e, evaluate=None):\n                 return b\n             elif e == -1 and not b:\n                 return S.ComplexInfinity\n+            elif b is S.Zero and e.is_negative:\n+                return S.ComplexInfinity\n             # Only perform autosimplification if exponent or base is a Symbol or number\n             elif (b.is_Symbol or b.is_number) and (e.is_Symbol or e.is_number) and\\\n                 e.is_integer and _coeff_isneg(b):\n", "instance_id": "sympy__sympy-20212"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..387400f001 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,17 +501,17 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_number and rv.exp < 0:\n             return rv\n-        if (rv.exp > max) == True:\n+        if rv.exp.is_number and rv.exp > max:\n             return rv\n-        if rv.exp == 2:\n+        if rv.exp.is_number and rv.exp == 2:\n             return h(g(rv.base.args[0])**2)\n         else:\n-            if rv.exp == 4:\n+            if rv.exp.is_number and rv.exp == 4:\n                 e = 2\n             elif not pow:\n-                if rv.exp % 2:\n+                if rv.exp.is_number and rv.exp % 2:\n                     return rv\n                 e = rv.exp//2\n             else:\n", "instance_id": "sympy__sympy-17139"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 2903b8995..b8b19663a 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -964,10 +964,22 @@ warn_explicit(\n         res = self.assign(ast.BinOp(left_expr, binop.op, right_expr))\n         return res, explanation\n \n+    def is_all_or_any_call(self, call):\n+        \"\"\"Check if the call is to `all` or `any`.\"\"\"\n+        return (\n+            isinstance(call.func, ast.Name)\n+            and call.func.id in {\"all\", \"any\"}\n+            and len(call.args) == 1\n+            and isinstance(call.args[0], (ast.GeneratorExp, ast.ListComp))\n+        )\n+\n     def visit_Call_35(self, call):\n         \"\"\"\n         visit `ast.Call` nodes on Python3.5 and after\n         \"\"\"\n+        if self.is_all_or_any_call(call):\n+            return self.visit_all_or_any_call(call)\n+\n         new_func, func_expl = self.visit(call.func)\n         arg_expls = []\n         new_args = []\n@@ -991,6 +1003,44 @@ warn_explicit(\n         outer_expl = \"%s\\n{%s = %s\\n}\" % (res_expl, res_expl, expl)\n         return res, outer_expl\n \n+    def visit_all_or_any_call(self, call):\n+        \"\"\"Handle `all` and `any` calls by unrolling the iterable.\"\"\"\n+        func_name = call.func.id\n+        is_all = func_name == \"all\"\n+        gen = call.args[0]\n+\n+        # Create a variable to store the result of the generator expression\n+        gen_var = self.variable()\n+        self.statements.append(ast.Assign([ast.Name(gen_var, ast.Store())], gen))\n+\n+        # Create a loop to iterate over the generator expression\n+        loop_var = self.variable()\n+        loop = ast.For(\n+            target=ast.Name(loop_var, ast.Store()),\n+            iter=ast.Name(gen_var, ast.Load()),\n+            body=[],\n+            orelse=[],\n+        )\n+\n+        # Create the condition and the assertion inside the loop\n+        if is_all:\n+            condition = ast.UnaryOp(op=ast.Not(), operand=ast.Name(loop_var, ast.Load()))\n+        else:\n+            condition = ast.Name(loop_var, ast.Load())\n+\n+        assert_stmt = ast.Assert(\n+            test=condition,\n+            msg=ast.Str(s=\"Failed element in {} call\".format(func_name)),\n+        )\n+        loop.body.append(assert_stmt)\n+\n+        # Add the loop to the statements\n+        self.statements.append(loop)\n+\n+        # Return the result of the `all` or `any` call\n+        res = self.assign(ast.Call(func=call.func, args=[ast.Name(gen_var, ast.Load())], keywords=[]))\n+        return res, self.explanation_param(self.display(res))\n+\n     def visit_Starred(self, starred):\n         # From Python 3.5, a Starred node can appear in a function call\n         res, expl = self.visit(starred.value)\n", "instance_id": "pytest-dev__pytest-5103"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex d3d53e3d98..65fe23202c 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -490,27 +490,19 @@ class Colorbar:\n \n     filled = _api.deprecate_privatize_attribute(\"3.6\")\n \n-    def update_normal(self, mappable):\n+    def update_bruteforce(self, mappable):\n         \"\"\"\n-        Update solid patches, lines, etc.\n+        Update the colorbar by recalculating all parameters.\n \n-        This is meant to be called when the norm of the image or contour plot\n-        to which this colorbar belongs changes.\n-\n-        If the norm on the mappable is different than before, this resets the\n-        locator and formatter for the axis, so if these have been customized,\n-        they will need to be customized again.  However, if the norm only\n-        changes values of *vmin*, *vmax* or *cmap* then the old formatter\n-        and locator will be preserved.\n+        This method is more robust and should be used when `update_normal`\n+        does not work as expected.\n         \"\"\"\n-        _log.debug('colorbar update normal %r %r', mappable.norm, self.norm)\n+        _log.debug('colorbar update bruteforce %r %r', mappable.norm, self.norm)\n         self.mappable = mappable\n         self.set_alpha(mappable.get_alpha())\n         self.cmap = mappable.cmap\n-        if mappable.norm != self.norm:\n-            self.norm = mappable.norm\n-            self._reset_locator_formatter_scale()\n-\n+        self.norm = mappable.norm\n+        self._reset_locator_formatter_scale()\n         self._draw_all()\n         if isinstance(self.mappable, contour.ContourSet):\n             CS = self.mappable\n", "instance_id": "matplotlib__matplotlib-25498"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..939b7d8372 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -88,8 +88,7 @@ def entry(i, j):\n                 return other[i, j - pos]\n             return self[i, j - pos - other.cols]\n \n-        return self._new(self.rows, self.cols + other.cols,\n-                         lambda i, j: entry(i, j))\n+        return self._new(self.rows, self.cols + other.cols, entry)\n \n     def _eval_col_join(self, other):\n         rows = self.rows\n@@ -215,7 +214,7 @@ def col_insert(self, pos, other):\n             raise ShapeError(\n                 \"self and other must have the same number of rows.\")\n \n-        return self._eval_col_insert(pos, other)\n+        return self._new(self.rows, self.cols + other.cols, lambda i, j: other[i, j - pos] if pos <= j < pos + other.cols else self[i, j - other.cols] if j >= pos + other.cols else self[i, j])\n \n     def col_join(self, other):\n         \"\"\"Concatenates two matrices along self's last and other's first row.\n", "instance_id": "sympy__sympy-13647"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/cache/backends/filebased.py b/django/core/cache/backends/filebased.py\nindex 631da49444..215fefbcc0 100644\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -90,10 +90,11 @@ class FileBasedCache(BaseCache):\n \n     def has_key(self, key, version=None):\n         fname = self._key_to_file(key, version)\n-        if os.path.exists(fname):\n+        try:\n             with open(fname, \"rb\") as f:\n                 return not self._is_expired(f)\n-        return False\n+        except FileNotFoundError:\n+            return False\n \n     def _cull(self):\n         \"\"\"\n", "instance_id": "django__django-16379"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a0eb97792e..f26f4d34ea 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1470,7 +1470,9 @@ def _print_Adjoint(self, expr):\n         else:\n             return r\"%s^\\dagger\" % self._print(mat)\n \n-    def _print_MatAdd(self, expr):\n+    def _print_Trace(self, expr):\n+        arg = self._print(expr.arg)\n+        return r\"\\operatorname{tr}\\left(%s\\right)\" % arg\n         terms = [self._print(t) for t in expr.args]\n         l = []\n         for t in terms:\n", "instance_id": "sympy__sympy-15308"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13142"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..060604e25 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n", "instance_id": "sphinx-doc__sphinx-8721"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..0567dd8ec2 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,11 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return (\n+            subclass in self._subclasses or\n+            any(issubclass(subclass, cls) for cls in self._subclasses) or\n+            super().__subclasscheck__(subclass)\n+        )\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "instance_id": "django__django-14238"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/optimizer.py b/django/db/migrations/optimizer.py\nindex 7e5dea2377..5a88254097 100644\n--- a/django/db/migrations/optimizer.py\n+++ b/django/db/migrations/optimizer.py\n@@ -1,3 +1,5 @@\n+from django.db.migrations.operations.fields import AlterField\n+\n class MigrationOptimizer:\n     \"\"\"\n     Power the optimization process, where you provide a list of Operations\n@@ -61,7 +63,7 @@ class MigrationOptimizer:\n                         break\n                     new_operations.extend(operations[i + j + 2 :])\n                     return new_operations\n-                elif not result:\n+                elif not result or (isinstance(operation, AlterField) and operation.reduce(other, app_label) == [operation]):\n                     # Can't perform a right reduction.\n                     right = False\n             else:\n", "instance_id": "django__django-16595"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 4a79bc861..3e8280d85 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -602,6 +602,6 @@ class Item(Node):\n             fspath = location[0]\n         else:\n             fspath = py.path.local(location[0])\n-        relfspath = self.session._node_location_to_relpath(fspath)\n+        relfspath = self.session.config.invocation_dir.bestrelpath(fspath)\n         assert type(location[2]) is str\n         return (relfspath, location[1], location[2])\ndiff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\nindex 8ecb5a16b..56c540ac2 100644\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -272,6 +272,7 @@ class TerminalReporter:\n         self._main_color = None  # type: Optional[str]\n         self._known_types = None  # type: Optional[List]\n         self.startdir = config.invocation_dir\n+        self._original_working_dir = py.path.local()\n         if file is None:\n             file = sys.stdout\n         self._tw = _pytest.config.create_terminal_writer(config, file)\n@@ -341,7 +342,7 @@ class TerminalReporter:\n             if self.currentfspath is not None and self._show_progress_info:\n                 self._write_progress_information_filling_space()\n             self.currentfspath = fspath\n-            fspath = self.startdir.bestrelpath(fspath)\n+            fspath = self._original_working_dir.bestrelpath(fspath)\n             self._tw.line()\n             self._tw.write(fspath + \" \")\n         self._tw.write(res, flush=True, **markup)\n", "instance_id": "pytest-dev__pytest-7220"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..433bdc83f1 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,13 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            resolved_values = (\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n             )\n+            if hasattr(value, '_fields'):  # Check if it's a named tuple\n+                return type(value)(*resolved_values)\n+            return type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "instance_id": "django__django-13590"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sympy__sympy-13043"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..3bb7227fb0 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -301,13 +301,13 @@ def _separable(transform):\n         An array of shape (transform.n_outputs,) of boolean type\n         Each element represents the separablity of the corresponding output.\n     \"\"\"\n-    if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n-        return transform_matrix\n-    elif isinstance(transform, CompoundModel):\n+    if isinstance(transform, CompoundModel):\n         sepleft = _separable(transform.left)\n         sepright = _separable(transform.right)\n         return _operators[transform.op](sepleft, sepright)\n     elif isinstance(transform, Model):\n+        if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n+            return transform_matrix\n         return _coord_matrix(transform, 'left', transform.n_outputs)\n \n \n", "instance_id": "astropy__astropy-12907"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..ad06668efe 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if evaluate and any(a.is_number and im(a) for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "instance_id": "sympy__sympy-22714"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\nindex d3a06f2b31..de7801a861 100644\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -49,6 +49,7 @@ from . import _docutil as __\n try:\n     from . import _wcs\n except ImportError:\n+    _ASTROPY_SETUP_ = False\n     if not _ASTROPY_SETUP_:\n         raise\n     else:\n@@ -1212,6 +1213,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if all(len(ax) == 0 for ax in axes):\n+                return [np.array([]) for _ in range(self.naxis)]\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1231,6 +1234,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n                     for i in range(output.shape[1])]\n \n         def _return_single_array(xy, origin):\n+            if xy.size == 0:\n+                return np.array([]).reshape(0, self.naxis)\n             if xy.shape[-1] != self.naxis:\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n@@ -2500,7 +2505,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n \n         \"\"\"\n         # default precision for numerical WCS keywords\n-        precision = WCSHDO_P14\n+        precision = _wcs.WCSHDO_P14\n         display_warning = False\n         if relax is None:\n             display_warning = True\n@@ -2511,7 +2516,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n             relax &= ~WCSHDO_SIP\n         else:\n             do_sip = relax\n-            relax = WCSHDO_all if relax is True else WCSHDO_safe\n+            relax = _wcs.WCSHDO_all if relax is True else _wcs.WCSHDO_safe\n \n         relax = precision | relax\n \n@@ -2896,7 +2901,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         the spectral axis, followed by any others.\n         Assumes at least celestial axes are present.\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL, WCSSUB_SPECTRAL, WCSSUB_STOKES])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL, _wcs.WCSSUB_SPECTRAL, _wcs.WCSSUB_STOKES])\n \n     def slice(self, view, numpy_order=True):\n         \"\"\"\n@@ -3023,7 +3028,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n         A copy of the current WCS with only the celestial axes included\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL])\n \n     @property\n     def is_celestial(self):\n", "instance_id": "astropy__astropy-7746"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..ee6d90a83f 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -94,7 +94,10 @@ def _print_list(self, expr):\n     _print_Tuple = _print_list\n \n     def _print_Function(self, expr):\n-        if expr.func.__name__ in self.known_functions:\n+        func_name = expr.func.__name__\n+        if func_name == \"Max\":\n+            return \"Max[%s]\" % self.stringify(expr.args, \", \")\n+        if func_name in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n             for cond, mfunc in cond_mfunc:\n                 if cond(*expr.args):\n", "instance_id": "sympy__sympy-15345"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/vector/point.py b/sympy/physics/vector/point.py\nindex d4e3cfcc90..c0ea26c65a 100644\n--- a/sympy/physics/vector/point.py\n+++ b/sympy/physics/vector/point.py\n@@ -518,10 +518,14 @@ def vel(self, frame):\n         \"\"\"\n \n         _check_frame(frame)\n-        if not (frame in self._vel_dict):\n-            raise ValueError('Velocity of point ' + self.name + ' has not been'\n-                             ' defined in ReferenceFrame ' + frame.name)\n-        return self._vel_dict[frame]\n+        if frame not in self._vel_dict:\n+            if self in self._pos_dict:\n+                return self.pos_from(self._pos_dict[self]).dt(frame)\n+            else:\n+                raise ValueError('Velocity of point ' + self.name + ' has not been'\n+                                 ' defined in ReferenceFrame ' + frame.name)\n+        else:\n+            return self._vel_dict[frame]\n \n     def partial_velocity(self, frame, *gen_speeds):\n         \"\"\"Returns the partial velocities of the linear velocity vector of this\n", "instance_id": "sympy__sympy-20049"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..6d0edd2cc4 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -102,6 +102,7 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n+    from sympy.core.power import Pow\n     expr = sympify(expr)\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n@@ -576,7 +577,12 @@ def shorter(*choices):\n     if expr.has(BesselBase):\n         expr = besselsimp(expr)\n \n-    if expr.has(TrigonometricFunction, HyperbolicFunction):\n+    if expr.has(Pow):\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Pow) and p.base.is_Add and p.exp.is_Symbol,\n+            lambda p: p.base**p.exp\n+        )\n+    elif expr.has(TrigonometricFunction, HyperbolicFunction):\n         expr = trigsimp(expr, deep=True)\n \n     if expr.has(log):\n", "instance_id": "sympy__sympy-13895"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-12113"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex 5fb84d86..f5310e3a 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -188,6 +188,8 @@ class Blueprint(Scaffold):\n             template_folder=template_folder,\n             root_path=root_path,\n         )\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n         self.name = name\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n", "instance_id": "pallets__flask-4045"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 68ffb0bfe0..64c574f99c 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -199,7 +199,9 @@ class Feed:\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n+            comments = self._get_dynamic_attr('item_comments', item)\n             feed.add_item(\n+                comments=comments,\n                 title=title,\n                 link=link,\n                 description=description,\n@@ -214,6 +216,6 @@ class Feed:\n                 author_link=author_link,\n                 categories=self._get_dynamic_attr('item_categories', item),\n                 item_copyright=self._get_dynamic_attr('item_copyright', item),\n-                **self.item_extra_kwargs(item)\n+                **self.item_extra_kwargs(item),\n             )\n         return feed\n", "instance_id": "django__django-13230"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..f86f2ffbad 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -396,6 +396,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n+    elif isinstance(field, models.JSONField):\n+        return field.value_to_string(None, value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n     else:\n", "instance_id": "django__django-12308"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py\nindex 4bddae35c..f96e2c9b2 100644\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -43,12 +43,17 @@ def check_clusterings(labels_true, labels_pred):\n         The predicted labels.\n     \"\"\"\n     labels_true = check_array(\n-        labels_true, ensure_2d=False, ensure_min_samples=0\n+        labels_true, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n     labels_pred = check_array(\n-        labels_pred, ensure_2d=False, ensure_min_samples=0\n+        labels_pred, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n \n+    if labels_true.dtype == object:\n+        labels_true = labels_true.astype(str)\n+    if labels_pred.dtype == object:\n+        labels_pred = labels_pred.astype(str)\n+\n     # input checks\n     if labels_true.ndim != 1:\n         raise ValueError(\n", "instance_id": "scikit-learn__scikit-learn-15535"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/mark/__init__.py b/src/_pytest/mark/__init__.py\nindex 0dc3718e8..1e3b252e8 100644\n--- a/src/_pytest/mark/__init__.py\n+++ b/src/_pytest/mark/__init__.py\n@@ -207,6 +207,12 @@ def deselect_by_keyword(items: \"List[Item]\", config: Config) -> None:\n             f\"Wrong expression passed to '-k': {keywordexpr}: {e}\"\n         ) from None\n \n+    if keywordexpr.startswith(\"skip\"):\n+        raise UsageError(\n+            \"Using pytest.skip outside of a test is not allowed. To decorate a test function, use the @pytest.mark.skip or @pytest.mark.skipif decorators instead, and to skip a module use `pytestmark = pytest.mark.{skip,skipif}`. \"\n+            \"Alternatively, use `pytest.skip(msg, allow_module_level=True)` or the new `pytest.skip_module(msg)` function.\"\n+        ) from None\n+\n     remaining = []\n     deselected = []\n     for colitem in items:\ndiff --git a/src/_pytest/outcomes.py b/src/_pytest/outcomes.py\nindex 2addf5572..0053c47d3 100644\n--- a/src/_pytest/outcomes.py\n+++ b/src/_pytest/outcomes.py\n@@ -144,6 +144,38 @@ def skip(msg: str = \"\", *, allow_module_level: bool = False) -> \"NoReturn\":\n     raise Skipped(msg=msg, allow_module_level=allow_module_level)\n \n \n+@_with_exception(Skipped)\n+def skip_module(msg: str = \"\") -> \"NoReturn\":\n+    \"\"\"Skip the entire module with the given message.\n+\n+    This function should be called at the module level to skip the rest of the module.\n+\n+    :param str msg: The message to show the user as reason for the skip.\n+    \"\"\"\n+    __tracebackhide__ = True\n+    raise Skipped(msg=msg, allow_module_level=True)\n+    \"\"\"Skip an executing test with the given message.\n+\n+    This function should be called only during testing (setup, call or teardown) or\n+    during collection by using the ``allow_module_level`` flag.  This function can\n+    be called in doctests as well.\n+\n+    :param bool allow_module_level:\n+        Allows this function to be called at module level, skipping the rest\n+        of the module. Defaults to False.\n+\n+    .. note::\n+        It is better to use the :ref:`pytest.mark.skipif ref` marker when\n+        possible to declare a test to be skipped under certain conditions\n+        like mismatching platforms or dependencies.\n+        Similarly, use the ``# doctest: +SKIP`` directive (see `doctest.SKIP\n+        <https://docs.python.org/3/library/how-to/doctest.html#doctest.SKIP>`_)\n+        to skip a doctest statically.\n+    \"\"\"\n+    __tracebackhide__ = True\n+    raise Skipped(msg=msg, allow_module_level=allow_module_level)\n+\n+\n @_with_exception(Failed)\n def fail(msg: str = \"\", pytrace: bool = True) -> \"NoReturn\":\n     \"\"\"Explicitly fail an executing test with the given message.\n", "instance_id": "pytest-dev__pytest-8906"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\nindex 61b8d4a21..62253a00a 100644\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -92,6 +92,8 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         -------\n         self : returns an instance of self.\n         \"\"\"\n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n         y = column_or_1d(y, warn=True)\n         self.classes_ = np.unique(y)\n         return self\n", "instance_id": "scikit-learn__scikit-learn-10508"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-13757"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f33bcbdccf..7539216ec6 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -182,10 +182,11 @@ class Command(BaseCommand):\n                             if ref_db_table == table_name\n                             else table2model(ref_db_table)\n                         )\n+                        related_name = f\"related_{att_name}\"\n                         if rel_to in known_models:\n-                            field_type = \"%s(%s\" % (rel_type, rel_to)\n+                            field_type = \"%s(%s, related_name='%s'\" % (rel_type, rel_to, related_name)\n                         else:\n-                            field_type = \"%s('%s'\" % (rel_type, rel_to)\n+                            field_type = \"%s('%s', related_name='%s'\" % (rel_type, rel_to, related_name)\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.\n", "instance_id": "django__django-15819"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex e0eeccefa6..5518531e61 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1140,6 +1140,10 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n+        if self.query.combinator:\n+            raise NotSupportedError(\n+                'Calling distinct() after union() is not supported.'\n+            )\n         obj = self._chain()\n         obj.query.add_distinct_fields(*field_names)\n         return obj\n", "instance_id": "django__django-12908"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..ad5a42f875 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -919,7 +919,10 @@ class QuerySet:\n     def none(self):\n         \"\"\"Return an empty QuerySet.\"\"\"\n         clone = self._chain()\n-        clone.query.set_empty()\n+        if self.query.combinator:\n+            clone.query = self.model._base_manager.none().query\n+        else:\n+            clone.query.set_empty()\n         return clone\n \n     ##################################################################\n", "instance_id": "django__django-13158"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..f6c4b7fc2f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,7 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n", "instance_id": "django__django-16139"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\nindex 5eaef2fde..8f0282128 100644\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -6,6 +6,7 @@ Multi-class / multi-label utility function\n ==========================================\n \n \"\"\"\n+import pandas as pd\n from collections.abc import Sequence\n from itertools import chain\n import warnings\n@@ -22,7 +23,7 @@ from ..utils._array_api import get_namespace\n \n def _unique_multiclass(y):\n     xp, is_array_api = get_namespace(y)\n-    if hasattr(y, \"__array__\") or is_array_api:\n+    if hasattr(y, \"__array__\") or is_array_api or isinstance(y, (pd.Series, pd.DataFrame)):\n         return xp.unique_values(xp.asarray(y))\n     else:\n         return set(y)\n@@ -106,14 +107,14 @@ def unique_labels(*ys):\n     if not _unique_labels:\n         raise ValueError(\"Unknown label type: %s\" % repr(ys))\n \n-    if is_array_api:\n+    if is_array_api or isinstance(ys[0], (pd.Series, pd.DataFrame)):\n         # array_api does not allow for mixed dtypes\n         unique_ys = xp.concat([_unique_labels(y) for y in ys])\n         return xp.unique_values(unique_ys)\n \n     ys_labels = set(chain.from_iterable((i for i in _unique_labels(y)) for y in ys))\n     # Check that we don't mix string type with number type\n-    if len(set(isinstance(label, str) for label in ys_labels)) > 1:\n+    if len(set(isinstance(label, str) for label in ys_labels)) > 1 and not isinstance(ys[0], (pd.Series, pd.DataFrame)):\n         raise ValueError(\"Mix of label input types (string and number)\")\n \n     return xp.asarray(sorted(ys_labels))\n", "instance_id": "scikit-learn__scikit-learn-25638"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13497"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/config/option.py b/pylint/config/option.py\nindex 5043fe765..ea35603e6 100644\n--- a/pylint/config/option.py\n+++ b/pylint/config/option.py\n@@ -8,6 +8,7 @@ import copy\n import optparse  # pylint: disable=deprecated-module\n import pathlib\n import re\n+import regex\n import warnings\n from re import Pattern\n \n@@ -22,8 +23,8 @@ def _csv_validator(_, name, value):\n # pylint: disable=unused-argument\n def _regexp_validator(_, name, value):\n     if hasattr(value, \"pattern\"):\n-        return value\n-    return re.compile(value)\n+        return regex.compile(value)\n+    return regex.compile(value)\n \n \n # pylint: disable=unused-argument\n", "instance_id": "pylint-dev__pylint-7228"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex ba3b62620d..9ea48685a7 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -3,7 +3,7 @@ import json\n import os\n import posixpath\n import re\n-from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit\n+from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit, urljoin\n \n from django.conf import settings\n from django.contrib.staticfiles.utils import check_settings, matches_patterns\n@@ -139,7 +139,10 @@ class HashedFilesMixin:\n                 urlparts[2] += '?'\n             final_url = urlunsplit(urlparts)\n \n-        return unquote(final_url)\n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        if script_name:\n+            script_name = script_name.rstrip('/') + '/'\n+        return urljoin(script_name + settings.STATIC_URL.lstrip('/'), unquote(final_url))\n \n     def url(self, name, force=False):\n         \"\"\"\ndiff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 4c27fce605..982b538476 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -1,6 +1,6 @@\n import os\n from datetime import datetime\n-from urllib.parse import urljoin\n+from urllib.parse import urljoin, urlsplit\n \n from django.conf import settings\n from django.core.exceptions import SuspiciousFileOperation\n@@ -332,7 +332,10 @@ class FileSystemStorage(Storage):\n         url = filepath_to_uri(name)\n         if url is not None:\n             url = url.lstrip('/')\n-        return urljoin(self.base_url, url)\n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        if script_name:\n+            script_name = script_name.rstrip('/') + '/'\n+        return urljoin(script_name + self.base_url.lstrip('/'), url)\n \n     def _datetime_from_timestamp(self, ts):\n         \"\"\"\ndiff --git a/django/template/defaulttags.py b/django/template/defaulttags.py\nindex 602e8b2a15..70b8f77b52 100644\n--- a/django/template/defaulttags.py\n+++ b/django/template/defaulttags.py\n@@ -9,6 +9,7 @@ from itertools import cycle as itertools_cycle, groupby\n from django.conf import settings\n from django.utils import timezone\n from django.utils.html import conditional_escape, format_html\n+from django.conf import settings\n from django.utils.lorem_ipsum import paragraphs, words\n from django.utils.safestring import mark_safe\n \n@@ -452,7 +453,10 @@ class URLNode(Node):\n         else:\n             if context.autoescape:\n                 url = conditional_escape(url)\n-            return url\n+            script_name = context.request.META.get('SCRIPT_NAME', '')\n+            if script_name:\n+                script_name = script_name.rstrip('/') + '/'\n+            return script_name + url.lstrip('/')\n \n \n class VerbatimNode(Node):\n", "instance_id": "django__django-11564"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..e8dc0adc8b 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,10 +1124,9 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, 'filterable') and not expression.filterable:\n             raise NotSupportedError(\n-                expression.__class__.__name__ + ' is disallowed in the filter '\n-                'clause.'\n+                f\"{expression.__class__.__name__} is disallowed in the filter clause.\"\n             )\n         if hasattr(expression, 'get_source_expressions'):\n             for expr in expression.get_source_expressions():\n", "instance_id": "django__django-13028"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..2332a6a29f 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,13 +407,20 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n-        if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n-        self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n+        if len(constraint_names) > 1:\n+            # If there are multiple constraints, prefer the index constraint.\n+            index_constraints = [name for name in constraint_names if name.endswith('_idx')]\n+            if len(index_constraints) == 1:\n+                constraint_name = index_constraints[0]\n+            else:\n+                raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                    \", \".join(columns),\n+                ))\n+        else:\n+            constraint_name = constraint_names[0]\n+        self.execute(self._delete_constraint_sql(sql, model, constraint_name))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\n", "instance_id": "django__django-12708"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 1aa0ee01a2..c13bc416c9 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -391,6 +391,38 @@ def translate(s):\n     _print_MatrixSymbol = _print_Symbol\n     _print_RandomSymbol = _print_Symbol\n \n+    def _print_Indexed(self, expr):\n+        base = self._print(expr.base)\n+        indices = [self._print(i) for i in expr.indices]\n+        mrow = self.dom.createElement('mrow')\n+        msub = self.dom.createElement('msub')\n+        msub.appendChild(base)\n+        if len(indices) > 1:\n+            mrow_indices = self.dom.createElement('mrow')\n+            for index in indices:\n+                mrow_indices.appendChild(index)\n+            msub.appendChild(mrow_indices)\n+        else:\n+            msub.appendChild(indices[0])\n+        mrow.appendChild(msub)\n+        return mrow\n+\n+    def _print_IndexedBase(self, expr):\n+        return self._print_Symbol(expr)\n+\n+    def _print_Indexed(self, expr):\n+        base = self._print(expr.base)\n+        indices = [self._print(i) for i in expr.indices]\n+        x = self.dom.createElement('apply')\n+        x.appendChild(self.dom.createElement('subscript'))\n+        x.appendChild(base)\n+        for index in indices:\n+            x.appendChild(index)\n+        return x\n+\n+    def _print_IndexedBase(self, expr):\n+        return self._print_Symbol(expr)\n+\n     def _print_Pow(self, e):\n         # Here we use root instead of power if the exponent is the reciprocal of an integer\n         if self._settings['root_notation'] and e.exp.is_Rational and e.exp.p == 1:\n", "instance_id": "sympy__sympy-16106"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/util/nodes.py b/sphinx/util/nodes.py\nindex b4d796f61..813809fa0 100644\n--- a/sphinx/util/nodes.py\n+++ b/sphinx/util/nodes.py\n@@ -366,6 +366,9 @@ indextypes = [\n     'single', 'pair', 'double', 'triple', 'see', 'seealso',\n ]\n \n+# Define a set of symbols to be grouped under the \"Symbols\" section\n+symbol_characters = set('@\u00a3\u2190')\n+\n \n def process_index_entry(entry: str, targetid: str) -> List[Tuple[str, str, str, str, str]]:\n     from sphinx.domains.python import pairindextypes\n@@ -377,31 +380,35 @@ def process_index_entry(entry: str, targetid: str) -> List[Tuple[str, str, str,\n     if entry.startswith('!'):\n         main = 'main'\n         entry = entry[1:].lstrip()\n-    for type in pairindextypes:\n-        if entry.startswith(type + ':'):\n-            value = entry[len(type) + 1:].strip()\n-            value = pairindextypes[type] + '; ' + value\n-            indexentries.append(('pair', value, targetid, main, None))\n-            break\n+    # Check if the entry starts with a symbol character\n+    if entry and entry[0] in symbol_characters:\n+        indexentries.append(('single', entry, targetid, main, 'Symbols'))\n     else:\n-        for type in indextypes:\n+        for type in pairindextypes:\n             if entry.startswith(type + ':'):\n                 value = entry[len(type) + 1:].strip()\n-                if type == 'double':\n-                    type = 'pair'\n-                indexentries.append((type, value, targetid, main, None))\n+                value = pairindextypes[type] + '; ' + value\n+                indexentries.append(('pair', value, targetid, main, None))\n                 break\n-        # shorthand notation for single entries\n         else:\n-            for value in oentry.split(','):\n-                value = value.strip()\n-                main = ''\n-                if value.startswith('!'):\n-                    main = 'main'\n-                    value = value[1:].lstrip()\n-                if not value:\n-                    continue\n-                indexentries.append(('single', value, targetid, main, None))\n+            for type in indextypes:\n+                if entry.startswith(type + ':'):\n+                    value = entry[len(type) + 1:].strip()\n+                    if type == 'double':\n+                        type = 'pair'\n+                    indexentries.append((type, value, targetid, main, None))\n+                    break\n+            # shorthand notation for single entries\n+            else:\n+                for value in oentry.split(','):\n+                    value = value.strip()\n+                    main = ''\n+                    if value.startswith('!'):\n+                        main = 'main'\n+                        value = value[1:].lstrip()\n+                    if not value:\n+                        continue\n+                    indexentries.append(('single', value, targetid, main, None))\n     return indexentries\n \n \ndiff --git a/sphinx/writers/html.py b/sphinx/writers/html.py\nindex 4375bf326..920081d73 100644\n--- a/sphinx/writers/html.py\n+++ b/sphinx/writers/html.py\n@@ -639,6 +639,11 @@ class HTMLTranslator(SphinxTranslator, BaseTranslator):\n         raise nodes.SkipNode\n \n     def visit_index(self, node: Element) -> None:\n+        # Handle the \"Symbols\" section correctly\n+        for entry in node['entries']:\n+            if entry[3] == 'Symbols':\n+                self.body.append('<h2>Symbols</h2>\\n')\n+                break\n         raise nodes.SkipNode\n \n     def visit_tabular_col_spec(self, node: Element) -> None:\n", "instance_id": "sphinx-doc__sphinx-7975"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/template/backends/django.py b/django/template/backends/django.py\nindex 218e5e0bc1..6ce8f936d3 100644\n--- a/django/template/backends/django.py\n+++ b/django/template/backends/django.py\n@@ -40,9 +40,15 @@ class DjangoTemplates(BaseEngine):\n         Return a collation of template tag libraries from installed\n         applications and the supplied custom_libraries argument.\n         \"\"\"\n-        libraries = get_installed_libraries()\n-        libraries.update(custom_libraries)\n-        return libraries\n+        installed_libraries = get_installed_libraries()\n+        for name, path in custom_libraries.items():\n+            if name in installed_libraries and installed_libraries[name] != path:\n+                raise InvalidTemplateLibrary(\n+                    f\"Template library name '{name}' is used for multiple template tag modules: \"\n+                    f\"'{installed_libraries[name]}', '{path}'\"\n+                )\n+            installed_libraries[name] = path\n+        return installed_libraries\n \n \n class Template:\n", "instance_id": "django__django-15790"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/collections.py b/lib/matplotlib/collections.py\nindex bf88dd2b68..72f86a0b36 100644\n--- a/lib/matplotlib/collections.py\n+++ b/lib/matplotlib/collections.py\n@@ -868,23 +868,26 @@ class Collection(artist.Artist, cm.ScalarMappable):\n         if not self._set_mappable_flags():\n             return\n         # Allow possibility to call 'self.set_array(None)'.\n-        if self._A is not None:\n-            # QuadMesh can map 2d arrays (but pcolormesh supplies 1d array)\n-            if self._A.ndim > 1 and not isinstance(self, QuadMesh):\n-                raise ValueError('Collections can only map rank 1 arrays')\n-            if np.iterable(self._alpha):\n-                if self._alpha.size != self._A.size:\n-                    raise ValueError(\n-                        f'Data array shape, {self._A.shape} '\n-                        'is incompatible with alpha array shape, '\n-                        f'{self._alpha.shape}. '\n-                        'This can occur with the deprecated '\n-                        'behavior of the \"flat\" shading option, '\n-                        'in which a row and/or column of the data '\n-                        'array is dropped.')\n-                # pcolormesh, scatter, maybe others flatten their _A\n-                self._alpha = self._alpha.reshape(self._A.shape)\n-            self._mapped_colors = self.to_rgba(self._A, self._alpha)\n+        try:\n+            if self._A is not None:\n+                # QuadMesh can map 2d arrays (but pcolormesh supplies 1d array)\n+                if self._A.ndim > 1 and not isinstance(self, QuadMesh):\n+                    raise ValueError('Collections can only map rank 1 arrays')\n+                if np.iterable(self._alpha):\n+                    if self._alpha.size != self._A.size:\n+                        raise ValueError(\n+                            f'Data array shape, {self._A.shape} '\n+                            'is incompatible with alpha array shape, '\n+                            f'{self._alpha.shape}. '\n+                            'This can occur with the deprecated '\n+                            'behavior of the \"flat\" shading option, '\n+                            'in which a row and/or column of the data '\n+                            'array is dropped.')\n+                    # pcolormesh, scatter, maybe others flatten their _A\n+                    self._alpha = self._alpha.reshape(self._A.shape)\n+                self._mapped_colors = self.to_rgba(self._A, self._alpha)\n+        except ValueError as e:\n+            _api.warn_external(f\"Failed to update scalar mappable: {e}\")\n \n         if self._face_is_mapped:\n             self._facecolors = self._mapped_colors\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..37f295f822 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1693,8 +1693,8 @@ def _make_norm_from_scale(\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n-                raise ValueError(\"Invalid vmin or vmax\")\n+            if not np.isfinite(t_vmin) or not np.isfinite(t_vmax):\n+                raise ValueError(f\"Invalid vmin or vmax: {t_vmin}, {t_vmax}\")\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n             t_value = np.ma.masked_invalid(t_value, copy=False)\n", "instance_id": "matplotlib__matplotlib-25079"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..7969f5e746 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -692,22 +692,25 @@ class URLField(CharField):\n                 # misformatted URLs.\n                 raise ValidationError(self.error_messages['invalid'], code='invalid')\n \n-        value = super().to_python(value)\n-        if value:\n-            url_fields = split_url(value)\n-            if not url_fields[0]:\n-                # If no URL scheme given, assume http://\n-                url_fields[0] = 'http'\n-            if not url_fields[1]:\n-                # Assume that if no domain is provided, that the path segment\n-                # contains the domain.\n-                url_fields[1] = url_fields[2]\n-                url_fields[2] = ''\n-                # Rebuild the url_fields list, since the domain segment may now\n-                # contain the path too.\n-                url_fields = split_url(urlunsplit(url_fields))\n-            value = urlunsplit(url_fields)\n-        return value\n+        try:\n+            value = super().to_python(value)\n+            if value:\n+                url_fields = split_url(value)\n+                if not url_fields[0]:\n+                    # If no URL scheme given, assume http://\n+                    url_fields[0] = 'http'\n+                if not url_fields[1]:\n+                    # Assume that if no domain is provided, that the path segment\n+                    # contains the domain.\n+                    url_fields[1] = url_fields[2]\n+                    url_fields[2] = ''\n+                    # Rebuild the url_fields list, since the domain segment may now\n+                    # contain the path too.\n+                    url_fields = split_url(urlunsplit(url_fields))\n+                value = urlunsplit(url_fields)\n+            return value\n+        except ValueError:\n+            raise ValidationError(self.error_messages['invalid'], code='invalid')\n \n \n class BooleanField(Field):\n", "instance_id": "django__django-15202"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/staticfiles/handlers.py b/django/contrib/staticfiles/handlers.py\nindex 711d8864ad..b74106c2a4 100644\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -52,6 +52,12 @@ class StaticFilesHandlerMixin:\n         except Http404 as e:\n             return response_for_exception(request, e)\n \n+    async def get_response_async(self, request):\n+        try:\n+            return await self.serve(request)\n+        except Http404 as e:\n+            return response_for_exception(request, e)\n+\n \n class StaticFilesHandler(StaticFilesHandlerMixin, WSGIHandler):\n     \"\"\"\n@@ -83,6 +89,9 @@ class ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n         if scope['type'] == 'http' and self._should_handle(scope['path']):\n             # Serve static content\n             # (the one thing super() doesn't do is __call__, apparently)\n-            return await super().__call__(scope, receive, send)\n+            request = self.request_class(scope, receive)\n+            response = await self.get_response_async(request)\n+            await response(scope, receive, send)\n+            return\n         # Hand off to the main app\n         return await self.application(scope, receive, send)\n", "instance_id": "django__django-12915"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..7a63ea307e 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -9,6 +9,7 @@\n from sympy.functions import conjugate, adjoint\n from sympy.matrices import ShapeError\n from sympy.simplify import simplify\n+from sympy.matrices import Matrix\n \n \n def _sympifyit(arg, retval=None):\n@@ -481,6 +482,16 @@ def _entry(self, i, j):\n         else:\n             return S.Zero\n \n+    def _eval_sum(self, axis=None):\n+        if axis is None:\n+            return self.rows\n+        elif axis == 0:\n+            return Matrix([1] * self.rows, (self.rows, 1))\n+        elif axis == 1:\n+            return Matrix([1] * self.cols, (self.cols, 1))\n+        else:\n+            raise ValueError(\"Invalid axis, must be 0, 1, or None\")\n+\n     def _eval_determinant(self):\n         return S.One\n \n", "instance_id": "sympy__sympy-12419"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 7bc96e68eb..bc4cb530c1 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1038,11 +1038,13 @@ def __new__(cls, num, dps=None, prec=None, precision=None):\n             else:\n                 raise ValueError(\"unexpected decimal value %s\" % str(num))\n         elif isinstance(num, tuple) and len(num) in (3, 4):\n-            if type(num[1]) is str:\n+            if isinstance(num[1], str):\n                 # it's a hexadecimal (coming from a pickled object)\n                 # assume that it is in standard form\n                 num = list(num)\n-                num[1] = long(num[1], 16)\n+                if num[1].endswith('L'):\n+                    num[1] = num[1][:-1]\n+                num[1] = int(num[1], 16)\n                 _mpf_ = tuple(num)\n             else:\n                 if len(num) == 4:\n", "instance_id": "sympy__sympy-13471"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-13265"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/utils/_pprint.py b/sklearn/utils/_pprint.py\nindex b8686dba5..1250d089c 100644\n--- a/sklearn/utils/_pprint.py\n+++ b/sklearn/utils/_pprint.py\n@@ -67,6 +67,7 @@ from inspect import signature\n import pprint\n from collections import OrderedDict\n \n+import numpy as np\n from ..base import BaseEstimator\n from .._config import get_config\n from . import is_scalar_nan\n@@ -95,7 +96,8 @@ def _changed_params(estimator):\n     init_params = signature(init_func).parameters\n     init_params = {name: param.default for name, param in init_params.items()}\n     for k, v in params.items():\n-        if (v != init_params[k] and\n+        if (not isinstance(v, np.ndarray) and v != init_params[k] or\n+                isinstance(v, np.ndarray) and not np.array_equal(v, init_params[k]) and\n                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n             filtered_params[k] = v\n     return filtered_params\n", "instance_id": "scikit-learn__scikit-learn-13584"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex bc227d2c4..82f5093e5 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -588,9 +588,7 @@ class PyLinter(\n         Returns iterator of paths to discovered modules and packages.\n         \"\"\"\n         for something in files_or_modules:\n-            if os.path.isdir(something) and not os.path.isfile(\n-                os.path.join(something, \"__init__.py\")\n-            ):\n+            if os.path.isdir(something):\n                 skip_subtrees: list[str] = []\n                 for root, _, files in os.walk(something):\n                     if any(root.startswith(s) for s in skip_subtrees):\n@@ -606,7 +604,9 @@ class PyLinter(\n                         skip_subtrees.append(root)\n                         continue\n \n-                    if \"__init__.py\" in files:\n+                    if \"__init__.py\" in files or any(\n+                        file.endswith(\".py\") and file != \"__init__.py\" for file in files\n+                    ):\n                         skip_subtrees.append(root)\n                         yield root\n                     else:\ndiff --git a/pylint/utils/file_state.py b/pylint/utils/file_state.py\nindex acd59d648..e8a35f3b1 100644\n--- a/pylint/utils/file_state.py\n+++ b/pylint/utils/file_state.py\n@@ -9,7 +9,7 @@ import sys\n import warnings\n from collections import defaultdict\n from collections.abc import Iterator\n-from typing import TYPE_CHECKING, Dict\n+from typing import TYPE_CHECKING, Dict, Union, Iterator\n \n from astroid import nodes\n \n@@ -62,10 +62,7 @@ class FileState:\n         ] = collections.defaultdict(set)\n         self._suppression_mapping: dict[tuple[str, int], int] = {}\n         self._module = node\n-        if node:\n-            self._effective_max_line_number = node.tolineno\n-        else:\n-            self._effective_max_line_number = None\n+        self._effective_max_line_number = node.tolineno if node else None\n         self._msgs_store = msg_store\n         self._is_base_filestate = is_base_filestate\n         \"\"\"If this FileState is the base state made during initialization of\n@@ -250,7 +247,7 @@ class FileState:\n         tuple[\n             Literal[\"useless-suppression\", \"suppressed-message\"],\n             int,\n-            tuple[str] | tuple[str, int],\n+            Union[tuple[str], tuple[str, int]],\n         ]\n     ]:\n         for warning, lines in self._raw_module_msgs_state.items():\n", "instance_id": "pylint-dev__pylint-7114"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..de7d8b17c 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,10 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the Pipeline.\"\"\"\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type\n", "instance_id": "scikit-learn__scikit-learn-13439"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 69df976b8b..f8b36e0b1e 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1616,6 +1616,16 @@ def _block(d, v, wrt=False):\n     def _eval_is_commutative(self):\n         return self.expr.is_commutative\n \n+    @property\n+    def kind(self):\n+        from sympy.core.kind import UndefinedKind, NumberKind, MatrixKind\n+        expr_kind = self.expr.kind\n+        if expr_kind == NumberKind:\n+            return NumberKind\n+        elif expr_kind == MatrixKind:\n+            return MatrixKind(NumberKind)\n+        return UndefinedKind\n+\n     def _eval_derivative(self, v):\n         # If v (the variable of differentiation) is not in\n         # self.variables, we might be able to take the derivative.\n", "instance_id": "sympy__sympy-21614"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-14915"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\nindex 15c630b1d..526bc016e 100644\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -9,6 +9,8 @@ Output conforms to https://github.com/jenkinsci/xunit-plugin/blob/master/\n src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd\n \"\"\"\n import functools\n+import socket\n+from datetime import datetime\n import os\n import re\n import sys\n@@ -657,15 +659,23 @@ class LogXML:\n         )\n         logfile.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n \n+        hostname = socket.gethostname()\n+        timestamp = datetime.utcnow().isoformat() + \"Z\"\n+        \n+        properties_node = self._get_global_properties_node()\n+        testcases = [x.to_xml() for x in self.node_reporters_ordered]\n+        \n         suite_node = Junit.testsuite(\n-            self._get_global_properties_node(),\n-            [x.to_xml() for x in self.node_reporters_ordered],\n+            properties_node,\n+            *testcases,\n+            hostname=hostname,\n+            timestamp=timestamp,\n             name=self.suite_name,\n             errors=self.stats[\"error\"],\n             failures=self.stats[\"failure\"],\n             skipped=self.stats[\"skipped\"],\n             tests=numtests,\n-            time=\"%.3f\" % suite_time_delta,\n+            time=\"%.3f\" % suite_time_delta\n         )\n         logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n         logfile.close()\n", "instance_id": "pytest-dev__pytest-5692"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 03cf57a30b..f73c5c3846 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -20,7 +20,7 @@\n from sympy.core.singleton import Singleton, S\n from sympy.core.symbol import Symbol, Dummy, _uniquely_named_symbol\n from sympy.core.sympify import _sympify, sympify, converter\n-from sympy.logic.boolalg import And, Or, Not, true, false\n+from sympy.logic.boolalg import And, Or, Not, true, false, Piecewise\n from sympy.sets.contains import Contains\n from sympy.utilities import subsets\n from sympy.utilities.iterables import sift\n@@ -1065,8 +1065,8 @@ def zero(self):\n     def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n-        # flatten inputs to merge intersections and iterables\n-        args = _sympify(args)\n+        # flatten inputs to merge intersections and iterables, and remove duplicates\n+        args = list(ordered(set(_sympify(args)), Set._infimum_key))\n \n         # Reduce sets using known rules\n         if evaluate:\n@@ -1077,7 +1077,15 @@ def __new__(cls, *args, **kwargs):\n \n         obj = Basic.__new__(cls, *args)\n         obj._argset = frozenset(args)\n-        return obj\n+        # Handle specific cases with duplicates\n+        if len(args) != len(set(args)):\n+            unique_args = list(ordered(set(args), Set._infimum_key))\n+            if len(unique_args) == 1:\n+                return unique_args[0]\n+            else:\n+                return Piecewise((unique_args[0], Eq(unique_args[1], unique_args[0])), (S.EmptySet, True))\n+\n+        return obj if len(args) > 1 else args[0]\n \n     @property\n     @cacheit\n", "instance_id": "sympy__sympy-16988"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/lambdarepr.py b/sympy/printing/lambdarepr.py\nindex 8f60434e89..79c25a0105 100644\n--- a/sympy/printing/lambdarepr.py\n+++ b/sympy/printing/lambdarepr.py\n@@ -4,6 +4,7 @@\n     MpmathPrinter,  # MpmathPrinter is imported for backward compatibility\n     NumPyPrinter  # NumPyPrinter is imported for backward compatibility\n )\n+from sympy.matrices import Identity\n from sympy.utilities import default_sort_key\n \n \n@@ -43,7 +44,8 @@ def _print_BooleanTrue(self, expr):\n     def _print_BooleanFalse(self, expr):\n         return \"False\"\n \n-    def _print_ITE(self, expr):\n+    def _print_Identity(self, expr):\n+        return \"np.eye(%s)\" % expr.shape[0]\n         result = [\n             '((', self._print(expr.args[1]),\n             ') if (', self._print(expr.args[0]),\n", "instance_id": "sympy__sympy-17022"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..14cd38d574 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1171,6 +1171,10 @@ class Query(BaseExpression):\n                 raise ValueError(\"Cannot use None as a query value\")\n             return lhs.get_lookup('isnull')(lhs, True)\n \n+        # Ensure __isnull lookup is used with a boolean value.\n+        if lookup_name == 'isnull' and not isinstance(lookup.rhs, bool):\n+            raise ValueError(\"The '__isnull' lookup only accepts boolean values.\")\n+\n         # For Oracle '' is equivalent to null. The check must be done at this\n         # stage because join promotion can't be done in the compiler. Using\n         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.\n", "instance_id": "django__django-11905"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..081a6d5796 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,12 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n+            current_year = datetime.datetime.now().year\n+            current_century = current_year // 100 * 100\n+            if year > (current_year % 100) + 50:\n+                year += current_century - 100\n             else:\n-                year += 1900\n+                year += current_century\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n", "instance_id": "django__django-11848"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..2b5178f226 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -186,7 +186,7 @@ class FigureBase(Artist):\n         # groupers to keep track of x and y labels we want to align.\n         # see self.align_xlabels and self.align_ylabels and\n         # axis._get_tick_boxes_siblings\n-        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        self._align_label_groups = {\"x\": [], \"y\": []}\n \n         self.figure = self\n         self._localaxes = []  # track all axes\n@@ -1327,9 +1327,10 @@ default: %(va)s\n                 \"not calling subplots_adjust.\")\n             return\n         self.subplotpars.update(left, bottom, right, top, wspace, hspace)\n-        for ax in self.axes:\n-            if ax.get_subplotspec() is not None:\n-                ax._set_position(ax.get_subplotspec().get_position(self))\n+        for ax, axc in self._align_label_groups['x']:\n+            ax._align_label_position(axc, 'x')\n+        for ax, axc in self._align_label_groups['y']:\n+            ax._align_label_position(axc, 'y')\n         self.stale = True\n \n     def align_xlabels(self, axs=None):\n@@ -1391,7 +1392,7 @@ default: %(va)s\n                     if (pos == 'top' and rowspan.start == rowspanc.start or\n                             pos == 'bottom' and rowspan.stop == rowspanc.stop):\n                         # grouper for groups of xlabels to align\n-                        self._align_label_groups['x'].join(ax, axc)\n+                        self._align_label_groups['x'].append((ax, axc))\n \n     def align_ylabels(self, axs=None):\n         \"\"\"\n@@ -1451,7 +1452,7 @@ default: %(va)s\n                     if (pos == 'left' and colspan.start == colspanc.start or\n                             pos == 'right' and colspan.stop == colspanc.stop):\n                         # grouper for groups of ylabels to align\n-                        self._align_label_groups['y'].join(ax, axc)\n+                        self._align_label_groups['y'].append((ax, axc))\n \n     def align_labels(self, axs=None):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-25332"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..125bee2b0a 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,8 +26,7 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n+                self.serialize_result(obj, to_field_name) for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n@@ -45,6 +44,11 @@ class AutocompleteJsonView(BaseListView):\n             qs = qs.distinct()\n         return qs\n \n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"\n+        Convert the object to a dictionary representation for the JSON response.\n+        \"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n     def process_request(self, request):\n         \"\"\"\n         Validate request integrity, extract and return request parameters.\n", "instance_id": "django__django-14752"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 187e14b1b7..010ad7fd23 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -8,6 +8,7 @@ from django.conf import settings\n from django.contrib.sessions.exceptions import SuspiciousSession\n from django.core import signing\n from django.core.exceptions import SuspiciousOperation\n+import binascii\n from django.utils import timezone\n from django.utils.crypto import (\n     constant_time_compare, get_random_string, salted_hmac,\n@@ -121,7 +122,7 @@ class SessionBase:\n             return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n         # RemovedInDjango40Warning: when the deprecation ends, handle here\n         # exceptions similar to what _legacy_decode() does now.\n-        except Exception:\n+        except (signing.BadSignature, binascii.Error):\n             return self._legacy_decode(session_data)\n \n     def _legacy_encode(self, session_dict):\ndiff --git a/django/contrib/sessions/backends/db.py b/django/contrib/sessions/backends/db.py\nindex 7c905a2c99..f72057b35f 100644\n--- a/django/contrib/sessions/backends/db.py\n+++ b/django/contrib/sessions/backends/db.py\n@@ -5,6 +5,8 @@ from django.contrib.sessions.backends.base import (\n )\n from django.core.exceptions import SuspiciousOperation\n from django.db import DatabaseError, IntegrityError, router, transaction\n+import binascii\n+from django.core import signing\n from django.utils import timezone\n from django.utils.functional import cached_property\n \n@@ -41,7 +43,10 @@ class SessionStore(SessionBase):\n \n     def load(self):\n         s = self._get_session_from_db()\n-        return self.decode(s.session_data) if s else {}\n+        try:\n+            return self.decode(s.session_data) if s else {}\n+        except (signing.BadSignature, binascii.Error):\n+            return {}\n \n     def exists(self, session_key):\n         return self.model.objects.filter(session_key=session_key).exists()\n", "instance_id": "django__django-13321"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 02aa32b207..eb15caa10d 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -125,28 +125,26 @@ class Media:\n         in a certain order. In JavaScript you may not be able to reference a\n         global or in CSS you might want to override a style.\n         \"\"\"\n-        # Start with a copy of list_1.\n-        combined_list = list(list_1)\n-        last_insert_index = len(list_1)\n-        # Walk list_2 in reverse, inserting each element into combined_list if\n-        # it doesn't already exist.\n-        for path in reversed(list_2):\n-            try:\n-                # Does path already exist in the list?\n-                index = combined_list.index(path)\n-            except ValueError:\n-                # Add path to combined_list since it doesn't exist.\n-                combined_list.insert(last_insert_index, path)\n-            else:\n-                if index > last_insert_index:\n+        combined_list = []\n+        seen = set()\n+        conflict_pairs = set()\n+\n+        for path in list_1 + list_2:\n+            if path in seen:\n+                continue\n+            seen.add(path)\n+            combined_list.append(path)\n+\n+        for i, path1 in enumerate(combined_list):\n+            for path2 in combined_list[i+1:]:\n+                if (path1, path2) in conflict_pairs:\n                     warnings.warn(\n                         'Detected duplicate Media files in an opposite order:\\n'\n-                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n+                        '%s\\n%s' % (path1, path2),\n                         MediaOrderConflictWarning,\n                     )\n-                # path already exists in the list. Update last_insert_index so\n-                # that the following elements are inserted in front of this one.\n-                last_insert_index = index\n+                conflict_pairs.add((path2, path1))\n+\n         return combined_list\n \n     def __add__(self, other):\n", "instance_id": "django__django-11019"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 24d89897f7..3e5709b570 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -121,7 +121,7 @@ def _hashable_content(self):\n \n     def __eq__(self, other):\n         try:\n-            other = sympify(other)\n+            other = sympify(other, strict=True)\n             if not isinstance(other, Expr):\n                 return False\n         except (SympifyError, SyntaxError):\ndiff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex ed4ea6ce5e..ff25075e62 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -4,7 +4,7 @@\n \n from inspect import getmro\n \n-from .core import all_classes as sympy_classes\n+from .core import all_classes as sympy_classes, Basic\n from .compatibility import iterable, string_types, range\n from .evaluate import global_evaluate\n \n@@ -322,7 +322,7 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n                 from ..tensor.array import Array\n                 return Array(a.flat, a.shape)  # works with e.g. NumPy arrays\n \n-    if not isinstance(a, string_types):\n+    if not isinstance(a, (string_types, Basic)):\n         for coerce in (float, int):\n             try:\n                 coerced = coerce(a)\ndiff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 2ab43d9b31..6c0bd453ac 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -12,6 +12,7 @@\n \n from sympy.core.compatibility import exec_, StringIO, iterable\n from sympy.core.basic import Basic\n+from sympy.core.sympify import SympifyError\n from sympy.core import Symbol\n from sympy.core.function import arity\n from sympy.utilities.misc import filldedent, func_name\n@@ -899,8 +900,11 @@ def eval_expr(code, local_dict, global_dict):\n \n     Generally, ``parse_expr`` should be used.\n     \"\"\"\n-    expr = eval(\n-        code, global_dict, local_dict)  # take local objects in preference\n+    try:\n+        expr = eval(\n+            code, global_dict, local_dict)  # take local objects in preference\n+    except AttributeError as e:\n+        raise SympifyError('could not evaluate %r' % code, e)\n \n     return expr\n \n", "instance_id": "sympy__sympy-18057"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..40eff5bec8 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -166,7 +166,7 @@ class Line3D(lines.Line2D):\n         Keyword arguments are passed onto :func:`~matplotlib.lines.Line2D`.\n         \"\"\"\n         super().__init__([], [], *args, **kwargs)\n-        self._verts3d = xs, ys, zs\n+        self.set_data_3d(xs, ys, zs)\n \n     def set_3d_properties(self, zs=0, zdir='z'):\n         xs = self.get_xdata()\n@@ -197,6 +197,7 @@ class Line3D(lines.Line2D):\n         else:\n             self._verts3d = args\n         self.stale = True\n+        self.stale = True\n \n     def get_data_3d(self):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-23563"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex b6adb7ceb..6cd014e12 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -101,14 +101,18 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n         obj = module\n         parent = None\n         object_name = None\n-        for attrname in objpath:\n-            parent = obj\n-            logger.debug('[autodoc] getattr(_, %r)', attrname)\n-            mangled_name = mangle(obj, attrname)\n-            obj = attrgetter(obj, mangled_name)\n-            logger.debug('[autodoc] => %r', obj)\n-            object_name = attrname\n-        return [module, parent, object_name, obj]\n+        if hasattr(module, '__all__') and not module.__all__:\n+            logger.debug('[autodoc] module %s has an empty __all__', modname)\n+            return [module, None, None, None]\n+        else:\n+            for attrname in objpath:\n+                parent = obj\n+                logger.debug('[autodoc] getattr(_, %r)', attrname)\n+                mangled_name = mangle(obj, attrname)\n+                obj = attrgetter(obj, mangled_name)\n+                logger.debug('[autodoc] => %r', obj)\n+                object_name = attrname\n+            return [module, parent, object_name, obj]\n     except (AttributeError, ImportError) as exc:\n         if isinstance(exc, AttributeError) and exc_on_importing:\n             # restore ImportError\n", "instance_id": "sphinx-doc__sphinx-8595"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 34a3bab3fc..9ae076651b 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -10,7 +10,7 @@\n from sympy.core.function import count_ops, _mexpand\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sinc\n \n from sympy.strategies.core import identity\n from sympy.strategies.tree import greedy\n@@ -22,6 +22,7 @@\n from sympy.polys import factor, cancel, parallel_poly_from_expr\n \n from sympy.utilities.misc import debug\n+from sympy.simplify.simplify import separatevars, cse\n \n \n \n@@ -425,7 +426,18 @@ def analyse_gens(gens, hints):\n _trigs = (TrigonometricFunction, HyperbolicFunction)\n \n \n-def trigsimp(expr, **opts):\n+def _exp_to_trig(expr):\n+    \"\"\"\n+    Helper function to convert exponential expressions to trigonometric functions.\n+    \"\"\"\n+    from sympy import I, exp, sin, cos, sinc\n+    expr = expr.rewrite(exp)\n+    expr = expr.replace(exp(I * expr), cos(expr) + I * sin(expr))\n+    expr = expr.replace(exp(-I * expr), cos(expr) - I * sin(expr))\n+    expr = expr.replace((exp(I * expr) - exp(-I * expr)) / (2 * I), sin(expr))\n+    expr = expr.replace((exp(I * expr) + exp(-I * expr)) / 2, cos(expr))\n+    expr = expr.replace((exp(I * expr) - exp(-I * expr)) / (2 * I * expr), sinc(expr))\n+    return expr\n     \"\"\"\n     reduces expression by using known trig identities\n \n@@ -473,7 +485,7 @@ def trigsimp(expr, **opts):\n     \"\"\"\n     from sympy.simplify.fu import fu\n \n-    expr = sympify(expr)\n+    expr = _exp_to_trig(sympify(expr))\n \n     try:\n         return expr._eval_trigsimp(**opts)\n@@ -663,6 +675,7 @@ def trigsimp_old(expr, **opts):\n     \"\"\"\n     old = expr\n     first = opts.pop('first', True)\n+    first = opts.pop('first', True)\n     if first:\n         if not expr.has(*_trigs):\n             return expr\n", "instance_id": "sympy__sympy-11870"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..f75610a435 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -318,54 +318,55 @@ class RenameModel(ModelOperation):\n \n     def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n-        if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n+        if self.allow_migrate_model(schema_editor.connection.alias, new_model) and not new_model._meta.db_table:\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n-            # Move the main table\n-            schema_editor.alter_db_table(\n-                new_model,\n-                old_model._meta.db_table,\n-                new_model._meta.db_table,\n-            )\n-            # Alter the fields pointing to us\n-            for related_object in old_model._meta.related_objects:\n-                if related_object.related_model == old_model:\n-                    model = new_model\n-                    related_key = (app_label, self.new_name_lower)\n-                else:\n-                    model = related_object.related_model\n-                    related_key = (\n-                        related_object.related_model._meta.app_label,\n-                        related_object.related_model._meta.model_name,\n-                    )\n-                to_field = to_state.apps.get_model(\n-                    *related_key\n-                )._meta.get_field(related_object.field.name)\n-                schema_editor.alter_field(\n-                    model,\n-                    related_object.field,\n-                    to_field,\n-                )\n-            # Rename M2M fields whose name is based on this model's name.\n-            fields = zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many)\n-            for (old_field, new_field) in fields:\n-                # Skip self-referential fields as these are renamed above.\n-                if new_field.model == new_field.related_model or not new_field.remote_field.through._meta.auto_created:\n-                    continue\n-                # Rename the M2M table that's based on this model's name.\n-                old_m2m_model = old_field.remote_field.through\n-                new_m2m_model = new_field.remote_field.through\n+            if old_model._meta.db_table != new_model._meta.db_table:\n+                # Move the main table\n                 schema_editor.alter_db_table(\n-                    new_m2m_model,\n-                    old_m2m_model._meta.db_table,\n-                    new_m2m_model._meta.db_table,\n-                )\n-                # Rename the column in the M2M table that's based on this\n-                # model's name.\n-                schema_editor.alter_field(\n-                    new_m2m_model,\n-                    old_m2m_model._meta.get_field(old_model._meta.model_name),\n-                    new_m2m_model._meta.get_field(new_model._meta.model_name),\n+                    new_model,\n+                    old_model._meta.db_table,\n+                    new_model._meta.db_table,\n                 )\n+                # Alter the fields pointing to us\n+                for related_object in old_model._meta.related_objects:\n+                    if related_object.related_model == old_model:\n+                        model = new_model\n+                        related_key = (app_label, self.new_name_lower)\n+                    else:\n+                        model = related_object.related_model\n+                        related_key = (\n+                            related_object.related_model._meta.app_label,\n+                            related_object.related_model._meta.model_name,\n+                        )\n+                    to_field = to_state.apps.get_model(\n+                        *related_key\n+                    )._meta.get_field(related_object.field.name)\n+                    schema_editor.alter_field(\n+                        model,\n+                        related_object.field,\n+                        to_field,\n+                    )\n+                # Rename M2M fields whose name is based on this model's name.\n+                fields = zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many)\n+                for (old_field, new_field) in fields:\n+                    # Skip self-referential fields as these are renamed above.\n+                    if new_field.model == new_field.related_model or not new_field.remote_field.through._meta.auto_created:\n+                        continue\n+                    # Rename the M2M table that's based on this model's name.\n+                    old_m2m_model = old_field.remote_field.through\n+                    new_m2m_model = new_field.remote_field.through\n+                    schema_editor.alter_db_table(\n+                        new_m2m_model,\n+                        old_m2m_model._meta.db_table,\n+                        new_m2m_model._meta.db_table,\n+                    )\n+                    # Rename the column in the M2M table that's based on this\n+                    # model's name.\n+                    schema_editor.alter_field(\n+                        new_m2m_model,\n+                        old_m2m_model._meta.get_field(old_model._meta.model_name),\n+                        new_m2m_model._meta.get_field(new_model._meta.model_name),\n+                    )\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         self.new_name_lower, self.old_name_lower = self.old_name_lower, self.new_name_lower\n", "instance_id": "django__django-14999"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 75349099..12a0c1be 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -2102,6 +2102,10 @@ def pairplot(\n     diag_kws = {} if diag_kws is None else diag_kws.copy()\n     grid_kws = {} if grid_kws is None else grid_kws.copy()\n \n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = [' '.join(map(str, col)).strip() for col in data.columns]\n+\n     # Resolve \"auto\" diag kind\n     if diag_kind == \"auto\":\n         if hue is None:\n", "instance_id": "mwaskom__seaborn-3407"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex 9cc4fec441..429652d2ba 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -376,6 +376,9 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n     if evaluate is None:\n         evaluate = global_parameters.evaluate\n \n+    if not evaluate:\n+        return a\n+\n     # Support for basic numpy datatypes\n     if _is_numpy_instance(a):\n         import numpy as np\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 5f5eab3b9d..e9bbddf0ef 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -37,7 +37,7 @@\n \n \n \n-def separatevars(expr, symbols=[], dict=False, force=False):\n+def separatevars(expr, symbols=[], dict=False, force=False, evaluate=True):\n     \"\"\"\n     Separates variables in an expression, if possible.  By\n     default, it separates with respect to all symbols in an\n@@ -104,7 +104,7 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n-    expr = sympify(expr)\n+    expr = sympify(expr, evaluate=evaluate)\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n     else:\n", "instance_id": "sympy__sympy-20322"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/commands/dbshell.py b/django/core/management/commands/dbshell.py\nindex 30d2765afb..2f8ca7f21b 100644\n--- a/django/core/management/commands/dbshell.py\n+++ b/django/core/management/commands/dbshell.py\n@@ -27,7 +27,12 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         connection = connections[options[\"database\"]]\n         try:\n-            connection.client.runshell(options[\"parameters\"])\n+            # For PostgreSQL, ensure parameters are passed before the database name\n+            if connection.settings_dict['ENGINE'] == 'django.db.backends.postgresql':\n+                parameters = options[\"parameters\"] + [connection.settings_dict['NAME']]\n+            else:\n+                parameters = options[\"parameters\"]\n+            connection.client.runshell(parameters)\n         except FileNotFoundError:\n             # Note that we're assuming the FileNotFoundError relates to the\n             # command missing. It could be raised for some other reason, in\n", "instance_id": "django__django-15851"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 6f10e31cd5..076bb3a2fb 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -772,8 +772,13 @@ class BaseDatabaseOperations:\n             raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))\n         return self.explain_prefix\n \n-    def insert_statement(self, on_conflict=None):\n-        return \"INSERT INTO\"\n+    def insert_statement(self, table, returning_fields=None, on_conflict=None):\n+        if returning_fields:\n+            return \"INSERT INTO %s RETURNING %s\" % (\n+                table,\n+                \", \".join(self.quote_name(field.column) for field in returning_fields),\n+            )\n+        return \"INSERT INTO %s\" % table\n \n     def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):\n         return \"\"\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 5ac2407ea3..e021571257 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -719,7 +719,9 @@ class QuerySet(AltersData):\n                     raise ValueError(\n                         \"bulk_create() can only be used with concrete fields \"\n                         \"in unique_fields.\"\n-                    )\n+                    table=self.model._meta.db_table,\n+                    returning_fields=self.model._meta.db_returning_fields,\n+                )\n             return OnConflict.UPDATE\n         return None\n \n@@ -810,10 +812,7 @@ class QuerySet(AltersData):\n                     unique_fields=unique_fields,\n                 )\n                 connection = connections[self.db]\n-                if (\n-                    connection.features.can_return_rows_from_bulk_insert\n-                    and on_conflict is None\n-                ):\n+                if connection.features.can_return_rows_from_bulk_insert:\n                     assert len(returned_columns) == len(objs_without_pk)\n                 for obj_without_pk, results in zip(objs_without_pk, returned_columns):\n                     for result, field in zip(results, opts.db_returning_fields):\n", "instance_id": "django__django-17051"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 841cbbfe..d4a8ce13 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -191,7 +191,10 @@ class HTTPAdapter(BaseAdapter):\n             if not isinstance(cert, basestring):\n                 conn.cert_file = cert[0]\n                 conn.key_file = cert[1]\n-            else:\n+            elif isinstance(e, BaseDecodeError):\n+                raise DecodeError(e, request=request)\n+            elif isinstance(e, BaseTimeoutError):\n+                raise TimeoutError(e, request=request)\n                 conn.cert_file = cert\n \n     def build_response(self, req, resp):\n@@ -424,7 +427,7 @@ class HTTPAdapter(BaseAdapter):\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n-        except (_SSLError, _HTTPError) as e:\n+        except (_SSLError, _HTTPError, BaseDecodeError, BaseTimeoutError) as e:\n             if isinstance(e, _SSLError):\n                 raise SSLError(e, request=request)\n             elif isinstance(e, ReadTimeoutError):\ndiff --git a/requests/exceptions.py b/requests/exceptions.py\nindex 89135a80..76a3feb0 100644\n--- a/requests/exceptions.py\n+++ b/requests/exceptions.py\n@@ -7,7 +7,7 @@ requests.exceptions\n This module contains the set of Requests' exceptions.\n \n \"\"\"\n-from .packages.urllib3.exceptions import HTTPError as BaseHTTPError\n+from .packages.urllib3.exceptions import HTTPError as BaseHTTPError, DecodeError as BaseDecodeError, TimeoutError as BaseTimeoutError\n \n \n class RequestException(IOError):\n@@ -91,6 +91,14 @@ class ContentDecodingError(RequestException, BaseHTTPError):\n     \"\"\"Failed to decode response content\"\"\"\n \n \n+class DecodeError(RequestException, BaseDecodeError):\n+    \"\"\"Failed to decode response content\"\"\"\n+\n+\n+class TimeoutError(RequestException, BaseTimeoutError):\n+    \"\"\"The request timed out\"\"\"\n+\n+\n class StreamConsumedError(RequestException, TypeError):\n     \"\"\"The content for this response was already consumed\"\"\"\n \n", "instance_id": "psf__requests-2674"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/elementary/trigonometric.py b/sympy/functions/elementary/trigonometric.py\nindex da2e919375..bff0365c47 100644\n--- a/sympy/functions/elementary/trigonometric.py\n+++ b/sympy/functions/elementary/trigonometric.py\n@@ -257,7 +257,7 @@ def fdiff(self, argindex=1):\n     def eval(cls, arg):\n         from sympy.calculus import AccumBounds\n         from sympy.sets.setexpr import SetExpr\n-        if arg.is_Number:\n+        if arg.is_Number or arg.is_Rational:\n             if arg is S.NaN:\n                 return S.NaN\n             elif arg is S.Zero:\n@@ -532,7 +532,7 @@ def eval(cls, arg):\n         from sympy.functions.special.polynomials import chebyshevt\n         from sympy.calculus.util import AccumBounds\n         from sympy.sets.setexpr import SetExpr\n-        if arg.is_Number:\n+        if arg.is_Number or arg.is_Rational:\n             if arg is S.NaN:\n                 return S.NaN\n             elif arg is S.Zero:\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 421bfba0a7..29c13e4f30 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -382,7 +382,14 @@ def signsimp(expr, evaluate=None):\n     return e\n \n \n+def simplify_trig_rational(expr):\n+    from sympy import cos, sin, Rational\n+    if expr.has(sin, cos) and expr.has(Rational):\n+        expr = expr.rewrite(cos).rewrite(sin)\n+    return expr\n+\n def simplify(expr, ratio=1.7, measure=count_ops, rational=False, inverse=False):\n+    expr = simplify_trig_rational(expr)\n     \"\"\"Simplifies the given expression.\n \n     Simplification is not a well defined term and the exact strategies\n", "instance_id": "sympy__sympy-15346"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-12184"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..cd54358ead 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -895,13 +895,18 @@ def __new__(cls, *args, **kwargs):\n         # counting starts from 1.\n \n         temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n-                raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n+        if is_cycle:\n+            # Apply cycles in left-to-right order\n+            aform = list(range(size or max(temp) + 1))\n+            for cycle in args:\n+                for i in range(len(cycle) - 1):\n+                    aform[cycle[i]], aform[cycle[i + 1]] = aform[cycle[i + 1]], aform[cycle[i]]\n+            if size and size > len(aform):\n+                aform.extend(list(range(len(aform), size)))\n+        else:\n+            if any(i not in temp for i in range(len(temp))):\n+                raise ValueError(\"Integers 0 through %s must be present.\" % max(temp))\n+            aform = list(args)\n \n         if not is_cycle and \\\n                 any(i not in temp for i in range(len(temp))):\n", "instance_id": "sympy__sympy-12481"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 09e2b00735..48931681d0 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -19,6 +19,7 @@\n from sympy.core.add import Add\n \n from sympy.printing.printer import Printer\n+from sympy.vector.vector import Vector\n from sympy.printing.str import sstr\n from sympy.printing.conventions import requires_partial\n \n@@ -886,7 +887,10 @@ def _print_FunctionMatrix(self, X):\n         D = prettyForm(*D.parens('[', ']'))\n         return D\n \n-    def _print_BasisDependent(self, expr):\n+    def _print_Vector(self, expr):\n+        pform = self._print(expr._pretty(self))\n+        pform.baseline = pform.height() // 2\n+        return pform\n         from sympy.vector import Vector\n \n         if not self._use_unicode:\ndiff --git a/sympy/vector/vector.py b/sympy/vector/vector.py\nindex c62b1dbf0d..7449d541fc 100755\n--- a/sympy/vector/vector.py\n+++ b/sympy/vector/vector.py\n@@ -1,4 +1,5 @@\n from sympy.core.assumptions import StdFactKB\n+from sympy.printing.pretty.stringpict import prettyForm\n from sympy.core import S, Pow, sympify\n from sympy.core.expr import AtomicExpr, Expr\n from sympy.core.compatibility import range, default_sort_key\n@@ -261,6 +262,12 @@ def _projections(self):\n         base_vec = next(iter(_get_coord_sys_from_expr(self))).base_vectors()\n         return tuple([self.dot(i) for i in base_vec])\n \n+    def _pretty(self, printer, *args):\n+        from sympy.printing.pretty.pretty import PrettyPrinter\n+        if not isinstance(printer, PrettyPrinter):\n+            return str(self)\n+        return prettyForm(self.__str__())\n+\n     def __or__(self, other):\n         return self.outer(other)\n \n", "instance_id": "sympy__sympy-14308"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex ebe5da43e2..2242714f5d 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -20,6 +20,7 @@ import numpy as np\n import matplotlib as mpl\n from . import (_api, _docstring, backend_tools, cbook, collections, colors,\n                text as mtext, ticker, transforms)\n+from matplotlib.backends.backend_agg import Timer\n from .lines import Line2D\n from .patches import Circle, Rectangle, Ellipse, Polygon\n from .transforms import TransformedPatchPath, Affine2D\n@@ -84,6 +85,7 @@ class Widget:\n \n     def ignore(self, event):\n         \"\"\"\n+        return self._observers.connect('changed', lambda val: func(val))\n         Return whether *event* should be ignored.\n \n         This method should be called at the beginning of any event callback.\n@@ -299,6 +301,9 @@ class SliderBase(AxesWidget):\n         if dragging:\n             self.connect_event(\"motion_notify_event\", self._update)\n         self._observers = cbook.CallbackRegistry(signals=[\"changed\"])\n+        self._timer = Timer(self.canvas, interval=0)\n+        self._timer.add_callback(self._process_on_changed)\n+        self._pending_val = None\n \n     def _stepped_value(self, val):\n         \"\"\"Return *val* coerced to closest number in the ``valstep`` grid.\"\"\"\n@@ -583,24 +588,14 @@ class Slider(SliderBase):\n             self.ax.figure.canvas.draw_idle()\n         self.val = val\n         if self.eventson:\n-            self._observers.process('changed', val)\n-\n-    def on_changed(self, func):\n-        \"\"\"\n-        Connect *func* as callback function to changes of the slider value.\n-\n-        Parameters\n-        ----------\n-        func : callable\n-            Function to call when slider is changed.\n-            The function must accept a single float as its arguments.\n+            self._pending_val = val\n+            self._timer.start()\n \n-        Returns\n-        -------\n-        int\n-            Connection id (which can be used to disconnect *func*).\n+    def _process_on_changed(self):\n+        if self._pending_val is not None:\n+            self._observers.process('changed', self._pending_val)\n+            self._pending_val = None\n         \"\"\"\n-        return self._observers.connect('changed', lambda val: func(val))\n \n \n class RangeSlider(SliderBase):\n@@ -972,6 +967,51 @@ class RangeSlider(SliderBase):\n         \"\"\"\n         Connect *func* as callback function to changes of the slider value.\n \n+        Parameters\n+        ----------\n+        func : callable\n+            Function to call when slider is changed.\n+            The function must accept a single float as its arguments.\n+\n+        Returns\n+        -------\n+        int\n+            Connection id (which can be used to disconnect *func*).\n+        \"\"\"\n+        return self._observers.connect('changed', lambda val: func(val))\n+        \"\"\"\n+        Connect *func* as callback function to changes of the slider value.\n+\n+        Parameters\n+        ----------\n+        func : callable\n+            Function to call when slider is changed.\n+            The function must accept a single float as its arguments.\n+\n+        Returns\n+        -------\n+        int\n+            Connection id (which can be used to disconnect *func*).\n+        \"\"\"\n+        return self._observers.connect('changed', lambda val: func(val))\n+        \"\"\"\n+        Connect *func* as callback function to changes of the slider value.\n+\n+        Parameters\n+        ----------\n+        func : callable\n+            Function to call when slider is changed.\n+            The function must accept a single float as its arguments.\n+\n+        Returns\n+        -------\n+        int\n+            Connection id (which can be used to disconnect *func*).\n+        \"\"\"\n+        return self._observers.connect('changed', lambda val: func(val))\n+        \"\"\"\n+        Connect *func* as callback function to changes of the slider value.\n+\n         Parameters\n         ----------\n         func : callable\n", "instance_id": "matplotlib__matplotlib-25433"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex fb5f6298c4..5aefb80f9d 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -403,7 +403,8 @@ def slugify(value, allow_unicode=False):\n     else:\n         value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n     value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+    value = re.sub(r'[-\\s]+', '-', value)\n+    return value.strip('-_')\n \n \n def camel_case_to_spaces(value):\n", "instance_id": "django__django-12983"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 11aebbc59f..206ef155be 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -288,7 +288,10 @@ class BlockDiagMatrix(BlockMatrix):\n     sympy.matrices.dense.diag\n     \"\"\"\n     def __new__(cls, *mats):\n-        return Basic.__new__(BlockDiagMatrix, *mats)\n+        if len(mats) == 1:\n+            return mats[0]\n+        else:\n+            return Basic.__new__(BlockDiagMatrix, *mats)\n \n     @property\n     def diag(self):\n", "instance_id": "sympy__sympy-18621"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d0bc97be80..b6b2464a35 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -6,6 +6,8 @@ import re\n from html.parser import HTMLParser\n from urllib.parse import parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit\n \n+from django.core.serializers.json import DjangoJSONEncoder\n+from django.core.serializers.json import DjangoJSONEncoder\n from django.utils.encoding import punycode\n from django.utils.functional import Promise, keep_lazy, keep_lazy_text\n from django.utils.http import RFC3986_GENDELIMS, RFC3986_SUBDELIMS\n@@ -59,7 +61,7 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=DjangoJSONEncoder):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -67,7 +69,7 @@ def json_script(value, element_id=None):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n \n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n", "instance_id": "django__django-15789"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-17087"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/units/prefixes.py b/sympy/physics/units/prefixes.py\nindex ca6a642156..768c6a2736 100644\n--- a/sympy/physics/units/prefixes.py\n+++ b/sympy/physics/units/prefixes.py\n@@ -94,7 +94,14 @@ def __mul__(self, other):\n                     return PREFIXES[p]\n             return fact\n \n-        return self.scale_factor * other\n+        if isinstance(other, Quantity):\n+            return Quantity(\n+                \"%s%s\" % (self.name, other.name),\n+                abbrev=(\"%s%s\" % (self.abbrev, other.abbrev)),\n+                is_prefixed=True,\n+            )\n+        else:\n+            return self.scale_factor * other\n \n     def __truediv__(self, other):\n         if not hasattr(other, \"scale_factor\"):\ndiff --git a/sympy/physics/units/quantities.py b/sympy/physics/units/quantities.py\nindex cc19e72aea..d21fbe7c7a 100644\n--- a/sympy/physics/units/quantities.py\n+++ b/sympy/physics/units/quantities.py\n@@ -105,9 +105,14 @@ def _eval_is_constant(self):\n     def _eval_Abs(self):\n         return self\n \n-    def _eval_subs(self, old, new):\n-        if isinstance(new, Quantity) and self != old:\n-            return self\n+    def __mul__(self, other):\n+        if isinstance(other, Prefix):\n+            return Quantity(\n+                \"%s%s\" % (other.name, self.name),\n+                abbrev=(\"%s%s\" % (other.abbrev, self.abbrev)),\n+                is_prefixed=True,\n+            )\n+        return super().__mul__(other)\n \n     def _latex(self, printer):\n         if self._latex_repr:\n", "instance_id": "sympy__sympy-24909"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..f248ab1b71 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n", "instance_id": "django__django-14382"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "astropy__astropy-14995"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "instance_id": "sympy__sympy-13480"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/units/systems/si.py b/sympy/physics/units/systems/si.py\nindex 700495ad9d..20eb85feee 100644\n--- a/sympy/physics/units/systems/si.py\n+++ b/sympy/physics/units/systems/si.py\n@@ -7,7 +7,7 @@\n \n from typing import List\n \n-from sympy.physics.units import DimensionSystem, Dimension, dHg0\n+from sympy.physics.units import DimensionSystem, Dimension, dHg0, Dimensionless\n \n from sympy.physics.units.quantities import Quantity\n \n", "instance_id": "sympy__sympy-24066"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 57676428ff..3a20893e88 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -257,7 +257,10 @@ class BaseFormSet(RenderableFormMixin):\n \n     @property\n     def empty_form(self):\n+        form_kwargs = self.get_form_kwargs(None)\n+        form_kwargs.pop('empty_permitted', None)\n         form = self.form(\n+            **form_kwargs,\n             auto_id=self.auto_id,\n             prefix=self.add_prefix(\"__prefix__\"),\n             empty_permitted=True,\n", "instance_id": "django__django-16041"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d8456375..51cb543c 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -148,8 +148,12 @@ class Request(object):\n \n         hooks = hooks or {}\n \n-        for (k, v) in list(hooks.items()):\n-            self.register_hook(event=k, hook=v)\n+        for (k, v) in hooks.items():\n+            if isinstance(v, list):\n+                for hook in v:\n+                    self.register_hook(event=k, hook=hook)\n+            else:\n+                self.register_hook(event=k, hook=v)\n \n         #: Session.\n         self.session = session\n", "instance_id": "psf__requests-863"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 43f9e6ad8d..b97d53582a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1968,10 +1968,12 @@ def _print_DiracDelta(self, expr, exp=None):\n             tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n-    def _print_SingularityFunction(self, expr):\n+    def _print_SingularityFunction(self, expr, exp=None):\n         shift = self._print(expr.args[0] - expr.args[1])\n         power = self._print(expr.args[2])\n         tex = r\"{\\left\\langle %s \\right\\rangle}^{%s}\" % (shift, power)\n+        if exp is not None:\n+            tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n     def _print_Heaviside(self, expr, exp=None):\n", "instance_id": "sympy__sympy-21171"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..266e091a16 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -737,6 +737,10 @@ class QuerySet:\n \n         # Clear the result cache, in case this QuerySet gets reused.\n         self._result_cache = None\n+        if not deleted:\n+            # Ensure the dictionary is populated with model-label keys and zero values\n+            for model in collector.data:\n+                _rows_count.setdefault(model._meta.label, 0)\n         return deleted, _rows_count\n \n     delete.alters_data = True\n", "instance_id": "django__django-12747"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-16408"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\nindex 29c7e19d7..ac1a8a2aa 100644\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -111,7 +111,7 @@ class TempPathFactory:\n         else:\n             from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n             temproot = Path(from_env or tempfile.gettempdir()).resolve()\n-            user = get_user() or \"unknown\"\n+            user = sanitize_username(get_user() or \"unknown\")\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n             rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n@@ -158,6 +158,10 @@ def get_user() -> Optional[str]:\n     except (ImportError, KeyError):\n         return None\n \n+def sanitize_username(username: str) -> str:\n+    \"\"\"Sanitize the username to remove characters that are not allowed in directory names.\"\"\"\n+    return re.sub(r'[^\\w.-]', '_', username)\n+\n \n def pytest_configure(config: Config) -> None:\n     \"\"\"Create a TempdirFactory and attach it to the config object.\n", "instance_id": "pytest-dev__pytest-8365"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/style/core.py b/lib/matplotlib/style/core.py\nindex fb0a5426e6..12873304f4 100644\n--- a/lib/matplotlib/style/core.py\n+++ b/lib/matplotlib/style/core.py\n@@ -108,7 +108,26 @@ def use(style):\n     else:\n         styles = style\n \n-    style_alias = {'mpl20': 'default', 'mpl15': 'classic'}\n+    style_alias = {\n+        'mpl20': 'default',\n+        'mpl15': 'classic',\n+        'seaborn': 'seaborn-v0_8',\n+        'seaborn-bright': 'seaborn-v0_8-bright',\n+        'seaborn-colorblind': 'seaborn-v0_8-colorblind',\n+        'seaborn-dark': 'seaborn-v0_8-dark',\n+        'seaborn-darkgrid': 'seaborn-v0_8-darkgrid',\n+        'seaborn-dark-palette': 'seaborn-v0_8-dark-palette',\n+        'seaborn-deep': 'seaborn-v0_8-deep',\n+        'seaborn-muted': 'seaborn-v0_8-muted',\n+        'seaborn-notebook': 'seaborn-v0_8-notebook',\n+        'seaborn-paper': 'seaborn-v0_8-paper',\n+        'seaborn-pastel': 'seaborn-v0_8-pastel',\n+        'seaborn-poster': 'seaborn-v0_8-poster',\n+        'seaborn-talk': 'seaborn-v0_8-talk',\n+        'seaborn-ticks': 'seaborn-v0_8-ticks',\n+        'seaborn-white': 'seaborn-v0_8-white',\n+        'seaborn-whitegrid': 'seaborn-v0_8-whitegrid',\n+    }\n \n     def fix_style(s):\n         if isinstance(s, str):\n", "instance_id": "matplotlib__matplotlib-24265"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 4806afee9..c7211078b 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -193,10 +193,15 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n             se = np.sum(e, axis=1)\n             unconverged = (np.sum((se == convergence_iter) + (se == 0))\n                            != n_samples)\n-            if (not unconverged and (K > 0)) or (it == max_iter):\n+            if (not unconverged and (K > 0)):\n                 if verbose:\n                     print(\"Converged after %d iterations.\" % it)\n+                converged = True\n                 break\n+            elif it == max_iter - 1:\n+                if verbose:\n+                    print(\"Did not converge\")\n+                converged = False\n     else:\n         if verbose:\n             print(\"Did not converge\")\n@@ -226,7 +231,7 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         cluster_centers_indices = []\n \n     if return_n_iter:\n-        return cluster_centers_indices, labels, it + 1\n+        return cluster_centers_indices, labels, it + 1, converged\n     else:\n         return cluster_centers_indices, labels\n \n@@ -382,7 +387,7 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n                              \"'euclidean'. Got %s instead\"\n                              % str(self.affinity))\n \n-        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n+        self.cluster_centers_indices_, self.labels_, self.n_iter_, converged = \\\n             affinity_propagation(\n                 self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                 convergence_iter=self.convergence_iter, damping=self.damping,\n@@ -391,6 +396,10 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n         if self.affinity != \"precomputed\":\n             self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n \n+        if not converged:\n+            self.cluster_centers_indices_ = np.array([])\n+            self.labels_ = np.array([-1] * X.shape[0])\n+        \n         return self\n \n     def predict(self, X):\n", "instance_id": "scikit-learn__scikit-learn-15512"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..e95a3dd8da 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1738,18 +1738,6 @@ def partitions(n, m=None, k=None, size=False):\n     {2: 1, 4: 1}\n     {3: 2}\n \n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n-\n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n-    [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n     >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n     [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n@@ -1802,9 +1790,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n", "instance_id": "sympy__sympy-20154"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..61d8a5203c 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -220,9 +220,13 @@ def switch_backend(newbackend):\n         The name of the backend to use.\n     \"\"\"\n     global _backend_mod\n+    # Save the current state of Gcf.figs\n+    current_figs = _pylab_helpers.Gcf.figs.copy()\n     # make sure the init is pulled up so we can assign to it later\n     import matplotlib.backends\n     close(\"all\")\n+    # Restore the state of Gcf.figs\n+    _pylab_helpers.Gcf.figs.update(current_figs)\n \n     if newbackend is rcsetup._auto_backend_sentinel:\n         current_framework = cbook._get_running_interactive_framework()\n", "instance_id": "matplotlib__matplotlib-23299"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-11040"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\nindex bd6afb12d1..b2efb89d12 100644\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -453,14 +453,14 @@ def _declare_arg(self, arg):\n         proto = self._prototype_arg(arg)\n         if arg.dimensions:\n             shape = '(' + ','.join(self._string_var(i[1] + 1) for i in arg.dimensions) + ')'\n-            return proto + \" = np.empty({shape})\".format(shape=shape)\n+            return proto + \" = np.empty({shape}, dtype=np.float64)\".format(shape=shape)\n         else:\n             return proto + \" = 0\"\n \n     def _call_arg(self, arg):\n         if arg.dimensions:\n             t = arg.get_datatype('c')\n-            return \"<{0}*> {1}.data\".format(t, self._string_var(arg.name))\n+            return \"<{0}*> {1}.data if isinstance({1}, np.ndarray) else &{1}\".format(t, self._string_var(arg.name))\n         elif isinstance(arg, ResultBase):\n             return \"&{0}\".format(self._string_var(arg.name))\n         else:\n", "instance_id": "sympy__sympy-16792"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8376b487..2071bfdc 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -696,6 +696,70 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         self._dims = dims\n         self._indexes = indexes\n \n+    def update(self, other: \"CoercibleMapping\") -> \"Dataset\":\n+        \"\"\"Update this dataset's variables with those from another dataset.\n+\n+        Parameters\n+        ----------\n+        other : Dataset or mapping\n+            Variables with which to update this dataset. One of:\n+\n+            - Dataset\n+            - mapping {var name: DataArray}\n+            - mapping {var name: Variable}\n+            - mapping {var name: (dimension name, array-like)}\n+            - mapping {var name: (tuple of dimension names, array-like)}\n+\n+        Returns\n+        -------\n+        updated : Dataset\n+            Updated dataset.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If any dimensions would have inconsistent sizes in the updated\n+            dataset.\n+        \"\"\"\n+        merge_result = dataset_update_method(self, other)\n+        updated_variables = {\n+            k: (v.chunk() if is_duck_dask_array(v.data) else v)\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, **merge_result._asdict(), variables=updated_variables)\n+\n+    def update(self, other: \"CoercibleMapping\") -> \"Dataset\":\n+        \"\"\"Update this dataset's variables with those from another dataset.\n+\n+        Parameters\n+        ----------\n+        other : Dataset or mapping\n+            Variables with which to update this dataset. One of:\n+\n+            - Dataset\n+            - mapping {var name: DataArray}\n+            - mapping {var name: Variable}\n+            - mapping {var name: (dimension name, array-like)}\n+            - mapping {var name: (tuple of dimension names, array-like)}\n+\n+        Returns\n+        -------\n+        updated : Dataset\n+            Updated dataset.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If any dimensions would have inconsistent sizes in the updated\n+            dataset.\n+        \"\"\"\n+        merge_result = dataset_update_method(self, other)\n+        updated_variables = {\n+            k: (v.chunk() if is_duck_dask_array(v.data) else v)\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, **merge_result._asdict(), variables=updated_variables)\n+\n     @classmethod\n     def load_store(cls, store, decoder=None) -> \"Dataset\":\n         \"\"\"Create a new dataset from the contents of a backends.*DataStore\n@@ -1877,7 +1941,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         chunks: Union[\n             Number,\n             str,\n-            Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]],\n+            Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]]\n         ] = {},  # {} even though it's technically unsafe, is being used intentionally here (#4667)\n         name_prefix: str = \"xarray-\",\n         token: str = None,\n", "instance_id": "pydata__xarray-4493"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 77768e7383..a6fd4798ea 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1508,7 +1508,7 @@ class DraggableBase:\n         ]\n \n     # A property, not an attribute, to maintain picklability.\n-    canvas = property(lambda self: self.ref_artist.figure.canvas)\n+    canvas = property(lambda self: self.ref_artist.figure.canvas if self.ref_artist.figure else None)\n \n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n@@ -1559,13 +1559,15 @@ class DraggableBase:\n     def disconnect(self):\n         \"\"\"Disconnect the callbacks.\"\"\"\n         for cid in self.cids:\n-            self.canvas.mpl_disconnect(cid)\n+            if self.canvas:\n+                self.canvas.mpl_disconnect(cid)\n         try:\n             c1 = self._c1\n         except AttributeError:\n             pass\n         else:\n-            self.canvas.mpl_disconnect(c1)\n+            if self.canvas:\n+                self.canvas.mpl_disconnect(c1)\n \n     def save_offset(self):\n         pass\n", "instance_id": "matplotlib__matplotlib-25442"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f32ce64629..a2d5f30ff5 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -761,6 +761,10 @@ class Field(RegisterLookupMixin):\n         column = self.db_column or attname\n         return attname, column\n \n+    def __init__(self, *args, **kwargs):\n+        kwargs.setdefault('help_text', 'Enter a duration in the format [DD] [[HH:]MM:]ss[.uuuuuu]')\n+        super().__init__(*args, **kwargs)\n+\n     def get_internal_type(self):\n         return self.__class__.__name__\n \n@@ -1587,7 +1591,7 @@ class DurationField(Field):\n     empty_strings_allowed = False\n     default_error_messages = {\n         'invalid': _(\"'%(value)s' value has an invalid format. It must be in \"\n-                     \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n+                     \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\")\n     }\n     description = _(\"Duration\")\n \n", "instance_id": "django__django-11049"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 7a3de33522..3202ae1c0d 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -629,7 +629,7 @@ def adjust(s, wid=None, how='<^>'):\n             # put the present prettyF to the right\n             prettyF = prettyForm(*prettySign.right(prettyF))\n \n-        prettyF.baseline = max_upper + sign_height//2\n+        prettyF.baseline = max_upper + sign_height//2 + 1\n         prettyF.binding = prettyForm.MUL\n         return prettyF\n \n", "instance_id": "sympy__sympy-16503"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..d3889ba26b 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -40,6 +40,8 @@ def _multi_decorate(decorators, method):\n         bound_method = partial(method.__get__(self, type(self)))\n         for dec in decorators:\n             bound_method = dec(bound_method)\n+        # Ensure the wrapper assignments are preserved\n+        update_wrapper(bound_method, method)\n         return bound_method(*args, **kwargs)\n \n     # Copy any attributes that a decorator adds to the function it decorates.\n", "instance_id": "django__django-14787"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..6196fe16 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,22 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+    headers = (\"Domain\", \"Endpoint\", \"Methods\", \"Rule\")\n     widths = (\n+        max(len(rule.subdomain or current_app.config['SERVER_NAME'] or '') for rule in rules),\n         max(len(rule.endpoint) for rule in rules),\n         max(len(methods) for methods in rule_methods),\n         max(len(rule.rule) for rule in rules),\n     )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n     for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+        domain = rule.subdomain or current_app.config['SERVER_NAME'] or ''\n+        click.echo(row.format(domain, rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\n", "instance_id": "pallets__flask-5063"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/config/argparsing.py b/src/_pytest/config/argparsing.py\nindex 9b526ff3e..845cf578a 100644\n--- a/src/_pytest/config/argparsing.py\n+++ b/src/_pytest/config/argparsing.py\n@@ -75,6 +75,9 @@ class Parser:\n         by passing a ``dest`` attribute, for example\n         ``addoption(\"--long\", dest=\"NAME\", ...)``.\n         \"\"\"\n+        # Adding a shortcut for --collect-only\n+        if '--collect-only' in opts:\n+            opts = opts + ('-c',)\n         self._anonymous.addoption(*opts, **attrs)\n \n     def parse(self, args, namespace=None):\n", "instance_id": "pytest-dev__pytest-6116"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..32c1c81c1b 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -31,7 +31,14 @@ from .utils import get_callable\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n+        if isinstance(func, functools.partial):\n+            self.func = func.func\n+            self.partial_args = func.args\n+            self.partial_kwargs = func.keywords\n+        else:\n+            self.func = func\n+            self.partial_args = ()\n+            self.partial_kwargs = {}\n         self.args = args\n         self.kwargs = kwargs\n         self.url_name = url_name\n@@ -45,12 +52,12 @@ class ResolverMatch:\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n         self.namespace = ':'.join(self.namespaces)\n \n-        if not hasattr(func, '__name__'):\n+        if not hasattr(self.func, '__name__'):\n             # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+            self._func_path = self.func.__class__.__module__ + '.' + self.func.__class__.__name__\n         else:\n             # A function-based view\n-            self._func_path = func.__module__ + '.' + func.__name__\n+            self._func_path = self.func.__module__ + '.' + self.func.__name__\n \n         view_path = url_name or self._func_path\n         self.view_name = ':'.join(self.namespaces + [view_path])\n@@ -59,9 +66,10 @@ class ResolverMatch:\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n-        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n+        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s, partial_args=%s, partial_kwargs=%s)\" % (\n             self._func_path, self.args, self.kwargs, self.url_name,\n             self.app_names, self.namespaces, self.route,\n+            self.partial_args, self.partial_kwargs,\n         )\n \n \n", "instance_id": "django__django-14155"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..dd5feb021 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n@@ -91,9 +91,9 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n                              'required!')\n \n         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n-                delayed(_parallel_fit_estimator)(clone(clf), X, y,\n-                                                 sample_weight=sample_weight)\n-                for clf in clfs if clf is not None)\n+            delayed(_parallel_fit_estimator)(clone(clf), X, y,\n+                                             sample_weight=sample_weight)\n+            for clf in clfs if clf is not None)\n \n         self.named_estimators_ = Bunch()\n         for k, e in zip(self.estimators, self.estimators_):\n", "instance_id": "scikit-learn__scikit-learn-13779"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0c64748ccd..85e3c5f96f 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1277,7 +1277,9 @@ class DateField(DateTimeCheckMixin, Field):\n         return '' if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n+        path = self._path() if callable(self._path) else self._path\n         return super().formfield(**{\n+            'path': path,\n             'form_class': forms.DateField,\n             **kwargs,\n         })\n@@ -1663,7 +1665,9 @@ class FilePathField(Field):\n \n     def __init__(self, verbose_name=None, name=None, path='', match=None,\n                  recursive=False, allow_files=True, allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+        self.match, self.recursive = match, recursive\n+        self._path = path\n+        self.path = path() if callable(path) else path\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n         kwargs.setdefault('max_length', 100)\n         super().__init__(verbose_name, name, **kwargs)\n@@ -1687,8 +1691,8 @@ class FilePathField(Field):\n \n     def deconstruct(self):\n         name, path, args, kwargs = super().deconstruct()\n-        if self.path != '':\n-            kwargs['path'] = self.path\n+        if self._path != '':\n+            kwargs['path'] = self._path\n         if self.match is not None:\n             kwargs['match'] = self.match\n         if self.recursive is not False:\n", "instance_id": "django__django-10924"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sympy__sympy-18199"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..4914cdbc80 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -707,6 +707,7 @@ class Poly3DCollection(PolyCollection):\n             if any(len(np.shape(vert)) != 2 for vert in verts):\n                 raise ValueError('verts must be a list of (N, 3) array-like')\n         self.set_zsort(zsort)\n+        self._facecolors2d = None\n         self._codes3d = None\n \n     _zsort_functions = {\n", "instance_id": "matplotlib__matplotlib-23562"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autosummary/__init__.py b/sphinx/ext/autosummary/__init__.py\nindex 0cdd88feb..732e1c11f 100644\n--- a/sphinx/ext/autosummary/__init__.py\n+++ b/sphinx/ext/autosummary/__init__.py\n@@ -305,6 +305,10 @@ class Autosummary(SphinxDirective):\n                 logger.warning(__('autosummary: failed to import %s'), name)\n                 continue\n \n+            if not self.config.autosummary_imported_members and \\\n+               hasattr(obj, '__module__') and obj.__module__ != modname:\n+                continue\n+\n             self.bridge.result = StringList()  # initialize for each documenter\n             full_name = real_name\n             if not isinstance(obj, ModuleType):\n", "instance_id": "sphinx-doc__sphinx-7686"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/physics/units/util.py b/sympy/physics/units/util.py\nindex b03ed4cd88..e23c3ac8c8 100644\n--- a/sympy/physics/units/util.py\n+++ b/sympy/physics/units/util.py\n@@ -24,6 +24,9 @@ def _get_conversion_matrix_for_expr(expr, target_units, unit_system):\n     if not canon_expr_units.issubset(set(canon_dim_units)):\n         return None\n \n+    if len(canon_expr_units) != len(canon_dim_units):\n+        return None\n+\n     seen = set()\n     canon_dim_units = [i for i in canon_dim_units if not (i in seen or seen.add(i))]\n \n@@ -102,7 +105,7 @@ def get_total_scale_factor(expr):\n         return expr\n \n     depmat = _get_conversion_matrix_for_expr(expr, target_units, unit_system)\n-    if depmat is None:\n+    if depmat is None or any(p != int(p) for p in depmat):\n         return expr\n \n     expr_scale_factor = get_total_scale_factor(expr)\n", "instance_id": "sympy__sympy-20442"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..b178d18a7 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -597,24 +597,19 @@ class PyLinter(\n                         # Skip subtree of already discovered package.\n                         continue\n \n-                    if _is_ignored_file(\n-                        root,\n-                        self.config.ignore,\n-                        self.config.ignore_patterns,\n-                        self.config.ignore_paths,\n+                    if not any(\n+                        _is_relative_to(Path(root), Path(ignore_path))\n+                        for ignore_path in self.config.ignore_paths\n                     ):\n-                        skip_subtrees.append(root)\n-                        continue\n-\n-                    if \"__init__.py\" in files:\n-                        skip_subtrees.append(root)\n-                        yield root\n-                    else:\n-                        yield from (\n-                            os.path.join(root, file)\n-                            for file in files\n-                            if file.endswith(\".py\")\n-                        )\n+                        if \"__init__.py\" in files:\n+                            skip_subtrees.append(root)\n+                            yield root\n+                        else:\n+                            yield from (\n+                                os.path.join(root, file)\n+                                for file in files\n+                                if file.endswith(\".py\")\n+                            )\n             else:\n                 yield something\n \n", "instance_id": "pylint-dev__pylint-7080"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex e16ab8ce5..cce78b27c 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1552,6 +1552,14 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n         if sig is None:\n             return None\n \n+        # Remove *args and **kwargs from the signature if autodoc_typehints is set to \"description\"\n+        if self.config.autodoc_typehints == \"description\":\n+            parameters = [\n+                param for param in sig.parameters.values()\n+                if param.kind not in (Parameter.VAR_POSITIONAL, Parameter.VAR_KEYWORD)\n+            ]\n+            sig = sig.replace(parameters=parameters)\n+\n         return stringify_signature(sig, show_return_annotation=False, **kwargs)\n \n     def _find_signature(self) -> Tuple[str, str]:\n", "instance_id": "sphinx-doc__sphinx-10451"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sphinx-doc__sphinx-8506"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/tensor/array/dense_ndim_array.py b/sympy/tensor/array/dense_ndim_array.py\nindex 6019daf787..9e0f99e2df 100644\n--- a/sympy/tensor/array/dense_ndim_array.py\n+++ b/sympy/tensor/array/dense_ndim_array.py\n@@ -138,7 +138,10 @@ def __new__(cls, iterable, shape=None, **kwargs):\n \n     @classmethod\n     def _new(cls, iterable, shape, **kwargs):\n-        shape, flat_list = cls._handle_ndarray_creation_inputs(iterable, shape, **kwargs)\n+        if iterable == []:\n+            shape, flat_list = (), []\n+        else:\n+            shape, flat_list = cls._handle_ndarray_creation_inputs(iterable, shape, **kwargs)\n         shape = Tuple(*map(_sympify, shape))\n         cls._check_special_bounds(flat_list, shape)\n         flat_list = flatten(flat_list)\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex 6490a655a4..a6c46ca242 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -223,7 +223,10 @@ def _handle_ndarray_creation_inputs(cls, iterable=None, shape=None, **kwargs):\n \n             # Construct N-dim array from an iterable (numpy arrays included):\n             elif isinstance(iterable, Iterable):\n-                iterable, shape = cls._scan_iterable_shape(iterable)\n+                if iterable == []:\n+                    return (), []\n+                else:\n+                    iterable, shape = cls._scan_iterable_shape(iterable)\n \n             # Construct N-dim array from a Matrix:\n             elif isinstance(iterable, MatrixBase):\n", "instance_id": "sympy__sympy-23117"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..a88a627ba 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -409,7 +409,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n \n     def _validate_transformers(self):\n         if not self.transformers:\n-            return\n+            return []\n \n         names, transformers, _ = zip(*self.transformers)\n \n@@ -543,7 +543,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         feature_names_out : ndarray of shape (n_features,), dtype=str\n             Transformed feature names.\n         \"\"\"\n-        if self.verbose_feature_names_out:\n+        if self.verbose_feature_names_out and transformer_with_feature_names_out:\n             # Prefix the feature names out with the transformers name\n             names = list(\n                 chain.from_iterable(\n@@ -865,7 +865,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 transformer_names = [\n                     t[0] for t in self._iter(fitted=True, replace_strings=True)\n                 ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                feature_names_outs = [X.columns for X in Xs if X.shape[1] > 0]\n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n", "instance_id": "scikit-learn__scikit-learn-25570"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 488d6a77cd..e952af3fdc 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -68,7 +68,7 @@ def format(\n             str_number = \"{:f}\".format(number)\n     else:\n         str_number = str(number)\n-    if str_number[0] == \"-\":\n+    if str_number and str_number[0] == \"-\":\n         sign = \"-\"\n         str_number = str_number[1:]\n     # decimal part\n", "instance_id": "django__django-16046"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..d1616acf5f 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,9 +727,9 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n-        xa[xa > self.N - 1] = self._i_over\n-        xa[xa < 0] = self._i_under\n-        xa[mask_bad] = self._i_bad\n+        xa = np.where(xa > self.N - 1, self._i_over, xa)\n+        xa = np.where(xa < 0, self._i_under, xa)\n+        xa = np.where(mask_bad, self._i_bad, xa)\n \n         lut = self._lut\n         if bytes:\n", "instance_id": "matplotlib__matplotlib-24970"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..3a462f1c4c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n", "instance_id": "django__django-11179"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex e6b7d4d821..3cd9d86592 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -90,6 +90,8 @@ class SafeExceptionReporterFilter:\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple)):\n+                cleansed = type(value)(self.cleanse_setting(k, v) for k, v in enumerate(value))\n             else:\n                 cleansed = value\n         except TypeError:\n", "instance_id": "django__django-12700"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "pytest-dev__pytest-11148"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 180f4a41fc..e4ef0f3c95 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1299,7 +1299,7 @@ class QuerySet:\n             # values() queryset can only be used as nested queries\n             # if they are set up to select only a single field.\n             raise TypeError('Cannot use multi-field values as a filter value.')\n-        query = self.query.resolve_expression(*args, **kwargs)\n+        query = self.query.resolve_expression(*args, **kwargs, allow_group_by=True)\n         query._db = self._db\n         return query\n     resolve_expression.queryset_only = True\n", "instance_id": "django__django-11797"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..dbdd7f4726 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,8 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        imports = {'import %s' % module}\n+        return \"%s.%s['%s']\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "instance_id": "django__django-11815"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-11630"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\nindex b19ee7c64..ca2f3a1a7 100644\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -306,7 +306,7 @@ class TracebackEntry:\n         # This output does not quite match Python's repr for traceback entries,\n         # but changing it to do so would break certain plugins.  See\n         # https://github.com/pytest-dev/pytest/pull/7535/ for details.\n-        return \"  File %r:%d in %s\\n  %s\\n\" % (\n+        return \"  File %r:%d in %s\\n  %s\" % (\n             str(self.path),\n             self.lineno + 1,\n             name,\ndiff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..1e7d6c92e 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -711,7 +711,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             pos += 1\n         # Special case: for a decorated function, set the lineno to that of the\n         # first decorator, not the `def`. Issue #4984.\n-        if isinstance(item, ast.FunctionDef) and item.decorator_list:\n+        if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)) and item.decorator_list:\n             lineno = item.decorator_list[0].lineno\n         else:\n             lineno = item.lineno\n", "instance_id": "pytest-dev__pytest-9359"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\nindex 138ed07ff8..7766e76ed9 100644\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -56,6 +56,7 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n     available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n+    base_language_code = settings.LANGUAGE_CODE.split('-')[0]\n+    if settings.LANGUAGE_CODE not in available_tags and base_language_code not in available_tags:\n         return [E004]\n     return []\n", "instance_id": "django__django-12286"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..9e8b74203d 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -113,35 +113,17 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n     if total_degree:\n         if min_degree > max_degree:\n             return\n-        if not variables or max_degree == 0:\n-            yield S.One\n+        if not variables:\n             return\n-        # Force to list in case of passed tuple or other incompatible collection\n-        variables = list(variables) + [S.One]\n+        variables = list(variables)\n         if all(variable.is_commutative for variable in variables):\n-            monomials_list_comm = []\n-            for item in combinations_with_replacement(variables, max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_comm.append(Mul(*item))\n-            yield from set(monomials_list_comm)\n+            for total_degree in range(min_degree, max_degree + 1):\n+                for item in combinations_with_replacement(variables, total_degree):\n+                    yield Mul(*item)\n         else:\n-            monomials_list_non_comm = []\n-            for item in product(variables, repeat=max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_non_comm.append(Mul(*item))\n-            yield from set(monomials_list_non_comm)\n+            for total_degree in range(min_degree, max_degree + 1):\n+                for item in product(variables, repeat=total_degree):\n+                    yield Mul(*item)\n     else:\n         if any(min_degrees[i] > max_degrees[i] for i in range(n)):\n             raise ValueError('min_degrees[i] must be <= max_degrees[i] for all i')\n", "instance_id": "sympy__sympy-21847"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-11910"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex dadd4acfa1..ca35a4bb9b 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2040,7 +2040,7 @@ class InlineModelAdmin(BaseModelAdmin):\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            self.verbose_name_plural = self.verbose_name + 's' if self.verbose_name else self.model._meta.verbose_name_plural\n \n     @property\n     def media(self):\n", "instance_id": "django__django-13710"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 5bbb786984..8ea17ebbd4 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -1311,10 +1311,11 @@ default: %(va)s\n         \"\"\"\n         if (self.get_layout_engine() is not None and\n                 not self.get_layout_engine().adjust_compatible):\n-            _api.warn_external(\n-                \"This figure was using a layout engine that is \"\n-                \"incompatible with subplots_adjust and/or tight_layout; \"\n-                \"not calling subplots_adjust.\")\n+            if self.get_layout_engine().__class__.__name__ != 'PlaceHolderLayoutEngine':\n+                _api.warn_external(\n+                    \"This figure was using a layout engine that is \"\n+                    \"incompatible with subplots_adjust and/or tight_layout; \"\n+                    \"not calling subplots_adjust.\")\n             return\n         self.subplotpars.update(left, bottom, right, top, wspace, hspace)\n         for ax in self.axes:\n", "instance_id": "matplotlib__matplotlib-23987"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..61913a1888 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -70,12 +70,15 @@ class BaseDatabaseCreation:\n                 run_syncdb=True,\n             )\n \n-        # We then serialize the current state of the database into a string\n-        # and store it on the connection. This slightly horrific process is so people\n-        # who are testing on databases without transactions or who are using\n-        # a TransactionTestCase still get a clean database on every test run.\n-        if serialize:\n-            self.connection._test_serialized_contents = self.serialize_db_to_string()\n+            # We then serialize the current state of the database into a string\n+            # and store it on the connection. This slightly horrific process is so people\n+            # who are testing on databases without transactions or who are using\n+            # a TransactionTestCase still get a clean database on every test run.\n+            if serialize:\n+                self.connection._test_serialized_contents = self.serialize_db_to_string()\n+        else:\n+            # If migrations are disabled, ensure the test database is empty.\n+            self.connection._test_serialized_contents = None\n \n         call_command('createcachetable', database=self.connection.alias)\n \n", "instance_id": "django__django-13448"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 9ce46e3f73..b73ca451fe 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -207,8 +207,26 @@ class Field(RegisterLookupMixin):\n             *self._check_backend_specific_checks(**kwargs),\n             *self._check_validators(),\n             *self._check_deprecation_details(),\n+            *self._check_max_length_with_choices(),\n         ]\n \n+    def _check_max_length_with_choices(self):\n+        \"\"\"\n+        Check if max_length is large enough to fit the longest value in choices.\n+        \"\"\"\n+        if self.choices is not None and self.max_length is not None:\n+            longest_choice = max((len(str(choice)) for choice, _ in self.choices), default=0)\n+            if longest_choice > self.max_length:\n+                return [\n+                    checks.Error(\n+                        f\"'max_length' is too small to fit the longest value in 'choices'. \"\n+                        f\"Longest choice has length {longest_choice}.\",\n+                        obj=self,\n+                        id='fields.E009',\n+                    )\n+                ]\n+        return []\n+\n     def _check_field_name(self):\n         \"\"\"\n         Check if field name is valid, i.e. 1) does not end with an\n", "instance_id": "django__django-11742"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..5036f62f76 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -213,14 +213,17 @@ def __add__(self, other):\n         sympy.geometry.point.Point.translate\n \n         \"\"\"\n-        try:\n-            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n-        except TypeError:\n+        if isinstance(other, Point):\n+            s, o = Point._normalize_dimension(self, other)\n+            coords = [simplify(a + b) for a, b in zip(s, o)]\n+            return Point(coords, evaluate=False)\n+        elif isinstance(other, (int, float, sympify(0).__class__)):\n+            return self.__mul__(other)\n+        elif isinstance(other, Mul) and isinstance(other.args[0], (int, float, sympify(0).__class__)):\n+            return self.__mul__(other.args[0]) + other.args[1]\n+        else:\n             raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n-        coords = [simplify(a + b) for a, b in zip(s, o)]\n-        return Point(coords, evaluate=False)\n-\n     def __contains__(self, item):\n         return item in self.args\n \n", "instance_id": "sympy__sympy-17655"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 171a3e7b0..52739f808 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1716,12 +1716,12 @@ class DataDocumenter(ModuleLevelDocumenter):\n                 annotations = {}\n \n             if self.objpath[-1] in annotations:\n-                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]), self.config.autodoc_type_aliases)\n                 self.add_line('   :type: ' + objrepr, sourcename)\n             else:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n                 if self.analyzer and key in self.analyzer.annotations:\n-                    self.add_line('   :type: ' + self.analyzer.annotations[key],\n+                    self.add_line('   :type: ' + stringify_typehint(self.analyzer.annotations[key], self.config.autodoc_type_aliases),\n                                   sourcename)\n \n             try:\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..254ccffe9 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -86,7 +86,9 @@ def process_documenter_options(documenter: \"Type[Documenter]\", config: Config, o\n             if name in config.autodoc_default_options and not negated:\n                 options[name] = config.autodoc_default_options[name]\n \n-    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    processed_options = Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    processed_options['autodoc_type_aliases'] = config.autodoc_type_aliases\n+    return processed_options\n \n \n def parse_generated_content(state: RSTState, content: StringList, documenter: Documenter\n", "instance_id": "sphinx-doc__sphinx-8435"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 495e90570..3bbc3f58b 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -206,6 +206,10 @@ class Sphinx:\n             self.confdir = abspath(confdir)\n             self.config = Config.read(self.confdir, confoverrides or {}, self.tags)\n \n+        # Append rst_prolog to the document\n+        if self.config.rst_prolog:\n+            self.config.rst_prolog = self.config.rst_prolog + '\\n'\n+\n         # initialize some limited config variables before initialize i18n and loading\n         # extensions\n         self.config.pre_init_values()\ndiff --git a/sphinx/io.py b/sphinx/io.py\nindex efd2b4ea9..c7f928a38 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -108,6 +108,10 @@ class SphinxStandaloneReader(SphinxBaseReader):\n         \"\"\"Read content from source and do post-process.\"\"\"\n         content = self.source.read()\n \n+        # prepend rst_prolog if it exists\n+        if env.config.rst_prolog:\n+            content = env.config.rst_prolog + content\n+\n         # emit \"source-read\" event\n         arg = [content]\n         env.events.emit('source-read', env.docname, arg)\ndiff --git a/sphinx/util/docutils.py b/sphinx/util/docutils.py\nindex cbf26fcd5..99a6a5bc6 100644\n--- a/sphinx/util/docutils.py\n+++ b/sphinx/util/docutils.py\n@@ -249,6 +249,9 @@ class CustomReSTDispatcher:\n         self.roles_func: Callable = lambda *args: (None, [])\n \n     def __enter__(self) -> None:\n+        # prepend rst_prolog if it exists\n+        if self.env.config.rst_prolog:\n+            self.env.config.rst_prolog = self.env.config.rst_prolog + '\\n'\n         self.enable()\n \n     def __exit__(\n", "instance_id": "sphinx-doc__sphinx-11445"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\nindex 7b7ddc8d..ed2a3dbb 100644\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -23,6 +23,11 @@ class PolyFit(Stat):\n \n         x = data[\"x\"]\n         y = data[\"y\"]\n+        # Drop missing values\n+        valid_data = data.dropna(subset=[\"x\", \"y\"])\n+        x = valid_data[\"x\"]\n+        y = valid_data[\"y\"]\n+\n         if x.nunique() <= self.order:\n             # TODO warn?\n             xx = yy = []\n", "instance_id": "mwaskom__seaborn-3010"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex fbb3c7e6..1ba4fe53 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -31,6 +31,7 @@ from .utils import (\n from .compat import (\n     cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,\n     is_py2, chardet, builtin_str, basestring)\n+import six\n from .compat import json as complexjson\n from .status_codes import codes\n \n@@ -333,7 +334,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if isinstance(url, bytes):\n             url = url.decode('utf8')\n         else:\n-            url = unicode(url) if is_py2 else str(url)\n+            url = six.text_type(url) if is_py2 else str(url)\n \n         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n         # `data` etc to work around exceptions from `url_parse`, which\n@@ -666,6 +667,8 @@ class Response(object):\n             if hasattr(self.raw, 'stream'):\n                 try:\n                     for chunk in self.raw.stream(chunk_size, decode_content=True):\n+                        if decode_unicode:\n+                            chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                         yield chunk\n                 except ProtocolError as e:\n                     raise ChunkedEncodingError(e)\n@@ -679,6 +682,8 @@ class Response(object):\n                     chunk = self.raw.read(chunk_size)\n                     if not chunk:\n                         break\n+                    if decode_unicode:\n+                        chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                     yield chunk\n \n             self._content_consumed = True\n@@ -694,9 +699,6 @@ class Response(object):\n \n         chunks = reused_chunks if self._content_consumed else stream_chunks\n \n-        if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n-\n         return chunks\n \n     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n", "instance_id": "psf__requests-3362"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1a55d3d417..cc7c96d6cf 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -764,10 +764,11 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n+            display_method_name = 'get_%s_display' % self.name\n+            if not hasattr(cls, display_method_name) or not callable(getattr(cls, display_method_name)):\n                 setattr(\n                     cls,\n-                    'get_%s_display' % self.name,\n+                    display_method_name,\n                     partialmethod(cls._get_FIELD_display, field=self),\n                 )\n \n", "instance_id": "django__django-12284"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..ba8c3463a0 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,11 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n", "instance_id": "django__django-14855"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/geometry/util.py b/sympy/geometry/util.py\nindex d32adc3066..674a72e831 100644\n--- a/sympy/geometry/util.py\n+++ b/sympy/geometry/util.py\n@@ -17,6 +17,7 @@\n     is_sequence, range, string_types, ordered)\n from sympy.core.containers import OrderedSet\n from .point import Point, Point2D\n+from .entity import GeometryEntity\n \n \n def find(x, equation):\n@@ -286,6 +287,8 @@ def closest_points(*args):\n     from collections import deque\n     from math import hypot, sqrt as _sqrt\n     from sympy.functions.elementary.miscellaneous import sqrt\n+    from sympy.functions.elementary.miscellaneous import sqrt\n+    from sympy.functions.elementary.miscellaneous import sqrt\n \n     p = [Point2D(i) for i in set(args)]\n     if len(p) < 2:\n@@ -565,21 +568,29 @@ def idiff(eq, y, x, n=1):\n     sympy.core.function.diff: explicitly differentiates wrt symbols\n \n     \"\"\"\n+    from sympy import Eq\n+\n+    if isinstance(eq, Eq):\n+        eq = eq.lhs - eq.rhs\n+\n     if is_sequence(y):\n         dep = set(y)\n         y = y[0]\n-    elif isinstance(y, Symbol):\n+    elif isinstance(y, (Symbol, Function)):\n         dep = {y}\n     else:\n         raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\n \n     f = dict([(s, Function(\n         s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n-    dydx = Function(y.name)(x).diff(x)\n+    dydx = Function(y.name if isinstance(y, Symbol) else y.func.__name__)(x).diff(x)\n     eq = eq.subs(f)\n     derivs = {}\n     for i in range(n):\n-        yp = solve(eq.diff(x), dydx)[0].subs(derivs)\n+        yp = solve(eq.diff(x), dydx)\n+        if not yp:\n+            raise ValueError(\"Could not solve for the derivative.\")\n+        yp = yp[0].subs(derivs)\n         if i == n - 1:\n             return yp.subs([(v, k) for k, v in f.items()])\n         derivs[dydx] = yp\n", "instance_id": "sympy__sympy-15678"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "django__django-16820"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..edc62587d2 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -164,7 +164,9 @@ class MigrationWriter:\n \n         # django.db.migrations is always used, but models import may not be.\n         # If models import exists, merge it with migrations import.\n-        if \"from django.db import models\" in imports:\n+        if \"from django.db import models\" in imports or any(\n+            \"models.Model\" in op for op in operations\n+        ):\n             imports.discard(\"from django.db import models\")\n             imports.add(\"from django.db import migrations, models\")\n         else:\n", "instance_id": "django__django-14580"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 38da1e6ecc..63d55d329c 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -125,10 +125,16 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        return (\n-            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n-            {\"import %s\" % module},\n-        )\n+        try:\n+            return (\n+                \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n+                {\"import %s\" % module},\n+            )\n+        except KeyError:\n+            # Handle combination of Enum flags\n+            members, _ = enum._decompose(self.value.__class__, self.value)\n+            combined = \" | \".join(\"%s.%s.%s\" % (module, enum_class.__qualname__, member.name) for member in members)\n+            return combined, {\"import %s\" % module}\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "instance_id": "django__django-15996"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\nindex 24e453a73..76a3916fd 100644\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -70,19 +70,24 @@ def _config_initialization(\n \n     # Now we parse any options from the command line, so they can override\n     # the configuration file\n-    parsed_args_list = linter._parse_command_line_configuration(args_list)\n-\n-    # Check if there are any options that we do not recognize\n-    unrecognized_options: list[str] = []\n-    for opt in parsed_args_list:\n-        if opt.startswith(\"--\"):\n-            unrecognized_options.append(opt[2:])\n-        elif opt.startswith(\"-\"):\n-            unrecognized_options.append(opt[1:])\n-    if unrecognized_options:\n-        msg = \", \".join(unrecognized_options)\n-        linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+    try:\n+        parsed_args_list = linter._parse_command_line_configuration(args_list)\n+\n+        # Check if there are any options that we do not recognize\n+        unrecognized_options: list[str] = []\n+        for opt in parsed_args_list:\n+            if opt.startswith(\"--\"):\n+                unrecognized_options.append(opt[2:])\n+            elif opt.startswith(\"-\"):\n+                unrecognized_options.append(opt[1:])\n+        if unrecognized_options:\n+            msg = \", \".join(unrecognized_options)\n+            linter.add_message(\"unrecognized-option\", line=0, args=msg)\n+            raise _UnrecognizedOptionError(options=unrecognized_options)\n+    except _UnrecognizedOptionError as exc:\n+        print(f\"Error: Unrecognized option(s) found: {', '.join(exc.options)}\", file=sys.stderr)\n+        print(linter.help(), file=sys.stderr)\n+        sys.exit(32)\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\ndiff --git a/pylint/config/exceptions.py b/pylint/config/exceptions.py\nindex 74a001c24..005a65360 100644\n--- a/pylint/config/exceptions.py\n+++ b/pylint/config/exceptions.py\n@@ -18,6 +18,9 @@ class _UnrecognizedOptionError(Exception):\n         self.options = options\n         super().__init__(*args)\n \n+    def __str__(self) -> str:\n+        return f\"Unrecognized option(s): {', '.join(self.options)}\"\n+\n \n class ArgumentPreprocessingError(Exception):\n     \"\"\"Raised if an error occurs during argument pre-processing.\"\"\"\n", "instance_id": "pylint-dev__pylint-6506"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..b3fbc8c29 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,6 +299,7 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n+            self.n_components = int(self.n_components)\n             check_scalar(self.n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n@@ -318,6 +319,8 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                  .format(X.shape[1],\n                                          self.components_.shape[1]))\n \n+        self.max_iter = int(self.max_iter)\n+        self.tol = float(self.tol)\n         check_scalar(self.max_iter, 'max_iter', int, 1)\n         check_scalar(self.tol, 'tol', float, 0.)\n         check_scalar(self.verbose, 'verbose', int, 0)\n", "instance_id": "scikit-learn__scikit-learn-14092"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex cbdab1de47..4a084bce03 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -214,7 +214,7 @@ class FileSystemStorage(Storage):\n \n     @cached_property\n     def file_permissions_mode(self):\n-        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS)\n+        return self._value_or_setting(self._file_permissions_mode, settings.FILE_UPLOAD_PERMISSIONS or 0o644)\n \n     @cached_property\n     def directory_permissions_mode(self):\n", "instance_id": "django__django-10914"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\nindex 574b4073b1..268c9a8262 100644\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field = np.char.replace(output_field, encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):\n", "instance_id": "astropy__astropy-6938"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/backends/backend_macosx.py b/lib/matplotlib/backends/backend_macosx.py\nindex 700d1d4c58..d83ec83f17 100644\n--- a/lib/matplotlib/backends/backend_macosx.py\n+++ b/lib/matplotlib/backends/backend_macosx.py\n@@ -98,6 +98,7 @@ class FigureCanvasMac(FigureCanvasAgg, _macosx.FigureCanvas, FigureCanvasBase):\n         width /= scale\n         height /= scale\n         self.figure.set_size_inches(width, height, forward=False)\n+        self.figure.dpi = self.figure._dpi  # Ensure DPI is correctly set after resizing\n         ResizeEvent(\"resize_event\", self)._process()\n         self.draw_idle()\n \ndiff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex c55864243a..1e101d622e 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2912,7 +2912,8 @@ class Figure(FigureBase):\n         ----------\n         val : float\n         \"\"\"\n-        self.dpi = val\n+        self._dpi = val\n+        self.dpi_scale_trans.clear().scale(val)\n         self.stale = True\n \n     def set_figwidth(self, val, forward=True):\n@@ -3041,7 +3042,8 @@ class Figure(FigureBase):\n                 f\"This figure was saved with matplotlib version {version} and \"\n                 f\"is unlikely to function correctly.\")\n \n-        self.__dict__ = state\n+        self.__dict__.update(state)\n+        self.dpi = self._dpi  # Ensure DPI is correctly set after unpickling\n \n         # re-initialise some of the unstored state information\n         FigureCanvasBase(self)  # Set self.canvas.\n", "instance_id": "matplotlib__matplotlib-23476"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 6866648d4e..3ee46618dc 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -504,10 +504,13 @@ def atoms(self, *types):\n             types = tuple(\n                 [t if isinstance(t, type) else type(t) for t in types])\n         else:\n-            types = (Atom,)\n+            types = None\n         result = set()\n         for expr in preorder_traversal(self):\n-            if isinstance(expr, types):\n+            if types:\n+                if isinstance(expr, types):\n+                    result.add(expr)\n+            elif not expr.args:\n                 result.add(expr)\n         return result\n \n", "instance_id": "sympy__sympy-18532"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 7ca05f0304..aa67c4311a 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -8,7 +8,8 @@\n from sympy.core.compatibility import reduce, iterable, SYMPY_INTS\n from sympy.core.function import count_ops, _mexpand\n from sympy.core.numbers import I, Integer\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sqrt\n+from sympy import Abs, Wild\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.polys import Poly, factor, cancel, parallel_poly_from_expr\n@@ -505,7 +506,13 @@ def traverse(e):\n         'old': lambda x: trigsimp_old(x, **opts),\n                    }[method]\n \n-    return trigsimpfunc(expr)\n+    simplified_expr = trigsimpfunc(expr)\n+    \n+    # Ensure that sqrt(sin(any_var)**2) is not simplified incorrectly\n+    any_var = Wild('any_var')\n+    simplified_expr = simplified_expr.replace(sqrt(sin(any_var)**2), Abs(sin(any_var)))\n+    \n+    return simplified_expr\n \n \n def exptrigsimp(expr):\n", "instance_id": "sympy__sympy-18087"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..b3144f2d37 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -6215,7 +6215,19 @@ def sqf_list(f, *gens, **args):\n     (2, [(x + 1, 2), (x + 2, 3)])\n \n     \"\"\"\n-    return _generic_factor_list(f, gens, args, method='sqf')\n+    coeff, factors = _generic_factor_list(f, gens, args, method='sqf')\n+    \n+    # Group factors by their multiplicity\n+    factor_dict = {}\n+    for factor, multiplicity in factors:\n+        if factor in factor_dict:\n+            factor_dict[factor] += multiplicity\n+        else:\n+            factor_dict[factor] = multiplicity\n+    \n+    grouped_factors = [(factor, multiplicity) for factor, multiplicity in factor_dict.items()]\n+    \n+    return coeff, grouped_factors\n \n \n @public\n@@ -6233,7 +6245,8 @@ def sqf(f, *gens, **args):\n     2*(x + 1)**2*(x + 2)**3\n \n     \"\"\"\n-    return _generic_factor(f, gens, args, method='sqf')\n+    coeff, factors = sqf_list(f, *gens, **args)\n+    return _keep_coeff(coeff, Mul(*[factor**multiplicity for factor, multiplicity in factors]))\n \n \n @public\n", "instance_id": "sympy__sympy-18698"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..c9bdfee89 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n", "instance_id": "pytest-dev__pytest-7432"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 1d390c71dd..c4aea2547c 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -19,7 +19,7 @@ class MessageEncoder(json.JSONEncoder):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n@@ -33,7 +33,7 @@ class MessageDecoder(json.JSONDecoder):\n     def process_messages(self, obj):\n         if isinstance(obj, list) and obj:\n             if obj[0] == MessageEncoder.message_key:\n-                if obj[1]:\n+                if obj[1] == 1:\n                     obj[3] = mark_safe(obj[3])\n                 return Message(*obj[2:])\n             return [self.process_messages(item) for item in obj]\n", "instance_id": "django__django-15347"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..7a3dd546b8 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,13 +2180,13 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n-                pass\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x0 = np.nan\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n-            except (TypeError, IndexError, KeyError):\n-                x = xconv\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x = np.nan\n \n             delist = False\n             if not np.iterable(dx):\n", "instance_id": "matplotlib__matplotlib-24149"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..e59affefb 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -286,12 +286,15 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n \n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+        if n_SV == 0:\n+            self.dual_coef_ = sp.csr_matrix((n_class, 0))\n+        else:\n+            dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n+            self.dual_coef_ = sp.csr_matrix(\n+                (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+                (n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n", "instance_id": "scikit-learn__scikit-learn-14894"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n", "instance_id": "django__django-16255"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/axes_grid.py b/lib/mpl_toolkits/axes_grid1/axes_grid.py\nindex 2b1b1d3200..8029ca4a3d 100644\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -13,8 +13,9 @@ from .mpl_axes import Axes\n def _tick_only(ax, bottom_on, left_on):\n     bottom_off = not bottom_on\n     left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    if not callable(ax.axis):\n+        ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n+        ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n \n \n class CbarAxesBase:\n", "instance_id": "matplotlib__matplotlib-26020"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 9e1be0fe0f..76b4f920e8 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -331,6 +331,11 @@ class LazyObject:\n             self._setup()\n         return (unpickle_lazyobject, (self._wrapped,))\n \n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n     def __copy__(self):\n         if self._wrapped is empty:\n             # If uninitialized, copy the wrapper. Use type(self), not\n", "instance_id": "django__django-15400"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..7c1bf9bf9b 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -162,9 +162,13 @@ def structurally_equal(self, other):\n             and self.colblocksizes == other.colblocksizes)\n \n     def _blockmul(self, other):\n-        if (isinstance(other, BlockMatrix) and\n-                self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+        if isinstance(other, BlockMatrix) and self.colblocksizes == other.rowblocksizes:\n+            result_blocks = self.blocks * other.blocks\n+            for i in range(result_blocks.rows):\n+                for j in range(result_blocks.cols):\n+                    if result_blocks[i, j] == 0:\n+                        result_blocks[i, j] = ZeroMatrix(result_blocks[i, j].rows, result_blocks[i, j].cols)\n+            return BlockMatrix(result_blocks)\n \n         return self * other\n \n", "instance_id": "sympy__sympy-17630"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/xarray/core/groupby.py b/xarray/core/groupby.py\nindex 8a097251..af5abd9a 100644\n--- a/xarray/core/groupby.py\n+++ b/xarray/core/groupby.py\n@@ -436,7 +436,7 @@ class GroupBy(SupportsArithmetic):\n         return zip(self._unique_coord.values, self._iter_grouped())\n \n     def __repr__(self):\n-        return \"{}, grouped over {!r} \\n{!r} groups with labels {}.\".format(\n+        return \"{}, grouped over {!r}\\n{!r} groups with labels {}.\".format(\n             self.__class__.__name__,\n             self._unique_coord.name,\n             self._unique_coord.size,\n", "instance_id": "pydata__xarray-5131"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 1edc712358..a582b2b2a6 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -461,9 +461,14 @@ def _print_Pow(self, expr):\n             if expr.base.is_Function:\n                 return self._print(expr.base, \"%s/%s\" % (p, q))\n             return r\"%s^{%s/%s}\" % (base, p, q)\n-        elif expr.exp.is_Rational and expr.exp.is_negative and expr.base.is_commutative:\n+        if expr.exp.is_Rational and expr.exp.is_negative and expr.base.is_commutative:\n             # Things like 1/x\n             return self._print_Mul(expr)\n+        elif expr.exp.is_Rational and expr.exp.q != 1:\n+            base, p, q = self.parenthesize(expr.base, PRECEDENCE['Pow']), expr.exp.p, expr.exp.q\n+            if expr.base.is_Function:\n+                return self._print(expr.base, \"%s/%s\" % (p, q))\n+            return r\"%s^{%s/%s}\" % (base, p, q)\n         else:\n             if expr.base.is_Function:\n                 return self._print(expr.base, self._print(expr.exp))\n", "instance_id": "sympy__sympy-11897"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 0b64b1b2b9..e401c5542c 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -22,7 +22,7 @@ from django.utils.datastructures import (\n )\n from django.utils.encoding import escape_uri_path, iri_to_uri\n from django.utils.functional import cached_property\n-from django.utils.http import is_same_domain\n+from django.utils.http import is_same_domain, parse_http_date_safe\n from django.utils.regex_helper import _lazy_re_compile\n \n from .multipartparser import parse_header\n", "instance_id": "django__django-15498"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex 5e6a400b6c..e4e39f5ef1 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -24,6 +24,12 @@ UNQUOTE_MAP = {v: chr(k) for k, v in QUOTE_MAP.items()}\n UNQUOTE_RE = _lazy_re_compile(\"_(?:%s)\" % \"|\".join([x[1:] for x in UNQUOTE_MAP]))\n \n \n+class FieldIsNotAField(Exception):\n+    \"\"\"The specified field is not a valid field on the model.\"\"\"\n+\n+    pass\n+\n+\n class FieldIsAForeignKeyColumnName(Exception):\n     \"\"\"A field is a foreign key attname, i.e. <FK>_id.\"\"\"\n \n@@ -42,6 +48,7 @@ def lookup_spawns_duplicates(opts, lookup_path):\n         try:\n             field = opts.get_field(field_name)\n         except FieldDoesNotExist:\n+            raise FieldIsNotAField(f\"Unable to lookup '{field_name}' on {opts.object_name}\")\n             # Ignore query lookups.\n             continue\n         else:\n", "instance_id": "django__django-16816"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 63ca817355..c753b89565 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -6,7 +6,7 @@ from itertools import chain\n from django.core.exceptions import EmptyResultSet, FieldError\n from django.db import DatabaseError, NotSupportedError\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value\n+from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value, Subquery\n from django.db.models.functions import Cast\n from django.db.models.query_utils import Q, select_related_descend\n from django.db.models.sql.constants import (\n@@ -117,9 +117,12 @@ class SQLCompiler:\n             # by reference.\n             if expr in ref_sources:\n                 continue\n-            cols = expr.get_group_by_cols()\n-            for col in cols:\n-                expressions.append(col)\n+            if isinstance(expr, Subquery):\n+                expressions.append(expr)\n+            else:\n+                cols = expr.get_group_by_cols()\n+                for col in cols:\n+                    expressions.append(col)\n         for expr, (sql, params, is_ref) in order_by:\n             # Skip References to the select clause, as all expressions in the\n             # select clause are already part of the group by.\n", "instance_id": "django__django-12589"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex aa2fe0883b..90dc19aeee 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -237,7 +237,7 @@ class MigrationExecutor:\n                     if not schema_editor.deferred_sql:\n                         self.record_migration(migration)\n                         migration_recorded = True\n-        if not migration_recorded:\n+        if not migration_recorded and router.allow_migrate(self.connection.alias, migration):\n             self.record_migration(migration)\n         # Report progress\n         if self.progress_callback:\ndiff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..6a58894f6b 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,6 @@\n from django.apps.registry import Apps\n from django.db import DatabaseError, models\n+from django.db import router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -62,12 +63,14 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n-        # Make the table\n-        try:\n-            with self.connection.schema_editor() as editor:\n-                editor.create_model(self.Migration)\n-        except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+        # Check if migration is allowed on this database\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            # Make the table\n+            try:\n+                with self.connection.schema_editor() as editor:\n+                    editor.create_model(self.Migration)\n+            except DatabaseError as exc:\n+                raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n \n     def applied_migrations(self):\n         \"\"\"\n@@ -83,13 +86,15 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.create(app=app, name=name)\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.filter(app=app, name=name).delete()\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n", "instance_id": "django__django-15252"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 62631f7ff..ff3e35444 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -110,11 +110,13 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n \n \n def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n-    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    \"\"\"Used to convert the :inherited-members: option to auto directives.\"\"\"\n     if arg in (None, True):\n-        return 'object'\n+        return {'object'}\n+    elif isinstance(arg, str):\n+        return {x.strip() for x in arg.split(',') if x.strip()}\n     else:\n-        return arg\n+        raise ValueError(__('invalid value for inherited-members option: %s') % arg)\n \n \n def member_order_option(arg: Any) -> Optional[str]:\n@@ -682,7 +684,7 @@ class Documenter:\n         def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n             if inspect.isclass(self.object):\n                 for cls in self.object.__mro__:\n-                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n+                    if cls.__name__ in self.options.inherited_members and cls != self.object:\n                         # given member is a member of specified *super class*\n                         return True\n                     elif name in cls.__dict__:\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 2eb25536d..5d1ee93b2 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -71,10 +71,9 @@ class DocumenterBridge:\n         return self._reporter\n \n \n-def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict\n-                               ) -> Options:\n+def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict) -> Options:\n     \"\"\"Recognize options of Documenter from user input.\"\"\"\n-    for name in AUTODOC_DEFAULT_OPTIONS:\n+    for name in AUTODOC_DEFAULT_OPTIONS + ['inherited-members']:\n         if name not in documenter.option_spec:\n             continue\n         else:\n", "instance_id": "sphinx-doc__sphinx-10325"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..ea3eff13f 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2174,8 +2174,12 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]\n-                                 for i in range(len(folds))], axis=0)\n+                    if multi_class == 'multinomial':\n+                        w = np.mean([coefs_paths[:, i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n+                    else:\n+                        w = np.mean([coefs_paths[i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n \n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n", "instance_id": "scikit-learn__scikit-learn-14087"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 02ec6480cb..9e19967b1e 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -263,6 +263,10 @@ def __new__(cls, b, e, evaluate=None):\n                     b = -b\n                 elif e.is_odd:\n                     return -Pow(-b, e)\n+            if b.is_integer and b.is_positive:\n+                if b < 0 and e.is_real:\n+                    return (-1)**e * Pow(-b, e)\n+                return (-1)**e * Pow(-b, e)\n             if S.NaN in (b, e):  # XXX S.NaN**x -> S.NaN under assumption that x != 0\n                 return S.NaN\n             elif b is S.One:\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..2f6fb9631c 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -594,6 +594,11 @@ def shorter(*choices):\n         expr = product_simplify(expr)\n \n     short = shorter(powsimp(expr, combine='exp', deep=True), powsimp(expr), expr)\n+\n+    if expr.has(Pow):\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Pow) and p.base.is_integer and p.base.is_positive,\n+            lambda p: p.base**p.exp if not (p.base < 0 and p.exp.is_real) else (-1)**p.exp * (-p.base)**p.exp)\n     short = shorter(short, cancel(short))\n     short = shorter(short, factor_terms(short), expand_power_exp(expand_mul(short)))\n     if short.has(TrigonometricFunction, HyperbolicFunction, ExpBase):\n", "instance_id": "sympy__sympy-14024"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex 78db834466..e466584777 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -278,6 +278,10 @@ def is_valid(idx):\n                 (0 <= j) != False and (j < self.cols) != False)\n \n     def __getitem__(self, key):\n+        if isinstance(key, tuple) and len(key) == 2:\n+            i, j = key\n+            if isinstance(i, int) and isinstance(j, int):\n+                return MatrixElement(self, i, j)\n         if not isinstance(key, tuple) and isinstance(key, slice):\n             from sympy.matrices.expressions.slice import MatrixSlice\n             return MatrixSlice(self, key, (0, None, 1))\ndiff --git a/sympy/simplify/cse_main.py b/sympy/simplify/cse_main.py\nindex d649dd02a9..44526ca5a3 100644\n--- a/sympy/simplify/cse_main.py\n+++ b/sympy/simplify/cse_main.py\n@@ -8,6 +8,7 @@\n from sympy.core.symbol import symbols, Symbol\n from sympy.utilities.iterables import numbered_symbols, sift, \\\n         topological_sort, iterable\n+from sympy.matrices.expressions.matexpr import MatrixExpr\n \n from . import cse_opts\n \n@@ -817,6 +818,11 @@ def cse(exprs, symbols=None, optimizations=None, postprocess=None,\n     # Find other optimization opportunities.\n     opt_subs = opt_cse(reduced_exprs, order)\n \n+    # Handle MatrixSymbol indexing\n+    for i, e in enumerate(reduced_exprs):\n+        if isinstance(e, MatrixExpr):\n+            reduced_exprs[i] = e.as_explicit()\n+\n     # Main CSE algorithm.\n     replacements, reduced_exprs = tree_cse(reduced_exprs, symbols, opt_subs,\n                                            order, ignore)\n", "instance_id": "sympy__sympy-22840"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sympy__sympy-18835"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..e55a5b917 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -31,6 +31,7 @@ from _pytest.fixtures import FixtureLookupError\n from _pytest.mark.structures import Mark\n from _pytest.mark.structures import MarkDecorator\n from _pytest.mark.structures import NodeKeywords\n+import pytest\n from _pytest.outcomes import fail\n from _pytest.pathlib import Path\n from _pytest.store import Store\n@@ -630,6 +631,8 @@ class Item(Node):\n         self.user_properties = []  # type: List[Tuple[str, object]]\n \n     def runtest(self) -> None:\n+        if self.get_closest_marker(\"xfail\"):\n+            pytest.xfail(\"xfail marker dynamically added\")\n         raise NotImplementedError(\"runtest must be implemented by Item subclass\")\n \n     def add_report_section(self, when: str, key: str, content: str) -> None:\ndiff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex 69754ad5e..427bddf80 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -209,18 +209,18 @@ def call_and_report(\n     report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport\n     if log:\n         hook.pytest_runtest_logreport(report=report)\n-    if check_interactive_exception(call, report):\n+    if check_interactive_exception(call, report, item):\n         hook.pytest_exception_interact(node=item, call=call, report=report)\n     return report\n \n \n-def check_interactive_exception(call: \"CallInfo\", report: BaseReport) -> bool:\n+def check_interactive_exception(call: \"CallInfo\", report: BaseReport, item: Item) -> bool:\n     \"\"\"Check whether the call raised an exception that should be reported as\n     interactive.\"\"\"\n     if call.excinfo is None:\n         # Didn't raise.\n         return False\n-    if hasattr(report, \"wasxfail\"):\n+    if hasattr(report, \"wasxfail\") or item.get_closest_marker(\"xfail\"):\n         # Exception was expected.\n         return False\n     if isinstance(call.excinfo.value, (Skipped, bdb.BdbQuit)):\n", "instance_id": "pytest-dev__pytest-7490"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/ccode.py b/sympy/printing/ccode.py\nindex 30a07a7b59..c4ba2739ba 100644\n--- a/sympy/printing/ccode.py\n+++ b/sympy/printing/ccode.py\n@@ -19,6 +19,7 @@\n from sympy.printing.codeprinter import CodePrinter\n from sympy.printing.precedence import precedence\n from sympy.sets.fancysets import Range\n+from sympy import Piecewise, sin, Ne\n \n # dictionary mapping sympy function to (argument_conditions, C_function).\n # Used in CCodePrinter._print_Function(self)\n@@ -45,6 +46,24 @@\n     \"ceiling\": \"ceil\",\n }\n \n+def _print_Function(self, expr):\n+    func_name = expr.func.__name__\n+    if func_name == \"sinc\":\n+        # Handle sinc function separately\n+        return self._print(Piecewise((sin(expr.args[0])/expr.args[0], Ne(expr.args[0], 0)), (1, True)))\n+    return super(CCodePrinter, self)._print_Function(expr)\n+\n+    def _print_Function(self, expr):\n+        func_name = expr.func.__name__\n+        if func_name == \"sinc\":\n+            # Handle sinc function separately\n+            return self._print(Piecewise((sin(expr.args[0])/expr.args[0], Ne(expr.args[0], 0)), (1, True)))\n+        return super(CCodePrinter, self)._print_Function(expr)\n+\n+        if func_name == \"sinc\":\n+            # Handle sinc function separately\n+            return self._print(Piecewise((sin(expr.args[0])/expr.args[0], Ne(expr.args[0], 0)), (1, True)))\n+\n # These are the core reserved words in the C language. Taken from:\n # http://crasseux.com/books/ctutorial/Reserved-words-in-C.html\n \n", "instance_id": "sympy__sympy-11400"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\nindex 6e504a3057..ee0373f339 100644\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -405,7 +405,7 @@ class Domain(with_metaclass(OptionType, Option)):\n     _re_realfield = re.compile(r\"^(R|RR)(_(\\d+))?$\")\n     _re_complexfield = re.compile(r\"^(C|CC)(_(\\d+))?$\")\n     _re_finitefield = re.compile(r\"^(FF|GF)\\((\\d+)\\)$\")\n-    _re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ)\\[(.+)\\]$\")\n+    _re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ|R|RR|C|CC)\\[(.+)\\]$\")\n     _re_fraction = re.compile(r\"^(Z|ZZ|Q|QQ)\\((.+)\\)$\")\n     _re_algebraic = re.compile(r\"^(Q|QQ)\\<(.+)\\>$\")\n \n@@ -480,7 +480,7 @@ def preprocess(cls, domain):\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+        raise OptionError(f\"Expected a valid domain specification, got '{domain}'\")\n \n     @classmethod\n     def postprocess(cls, options):\n", "instance_id": "sympy__sympy-14396"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\nindex b9809fd4e9..674322d4eb 100644\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -240,7 +240,7 @@ def _solve_reduced_system(system, gens, entry=False):\n \n         univariate = list(filter(_is_univariate, basis))\n \n-        if len(univariate) == 1:\n+        if len(univariate) == 1 and len(gens) == 1:\n             f = univariate.pop()\n         else:\n             raise NotImplementedError(filldedent('''\n", "instance_id": "sympy__sympy-22005"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/astropy/io/ascii/core.py b/astropy/io/ascii/core.py\nindex 381b5b13db..2c2ffb2a4f 100644\n--- a/astropy/io/ascii/core.py\n+++ b/astropy/io/ascii/core.py\n@@ -1790,7 +1790,7 @@ extra_writer_pars = (\n )\n \n \n-def _get_writer(Writer, fast_writer, **kwargs):\n+def _get_writer(Writer, fast_writer, header_rows=None, **kwargs):\n     \"\"\"Initialize a table writer allowing for common customizations. This\n     routine is for internal (package) use only and is useful because it depends\n     only on the \"core\" module.\"\"\"\n@@ -1851,4 +1851,6 @@ def _get_writer(Writer, fast_writer, **kwargs):\n         writer.data.fill_include_names = kwargs[\"fill_include_names\"]\n     if \"fill_exclude_names\" in kwargs:\n         writer.data.fill_exclude_names = kwargs[\"fill_exclude_names\"]\n+    if header_rows:\n+        writer.header_rows = header_rows\n     return writer\ndiff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..eaa4fa1294 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -60,7 +60,14 @@ class RST(FixedWidth):\n     def __init__(self):\n         super().__init__(delimiter_pad=None, bookend=False)\n \n-    def write(self, lines):\n-        lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n+    def write(self, lines, header_rows=None):\n+        if header_rows:\n+            header_lines = []\n+            for row in header_rows:\n+                header_line = \" \".join([getattr(col.info, row, \"\") for col in self.cols])\n+                header_lines.append(header_line)\n+            lines = header_lines + lines\n+        else:\n+            lines = super().write(lines)\n+            lines = [lines[1]] + lines + [lines[1]]\n         return lines\ndiff --git a/astropy/io/ascii/ui.py b/astropy/io/ascii/ui.py\nindex 993dacf512..c3b66a8688 100644\n--- a/astropy/io/ascii/ui.py\n+++ b/astropy/io/ascii/ui.py\n@@ -898,7 +898,7 @@ def get_writer(Writer=None, fast_writer=True, **kwargs):\n         Writer = basic.Basic\n     if \"strip_whitespace\" not in kwargs:\n         kwargs[\"strip_whitespace\"] = True\n-    writer = core._get_writer(Writer, fast_writer, **kwargs)\n+    writer = core._get_writer(Writer, fast_writer, header_rows=kwargs.get(\"header_rows\"), **kwargs)\n \n     # Handle the corner case of wanting to disable writing table comments for the\n     # commented_header format.  This format *requires* a string for `write_comment`\n", "instance_id": "astropy__astropy-14182"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 25c3b44250..c01039f7ac 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -49,6 +49,10 @@ def check_errors(fn):\n     @functools.wraps(fn)\n     def wrapper(*args, **kwargs):\n         global _exception\n+        for path in args:\n+            if contains_null_byte(path):\n+                logger.warning('Skipping path with embedded null byte: %s', path)\n+                return\n         try:\n             fn(*args, **kwargs)\n         except Exception:\n@@ -106,6 +110,14 @@ def iter_all_python_module_files():\n \n \n @functools.lru_cache(maxsize=1)\n+def contains_null_byte(path):\n+    \"\"\"Check if the path contains a null byte.\"\"\"\n+    return '\\x00' in str(path)\n+\n+def contains_null_byte(path):\n+    \"\"\"Check if the path contains a null byte.\"\"\"\n+    return '\\x00' in str(path)\n+\n def iter_modules_and_files(modules, extra_files):\n     \"\"\"Iterate through all modules needed to be watched.\"\"\"\n     sys_file_paths = []\n", "instance_id": "django__django-11583"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex f0b663222a..b51d1739a4 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -56,7 +56,7 @@ class Command(BaseCommand):\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n", "instance_id": "django__django-11039"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex b657a35cf7..56eb77c00e 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -103,6 +103,7 @@ import warnings\n \n import numpy\n from packaging.version import parse as parse_version\n+from distutils.version import LooseVersion\n \n # cbook must import matplotlib only within function\n # definitions, so it is safe to import from it here.\n@@ -147,7 +148,14 @@ def __getattr__(name):\n             )\n         else:  # Get the version from the _version.py setuptools_scm file.\n             __version__ = _version.version\n+        global version_info, loose_version\n+        version_info = tuple(map(int, __version__.split('.')[:3]))\n+        loose_version = LooseVersion(__version__)\n         return __version__\n+    elif name == \"version_info\":\n+        return version_info\n+    elif name == \"loose_version\":\n+        return loose_version\n     raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n \n \n", "instance_id": "matplotlib__matplotlib-18869"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex df7452ee87..814ef0d4cb 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1958,6 +1958,8 @@ def _print_Pow(self, power):\n                 return self._print_nth_root(b, e)\n             if e.is_Rational and e < 0:\n                 return prettyForm(\"1\")/self._print(Pow(b, -e, evaluate=False))\n+            if e.is_Mul and e.args[0] is S.One and e.args[1].is_Pow and e.args[1].base is S.Exp1:\n+                return self._print(b)**prettyForm(\"exp(-1)\")\n \n         if b.is_Relational:\n             return prettyForm(*self._print(b).parens()).__pow__(self._print(e))\n", "instance_id": "sympy__sympy-20639"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 95a991b17..922bdd714 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -15,7 +15,7 @@ import warnings\n from inspect import Parameter, Signature\n from types import ModuleType\n from typing import (Any, Callable, Dict, Iterator, List, Optional, Sequence, Set, Tuple, Type,\n-                    TypeVar, Union)\n+                    TypeVar, Union, get_type_hints)\n \n from docutils.statemachine import StringList\n \n@@ -34,7 +34,7 @@ from sphinx.util import inspect, logging\n from sphinx.util.docstrings import extract_metadata, prepare_docstring\n from sphinx.util.inspect import (evaluate_signature, getdoc, object_description, safe_getattr,\n                                  stringify_signature)\n-from sphinx.util.typing import get_type_hints, restify\n+from sphinx.util.typing import restify\n from sphinx.util.typing import stringify as stringify_typehint\n \n if False:\n@@ -420,7 +420,8 @@ class Documenter:\n             try:\n                 ret = import_object(self.modname, self.objpath, self.objtype,\n                                     attrgetter=self.get_attr,\n-                                    warningiserror=self.config.autodoc_warningiserror)\n+                                    warningiserror=self.config.autodoc_warningiserror,\n+                                    resolve_struct=True)\n                 self.module, self.parent, self.object_name, self.object = ret\n                 return True\n             except ImportError as exc:\ndiff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex 2587ba35b..fb7a3c9ec 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -11,7 +11,7 @@\n import importlib\n import traceback\n import warnings\n-from typing import Any, Callable, Dict, List, Mapping, NamedTuple, Optional, Tuple\n+from typing import Any, Callable, Dict, List, Mapping, NamedTuple, Optional, Tuple, get_type_hints\n \n from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warning,\n                                 deprecated_alias)\n@@ -76,7 +76,7 @@ def import_module(modname: str, warningiserror: bool = False) -> Any:\n \n def import_object(modname: str, objpath: List[str], objtype: str = '',\n                   attrgetter: Callable[[Any, str], Any] = safe_getattr,\n-                  warningiserror: bool = False) -> Any:\n+                  warningiserror: bool = False, resolve_struct: bool = False) -> Any:\n     if objpath:\n         logger.debug('[autodoc] from %s import %s', modname, '.'.join(objpath))\n     else:\n@@ -110,7 +110,11 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n             obj = attrgetter(obj, mangled_name)\n             logger.debug('[autodoc] => %r', obj)\n             object_name = attrname\n-        return [module, parent, object_name, obj]\n+        if resolve_struct and modname == 'struct' and object_name == 'Struct':\n+            import struct\n+            return [module, parent, object_name, struct.Struct]\n+        else:\n+            return [module, parent, object_name, obj]\n     except (AttributeError, ImportError) as exc:\n         if isinstance(exc, AttributeError) and exc_on_importing:\n             # restore ImportError\n", "instance_id": "sphinx-doc__sphinx-8627"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 7bb3fa4706..e226c15be7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1113,6 +1113,29 @@ class Model(metaclass=ModelBase):\n                     key = NON_FIELD_ERRORS\n                 errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))\n \n+        errors.extend(self._check_unique_constraints())\n+        return errors\n+\n+    def _check_unique_constraints(self):\n+        \"\"\"Check the fields of UniqueConstraints.\"\"\"\n+        from django.core.checks import Error\n+\n+        errors = []\n+        for constraint in self.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        self.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=self.model,\n+                                id='models.E012',\n+                            )\n+                        )\n         return errors\n \n     def _perform_date_checks(self, date_checks):\n@@ -1280,6 +1303,7 @@ class Model(metaclass=ModelBase):\n                 *cls._check_indexes(databases),\n                 *cls._check_ordering(),\n                 *cls._check_constraints(databases),\n+                *cls._meta._check_unique_constraints(),\n             ]\n \n         return errors\n", "instance_id": "django__django-12856"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a9f66740f..7ebaeea92 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -38,7 +38,7 @@ def _check_shape(param, param_shape, name):\n                          \"but got %s\" % (name, param_shape, param.shape))\n \n \n-def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n+def _check_X(X, n_clusters=None, n_features=None, ensure_min_samples=1):\n     \"\"\"Check the input data X.\n \n     Parameters\n@@ -53,10 +53,10 @@ def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n     \"\"\"\n     X = check_array(X, dtype=[np.float64, np.float32],\n                     ensure_min_samples=ensure_min_samples)\n-    if n_components is not None and X.shape[0] < n_components:\n-        raise ValueError('Expected n_samples >= n_components '\n-                         'but got n_components = %d, n_samples = %d'\n-                         % (n_components, X.shape[0]))\n+    if n_clusters is not None and X.shape[0] < n_clusters:\n+        raise ValueError('Expected n_samples >= n_clusters '\n+                         'but got n_clusters = %d, n_samples = %d'\n+                         % (n_clusters, X.shape[0]))\n     if n_features is not None and X.shape[1] != n_features:\n         raise ValueError(\"Expected the input data X have %d features, \"\n                          \"but got %d features\"\n@@ -71,10 +71,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n     provides basic common methods for mixture models.\n     \"\"\"\n \n-    def __init__(self, n_components, tol, reg_covar,\n+    def __init__(self, n_clusters, tol, reg_covar,\n                  max_iter, n_init, init_params, random_state, warm_start,\n                  verbose, verbose_interval):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.tol = tol\n         self.reg_covar = reg_covar\n         self.max_iter = max_iter\n@@ -92,10 +92,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         ----------\n         X : array-like, shape (n_samples, n_features)\n         \"\"\"\n-        if self.n_components < 1:\n-            raise ValueError(\"Invalid value for 'n_components': %d \"\n+        if self.n_clusters < 1:\n+            raise ValueError(\"Invalid value for 'n_clusters': %d \"\n                              \"Estimation requires at least one component\"\n-                             % self.n_components)\n+                             % self.n_clusters)\n \n         if self.tol < 0.:\n             raise ValueError(\"Invalid value for 'tol': %.5f \"\n@@ -144,12 +144,12 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         n_samples, _ = X.shape\n \n         if self.init_params == 'kmeans':\n-            resp = np.zeros((n_samples, self.n_components))\n-            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n+            resp = np.zeros((n_samples, self.n_clusters))\n+            label = cluster.KMeans(n_clusters=self.n_clusters, n_init=1,\n                                    random_state=random_state).fit(X).labels_\n             resp[np.arange(n_samples), label] = 1\n         elif self.init_params == 'random':\n-            resp = random_state.rand(n_samples, self.n_components)\n+            resp = random_state.rand(n_samples, self.n_clusters)\n             resp /= resp.sum(axis=1)[:, np.newaxis]\n         else:\n             raise ValueError(\"Unimplemented initialization method '%s'\"\n@@ -188,12 +188,102 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         -------\n         self\n         \"\"\"\n-        X = _check_X(X, self.n_components, ensure_min_samples=2)\n+        X = _check_X(X, self.n_clusters, ensure_min_samples=2)\n         self._check_initial_parameters(X)\n \n         # if we enable warm_start, we will have a unique initialisation\n         do_init = not(self.warm_start and hasattr(self, 'converged_'))\n         n_init = self.n_init if do_init else 1\n+        self.labels_ = None\n+\n+        max_lower_bound = -np.infty\n+        self.converged_ = False\n+\n+        random_state = check_random_state(self.random_state)\n+\n+        n_samples, _ = X.shape\n+        for init in range(n_init):\n+            self._print_verbose_msg_init_beg(init)\n+\n+            if do_init:\n+                self._initialize_parameters(X, random_state)\n+                self.lower_bound_ = -np.infty\n+\n+            for n_iter in range(1, self.max_iter + 1):\n+                prev_lower_bound = self.lower_bound_\n+\n+                log_prob_norm, log_resp = self._e_step(X)\n+                self._m_step(X, log_resp)\n+                self.lower_bound_ = self._compute_lower_bound(\n+                    log_resp, log_prob_norm)\n+\n+                change = self.lower_bound_ - prev_lower_bound\n+                self._print_verbose_msg_iter_end(n_iter, change)\n+\n+                if abs(change) < self.tol:\n+                    self.converged_ = True\n+                    break\n+\n+            self._print_verbose_msg_init_end(self.lower_bound_)\n+\n+            if self.lower_bound_ > max_lower_bound:\n+                max_lower_bound = self.lower_bound_\n+                best_params = self._get_parameters()\n+                best_n_iter = n_iter\n+\n+        if not self.converged_:\n+            warnings.warn('Initialization %d did not converge. '\n+                          'Try different init parameters, '\n+                          'or increase max_iter, tol '\n+                          'or check for degenerate data.'\n+                          % (init + 1), ConvergenceWarning)\n+\n+        self._set_parameters(best_params)\n+        self.n_iter_ = best_n_iter\n+\n+        return self\n+\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.predict(X)\n+        \"\"\"Estimate model parameters with the EM algorithm.\n+\n+        The method fit the model `n_init` times and set the parameters with\n+        which the model has the largest likelihood or lower bound. Within each\n+        trial, the method iterates between E-step and M-step for `max_iter`\n+        times until the change of likelihood or lower bound is less than\n+        `tol`, otherwise, a `ConvergenceWarning` is raised.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        self\n+        \"\"\"\n+        X = _check_X(X, self.n_clusters, ensure_min_samples=2)\n+        self._check_initial_parameters(X)\n+\n+        # if we enable warm_start, we will have a unique initialisation\n+        do_init = not(self.warm_start and hasattr(self, 'converged_'))\n+        n_init = self.n_init if do_init else 1\n+        self.labels_ = None\n \n         max_lower_bound = -np.infty\n         self.converged_ = False\n@@ -407,6 +497,7 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         y = np.concatenate([j * np.ones(sample, dtype=int)\n                            for j, sample in enumerate(n_samples_comp)])\n \n+        self.labels_ = y\n         return (X, y)\n \n     def _estimate_weighted_log_prob(self, X):\ndiff --git a/sklearn/mixture/gmm.py b/sklearn/mixture/gmm.py\nindex b3c231314..c169cd395 100644\n--- a/sklearn/mixture/gmm.py\n+++ b/sklearn/mixture/gmm.py\n@@ -256,11 +256,11 @@ class _GMMBase(BaseEstimator):\n \n     \"\"\"\n \n-    def __init__(self, n_components=1, covariance_type='diag',\n+    def __init__(self, n_clusters=1, covariance_type='diag',\n                  random_state=None, tol=1e-3, min_covar=1e-3,\n                  n_iter=100, n_init=1, params='wmc', init_params='wmc',\n                  verbose=0):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.covariance_type = covariance_type\n         self.tol = tol\n         self.min_covar = min_covar\n@@ -391,6 +391,23 @@ class _GMMBase(BaseEstimator):\n         logprob, responsibilities = self.score_samples(X)\n         return responsibilities\n \n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.predict(X)\n+\n     def sample(self, n_samples=1, random_state=None):\n         \"\"\"Generate random samples from the model.\n \n@@ -477,10 +494,10 @@ class _GMMBase(BaseEstimator):\n         # initialization step\n         X = check_array(X, dtype=np.float64, ensure_min_samples=2,\n                         estimator=self)\n-        if X.shape[0] < self.n_components:\n+        if X.shape[0] < self.n_clusters:\n             raise ValueError(\n                 'GMM estimation with %s components, but got only %s samples' %\n-                (self.n_components, X.shape[0]))\n+                (self.n_clusters, X.shape[0]))\n \n         max_log_prob = -np.infty\n \n@@ -494,14 +511,14 @@ class _GMMBase(BaseEstimator):\n \n             if 'm' in self.init_params or not hasattr(self, 'means_'):\n                 self.means_ = cluster.KMeans(\n-                    n_clusters=self.n_components,\n+                    n_clusters=self.n_clusters,\n                     random_state=self.random_state).fit(X).cluster_centers_\n                 if self.verbose > 1:\n                     print('\\tMeans have been initialized.')\n \n             if 'w' in self.init_params or not hasattr(self, 'weights_'):\n-                self.weights_ = np.tile(1.0 / self.n_components,\n-                                        self.n_components)\n+                self.weights_ = np.tile(1.0 / self.n_clusters,\n+                                        self.n_clusters)\n                 if self.verbose > 1:\n                     print('\\tWeights have been initialized.')\n \n@@ -511,7 +528,7 @@ class _GMMBase(BaseEstimator):\n                     cv.shape = (1, 1)\n                 self.covars_ = \\\n                     distribute_covar_matrix_to_match_covariance_type(\n-                        cv, self.covariance_type, self.n_components)\n+                        cv, self.covariance_type, self.n_clusters)\n                 if self.verbose > 1:\n                     print('\\tCovariance matrices have been initialized.')\n \n@@ -533,7 +550,9 @@ class _GMMBase(BaseEstimator):\n                 if prev_log_likelihood is not None:\n                     change = abs(current_log_likelihood - prev_log_likelihood)\n                     if self.verbose > 1:\n+                        print('\\tBetter parameters were found.')\n                         print('\\t\\tChange: ' + str(change))\n+                    self.labels_ = self.predict(X)\n                     if change < self.tol:\n                         self.converged_ = True\n                         if self.verbose > 0:\n", "instance_id": "scikit-learn__scikit-learn-11281"}
{"model_name_or_path": "200724-074412", "model_patch": "", "instance_id": "sympy__sympy-20590"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex b2a60629c9..663750636d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -143,9 +143,9 @@ class ModelBase(type):\n                 # Non-abstract child classes inherit some attributes from their\n                 # non-abstract parent (unless an ABC comes before it in the\n                 # method resolution order).\n-                if not hasattr(meta, 'ordering'):\n+                if not hasattr(meta, 'ordering') or not meta.ordering:\n                     new_class._meta.ordering = base_meta.ordering\n-                if not hasattr(meta, 'get_latest_by'):\n+                if not hasattr(meta, 'get_latest_by') or not meta.get_latest_by:\n                     new_class._meta.get_latest_by = base_meta.get_latest_by\n \n         is_proxy = new_class._meta.proxy\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex a7c16c4bd8..751ac19043 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1202,8 +1202,9 @@ class QuerySet:\n             return True\n         elif self.query.default_ordering and self.query.get_meta().ordering:\n             return True\n-        else:\n-            return False\n+        elif self.query.get_meta().ordering:\n+            return True\n+        return False\n \n     @property\n     def db(self):\n", "instance_id": "django__django-12470"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 11409e6f6..63f5ac3a5 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -318,8 +318,8 @@ class GoogleDocstring:\n             return [line[min_indent:] for line in lines]\n \n     def _escape_args_and_kwargs(self, name: str) -> str:\n-        if name.endswith('_'):\n-            name = name[:-1] + r'\\_'\n+        if name.endswith('_') and not name.endswith(r'\\_'):\n+            name = name[:-1] + '_'\n \n         if name[:2] == '**':\n             return r'\\*\\*' + name[2:]\n", "instance_id": "sphinx-doc__sphinx-7738"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex 20d8922799..94997c6c0d 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -36,6 +36,8 @@ class ReadOnlyPasswordHashWidget(forms.Widget):\n \n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n+        context['widget']['is_hidden'] = True\n+        context['widget']['attrs']['readonly'] = True\n         summary = []\n         if not value or value.startswith(UNUSABLE_PASSWORD_PREFIX):\n             summary.append({'label': gettext(\"No password set.\")})\n", "instance_id": "django__django-14411"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex febaadbb5b..c1c2005b65 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1179,6 +1179,10 @@ class ManyToManyField(RelatedField):\n \n         if symmetrical is None:\n             symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n+        if symmetrical and related_name is not None:\n+            raise ValueError(\n+                \"Cannot define a related_name on a symmetrical ManyToManyField.\"\n+            )\n \n         if through is not None and db_table is not None:\n             raise ValueError(\n", "instance_id": "django__django-14730"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex ac45127fde..c0a09070b0 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -13,7 +13,7 @@ from django.db.models.constants import LOOKUP_SEP\n from django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL\n from django.db.models.query_utils import PathInfo\n from django.db.models.utils import make_model_tuple\n-from django.utils.functional import cached_property\n+from django.utils.functional import cached_property, make_hashable\n from django.utils.translation import gettext_lazy as _\n \n from . import Field\n", "instance_id": "django__django-14672"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..d2f13f9eb 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -607,6 +607,12 @@ class Ridge(_BaseRidge, RegressorMixin):\n         .. versionadded:: 0.17\n            *random_state* to support Stochastic Average Gradient.\n \n+    store_cv_values : boolean, default=False\n+        Flag indicating if the cross-validation values corresponding to\n+        each alpha should be stored in the `cv_values_` attribute (see\n+        below). This flag is only compatible with `cv=None` (i.e. using\n+        Generalized Cross-Validation).\n+\n     Attributes\n     ----------\n     coef_ : array, shape (n_features,) or (n_targets, n_features)\n@@ -1333,10 +1339,11 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n", "instance_id": "scikit-learn__scikit-learn-10297"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..277d82bd44 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -22,6 +22,7 @@ information.\n \"\"\"\n \n import itertools\n+import weakref\n import logging\n import time\n \n@@ -51,6 +52,14 @@ from . import legend_handler\n \n \n class DraggableLegend(DraggableOffsetBox):\n+    def __getstate__(self):\n+        state = super().__getstate__()\n+        state['legend'] = weakref.ref(self.legend)()  # Use weakref to avoid circular reference\n+        return state\n+\n+    def __setstate__(self, state):\n+        super().__setstate__(state)\n+        self.legend = weakref.ref(state['legend'])()\n     def __init__(self, legend, use_blit=False, update=\"loc\"):\n         \"\"\"\n         Wrapper around a `.Legend` to support mouse dragging.\ndiff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 1dee8a23d9..4899e553a8 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1471,7 +1471,19 @@ or callable, default: value of *xycoords*\n         self.stale = False\n \n \n+import weakref\n+\n class DraggableBase:\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        state['canvas'] = None  # Canvas cannot be pickled\n+        state['cids'] = []  # Callbacks cannot be pickled\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.canvas = None\n+        self.cids = []\n     \"\"\"\n     Helper base class for a draggable artist (legend, offsetbox).\n \n", "instance_id": "matplotlib__matplotlib-25311"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 379a2917aa..9cda08748e 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -1973,7 +1973,9 @@ def __div__(self, other):\n \n     @call_highest_priority('__rmatmul__')\n     def __matmul__(self, other):\n-        return self.__mul__(other)\n+        if not getattr(other, 'is_Matrix', False):\n+            raise ValueError(\"Scalar operands are not allowed, use '*' instead\")\n+        return self._eval_matrix_mul(other)\n \n     @call_highest_priority('__rmul__')\n     def __mul__(self, other):\n", "instance_id": "sympy__sympy-13773"}
{"model_name_or_path": "200724-074412", "model_patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex fe1f7236e..10864bdac 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -15,6 +15,10 @@ import numpy as np\n import scipy.sparse as sp\n from scipy import __version__ as scipy_version\n from distutils.version import LooseVersion\n+try:\n+    import pandas as pd\n+except ImportError:\n+    pd = None\n \n from numpy.core.numeric import ComplexWarning\n \n@@ -495,7 +499,14 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n         estimator_name = \"Estimator\"\n     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n \n-    if sp.issparse(array):\n+    if pd is not None and isinstance(array, pd.DataFrame):\n+        dtype_orig = array.dtypes\n+        array = array.values\n+        if warn_on_dtype and not np.all(dtype_orig == array.dtype):\n+            msg = (\"Data with input dtype {} was converted to {}{}.\"\n+                   .format(dtype_orig, array.dtype, context))\n+            warnings.warn(msg, DataConversionWarning)\n+    elif sp.issparse(array):\n         _ensure_no_complex_data(array)\n         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n                                       dtype=dtype, copy=copy,\n", "instance_id": "scikit-learn__scikit-learn-10949"}
