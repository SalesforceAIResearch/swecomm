{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-17087"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 7a3de33522..fdbbd21773 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -618,8 +618,7 @@ def adjust(s, wid=None, how='<^>'):\n \n             if first:\n                 # change F baseline so it centers on the sign\n-                prettyF.baseline -= d - (prettyF.height()//2 -\n-                                         prettyF.baseline) - adjustment\n+                prettyF.baseline = max(prettyF.baseline, prettySign.baseline)\n                 first = False\n \n             # put padding to the right\n@@ -629,7 +628,7 @@ def adjust(s, wid=None, how='<^>'):\n             # put the present prettyF to the right\n             prettyF = prettyForm(*prettySign.right(prettyF))\n \n-        prettyF.baseline = max_upper + sign_height//2\n+        prettyF.baseline = max_upper + sign_height//2 + 1\n         prettyF.binding = prettyForm.MUL\n         return prettyF\n \n", "instance_id": "sympy__sympy-16503"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..72348505f5 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\ndiff --git a/django/forms/utils.py b/django/forms/utils.py\nindex 50412f414b..928fe8797b 100644\n--- a/django/forms/utils.py\n+++ b/django/forms/utils.py\n@@ -114,11 +114,18 @@ class ErrorList(UserList, list):\n         if not self.data:\n             return ''\n \n-        return format_html(\n-            '<ul class=\"{}\">{}</ul>',\n-            self.error_class,\n-            format_html_join('', '<li>{}</li>', ((e,) for e in self))\n-        )\n+        if 'nonform' in self.error_class:\n+            return format_html(\n+                '<ul class=\"{}\">{}</ul>',\n+                self.error_class,\n+                format_html_join('', '<li>{}</li>', ((e,) for e in self))\n+            )\n+        else:\n+            return format_html(\n+                '<ul class=\"{}\">{}</ul>',\n+                self.error_class,\n+                format_html_join('', '<li>{}</li>', ((e,) for e in self))\n+            )\n \n     def as_text(self):\n         return '\\n'.join('* %s' % e for e in self)\n", "instance_id": "django__django-14608"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/flask/config.py b/src/flask/config.py\nindex d4fc310f..c7ae9f74 100644\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -234,6 +234,7 @@ class Config(dict):\n         filename: str,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n+        mode: str = \"r\",\n     ) -> bool:\n         \"\"\"Update the values in the config from a file that is loaded\n         using the ``load`` parameter. The loaded data is passed to the\n@@ -261,7 +262,7 @@ class Config(dict):\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, mode) as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n", "instance_id": "pallets__flask-4992"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sphinx-doc__sphinx-8506"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 68ffb0bfe0..64c574f99c 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -199,7 +199,9 @@ class Feed:\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n+            comments = self._get_dynamic_attr('item_comments', item)\n             feed.add_item(\n+                comments=comments,\n                 title=title,\n                 link=link,\n                 description=description,\n@@ -214,6 +216,6 @@ class Feed:\n                 author_link=author_link,\n                 categories=self._get_dynamic_attr('item_categories', item),\n                 item_copyright=self._get_dynamic_attr('item_copyright', item),\n-                **self.item_extra_kwargs(item)\n+                **self.item_extra_kwargs(item),\n             )\n         return feed\n", "instance_id": "django__django-13230"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\nindex 93298f47e6..3ffbaa14eb 100644\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -123,22 +123,22 @@ def dmp_trial_division(f, factors, u, K):\n     return _sort_factors(result)\n \n \n-def dup_zz_mignotte_bound(f, K):\n-    \"\"\"Mignotte bound for univariate polynomials in `K[x]`. \"\"\"\n+def dup_zz_knuth_cohen_bound(f, K):\n+    \"\"\"Knuth-Cohen bound for univariate polynomials in `K[x]`. \"\"\"\n     a = dup_max_norm(f, K)\n     b = abs(dup_LC(f, K))\n     n = dup_degree(f)\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2**(n - 1)) * a * b\n \n \n-def dmp_zz_mignotte_bound(f, u, K):\n-    \"\"\"Mignotte bound for multivariate polynomials in `K[X]`. \"\"\"\n+def dmp_zz_knuth_cohen_bound(f, u, K):\n+    \"\"\"Knuth-Cohen bound for multivariate polynomials in `K[X]`. \"\"\"\n     a = dmp_max_norm(f, u, K)\n     b = abs(dmp_ground_LC(f, u, K))\n     n = sum(dmp_degree_list(f, u))\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2**(n - 1)) * a * b\n \n \n def dup_zz_hensel_step(m, f, g, h, s, t, K):\n@@ -933,7 +933,7 @@ def dmp_zz_wang(f, u, K, mod=None, seed=None):\n \n     ct, T = dmp_zz_factor(dmp_LC(f, K), u - 1, K)\n \n-    b = dmp_zz_mignotte_bound(f, u, K)\n+    b = dmp_zz_knuth_cohen_bound(f, u, K)\n     p = K(nextprime(b))\n \n     if mod is None:\n", "instance_id": "sympy__sympy-19254"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 11409e6f6..63f5ac3a5 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -318,8 +318,8 @@ class GoogleDocstring:\n             return [line[min_indent:] for line in lines]\n \n     def _escape_args_and_kwargs(self, name: str) -> str:\n-        if name.endswith('_'):\n-            name = name[:-1] + r'\\_'\n+        if name.endswith('_') and not name.endswith(r'\\_'):\n+            name = name[:-1] + '_'\n \n         if name[:2] == '**':\n             return r'\\*\\*' + name[2:]\n", "instance_id": "sphinx-doc__sphinx-7738"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..f248ab1b71 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n", "instance_id": "django__django-14382"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d0bc97be80..cd7486283e 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -59,7 +59,7 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=None):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -67,7 +67,9 @@ def json_script(value, element_id=None):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n \n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    if encoder is None:\n+        encoder = DjangoJSONEncoder\n+    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n", "instance_id": "django__django-15789"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..09f437e94 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -111,6 +111,9 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n                     # removed later.\n                     X_mask[:, i] = valid_mask\n                     Xi = Xi.copy()\n+                    # Ensure the array can hold the new value without truncation\n+                    if Xi.dtype.itemsize < np.array(self.categories_[i][0]).dtype.itemsize:\n+                        Xi = Xi.astype(object)\n                     Xi[~valid_mask] = self.categories_[i][0]\n             _, encoded = _encode(Xi, self.categories_[i], encode=True)\n             X_int[:, i] = encoded\n", "instance_id": "scikit-learn__scikit-learn-12471"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 6c1fcfefb4..6f024810fd 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3075,7 +3075,9 @@ def together(self, *args, **kwargs):\n     def apart(self, x=None, **args):\n         \"\"\"See the apart function in sympy.polys\"\"\"\n         from sympy.polys import apart\n-        return apart(self, x, **args)\n+        if x is not None:\n+            return apart(self, x, **args)\n+        return apart(self, **args)\n \n     def ratsimp(self):\n         \"\"\"See the ratsimp function in sympy.simplify\"\"\"\n", "instance_id": "sympy__sympy-12236"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/config/option.py b/pylint/config/option.py\nindex 5043fe765..ff7a59673 100644\n--- a/pylint/config/option.py\n+++ b/pylint/config/option.py\n@@ -7,7 +7,7 @@ from __future__ import annotations\n import copy\n import optparse  # pylint: disable=deprecated-module\n import pathlib\n-import re\n+import regex as re\n import warnings\n from re import Pattern\n \n", "instance_id": "pylint-dev__pylint-7228"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..cb0e7c39b9 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -2298,33 +2298,35 @@ def getRuleIndex(self):\n \n \n \n-    def frac(self):\n-\n-        localctx = LaTeXParser.FracContext(self, self._ctx, self.state)\n-        self.enterRule(localctx, 52, self.RULE_frac)\n-        try:\n-            self.enterOuterAlt(localctx, 1)\n-            self.state = 305\n-            self.match(LaTeXParser.CMD_FRAC)\n-            self.state = 306\n-            self.match(LaTeXParser.L_BRACE)\n-            self.state = 307\n-            localctx.upper = self.expr()\n-            self.state = 308\n-            self.match(LaTeXParser.R_BRACE)\n-            self.state = 309\n-            self.match(LaTeXParser.L_BRACE)\n-            self.state = 310\n-            localctx.lower = self.expr()\n-            self.state = 311\n-            self.match(LaTeXParser.R_BRACE)\n-        except RecognitionException as re:\n-            localctx.exception = re\n-            self._errHandler.reportError(self, re)\n-            self._errHandler.recover(self, re)\n-        finally:\n-            self.exitRule()\n-        return localctx\n+def frac(self):\n+\n+    localctx = LaTeXParser.FracContext(self, self._ctx, self.state)\n+    self.enterRule(localctx, 52, self.RULE_frac)\n+    try:\n+        self.enterOuterAlt(localctx, 1)\n+        self.state = 305\n+        self.match(LaTeXParser.CMD_FRAC)\n+        self.state = 306\n+        self.match(LaTeXParser.L_BRACE)\n+        self.state = 307\n+        localctx.upper = self.expr()\n+        self.state = 308\n+        self.match(LaTeXParser.R_BRACE)\n+        self.state = 309\n+        self.match(LaTeXParser.L_BRACE)\n+        self.state = 310\n+        localctx.lower = self.expr()\n+        self.state = 311\n+        self.match(LaTeXParser.R_BRACE)\n+        self.state = 312\n+        self.match(LaTeXParser.R_BRACE)\n+    except RecognitionException as re:\n+        localctx.exception = re\n+        self._errHandler.reportError(self, re)\n+        self._errHandler.recover(self, re)\n+    finally:\n+        self.exitRule()\n+    return localctx\n \n \n     class BinomContext(ParserRuleContext):\n", "instance_id": "sympy__sympy-21612"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..196114b814 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -222,7 +222,8 @@ def switch_backend(newbackend):\n     global _backend_mod\n     # make sure the init is pulled up so we can assign to it later\n     import matplotlib.backends\n-    close(\"all\")\n+    # Preserve the current figures\n+    current_figures = _pylab_helpers.Gcf.figs.copy()\n \n     if newbackend is rcsetup._auto_backend_sentinel:\n         current_framework = cbook._get_running_interactive_framework()\n@@ -317,6 +318,9 @@ def switch_backend(newbackend):\n     # See https://github.com/matplotlib/matplotlib/issues/6092\n     matplotlib.backends.backend = newbackend\n \n+    # Restore the figures\n+    _pylab_helpers.Gcf.figs.update(current_figures)\n+\n     # make sure the repl display hook is installed in case we become\n     # interactive\n     install_repl_displayhook()\n", "instance_id": "matplotlib__matplotlib-23299"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 187e14b1b7..2acb265fc2 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -1,4 +1,5 @@\n import base64\n+import binascii\n import logging\n import string\n import warnings\n@@ -141,9 +142,9 @@ class SessionBase:\n                 raise SuspiciousSession(\"Session data corrupted\")\n             else:\n                 return self.serializer().loads(serialized)\n-        except Exception as e:\n-            # ValueError, SuspiciousOperation, unpickling exceptions. If any of\n-            # these happen, just return an empty dictionary (an empty session).\n+        except (ValueError, SuspiciousOperation, binascii.Error) as e:\n+            # ValueError, SuspiciousOperation, binascii.Error, unpickling exceptions.\n+            # If any of these happen, just return an empty dictionary (an empty session).\n             if isinstance(e, SuspiciousOperation):\n                 logger = logging.getLogger('django.security.%s' % e.__class__.__name__)\n                 logger.warning(str(e))\n", "instance_id": "django__django-13321"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/config/argument.py b/pylint/config/argument.py\nindex 3c2951517..2608f1ded 100644\n--- a/pylint/config/argument.py\n+++ b/pylint/config/argument.py\n@@ -99,7 +99,7 @@ def _py_version_transformer(value: str) -> tuple[int, ...]:\n     return version\n \n \n-def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n+def _regexp_paths_csv_transformer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions.\"\"\"\n     patterns: list[Pattern[str]] = []\n     for pattern in _csv_transformer(value):\n@@ -107,7 +107,7 @@ def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n     return patterns\n \n \n-def _regexp_paths_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n+def _regexp_paths_csv_transformer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions paths.\"\"\"\n     patterns: list[Pattern[str]] = []\n     for pattern in _csv_transformer(value):\n@@ -132,7 +132,7 @@ _TYPE_TRANSFORMERS: dict[str, Callable[[str], _ArgumentTypes]] = {\n     \"py_version\": _py_version_transformer,\n     \"regexp\": re.compile,\n     \"regexp_csv\": _regexp_csv_transfomer,\n-    \"regexp_paths_csv\": _regexp_paths_csv_transfomer,\n+    \"regexp_paths_csv\": _regexp_paths_csv_transformer,\n     \"string\": pylint_utils._unquote,\n     \"yn\": _yn_transformer,\n }\ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..c419ac313 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -587,6 +587,14 @@ class PyLinter(\n \n         Returns iterator of paths to discovered modules and packages.\n         \"\"\"\n+        def is_ignored(path: str) -> bool:\n+            return _is_ignored_file(\n+                path,\n+                self.config.ignore,\n+                self.config.ignore_patterns,\n+                self.config.ignore_paths,\n+            )\n+\n         for something in files_or_modules:\n             if os.path.isdir(something) and not os.path.isfile(\n                 os.path.join(something, \"__init__.py\")\n@@ -597,12 +605,7 @@ class PyLinter(\n                         # Skip subtree of already discovered package.\n                         continue\n \n-                    if _is_ignored_file(\n-                        root,\n-                        self.config.ignore,\n-                        self.config.ignore_patterns,\n-                        self.config.ignore_paths,\n-                    ):\n+                    if is_ignored(root):\n                         skip_subtrees.append(root)\n                         continue\n \n@@ -613,10 +616,11 @@ class PyLinter(\n                         yield from (\n                             os.path.join(root, file)\n                             for file in files\n-                            if file.endswith(\".py\")\n+                            if file.endswith(\".py\") and not is_ignored(os.path.join(root, file))\n                         )\n             else:\n-                yield something\n+                if not is_ignored(something):\n+                    yield something\n \n     def check(self, files_or_modules: Sequence[str] | str) -> None:\n         \"\"\"Main checking entry: check a list of files or modules from their name.\n", "instance_id": "pylint-dev__pylint-7080"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 7bc96e68eb..260de6617e 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1042,7 +1042,9 @@ def __new__(cls, num, dps=None, prec=None, precision=None):\n                 # it's a hexadecimal (coming from a pickled object)\n                 # assume that it is in standard form\n                 num = list(num)\n-                num[1] = long(num[1], 16)\n+                if num[1].endswith('L'):\n+                    num[1] = num[1][:-1]\n+                num[1] = int(num[1], 16)\n                 _mpf_ = tuple(num)\n             else:\n                 if len(num) == 4:\n", "instance_id": "sympy__sympy-13471"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "instance_id": "sympy__sympy-13480"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-12470"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\nindex 1f33b9d3ec..5d766cfc59 100644\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -1302,15 +1302,18 @@ class Artist:\n             if np.ma.getmask(data):\n                 return \"[]\"\n             normed = self.norm(data)\n-            if np.isfinite(normed):\n-                # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n-                g_sig_digits = cbook._g_sig_digits(data, delta)\n-            else:\n-                g_sig_digits = 3  # Consistent with default below.\n-            return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n+            try:\n+                if np.isfinite(normed):\n+                    # Midpoints of neighboring color intervals.\n+                    neighbors = self.norm.inverse(\n+                        (int(self.norm(data) * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n+                    g_sig_digits = cbook._g_sig_digits(data, delta)\n+                else:\n+                    g_sig_digits = 3  # Consistent with default below.\n+                return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n+            except ValueError:\n+                return \"[BoundaryNorm is not invertible]\"\n         else:\n             try:\n                 data[0]\n", "instance_id": "matplotlib__matplotlib-22835"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 171a3e7b0..52739f808 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1716,12 +1716,12 @@ class DataDocumenter(ModuleLevelDocumenter):\n                 annotations = {}\n \n             if self.objpath[-1] in annotations:\n-                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]), self.config.autodoc_type_aliases)\n                 self.add_line('   :type: ' + objrepr, sourcename)\n             else:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n                 if self.analyzer and key in self.analyzer.annotations:\n-                    self.add_line('   :type: ' + self.analyzer.annotations[key],\n+                    self.add_line('   :type: ' + stringify_typehint(self.analyzer.annotations[key], self.config.autodoc_type_aliases),\n                                   sourcename)\n \n             try:\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..956c13b9e 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -21,6 +21,7 @@ from sphinx.environment import BuildEnvironment\n from sphinx.ext.autodoc import Documenter, Options\n from sphinx.util import logging\n from sphinx.util.docutils import SphinxDirective, switch_source_input\n+from sphinx.util.typing import stringify as stringify_typehint\n from sphinx.util.nodes import nested_parse_with_titles\n \n if False:\n@@ -86,7 +87,10 @@ def process_documenter_options(documenter: \"Type[Documenter]\", config: Config, o\n             if name in config.autodoc_default_options and not negated:\n                 options[name] = config.autodoc_default_options[name]\n \n-    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    assembled_options = assemble_option_dict(options.items(), documenter.option_spec)\n+    if 'annotation' in assembled_options:\n+        assembled_options['annotation'] = stringify_typehint(assembled_options['annotation'], config.autodoc_type_aliases)\n+    return Options(assembled_options)\n \n \n def parse_generated_content(state: RSTState, content: StringList, documenter: Documenter\n", "instance_id": "sphinx-doc__sphinx-8435"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-16229"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "instance_id": "sympy__sympy-24213"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex f88662de12..4482cb4b1f 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -2524,6 +2524,98 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n \n \n class RelatedPopulator:\n+    def __init__(self, klass_info, select, db, base_model=None):\n+        self.db = db\n+        self.base_model = base_model or klass_info[\"model\"]\n+        select_fields = klass_info[\"select_fields\"]\n+        from_parent = klass_info[\"from_parent\"]\n+        if not from_parent:\n+            self.cols_start = select_fields[0]\n+            self.cols_end = select_fields[-1] + 1\n+            self.init_list = [\n+                f[0].target.attname for f in select[self.cols_start : self.cols_end]\n+            ]\n+            self.reorder_for_init = None\n+        else:\n+            attname_indexes = {\n+                select[idx][0].target.attname: idx for idx in select_fields\n+            }\n+            model_init_attnames = (\n+                f.attname for f in klass_info[\"model\"]._meta.concrete_fields\n+            )\n+            self.init_list = [\n+                attname for attname in model_init_attnames if attname in attname_indexes\n+            ]\n+            self.reorder_for_init = operator.itemgetter(\n+                *[attname_indexes[attname] for attname in self.init_list]\n+            )\n+\n+        self.model_cls = klass_info[\"model\"]\n+        self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n+        self.related_populators = get_related_populators(klass_info, select, self.db, base_model=self.base_model)\n+        self.local_setter = klass_info[\"local_setter\"]\n+        self.remote_setter = klass_info[\"remote_setter\"]\n+\n+    def populate(self, row, from_obj):\n+        if self.reorder_for_init:\n+            obj_data = self.reorder_for_init(row)\n+        else:\n+            obj_data = row[self.cols_start : self.cols_end]\n+        if obj_data[self.pk_idx] is None:\n+            obj = None\n+        else:\n+            obj = self.model_cls.from_db(self.db, self.init_list, obj_data)\n+            for rel_iter in self.related_populators:\n+                rel_iter.populate(row, obj)\n+        self.local_setter(from_obj, obj)\n+        if obj is not None:\n+            self.remote_setter(obj, from_obj)\n+    def __init__(self, klass_info, select, db, base_model=None):\n+        self.db = db\n+        self.base_model = base_model or klass_info[\"model\"]\n+        select_fields = klass_info[\"select_fields\"]\n+        from_parent = klass_info[\"from_parent\"]\n+        if not from_parent:\n+            self.cols_start = select_fields[0]\n+            self.cols_end = select_fields[-1] + 1\n+            self.init_list = [\n+                f[0].target.attname for f in select[self.cols_start : self.cols_end]\n+            ]\n+            self.reorder_for_init = None\n+        else:\n+            attname_indexes = {\n+                select[idx][0].target.attname: idx for idx in select_fields\n+            }\n+            model_init_attnames = (\n+                f.attname for f in klass_info[\"model\"]._meta.concrete_fields\n+            )\n+            self.init_list = [\n+                attname for attname in model_init_attnames if attname in attname_indexes\n+            ]\n+            self.reorder_for_init = operator.itemgetter(\n+                *[attname_indexes[attname] for attname in self.init_list]\n+            )\n+\n+        self.model_cls = klass_info[\"model\"]\n+        self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n+        self.related_populators = get_related_populators(klass_info, select, self.db, base_model=self.base_model)\n+        self.local_setter = klass_info[\"local_setter\"]\n+        self.remote_setter = klass_info[\"remote_setter\"]\n+\n+    def populate(self, row, from_obj):\n+        if self.reorder_for_init:\n+            obj_data = self.reorder_for_init(row)\n+        else:\n+            obj_data = row[self.cols_start : self.cols_end]\n+        if obj_data[self.pk_idx] is None:\n+            obj = None\n+        else:\n+            obj = self.model_cls.from_db(self.db, self.init_list, obj_data)\n+            for rel_iter in self.related_populators:\n+                rel_iter.populate(row, obj)\n+        self.local_setter(from_obj, obj)\n+        if obj is not None:\n+            self.remote_setter(obj, from_obj)\n     \"\"\"\n     RelatedPopulator is used for select_related() object instantiation.\n \n@@ -2609,10 +2701,10 @@ class RelatedPopulator:\n             self.remote_setter(obj, from_obj)\n \n \n-def get_related_populators(klass_info, select, db):\n+def get_related_populators(klass_info, select, db, base_model=None):\n     iterators = []\n     related_klass_infos = klass_info.get(\"related_klass_infos\", [])\n     for rel_klass_info in related_klass_infos:\n-        rel_cls = RelatedPopulator(rel_klass_info, select, db)\n+        rel_cls = RelatedPopulator(rel_klass_info, select, db, base_model=base_model)\n         iterators.append(rel_cls)\n     return iterators\n", "instance_id": "django__django-16408"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/staticfiles/handlers.py b/django/contrib/staticfiles/handlers.py\nindex 711d8864ad..8aea2bac73 100644\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -42,10 +42,20 @@ class StaticFilesHandlerMixin:\n         relative_url = url[len(self.base_url[2]):]\n         return url2pathname(relative_url)\n \n+    async def serve_async(self, request):\n+        \"\"\"Serve the request path asynchronously.\"\"\"\n+        return await serve(request, self.file_path(request.path), insecure=True)\n+\n     def serve(self, request):\n         \"\"\"Serve the request path.\"\"\"\n         return serve(request, self.file_path(request.path), insecure=True)\n \n+    async def get_response_async(self, request):\n+        try:\n+            return await self.serve_async(request)\n+        except Http404 as e:\n+            return response_for_exception(request, e)\n+\n     def get_response(self, request):\n         try:\n             return self.serve(request)\n@@ -83,6 +93,9 @@ class ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n         if scope['type'] == 'http' and self._should_handle(scope['path']):\n             # Serve static content\n             # (the one thing super() doesn't do is __call__, apparently)\n-            return await super().__call__(scope, receive, send)\n+            request = self.request_class(scope, receive)\n+            response = await self.get_response_async(request)\n+            await response(scope, receive, send)\n+            return\n         # Hand off to the main app\n         return await self.application(scope, receive, send)\ndiff --git a/staticfiles_tests/__init__.py b/staticfiles_tests/__init__.py\nnew file mode 100644\nindex 0000000000..1e4d4269b7\n--- /dev/null\n+++ b/staticfiles_tests/__init__.py\n@@ -0,0 +1,2 @@\n+# This file is required to make the directory a package.\n+# This file is required to make the directory a package.\n", "instance_id": "django__django-12915"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..7015eba6 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,6 +425,8 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n         method = builtin_str(method)\n \n         # Create the Request.\n", "instance_id": "psf__requests-2317"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 43f9e6ad8d..b97d53582a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1968,10 +1968,12 @@ def _print_DiracDelta(self, expr, exp=None):\n             tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n-    def _print_SingularityFunction(self, expr):\n+    def _print_SingularityFunction(self, expr, exp=None):\n         shift = self._print(expr.args[0] - expr.args[1])\n         power = self._print(expr.args[2])\n         tex = r\"{\\left\\langle %s \\right\\rangle}^{%s}\" % (shift, power)\n+        if exp is not None:\n+            tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n     def _print_Heaviside(self, expr, exp=None):\n", "instance_id": "sympy__sympy-21171"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-13265"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\nindex 69149e61a..f3f0a5f51 100644\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -121,9 +121,9 @@ class EncodingChecker(BaseChecker):\n \n         notes = \"|\".join(re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n-            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n+            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\"\n         else:\n-            regex_string = rf\"#\\s*({notes})\\b\"\n+            regex_string = rf\"#\\s*({notes})\"\n \n         self._fixme_pattern = re.compile(regex_string, re.I)\n \n", "instance_id": "pylint-dev__pylint-5859"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/tensor/array/dense_ndim_array.py b/sympy/tensor/array/dense_ndim_array.py\nindex 6019daf787..9c01f682c0 100644\n--- a/sympy/tensor/array/dense_ndim_array.py\n+++ b/sympy/tensor/array/dense_ndim_array.py\n@@ -138,6 +138,8 @@ def __new__(cls, iterable, shape=None, **kwargs):\n \n     @classmethod\n     def _new(cls, iterable, shape, **kwargs):\n+        if iterable is None:\n+            iterable = []\n         shape, flat_list = cls._handle_ndarray_creation_inputs(iterable, shape, **kwargs)\n         shape = Tuple(*map(_sympify, shape))\n         cls._check_special_bounds(flat_list, shape)\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex 6490a655a4..4fa85d54dd 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -193,6 +193,8 @@ def _scan_iterable_shape(cls, iterable):\n         def f(pointer):\n             if not isinstance(pointer, Iterable):\n                 return [pointer], ()\n+            if not pointer:\n+                return [], (0,)\n \n             result = []\n             elems, shapes = zip(*[f(i) for i in pointer])\n", "instance_id": "sympy__sympy-23117"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "psf__requests-1963"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/dispatch/dispatcher.py b/django/dispatch/dispatcher.py\nindex b7d9d26389..a9c139a7a6 100644\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,3 +1,4 @@\n+import logging\n import threading\n import warnings\n import weakref\n@@ -5,6 +6,8 @@ import weakref\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.inspect import func_accepts_kwargs\n \n+logger = logging.getLogger(__name__)\n+\n \n def _make_id(target):\n     if hasattr(target, '__func__'):\n@@ -209,6 +212,9 @@ class Signal:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n                 responses.append((receiver, err))\n+                logger.exception(\n+                    \"Error in signal handler for: %s\", receiver\n+                )\n             else:\n                 responses.append((receiver, response))\n         return responses\n", "instance_id": "django__django-13768"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex f0b663222a..b51d1739a4 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -56,7 +56,7 @@ class Command(BaseCommand):\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n", "instance_id": "django__django-11039"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/functions/elementary/complexes.py b/sympy/functions/elementary/complexes.py\nindex 7fda45982b..3f07956bcf 100644\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -385,6 +385,11 @@ def _sage_(self):\n         import sage.all as sage\n         return sage.sgn(self.args[0]._sage_())\n \n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        if arg.is_zero:\n+            return S.NaN\n+        return arg / Abs(arg)\n+\n     def _eval_rewrite_as_Piecewise(self, arg, **kwargs):\n         if arg.is_extended_real:\n             return Piecewise((1, arg > 0), (-1, arg < 0), (0, True))\n", "instance_id": "sympy__sympy-19487"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-14534"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..d66613dd95 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -73,6 +73,8 @@ def method_decorator(decorator, name=''):\n                 \"%s (%s).\" % (name, obj, method)\n             )\n         _wrapper = _multi_decorate(decorator, method)\n+        # Preserve the original method's attributes.\n+        update_wrapper(_wrapper, method)\n         setattr(obj, name, _wrapper)\n         return obj\n \n", "instance_id": "django__django-14787"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/functions/combinatorial/numbers.py b/sympy/functions/combinatorial/numbers.py\nindex 896729ac87..5adfbe8b33 100644\n--- a/sympy/functions/combinatorial/numbers.py\n+++ b/sympy/functions/combinatorial/numbers.py\n@@ -14,6 +14,7 @@\n from sympy.core.cache import cacheit\n from sympy.core.function import Function, expand_mul\n from sympy.core.numbers import E, pi\n+from sympy.core.logic import fuzzy_not\n from sympy.core.relational import LessThan, StrictGreaterThan\n from sympy.functions.combinatorial.factorials import binomial, factorial\n from sympy.functions.elementary.exponential import log\n@@ -443,6 +444,10 @@ def eval(cls, n, k_sym=None, symbols=None):\n                 r = cls._bell_incomplete_poly(int(n), int(k_sym), symbols)\n                 return r\n \n+    def _eval_as_leading_term(self, x):\n+        from sympy import oo\n+        return oo\n+\n     def _eval_rewrite_as_Sum(self, n, k_sym=None, symbols=None):\n         from sympy import Sum\n         if (k_sym is not None) or (symbols is not None):\n", "instance_id": "sympy__sympy-13437"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/config/argparsing.py b/src/_pytest/config/argparsing.py\nindex cc48ed337..2a7ad3e15 100644\n--- a/src/_pytest/config/argparsing.py\n+++ b/src/_pytest/config/argparsing.py\n@@ -1,4 +1,5 @@\n import argparse\n+import sys\n import warnings\n \n import py\n@@ -84,16 +85,12 @@ class Parser(object):\n \n         optparser = MyOptionParser(self, self.extra_info, prog=self.prog)\n         groups = self._groups + [self._anonymous]\n-        for group in groups:\n-            if group.options:\n-                desc = group.description or group.name\n-                arggroup = optparser.add_argument_group(desc)\n-                for option in group.options:\n-                    n = option.names()\n-                    a = option.attrs()\n-                    arggroup.add_argument(*n, **a)\n-        # bash like autocompletion for dirs (appending '/')\n-        optparser.add_argument(FILE_OR_DIR, nargs=\"*\").completer = filescompleter\n+        optparser.add_argument(\n+            \"--fixtures\",\n+            action=\"store_true\",\n+            help=\"show available fixtures, sorted by plugin and module\",\n+        ).completer = filescompleter\n+\n         return optparser\n \n     def parse_setoption(self, args, option, namespace=None):\ndiff --git a/src/_pytest/fixtures.py b/src/_pytest/fixtures.py\nindex 902904457..57f0a71ac 100644\n--- a/src/_pytest/fixtures.py\n+++ b/src/_pytest/fixtures.py\n@@ -633,7 +633,12 @@ class FixtureRequest(FuncargnamesCompatAttr):\n         )\n         return node\n \n-    def __repr__(self):\n+    def __str__(self):\n+        return \"<FixtureDef argname=%r scope=%r baseid=%r>\" % (\n+            self.argname,\n+            self.scope,\n+            self.baseid,\n+        )\n         return \"<FixtureRequest for %r>\" % (self.node)\n \n \n", "instance_id": "pytest-dev__pytest-5221"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8376b487..83c44991 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1874,11 +1874,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n \n     def chunk(\n         self,\n-        chunks: Union[\n-            Number,\n-            str,\n-            Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]],\n-        ] = {},  # {} even though it's technically unsafe, is being used intentionally here (#4667)\n+        chunks: Union[Number, str, Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]]] = {},  # {} even though it's technically unsafe, is being used intentionally here (#4667)\n         name_prefix: str = \"xarray-\",\n         token: str = None,\n         lock: bool = False,\n@@ -3907,7 +3903,11 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             dataset.\n         \"\"\"\n         merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        variables = {\n+            k: (v if not is_duck_dask_array(v.data) else v.copy(deep=False))\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, variables=variables, **merge_result._asdict())\n \n     def merge(\n         self,\n", "instance_id": "pydata__xarray-4493"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 66461181d0..304fa51bf6 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1108,33 +1108,38 @@ def _print_BasisDependent(self, expr):\n             items = [(0, expr)]\n         for system, vect in items:\n             inneritems = list(vect.components.items())\n-            inneritems.sort(key = lambda x: x[0].__str__())\n+            inneritems.sort(key=lambda x: x[0].__str__())\n             for k, v in inneritems:\n-                #if the coef of the basis vector is 1\n-                #we skip the 1\n+                # if the coef of the basis vector is 1\n+                # we skip the 1\n                 if v == 1:\n                     o1.append(\"\" +\n                               k._pretty_form)\n-                #Same for -1\n+                # Same for -1\n                 elif v == -1:\n                     o1.append(\"(-1) \" +\n                               k._pretty_form)\n-                #For a general expr\n+                # For a general expr\n                 else:\n-                    #We always wrap the measure numbers in\n-                    #parentheses\n+                    # We always wrap the measure numbers in\n+                    # parentheses\n                     arg_str = self._print(\n                         v).parens()[0]\n \n                     o1.append(arg_str + ' ' + k._pretty_form)\n                 vectstrs.append(k._pretty_form)\n \n-        #outstr = u(\"\").join(o1)\n+        # Ensure that the unit vectors are correctly placed at the end\n+        for i, partstr in enumerate(o1):\n+            if vectstrs[i] in partstr:\n+                o1[i] = partstr.replace(vectstrs[i], '') + ' ' + vectstrs[i]\n+\n+        # outstr = u(\"\").join(o1)\n         if o1[0].startswith(\" + \"):\n             o1[0] = o1[0][3:]\n         elif o1[0].startswith(\" \"):\n             o1[0] = o1[0][1:]\n-        #Fixing the newlines\n+        # Fixing the newlines\n         lengths = []\n         strs = ['']\n         flag = []\n@@ -1144,51 +1149,51 @@ def _print_BasisDependent(self, expr):\n             if '\\n' in partstr:\n                 tempstr = partstr\n                 tempstr = tempstr.replace(vectstrs[i], '')\n-                if '\\N{right parenthesis extension}' in tempstr:   # If scalar is a fraction\n+                if '\\N{right parenthesis extension}' in tempstr:  # If scalar is a fraction\n                     for paren in range(len(tempstr)):\n                         flag[i] = 1\n                         if tempstr[paren] == '\\N{right parenthesis extension}':\n-                            tempstr = tempstr[:paren] + '\\N{right parenthesis extension}'\\\n-                                         + ' '  + vectstrs[i] + tempstr[paren + 1:]\n+                            tempstr = tempstr[:paren] + '\\N{right parenthesis extension}' \\\n+                                + ' ' + vectstrs[i] + tempstr[paren + 1:]\n                             break\n                 elif '\\N{RIGHT PARENTHESIS LOWER HOOK}' in tempstr:\n                     flag[i] = 1\n                     tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS LOWER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS LOWER HOOK}'\n-                                        + ' ' + vectstrs[i])\n+                                              '\\N{RIGHT PARENTHESIS LOWER HOOK}'\n+                                              + ' ' + vectstrs[i])\n                 else:\n                     tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                        + ' ' + vectstrs[i])\n+                                              '\\N{RIGHT PARENTHESIS UPPER HOOK}'\n+                                              + ' ' + vectstrs[i])\n                 o1[i] = tempstr\n \n         o1 = [x.split('\\n') for x in o1]\n         n_newlines = max([len(x) for x in o1])  # Width of part in its pretty form\n \n-        if 1 in flag:                           # If there was a fractional scalar\n+        if 1 in flag:  # If there was a fractional scalar\n             for i, parts in enumerate(o1):\n-                if len(parts) == 1:             # If part has no newline\n+                if len(parts) == 1:  # If part has no newline\n                     parts.insert(0, ' ' * (len(parts[0])))\n                     flag[i] = 1\n \n         for i, parts in enumerate(o1):\n             lengths.append(len(parts[flag[i]]))\n             for j in range(n_newlines):\n-                if j+1 <= len(parts):\n+                if j + 1 <= len(parts):\n                     if j >= len(strs):\n                         strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n+                                           3 * (len(lengths) - 1)))\n                     if j == flag[i]:\n                         strs[flag[i]] += parts[flag[i]] + ' + '\n                     else:\n-                        strs[j] += parts[j] + ' '*(lengths[-1] -\n-                                                   len(parts[j])+\n-                                                   3)\n+                        strs[j] += parts[j] + ' ' * (lengths[-1] -\n+                                                     len(parts[j]) +\n+                                                     3)\n                 else:\n                     if j >= len(strs):\n                         strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n-                    strs[j] += ' '*(lengths[-1]+3)\n+                                           3 * (len(lengths) - 1)))\n+                    strs[j] += ' ' * (lengths[-1] + 3)\n \n         return prettyForm('\\n'.join([s[:-3] for s in strs]))\n \n", "instance_id": "sympy__sympy-23191"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 755088ca5..cc7486d19 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -682,7 +682,11 @@ class GoogleDocstring:\n         return self._parse_generic_section(_('Notes'), use_admonition)\n \n     def _parse_other_parameters_section(self, section: str) -> List[str]:\n-        return self._format_fields(_('Other Parameters'), self._consume_fields())\n+        fields = self._consume_fields()\n+        if self._config.napoleon_use_param:\n+            return self._format_docutils_params(fields)\n+        else:\n+            return self._format_fields(_('Other Parameters'), fields)\n \n     def _parse_parameters_section(self, section: str) -> List[str]:\n         if self._config.napoleon_use_param:\n", "instance_id": "sphinx-doc__sphinx-8713"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..89afe90b28 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -707,6 +707,8 @@ class Poly3DCollection(PolyCollection):\n             if any(len(np.shape(vert)) != 2 for vert in verts):\n                 raise ValueError('verts must be a list of (N, 3) array-like')\n         self.set_zsort(zsort)\n+        self._facecolors2d = np.empty((0, 4))\n+        self._edgecolors2d = np.empty((0, 4))\n         self._codes3d = None\n \n     _zsort_functions = {\n@@ -867,10 +869,10 @@ class Poly3DCollection(PolyCollection):\n         self.stale = True\n \n     def get_facecolor(self):\n-        return self._facecolors2d\n+        return getattr(self, '_facecolors2d', self._facecolor3d)\n \n     def get_edgecolor(self):\n-        return self._edgecolors2d\n+        return getattr(self, '_edgecolors2d', self._edgecolor3d)\n \n \n def poly_collection_2d_to_3d(col, zs=0, zdir='z'):\n", "instance_id": "matplotlib__matplotlib-23562"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13497"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..eb2546f44 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -405,7 +405,8 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     # selection is done with one dimension\n                     columns = columns[0]\n \n-            yield (name, trans, columns, get_weight(name))\n+            if not _is_empty_column_selection(columns):\n+                yield (name, trans, columns, get_weight(name))\n \n     def _validate_transformers(self):\n         if not self.transformers:\n@@ -872,7 +873,10 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 output.columns = names_out\n                 return output\n \n-            return np.hstack(Xs)\n+            if Xs:\n+                return np.hstack(Xs)\n+            else:\n+                return np.zeros((Xs[0].shape[0], 0))\n \n     def _sk_visual_block_(self):\n         if isinstance(self.remainder, str) and self.remainder == \"drop\":\n", "instance_id": "scikit-learn__scikit-learn-25570"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..47cee58e00 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -181,8 +181,12 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n             syms = [i for i in syms if i in var]\n             if syms != var:\n                 dict_sym_index = dict(zip(syms, range(len(syms))))\n-                return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                base_solutions = diophantine(eq, param)\n+                permuted_solutions = set()\n+                for sol in base_solutions:\n+                    permuted_solutions.update(signed_permutations(sol))\n+                return {tuple([t[dict_sym_index[i]] for i in syms])\n+                            for t in permuted_solutions}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n", "instance_id": "sympy__sympy-18189"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 4806afee9..485d2c24e 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -200,6 +200,7 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n     else:\n         if verbose:\n             print(\"Did not converge\")\n+        converged = False\n \n     I = np.flatnonzero(E)\n     K = I.size  # Identify exemplars\n@@ -226,9 +227,9 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         cluster_centers_indices = []\n \n     if return_n_iter:\n-        return cluster_centers_indices, labels, it + 1\n+        return cluster_centers_indices, labels, it + 1, converged\n     else:\n-        return cluster_centers_indices, labels\n+        return cluster_centers_indices, labels, converged\n \n \n ###############################################################################\n@@ -382,7 +383,7 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n                              \"'euclidean'. Got %s instead\"\n                              % str(self.affinity))\n \n-        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n+        self.cluster_centers_indices_, self.labels_, self.n_iter_, converged = \\\n             affinity_propagation(\n                 self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                 convergence_iter=self.convergence_iter, damping=self.damping,\n@@ -391,6 +392,11 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n         if self.affinity != \"precomputed\":\n             self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n \n+        if not converged:\n+            self.cluster_centers_indices_ = np.array([])\n+            self.labels_ = np.array([-1] * X.shape[0])\n+            self.cluster_centers_ = np.array([])\n+\n         return self\n \n     def predict(self, X):\n", "instance_id": "scikit-learn__scikit-learn-15512"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 495e90570..eb22fa4dc 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -206,6 +206,10 @@ class Sphinx:\n             self.confdir = abspath(confdir)\n             self.config = Config.read(self.confdir, confoverrides or {}, self.tags)\n \n+        # Apply rst_prolog if set\n+        if self.config.rst_prolog:\n+            self.config.rst_prolog = '\\n' + self.config.rst_prolog + '\\n'\n+\n         # initialize some limited config variables before initialize i18n and loading\n         # extensions\n         self.config.pre_init_values()\ndiff --git a/sphinx/io.py b/sphinx/io.py\nindex efd2b4ea9..0d08fb846 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -111,7 +111,10 @@ class SphinxStandaloneReader(SphinxBaseReader):\n         # emit \"source-read\" event\n         arg = [content]\n         env.events.emit('source-read', env.docname, arg)\n-        return arg[0]\n+        content = arg[0]\n+        if self._app.config.rst_prolog:\n+            content = self._app.config.rst_prolog + content\n+        return content\n \n \n class SphinxI18nReader(SphinxBaseReader):\ndiff --git a/sphinx/transforms/__init__.py b/sphinx/transforms/__init__.py\nindex f36473084..fb393a7a5 100644\n--- a/sphinx/transforms/__init__.py\n+++ b/sphinx/transforms/__init__.py\n@@ -90,6 +90,21 @@ class SphinxTransformer(Transformer):\n                 self.document = self.document[0]\n \n \n+class PreserveTopLevelHeadings(SphinxTransform):\n+    \"\"\"\n+    Ensure top-level headings containing domain directives are preserved.\n+    \"\"\"\n+    default_priority = 200\n+\n+    def apply(self, **kwargs: Any) -> None:\n+        for node in self.document.findall(nodes.section):\n+            if node.children and isinstance(node.children[0], nodes.title):\n+                title_node = node.children[0]\n+                if title_node.children and isinstance(title_node.children[0], nodes.Text):\n+                    text_node = title_node.children[0]\n+                    if text_node.astext().startswith(':'):\n+                        text_node.parent.replace(text_node, nodes.Text(text_node.astext()))\n+\n class DefaultSubstitutions(SphinxTransform):\n     \"\"\"\n     Replace some substitutions if they aren't defined in the document.\n@@ -395,6 +410,7 @@ class GlossarySorter(SphinxTransform):\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n+    app.add_transform(PreserveTopLevelHeadings)\n     app.add_transform(ApplySourceWorkaround)\n     app.add_transform(ExtraTranslatableNodes)\n     app.add_transform(DefaultSubstitutions)\n", "instance_id": "sphinx-doc__sphinx-11445"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 978fd5df8..baf631aea 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1266,6 +1266,9 @@ class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # typ\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    kwargs.setdefault('show_annotation', False)\n+\n                 sig = stringify_signature(overload, **kwargs)\n                 sigs.append(sig)\n \n", "instance_id": "sphinx-doc__sphinx-8282"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 34a3bab3fc..2a09dbfc63 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -10,7 +10,7 @@\n from sympy.core.function import count_ops, _mexpand\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sinc\n \n from sympy.strategies.core import identity\n from sympy.strategies.tree import greedy\n@@ -22,6 +22,8 @@\n from sympy.polys import factor, cancel, parallel_poly_from_expr\n \n from sympy.utilities.misc import debug\n+from sympy.simplify.cse_main import cse\n+from sympy.simplify.separatevars import separatevars\n \n \n \n@@ -539,7 +541,26 @@ def exp_trig(e):\n             choices.append(e.rewrite(exp))\n         choices.append(e.rewrite(cos))\n         return min(*choices, key=count_ops)\n-    newexpr = bottom_up(expr, exp_trig)\n+    def exp_to_trig(e):\n+        if e.is_Mul:\n+            coeff, e = e.as_coeff_Mul()\n+        else:\n+            coeff = S.One\n+\n+        if e.is_Add:\n+            return coeff * Add(*[exp_to_trig(arg) for arg in e.args])\n+\n+        if e.is_Pow and e.base is S.Exp1:\n+            if e.exp.is_Mul:\n+                I_coeff, rest = e.exp.as_coeff_Mul()\n+                if I_coeff == I:\n+                    return coeff * (cos(rest) + I * sin(rest))\n+                elif I_coeff == -I:\n+                    return coeff * (cos(rest) - I * sin(rest))\n+\n+        return coeff * e\n+\n+    newexpr = bottom_up(expr, lambda e: exp_to_trig(exp_trig(e)))\n \n     def f(rv):\n         if not rv.is_Mul:\n", "instance_id": "sympy__sympy-11870"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex b821c42845..1d2ac7aae6 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -235,16 +235,14 @@ def transpose(self):\n     def _entry(self, i, j, **kwargs):\n         # Find row entry\n         for row_block, numrows in enumerate(self.rowblocksizes):\n-            if (i < numrows) != False:\n+            if i < numrows:\n                 break\n-            else:\n-                i -= numrows\n+            i -= numrows\n         for col_block, numcols in enumerate(self.colblocksizes):\n-            if (j < numcols) != False:\n+            if j < numcols:\n                 break\n-            else:\n-                j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+            j -= numcols\n+        return self.blocks[row_block, col_block]._entry(i, j)\n \n     @property\n     def is_Identity(self):\n", "instance_id": "sympy__sympy-19007"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/axes_grid.py b/lib/mpl_toolkits/axes_grid1/axes_grid.py\nindex 2b1b1d3200..101628cd95 100644\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -13,8 +13,12 @@ from .mpl_axes import Axes\n def _tick_only(ax, bottom_on, left_on):\n     bottom_off = not bottom_on\n     left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    if isinstance(ax.axis, dict):\n+        ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n+        ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    else:\n+        ax.tick_params(axis='x', labelbottom=bottom_on)\n+        ax.tick_params(axis='y', labelleft=left_on)\n \n \n class CbarAxesBase:\n", "instance_id": "matplotlib__matplotlib-26020"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\nindex b19ee7c64..e363400c6 100644\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -76,7 +76,7 @@ class Code:\n \n     @property\n     def firstlineno(self) -> int:\n-        return self.raw.co_firstlineno - 1\n+        return self.raw.co_firstlineno\n \n     @property\n     def name(self) -> str:\ndiff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..19e5ebd24 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -715,6 +715,9 @@ class AssertionRewriter(ast.NodeVisitor):\n             lineno = item.decorator_list[0].lineno\n         else:\n             lineno = item.lineno\n+        # Adjust lineno for Python 3.9+ to avoid extra code lines in error messages\n+        if sys.version_info >= (3, 9):\n+            lineno += 1\n         # Now actually insert the special imports.\n         if sys.version_info >= (3, 10):\n             aliases = [\n", "instance_id": "pytest-dev__pytest-9359"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 9ce46e3f73..7974921d02 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -207,8 +207,31 @@ class Field(RegisterLookupMixin):\n             *self._check_backend_specific_checks(**kwargs),\n             *self._check_validators(),\n             *self._check_deprecation_details(),\n+            *self._check_max_length_with_choices(),\n         ]\n \n+    def _check_max_length_with_choices(self):\n+        \"\"\"\n+        Check if max_length is large enough to fit the longest value in choices.\n+        \"\"\"\n+        if self.choices is not None and self.max_length is not None:\n+            def get_choice_length(choice):\n+                if isinstance(choice, (list, tuple)):\n+                    return max(get_choice_length(c) for c in choice)\n+                return len(str(choice))\n+\n+            longest_choice = max((get_choice_length(choice) for choice in self.flatchoices if isinstance(choice, (list, tuple)) or isinstance(choice, str)), default=0)\n+            if longest_choice > self.max_length:\n+                return [\n+                    checks.Error(\n+                        f\"'max_length' is too small to fit the longest value in 'choices'. \"\n+                        f\"Longest choice has length {longest_choice}.\",\n+                        obj=self,\n+                        id='fields.E009',\n+                    )\n+                ]\n+        return []\n+\n     def _check_field_name(self):\n         \"\"\"\n         Check if field name is valid, i.e. 1) does not end with an\n", "instance_id": "django__django-11742"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 9e1be0fe0f..76b4f920e8 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -331,6 +331,11 @@ class LazyObject:\n             self._setup()\n         return (unpickle_lazyobject, (self._wrapped,))\n \n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n     def __copy__(self):\n         if self._wrapped is empty:\n             # If uninitialized, copy the wrapper. Use type(self), not\n", "instance_id": "django__django-15400"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "pytest-dev__pytest-11148"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..c9bdfee89 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n", "instance_id": "pytest-dev__pytest-7432"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 1ce54470..fa9a19ce 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -25,7 +25,7 @@ from .packages.urllib3.exceptions import SSLError as _SSLError\n from .packages.urllib3.exceptions import HTTPError as _HTTPError\n from .packages.urllib3.exceptions import ProxyError as _ProxyError\n from .cookies import extract_cookies_to_jar\n-from .exceptions import ConnectionError, Timeout, SSLError, ProxyError\n+from .exceptions import ConnectionError, Timeout, SSLError, ProxyError, RequestException\n from .auth import _basic_auth_str\n \n DEFAULT_POOLBLOCK = False\n@@ -387,7 +387,7 @@ class HTTPAdapter(BaseAdapter):\n                     conn._put_conn(low_conn)\n \n         except socket.error as sockerr:\n-            raise ConnectionError(sockerr, request=request)\n+            raise ConnectionError(f\"Socket error: {sockerr}\", request=request)\n \n         except MaxRetryError as e:\n             raise ConnectionError(e, request=request)\n", "instance_id": "psf__requests-2148"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex b657a35cf7..54928191b8 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -103,6 +103,7 @@ import warnings\n \n import numpy\n from packaging.version import parse as parse_version\n+from distutils.version import LooseVersion\n \n # cbook must import matplotlib only within function\n # definitions, so it is safe to import from it here.\n@@ -147,6 +148,10 @@ def __getattr__(name):\n             )\n         else:  # Get the version from the _version.py setuptools_scm file.\n             __version__ = _version.version\n+        global version_info\n+        version_info = tuple(map(int, __version__.split('.')[:3]))\n+        global loose_version\n+        loose_version = LooseVersion(__version__)\n         return __version__\n     raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n \n@@ -172,6 +177,10 @@ def _check_versions():\n \n _check_versions()\n \n+# Expose version_info and loose_version at the top level\n+version_info = tuple(map(int, __version__.split('.')[:3]))\n+loose_version = LooseVersion(__version__)\n+\n \n # The decorator ensures this always returns the same handler (and it is only\n # attached once).\n", "instance_id": "matplotlib__matplotlib-18869"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..7e152fdacb 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -396,6 +396,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n+    elif isinstance(field, models.JSONField):\n+        return field.value_from_object(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n     else:\n", "instance_id": "django__django-12308"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex febaadbb5b..9e94168345 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1180,6 +1180,11 @@ class ManyToManyField(RelatedField):\n         if symmetrical is None:\n             symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n \n+        if symmetrical and related_name is not None:\n+            raise ValueError(\n+                \"Cannot set related_name on symmetrical ManyToManyField.\"\n+            )\n+\n         if through is not None and db_table is not None:\n             raise ValueError(\n                 'Cannot specify a db_table if an intermediary model is used.'\n", "instance_id": "django__django-14730"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 892e19cabb..a12120e418 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -268,6 +268,14 @@ def _eval_is_zero(self):\n         arg = self.args[0]\n         if arg.is_zero:\n             return True\n+        if arg.func == acosh:\n+            return arg.args[0] == 1\n+        if arg.func == asinh:\n+            return arg.args[0] == 0\n+        if arg.func == atanh:\n+            return arg.args[0] == 0\n+        if arg.func == acoth:\n+            return arg.args[0] == 1\n \n \n class cosh(HyperbolicFunction):\n", "instance_id": "sympy__sympy-21627"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex 78db834466..0f32c547c5 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -12,7 +12,7 @@\n from sympy.functions import conjugate, adjoint\n from sympy.functions.special.tensor_functions import KroneckerDelta\n from sympy.matrices.common import NonSquareMatrixError\n-from sympy.matrices.matrices import MatrixKind, MatrixBase\n+from sympy.matrices.matrices import MatrixKind, MatrixBase, MatrixElement\n from sympy.multipledispatch import dispatch\n from sympy.simplify import simplify\n from sympy.utilities.misc import filldedent\n@@ -230,7 +230,8 @@ def _check_dim(cls, dim):\n                 \"a nonnegative integer.\".format(dim))\n \n \n-    def _entry(self, i, j, **kwargs):\n+    def element(self, i, j):\n+        return MatrixElement(self, i, j)\n         raise NotImplementedError(\n             \"Indexing not implemented for %s\" % self.__class__.__name__)\n \ndiff --git a/sympy/simplify/cse_main.py b/sympy/simplify/cse_main.py\nindex d649dd02a9..ec5cb79f57 100644\n--- a/sympy/simplify/cse_main.py\n+++ b/sympy/simplify/cse_main.py\n@@ -566,7 +566,7 @@ def tree_cse(exprs, symbols, opt_subs=None, order='canonical', ignore=()):\n     ignore : iterable of Symbols\n         Substitutions containing any Symbol from ``ignore`` will be ignored.\n     \"\"\"\n-    from sympy.matrices.expressions import MatrixExpr, MatrixSymbol, MatMul, MatAdd\n+    from sympy.matrices.expressions import MatrixExpr, MatrixSymbol, MatMul, MatAdd, MatrixElement\n     from sympy.polys.rootoftools import RootOf\n \n     if opt_subs is None:\n@@ -586,7 +586,7 @@ def _find_repeated(expr):\n         if isinstance(expr, RootOf):\n             return\n \n-        if isinstance(expr, Basic) and (expr.is_Atom or expr.is_Order):\n+        if isinstance(expr, Basic) and (expr.is_Atom or expr.is_Order or isinstance(expr, MatrixElement)):\n             if expr.is_Symbol:\n                 excluded_symbols.add(expr)\n             return\n", "instance_id": "sympy__sympy-22840"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex dc413b5c2..737dd17b9 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -730,6 +730,12 @@ class Documenter:\n \n             has_doc = bool(doc)\n \n+            # Check if the member is an annotation-only member in the superclass\n+            if not has_doc and isinstance(self.parent, type):\n+                annotations = get_type_hints(self.parent, None, self.config.autodoc_type_aliases)\n+                if membername in annotations:\n+                    has_doc = True\n+\n             metadata = extract_metadata(doc)\n             if 'private' in metadata:\n                 # consider a member private if docstring has \"private\" metadata\n", "instance_id": "sphinx-doc__sphinx-8801"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/python_api.py b/src/_pytest/python_api.py\nindex 011181a40..521c9f2f5 100644\n--- a/src/_pytest/python_api.py\n+++ b/src/_pytest/python_api.py\n@@ -713,6 +713,9 @@ class RaisesContext:\n         self.match_expr = match_expr\n         self.excinfo = None\n \n+    def __str__(self):\n+        return str(self.excinfo.value) if self.excinfo else \"\"\n+\n     def __enter__(self):\n         self.excinfo = _pytest._code.ExceptionInfo.for_later()\n         return self.excinfo\n", "instance_id": "pytest-dev__pytest-5413"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex 5fb84d86..f5310e3a 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -188,6 +188,8 @@ class Blueprint(Scaffold):\n             template_folder=template_folder,\n             root_path=root_path,\n         )\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n         self.name = name\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n", "instance_id": "pallets__flask-4045"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 57676428ff..0b9ea8cece 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -257,13 +257,15 @@ class BaseFormSet(RenderableFormMixin):\n \n     @property\n     def empty_form(self):\n+        form_kwargs = self.get_form_kwargs(None)\n+        form_kwargs.pop('empty_permitted', None)\n         form = self.form(\n             auto_id=self.auto_id,\n             prefix=self.add_prefix(\"__prefix__\"),\n             empty_permitted=True,\n             use_required_attribute=False,\n-            **self.get_form_kwargs(None),\n             renderer=self.renderer,\n+            **form_kwargs,\n         )\n         self.add_fields(form, None)\n         return form\n", "instance_id": "django__django-16041"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex c50fc90171..5cf1f5b3c2 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -5,7 +5,7 @@ from io import StringIO\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n \n # The prefix to put on the default database name when creating\n # the test database.\n@@ -126,8 +126,9 @@ class BaseDatabaseCreation:\n         the serialize_db_to_string() method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n", "instance_id": "django__django-12453"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/checks/templates.py b/django/core/checks/templates.py\nindex 5214276987..692ec98203 100644\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -50,15 +50,15 @@ def check_string_if_invalid_is_string(app_configs, **kwargs):\n @register(Tags.templates)\n def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n     errors = []\n-    libraries = defaultdict(list)\n+    libraries = defaultdict(set)\n \n     for conf in settings.TEMPLATES:\n         custom_libraries = conf.get(\"OPTIONS\", {}).get(\"libraries\", {})\n         for module_name, module_path in custom_libraries.items():\n-            libraries[module_name].append(module_path)\n+            libraries[module_name].add(module_path)\n \n     for module_name, module_path in get_template_tag_modules():\n-        libraries[module_name].append(module_path)\n+        libraries[module_name].add(module_path)\n \n     for library_name, items in libraries.items():\n         if len(items) > 1:\n@@ -66,7 +66,7 @@ def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n                 Error(\n                     E003.msg.format(\n                         repr(library_name),\n-                        \", \".join(repr(item) for item in items),\n+                        \", \".join(repr(item) for item in sorted(items)),\n                     ),\n                     id=E003.id,\n                 )\n", "instance_id": "django__django-15790"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..371786d959 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,6 +407,9 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n+        if len(constraint_names) > 1:\n+            # If there are multiple constraints, filter out the unique constraint\n+            constraint_names = [name for name in constraint_names if not name.endswith('_uniq')]\n         if len(constraint_names) != 1:\n             raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n                 len(constraint_names),\n", "instance_id": "django__django-12708"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..e96b12e08b 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -85,7 +85,8 @@ class PasswordResetTokenGenerator:\n            same password is chosen, due to password salting).\n         2. The last_login field will usually be updated very shortly after\n            a password reset.\n-        Failing those things, settings.PASSWORD_RESET_TIMEOUT eventually\n+        3. The email field will change if the user's email is updated.\n+        Failing these things, settings.PASSWORD_RESET_TIMEOUT eventually\n         invalidates the token.\n \n         Running this data through salted_hmac() prevents password cracking\n@@ -94,7 +95,8 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email_timestamp = '' if user.email is None else user.email\n+        return str(user.pk) + user.password + str(login_timestamp) + str(email_timestamp) + str(timestamp)\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n", "instance_id": "django__django-13551"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n", "instance_id": "django__django-16527"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex ba3b62620d..92f0a0a354 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -3,7 +3,7 @@ import json\n import os\n import posixpath\n import re\n-from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit\n+from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit, urljoin\n \n from django.conf import settings\n from django.contrib.staticfiles.utils import check_settings, matches_patterns\n@@ -139,6 +139,10 @@ class HashedFilesMixin:\n                 urlparts[2] += '?'\n             final_url = urlunsplit(urlparts)\n \n+        request = getattr(settings, 'REQUEST', None)\n+        if request:\n+            script_name = request.META.get('SCRIPT_NAME', '')\n+            final_url = urljoin(script_name, final_url)\n         return unquote(final_url)\n \n     def url(self, name, force=False):\ndiff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 4c27fce605..b68a1c68ae 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -332,6 +332,10 @@ class FileSystemStorage(Storage):\n         url = filepath_to_uri(name)\n         if url is not None:\n             url = url.lstrip('/')\n+        request = getattr(settings, 'REQUEST', None)\n+        if request:\n+            script_name = request.META.get('SCRIPT_NAME', '')\n+            url = urljoin(script_name, url)\n         return urljoin(self.base_url, url)\n \n     def _datetime_from_timestamp(self, ts):\ndiff --git a/django/templatetags/static.py b/django/templatetags/static.py\nindex 39712aaba0..be8ed80103 100644\n--- a/django/templatetags/static.py\n+++ b/django/templatetags/static.py\n@@ -104,6 +104,10 @@ class StaticNode(template.Node):\n \n     def render(self, context):\n         url = self.url(context)\n+        request = context.get('request')\n+        if request:\n+            script_name = request.META.get('SCRIPT_NAME', '')\n+            url = urljoin(script_name, url)\n         if context.autoescape:\n             url = conditional_escape(url)\n         if self.varname is None:\n", "instance_id": "django__django-11564"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex 29c6ff0926..cec86c0fc1 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -368,6 +368,13 @@ class KeyTransformIsNull(lookups.IsNull):\n     def as_oracle(self, compiler, connection):\n         if not self.rhs:\n             return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)\n+        if connection.vendor in {'sqlite', 'oracle'}:\n+            has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)\n+            has_key_sql, has_key_params = has_key_expr.as_sql(compiler, connection)\n+            return (\n+                'NOT %s' % has_key_sql,\n+                tuple(has_key_params),\n+            )\n         return super().as_sql(compiler, connection)\n \n     def as_sqlite(self, compiler, connection):\n", "instance_id": "django__django-13757"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/units/prefixes.py b/sympy/physics/units/prefixes.py\nindex ca6a642156..4711d98e6f 100644\n--- a/sympy/physics/units/prefixes.py\n+++ b/sympy/physics/units/prefixes.py\n@@ -80,7 +80,10 @@ def __repr__(self):\n \n     def __mul__(self, other):\n         from sympy.physics.units import Quantity\n-        if not isinstance(other, (Quantity, Prefix)):\n+        from sympy.physics.units import Unit\n+        if isinstance(other, Unit):\n+            return other * self.scale_factor\n+        elif not isinstance(other, (Quantity, Prefix)):\n             return super().__mul__(other)\n \n         fact = self.scale_factor * other.scale_factor\n", "instance_id": "sympy__sympy-24909"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 77768e7383..e7c1ebb62b 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1550,7 +1550,7 @@ class DraggableBase:\n                 self.ref_artist.set_animated(False)\n \n     def _check_still_parented(self):\n-        if self.ref_artist.figure is None:\n+        if self.ref_artist.figure is None or self.ref_artist.figure.canvas is None:\n             self.disconnect()\n             return False\n         else:\n@@ -1559,13 +1559,11 @@ class DraggableBase:\n     def disconnect(self):\n         \"\"\"Disconnect the callbacks.\"\"\"\n         for cid in self.cids:\n-            self.canvas.mpl_disconnect(cid)\n-        try:\n-            c1 = self._c1\n-        except AttributeError:\n-            pass\n-        else:\n-            self.canvas.mpl_disconnect(c1)\n+            if self.canvas is not None:\n+                self.canvas.mpl_disconnect(cid)\n+        if hasattr(self, '_c1'):\n+            if self.canvas is not None:\n+                self.canvas.mpl_disconnect(self._c1)\n \n     def save_offset(self):\n         pass\n", "instance_id": "matplotlib__matplotlib-25442"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 5f6b429dfd..23cbd57c7c 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -15,6 +15,7 @@\n \n @sympify_method_args\n class Expr(Basic, EvalfMixin):\n+    __slots__ = ()\n     \"\"\"\n     Base class for algebraic expressions.\n \n@@ -3853,6 +3854,7 @@ def _eval_derivative_matrix_lines(self, x):\n \n \n class AtomicExpr(Atom, Expr):\n+    __slots__ = ()\n     \"\"\"\n     A parent class for object which are both atoms and Exprs.\n \ndiff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex 70e6953559..6b5a51b25c 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -180,6 +180,7 @@ def numbered_string_incr(s, start=0):\n _uniquely_named_symbol = uniquely_named_symbol\n \n class Symbol(AtomicExpr, Boolean):\n+    __slots__ = ('name',)\n     \"\"\"\n     Assumptions:\n        commutative = True\n", "instance_id": "sympy__sympy-20590"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex dc084b8692..af98a440c1 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -163,6 +163,16 @@ class ValidationError(Exception):\n             error_dict.setdefault(NON_FIELD_ERRORS, []).extend(self.error_list)\n         return error_dict\n \n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return False\n+        if hasattr(self, 'error_dict') and hasattr(other, 'error_dict'):\n+            return (\n+                sorted((k, sorted(v)) for k, v in self.error_dict.items()) ==\n+                sorted((k, sorted(v)) for k, v in other.error_dict.items())\n+            )\n+        return sorted(self.messages) == sorted(other.messages)\n+\n     def __iter__(self):\n         if hasattr(self, 'error_dict'):\n             for field, errors in self.error_dict.items():\n", "instance_id": "django__django-13220"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..a18791c54 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -111,6 +111,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n            ``behaviour`` parameter will be deprecated in 0.22 and removed in\n            0.24.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         If int, random_state is the seed used by the random number generator;\n         If RandomState instance, random_state is the random number generator;\n@@ -173,8 +178,9 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n-        super().__init__(\n+                 verbose=0,\n+                 warm_start=False):\n+        super().__init__( \n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n                 splitter='random',\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n", "instance_id": "scikit-learn__scikit-learn-13496"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..c261a1fe05 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -919,7 +919,11 @@ class QuerySet:\n     def none(self):\n         \"\"\"Return an empty QuerySet.\"\"\"\n         clone = self._chain()\n-        clone.query.set_empty()\n+        if self.query.combinator:\n+            clone.query = self.query.chain()\n+            clone.query.set_empty()\n+        else:\n+            clone.query.set_empty()\n         return clone\n \n     ##################################################################\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex c913267476..21cfd71d23 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1776,7 +1776,11 @@ class Query(BaseExpression):\n         return condition, needed_inner\n \n     def set_empty(self):\n-        self.where.add(NothingNode(), AND)\n+        if self.combinator:\n+            for query in self.combined_queries:\n+                query.set_empty()\n+        else:\n+            self.where.add(NothingNode(), AND)\n \n     def is_empty(self):\n         return any(isinstance(c, NothingNode) for c in self.where.children)\n", "instance_id": "django__django-13158"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "matplotlib__matplotlib-26011"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex f50d8200e..e37abcf47 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -396,6 +396,12 @@ def _call_reprcompare(ops, results, expls, each_obj):\n         custom = util._reprcompare(ops[i], each_obj[i], each_obj[i + 1])\n         if custom is not None:\n             return custom\n+    if isinstance(each_obj[i], bytes) and isinstance(each_obj[i + 1], bytes):\n+        custom = \"assert {} == {}\\n  Full diff:\\n  - {}\\n  + {}\".format(\n+            saferepr(each_obj[i]), saferepr(each_obj[i + 1]),\n+            saferepr(each_obj[i]), saferepr(each_obj[i + 1])\n+        )\n+        return custom\n     return expl\n \n \n", "instance_id": "pytest-dev__pytest-5495"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-11040"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 157903faf..65bfcb5d1 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -667,7 +667,7 @@ class AssertionRewriter(ast.NodeVisitor):\n         # docstrings and __future__ imports, so first figure out where that is.\n         doc = getattr(mod, \"docstring\", None)\n         expect_docstring = doc is None\n-        if doc is not None and self.is_rewrite_disabled(doc):\n+        if isinstance(doc, str) and self.is_rewrite_disabled(doc):\n             return\n         pos = 0\n         item = None\n@@ -676,6 +676,7 @@ class AssertionRewriter(ast.NodeVisitor):\n                 expect_docstring\n                 and isinstance(item, ast.Expr)\n                 and isinstance(item.value, ast.Constant)\n+                and isinstance(item.value.value, str)\n             ):\n                 doc = item.value.value\n                 if self.is_rewrite_disabled(doc):\n", "instance_id": "pytest-dev__pytest-11143"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/ccode.py b/sympy/printing/ccode.py\nindex 30a07a7b59..9bade2ba19 100644\n--- a/sympy/printing/ccode.py\n+++ b/sympy/printing/ccode.py\n@@ -43,6 +43,7 @@\n     \"atanh\": \"atanh\",\n     \"floor\": \"floor\",\n     \"ceiling\": \"ceil\",\n+    \"sinc\": [(lambda x: x != 0, lambda x: \"sin(%s)/%s\" % (x, x)), (lambda x: x == 0, lambda x: \"1\")],\n }\n \n # These are the core reserved words in the C language. Taken from:\n", "instance_id": "sympy__sympy-11400"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex f2560117d2..fd4d3f965e 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -916,7 +916,12 @@ class Model(metaclass=ModelBase):\n \n         collector = Collector(using=using)\n         collector.collect([self], keep_parents=keep_parents)\n-        return collector.delete()\n+        result = collector.delete()\n+        if not keep_parents:\n+            self._state.adding = True\n+            self._state.db = None\n+            self.pk = None\n+        return result\n \n     delete.alters_data = True\n \n", "instance_id": "django__django-11179"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..1304f20a60 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n", "instance_id": "django__django-11099"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-15388"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..8ac5a92838 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,13 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            resolved_values = [\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n-            )\n+            ]\n+            if isinstance(value, tuple) and hasattr(value, '_fields'):  # Check if it's a namedtuple\n+                return type(value)(*resolved_values)\n+            return type(value)(resolved_values)\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "instance_id": "django__django-13590"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..566a6726bb 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -898,7 +898,10 @@ def subs(self, *args, **kwargs):\n                 sequence = sorted([(k, v) for (k, v) in sequence.items()],\n                                   key=default_sort_key)\n \n-        if kwargs.pop('simultaneous', False):  # XXX should this be the default for dict subs?\n+        if kwargs.pop('simultaneous', False):\n+            # Check for undefined expressions\n+            if any(old == new for old, new in sequence):\n+                return S.NaN\n             reps = {}\n             rv = self\n             kwargs['hack2'] = True\n", "instance_id": "sympy__sympy-13915"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 9344979c56..add47c3151 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -464,6 +464,8 @@ class IsNull(BuiltinLookup):\n \n     def as_sql(self, compiler, connection):\n         sql, params = compiler.compile(self.lhs)\n+        if not isinstance(self.rhs, bool):\n+            raise ValueError(\"The value for __isnull must be a boolean.\")\n         if self.rhs:\n             return \"%s IS NULL\" % sql, params\n         else:\n", "instance_id": "django__django-11905"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/builders/latex/__init__.py b/sphinx/builders/latex/__init__.py\nindex 77825f0ea..4a21c698f 100644\n--- a/sphinx/builders/latex/__init__.py\n+++ b/sphinx/builders/latex/__init__.py\n@@ -347,6 +347,8 @@ class LaTeXBuilder(Builder):\n         logger.info('')\n         logger.info(__(\"resolving references...\"))\n         self.env.resolve_references(largetree, indexfile, self)\n+        self.env.assign_section_numbers(largetree)\n+        self.env.assign_figure_numbers(largetree)\n         # resolve :ref:s to distant tex files -- we can't add a cross-reference,\n         # but append the document name\n         for pendingnode in largetree.traverse(addnodes.pending_xref):\ndiff --git a/sphinx/builders/singlehtml.py b/sphinx/builders/singlehtml.py\nindex d8ab978ed..86ea4117d 100644\n--- a/sphinx/builders/singlehtml.py\n+++ b/sphinx/builders/singlehtml.py\n@@ -80,6 +80,8 @@ class SingleFileHTMLBuilder(StandaloneHTMLBuilder):\n         tree = inline_all_toctrees(self, set(), master, tree, darkgreen, [master])\n         tree['docname'] = master\n         self.env.resolve_references(tree, master, self)\n+        self.env.assign_section_numbers(tree)\n+        self.env.assign_figure_numbers(tree)\n         self.fix_refuris(tree)\n         return tree\n \ndiff --git a/sphinx/transforms/__init__.py b/sphinx/transforms/__init__.py\nindex f854f1772..8911b3d95 100644\n--- a/sphinx/transforms/__init__.py\n+++ b/sphinx/transforms/__init__.py\n@@ -173,10 +173,11 @@ class AutoNumbering(SphinxTransform):\n         domain = self.env.get_domain('std')  # type: StandardDomain\n \n         for node in self.document.traverse(nodes.Element):\n-            if (domain.is_enumerable_node(node) and\n-                    domain.get_numfig_title(node) is not None and\n-                    node['ids'] == []):\n-                self.document.note_implicit_target(node)\n+            if domain.is_enumerable_node(node) and domain.get_numfig_title(node) is not None:\n+                if not node['ids']:\n+                    self.document.note_implicit_target(node)\n+                if not node.get('numbered'):\n+                    domain.assign_numfig(node)\n \n \n class SortIds(SphinxTransform):\n", "instance_id": "sphinx-doc__sphinx-8474"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/_io/saferepr.py b/src/_pytest/_io/saferepr.py\nindex 23af4d0bb..d96314f83 100644\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -19,8 +19,12 @@ def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n         raise\n     except BaseException as exc:\n         exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc))\n+    try:\n+        class_name = obj.__class__.__name__\n+    except Exception:\n+        class_name = \"Unknown\"\n     return \"<[{} raised in repr()] {} object at 0x{:x}>\".format(\n-        exc_info, obj.__class__.__name__, id(obj)\n+        exc_info, class_name, id(obj)\n     )\n \n \n", "instance_id": "pytest-dev__pytest-7168"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..17a8f79d32 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,7 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if hasattr(expression, 'filterable') and not expression.filterable:\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'\n", "instance_id": "django__django-13028"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex fe1f7236e..a75b12871 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -15,6 +15,7 @@ import numpy as np\n import scipy.sparse as sp\n from scipy import __version__ as scipy_version\n from distutils.version import LooseVersion\n+import pandas as pd\n \n from numpy.core.numeric import ComplexWarning\n \n@@ -495,7 +496,14 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n         estimator_name = \"Estimator\"\n     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n \n-    if sp.issparse(array):\n+    if isinstance(array, pd.DataFrame):\n+        dtype_orig = array.dtypes\n+        array = array.values\n+        if warn_on_dtype and not all(dtype_orig == array.dtype):\n+            msg = (\"Data with input dtype {} was converted to {}{}.\"\n+                   .format(dtype_orig, array.dtype, context))\n+            warnings.warn(msg, DataConversionWarning)\n+    elif sp.issparse(array):\n         _ensure_no_complex_data(array)\n         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n                                       dtype=dtype, copy=copy,\n", "instance_id": "scikit-learn__scikit-learn-10949"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..7f81cc93c1 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -197,6 +197,11 @@ def _eval_adjoint(self):\n         from sympy.matrices.expressions.adjoint import Adjoint\n         return Adjoint(self)\n \n+    def __add__(self, other):\n+        if isinstance(other, Identity):\n+            return Identity(self.rows + other.rows)\n+        return super(Identity, self).__add__(other)\n+\n     def _entry(self, i, j):\n         raise NotImplementedError(\n             \"Indexing not implemented for %s\" % self.__class__.__name__)\n", "instance_id": "sympy__sympy-12419"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 757cb2797..08670d2b2 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -15,7 +15,7 @@ from _pytest.compat import dummy_context_manager\n from _pytest.config import create_terminal_writer\n from _pytest.pathlib import Path\n \n-DEFAULT_LOG_FORMAT = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n+DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\"\n \n \n", "instance_id": "pytest-dev__pytest-5227"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\nindex 28eaae5f..ae64b4bd 100644\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -283,7 +283,15 @@ def summarize_variable(\n         dims_str = \"({}) \".format(\", \".join(map(str, var.dims)))\n     else:\n         dims_str = \"\"\n-    front_str = f\"{first_col}{dims_str}{var.dtype} \"\n+    \n+    # Add units if available\n+    units = var.attrs.get('units', '')\n+    if units:\n+        units_str = f\", in {units}\"\n+    else:\n+        units_str = \"\"\n+\n+    front_str = f\"{first_col}{dims_str}{var.dtype}{units_str} \"\n \n     values_width = max_width - len(front_str)\n     values_str = inline_variable_array_repr(var, values_width)\ndiff --git a/xarray/core/formatting_html.py b/xarray/core/formatting_html.py\nindex 5521b33e..cba4ba21 100644\n--- a/xarray/core/formatting_html.py\n+++ b/xarray/core/formatting_html.py\n@@ -105,6 +105,13 @@ def summarize_variable(name, var, is_index=False, dtype=None, preview=None):\n     name = escape(str(name))\n     dtype = dtype or escape(str(var.dtype))\n \n+    # Add units if available\n+    units = var.attrs.get('units', '')\n+    if units:\n+        units_str = f\", in {units}\"\n+    else:\n+        units_str = \"\"\n+\n     # \"unique\" ids required to expand/collapse subsections\n     attrs_id = \"attrs-\" + str(uuid.uuid4())\n     data_id = \"data-\" + str(uuid.uuid4())\n@@ -120,7 +127,7 @@ def summarize_variable(name, var, is_index=False, dtype=None, preview=None):\n     return (\n         f\"<div class='xr-var-name'><span{cssclass_idx}>{name}</span></div>\"\n         f\"<div class='xr-var-dims'>{dims_str}</div>\"\n-        f\"<div class='xr-var-dtype'>{dtype}</div>\"\n+        f\"<div class='xr-var-dtype'>{dtype}{units_str}</div>\"\n         f\"<div class='xr-var-preview xr-preview'>{preview}</div>\"\n         f\"<input id='{attrs_id}' class='xr-var-attrs-in' \"\n         f\"type='checkbox' {disabled}>\"\n", "instance_id": "pydata__xarray-4248"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..095ad0ccf0 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "instance_id": "django__django-13658"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 5bbb786984..8ea17ebbd4 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -1311,10 +1311,11 @@ default: %(va)s\n         \"\"\"\n         if (self.get_layout_engine() is not None and\n                 not self.get_layout_engine().adjust_compatible):\n-            _api.warn_external(\n-                \"This figure was using a layout engine that is \"\n-                \"incompatible with subplots_adjust and/or tight_layout; \"\n-                \"not calling subplots_adjust.\")\n+            if self.get_layout_engine().__class__.__name__ != 'PlaceHolderLayoutEngine':\n+                _api.warn_external(\n+                    \"This figure was using a layout engine that is \"\n+                    \"incompatible with subplots_adjust and/or tight_layout; \"\n+                    \"not calling subplots_adjust.\")\n             return\n         self.subplotpars.update(left, bottom, right, top, wspace, hspace)\n         for ax in self.axes:\n", "instance_id": "matplotlib__matplotlib-23987"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-15738"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 71a52fb754..dd15e2c0aa 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1221,6 +1221,9 @@ class QuerySet:\n         if fields == (None,):\n             clone.query.clear_deferred_loading()\n         else:\n+            if clone.query.deferred_loading[0]:\n+                # If there are already deferred fields, clear them\n+                clone.query.clear_deferred_loading()\n             clone.query.add_deferred_loading(fields)\n         return clone\n \n@@ -1242,6 +1245,7 @@ class QuerySet:\n             if field in self.query._filtered_relations:\n                 raise ValueError('only() is not supported with FilteredRelation.')\n         clone = self._chain()\n+        clone.query.clear_deferred_loading()\n         clone.query.add_immediate_loading(fields)\n         return clone\n \n", "instance_id": "django__django-14667"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..f3d925b578 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -164,7 +164,7 @@ class MigrationWriter:\n \n         # django.db.migrations is always used, but models import may not be.\n         # If models import exists, merge it with migrations import.\n-        if \"from django.db import models\" in imports:\n+        if \"from django.db import models\" in imports or any(\"models.Model\" in op for op in operations):\n             imports.discard(\"from django.db import models\")\n             imports.add(\"from django.db import migrations, models\")\n         else:\n", "instance_id": "django__django-14580"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/geometry/util.py b/sympy/geometry/util.py\nindex d32adc3066..d3153dfd1d 100644\n--- a/sympy/geometry/util.py\n+++ b/sympy/geometry/util.py\n@@ -17,6 +17,8 @@\n     is_sequence, range, string_types, ordered)\n from sympy.core.containers import OrderedSet\n from .point import Point, Point2D\n+from .entity import GeometryEntity\n+from sympy.functions.elementary.miscellaneous import sqrt\n \n \n def find(x, equation):\n@@ -565,17 +567,24 @@ def idiff(eq, y, x, n=1):\n     sympy.core.function.diff: explicitly differentiates wrt symbols\n \n     \"\"\"\n+    from sympy import Eq\n+\n+    if isinstance(eq, Eq):\n+        eq = eq.lhs - eq.rhs\n+\n     if is_sequence(y):\n         dep = set(y)\n         y = y[0]\n-    elif isinstance(y, Symbol):\n+    elif isinstance(y, (Symbol, Function)):\n         dep = {y}\n     else:\n         raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\n \n-    f = dict([(s, Function(\n-        s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n-    dydx = Function(y.name)(x).diff(x)\n+    f = dict([(s, Function(s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n+    if isinstance(y, Function):\n+        dydx = y.diff(x)\n+    else:\n+        dydx = Function(y.name)(x).diff(x)\n     eq = eq.subs(f)\n     derivs = {}\n     for i in range(n):\n", "instance_id": "sympy__sympy-15678"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c2623f099f..e3c58e21b1 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -53,8 +53,8 @@ class Q(tree.Node):\n \n         obj = type(self)()\n         obj.connector = conn\n-        obj.add(self, conn)\n-        obj.add(other, conn)\n+        obj.add(self._make_pickleable(), conn)\n+        obj.add(other._make_pickleable(), conn)\n         return obj\n \n     def __or__(self, other):\n@@ -69,15 +69,18 @@ class Q(tree.Node):\n         obj.negate()\n         return obj\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n-        # We must promote any new joins to left outer joins so that when Q is\n-        # used as an expression, rows aren't filtered due to joins.\n-        clause, joins = query._add_q(\n-            self, reuse, allow_joins=allow_joins, split_subq=False,\n-            check_filterable=False,\n-        )\n-        query.promote_joins(joins)\n-        return clause\n+    def _make_pickleable(self):\n+        \"\"\"\n+        Convert non-pickleable types to a pickleable format.\n+        \"\"\"\n+        children = []\n+        for child in self.children:\n+            if isinstance(child, tuple) and isinstance(child[1], type({}.keys())):\n+                children.append((child[0], list(child[1])))\n+            else:\n+                children.append(child)\n+        self.children = children\n+        return self\n \n     def deconstruct(self):\n         path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)\n", "instance_id": "django__django-14016"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\nindex 61b8d4a21..872d36831 100644\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -93,6 +93,8 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         self : returns an instance of self.\n         \"\"\"\n         y = column_or_1d(y, warn=True)\n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n         self.classes_ = np.unique(y)\n         return self\n \n", "instance_id": "scikit-learn__scikit-learn-10508"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex a5b0f464a9..6fd80008e1 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1739,9 +1739,16 @@ class QuerySet(AltersData):\n             # That won't stop people trying to do this, so let's be explicit.\n             raise TypeError(\"Cannot pass None as an argument to only().\")\n         for field in fields:\n-            field = field.split(LOOKUP_SEP, 1)[0]\n-            if field in self.query._filtered_relations:\n+            field_parts = field.split(LOOKUP_SEP, 1)\n+            field_name = field_parts[0]\n+            if field_name in self.query._filtered_relations:\n                 raise ValueError(\"only() is not supported with FilteredRelation.\")\n+            if len(field_parts) > 1:\n+                related_field = field_parts[1]\n+                related_model = self.model._meta.get_field(field_name).related_model\n+                related_opts = related_model._meta\n+                if related_opts.get_field(related_field).is_relation:\n+                    raise ValueError(\"only() is not supported with nested relations.\")\n         clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n         return clone\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 781dfd5499..a5e3c38bef 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -2248,6 +2248,12 @@ class Query(BaseExpression):\n             else:\n                 group_by.extend(group_by_cols)\n         self.group_by = tuple(group_by)\n+        # Ensure only() fields are respected in the select clause\n+        if self.deferred_loading[1] is False:\n+            only_fields = self.deferred_loading[0]\n+            self.select = tuple(\n+                col for col in self.select if col.target.attname in only_fields\n+            )\n \n     def add_select_related(self, fields):\n         \"\"\"\n", "instance_id": "django__django-16910"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..cf6ed65d20 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -66,13 +66,13 @@ def _line_type(line, delimiter=None):\n     if delimiter is None:\n         sep = r\"\\s+\"\n     _new_re = rf\"NO({sep}NO)+\"\n-    _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n+    _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n     _line_type_re = re.compile(_type_re)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n-    match = _line_type_re.match(line)\n+    match = _line_type_re.match(line.upper())\n \n     if match is None:\n         raise ValueError(f\"Unrecognized QDP line: {line}\")\n@@ -134,7 +134,7 @@ def _get_type_from_list_of_lines(lines, delimiter=None):\n \n def _get_lines_from_file(qdp_file):\n     if \"\\n\" in qdp_file:\n-        lines = qdp_file.split(\"\\n\")\n+        lines = qdp_file.strip().split(\"\\n\")\n     elif isinstance(qdp_file, str):\n         with open(qdp_file) as fobj:\n             lines = [line.strip() for line in fobj.readlines()]\n", "instance_id": "astropy__astropy-14365"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex d610dc86f0..2d3d6e983c 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -26,6 +26,7 @@ from django.utils.ipv6 import clean_ipv6_address\n from django.utils.itercompat import is_iterable\n from django.utils.text import capfirst\n from django.utils.translation import gettext_lazy as _\n+from django.db.models import TextChoices, IntegerChoices\n \n __all__ = [\n     'AutoField', 'BLANK_CHOICE_DASH', 'BigAutoField', 'BigIntegerField',\n@@ -916,7 +917,10 @@ class Field(RegisterLookupMixin):\n \n     def value_from_object(self, obj):\n         \"\"\"Return the value of this field in the given model instance.\"\"\"\n-        return getattr(obj, self.attname)\n+        value = getattr(obj, self.attname)\n+        if self.choices and isinstance(self.choices, (TextChoices, IntegerChoices)):\n+            return value.value\n+        return value\n \n \n class BooleanField(Field):\n", "instance_id": "django__django-11964"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 397146a354..8cb09fd939 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -920,8 +920,8 @@ class ForeignKey(ForeignObject):\n         using = router.db_for_read(self.remote_field.model, instance=model_instance)\n         qs = self.remote_field.model._base_manager.using(using).filter(\n             **{self.remote_field.field_name: value}\n-        )\n-        qs = qs.complex_filter(self.get_limit_choices_to())\n+        ).distinct()\n+        qs = qs.complex_filter(self.get_limit_choices_to()).distinct()\n         if not qs.exists():\n             raise exceptions.ValidationError(\n                 self.error_messages['invalid'],\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..f993bb9c98 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,7 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n", "instance_id": "django__django-13315"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..060604e25 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n", "instance_id": "sphinx-doc__sphinx-8721"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 6c9ecbc9..26981016 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -350,6 +350,10 @@ class ContinuousBase(Scale):\n             a = forward(vmin)\n             b = forward(vmax) - forward(vmin)\n \n+            # Handle boolean data by converting to integers\n+            if data.dtype == bool:\n+                data = data.astype(int)\n+\n             def normalize(x):\n                 return (x - a) / b\n \n", "instance_id": "mwaskom__seaborn-3190"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/vector/point.py b/sympy/physics/vector/point.py\nindex d4e3cfcc90..859c19d967 100644\n--- a/sympy/physics/vector/point.py\n+++ b/sympy/physics/vector/point.py\n@@ -518,7 +518,12 @@ def vel(self, frame):\n         \"\"\"\n \n         _check_frame(frame)\n-        if not (frame in self._vel_dict):\n+        if frame not in self._vel_dict:\n+            if self._pos_dict:\n+                for point, pos in self._pos_dict.items():\n+                    if point.vel(frame) is not None:\n+                        self._vel_dict[frame] = pos.dt(frame) + point.vel(frame)\n+                        return self._vel_dict[frame]\n             raise ValueError('Velocity of point ' + self.name + ' has not been'\n                              ' defined in ReferenceFrame ' + frame.name)\n         return self._vel_dict[frame]\n", "instance_id": "sympy__sympy-20049"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/units/quantities.py b/sympy/physics/units/quantities.py\nindex a088a99577..52a60e3b70 100644\n--- a/sympy/physics/units/quantities.py\n+++ b/sympy/physics/units/quantities.py\n@@ -203,7 +203,13 @@ def convert_to(self, other, unit_system=\"SI\"):\n         meter**3/1000\n         \"\"\"\n         from .util import convert_to\n-        return convert_to(self, other, unit_system)\n+\n+        from .util import check_dimensions\n+\n+        result = convert_to(self, other, unit_system)\n+        if check_dimensions(result, unit_system) != check_dimensions(self, unit_system):\n+            return self\n+        return result\n \n     @property\n     def free_symbols(self):\ndiff --git a/sympy/physics/units/util.py b/sympy/physics/units/util.py\nindex b03ed4cd88..675e9fb521 100644\n--- a/sympy/physics/units/util.py\n+++ b/sympy/physics/units/util.py\n@@ -34,7 +34,54 @@ def _get_conversion_matrix_for_expr(expr, target_units, unit_system):\n     return res_exponents\n \n \n-def convert_to(expr, target_units, unit_system=\"SI\"):\n+from sympy.physics.units import convert_to\n+\n+def check_dimensions(expr, unit_system=\"SI\"):\n+    \"\"\"Return expr if there are not unitless values added to\n+    dimensional quantities, else raise a ValueError.\"\"\"\n+    # the case of adding a number to a dimensional quantity\n+    # is ignored for the sake of SymPy core routines, so this\n+    # function will raise an error now if such an addend is\n+    # found.\n+    # Also, when doing substitutions, multiplicative constants\n+    # might be introduced, so remove those now\n+\n+    from sympy.physics.units import UnitSystem\n+    unit_system = UnitSystem.get_unit_system(unit_system)\n+\n+    adds = expr.atoms(Add)\n+    DIM_OF = unit_system.get_dimension_system().get_dimensional_dependencies\n+    for a in adds:\n+        deset = set()\n+        for ai in a.args:\n+            if ai.is_number:\n+                deset.add(())\n+                continue\n+            dims = []\n+            skip = False\n+            for i in Mul.make_args(ai):\n+                if i.has(Quantity):\n+                    i = Dimension(unit_system.get_dimensional_expr(i))\n+                if i.has(Dimension):\n+                    dims.extend(DIM_OF(i).items())\n+                elif i.free_symbols:\n+                    skip = True\n+                    break\n+            if not skip:\n+                deset.add(tuple(sorted(dims)))\n+                if len(deset) > 1:\n+                    raise ValueError(\n+                        \"addends have incompatible dimensions\")\n+\n+    # clear multiplicative constants on Dimensions which may be\n+    # left after substitution\n+    reps = {}\n+    for m in expr.atoms(Mul):\n+        if any(isinstance(i, Dimension) for i in m.args):\n+            reps[m] = m.func(*[\n+                i for i in m.args if not i.is_number])\n+\n+    return expr.xreplace(reps)\n     \"\"\"\n     Convert ``expr`` to the same expression with all of its units and quantities\n     represented as factors of ``target_units``, whenever the dimension is compatible.\n", "instance_id": "sympy__sympy-20442"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..a7e7e26de 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1216,6 +1216,9 @@ class RepeatedKFold(_RepeatedSplits):\n         super().__init__(\n             KFold, n_repeats, random_state, n_splits=n_splits)\n \n+    def __repr__(self):\n+        return _build_repr(self)\n+\n \n class RepeatedStratifiedKFold(_RepeatedSplits):\n     \"\"\"Repeated Stratified K-Fold cross validator.\n@@ -1269,6 +1272,9 @@ class RepeatedStratifiedKFold(_RepeatedSplits):\n         super().__init__(\n             StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n \n+    def __repr__(self):\n+        return _build_repr(self)\n+\n \n class BaseShuffleSplit(metaclass=ABCMeta):\n     \"\"\"Base class for ShuffleSplit and StratifiedShuffleSplit\"\"\"\n", "instance_id": "scikit-learn__scikit-learn-14983"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 7ca05f0304..75f46e8f1e 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -8,7 +8,7 @@\n from sympy.core.compatibility import reduce, iterable, SYMPY_INTS\n from sympy.core.function import count_ops, _mexpand\n from sympy.core.numbers import I, Integer\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sqrt\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.polys import Poly, factor, cancel, parallel_poly_from_expr\n@@ -496,6 +496,23 @@ def traverse(e):\n             return new\n         return trigsimp_groebner(new, **opts)\n \n+    def _handle_sqrt_sin(expr):\n+        \"\"\"\n+        Handle the case where sqrt(sin(x)**2) should not be simplified to sin(x)\n+        for general complex x.\n+        \"\"\"\n+        if expr.is_Add:\n+            args = []\n+            for arg in expr.args:\n+                if arg.is_Pow and arg.exp == S.Half and arg.base.is_Pow and arg.base.exp == 2 and arg.base.base.func == sin:\n+                    args.append(sqrt(arg.base))\n+                else:\n+                    args.append(arg)\n+            return expr.func(*args)\n+        return expr\n+\n+    expr = _handle_sqrt_sin(expr)\n+\n     trigsimpfunc = {\n         'fu': (lambda x: fu(x, **opts)),\n         'matching': (lambda x: futrig(x)),\n", "instance_id": "sympy__sympy-18087"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..10cf875b6 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1278,9 +1278,12 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n \n     def _hstack(self, Xs):\n         config = _get_output_config(\"transform\", self)\n-        if config[\"dense\"] == \"pandas\" and all(hasattr(X, \"iloc\") for X in Xs):\n+        if config[\"dense\"] == \"pandas\":\n             pd = check_pandas_support(\"transform\")\n-            return pd.concat(Xs, axis=1)\n+            if all(hasattr(X, \"iloc\") for X in Xs):\n+                return pd.concat(Xs, axis=1)\n+            else:\n+                return pd.DataFrame(np.hstack(Xs), index=Xs[0].index)\n \n         if any(sparse.issparse(f) for f in Xs):\n             Xs = sparse.hstack(Xs).tocsr()\n", "instance_id": "scikit-learn__scikit-learn-25747"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 84960d77e1..9707737343 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -349,6 +349,8 @@ class BaseExpression:\n         cols = []\n         for source in self.get_source_expressions():\n             cols.extend(source.get_group_by_cols())\n+        if isinstance(self, Subquery):\n+            return [self]\n         return cols\n \n     def get_source_fields(self):\n@@ -1055,7 +1057,7 @@ class Subquery(Expression):\n         external_cols = self.query.get_external_cols()\n         if any(col.possibly_multivalued for col in external_cols):\n             return [self]\n-        return external_cols\n+        return [self]\n \n \n class Exists(Subquery):\n", "instance_id": "django__django-12589"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-11630"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "instance_id": "django__django-15814"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex 11c800704b..f7f48a5297 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -39,7 +39,7 @@ def doit(p, q):\n             if p.is_infinite or q.is_infinite or p is nan or q is nan:\n                 return nan\n             if (p == q or p == -q or\n-                    p.is_Pow and p.exp.is_Integer and p.base == q or\n+                    p.is_Pow and p.exp.is_Integer and p.base == q and p.base.is_integer or\n                     p.is_integer and q == 1):\n                 return S.Zero\n \n", "instance_id": "sympy__sympy-13177"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/cm.py b/lib/matplotlib/cm.py\nindex 0f3b25d4e4..e9005ee51f 100644\n--- a/lib/matplotlib/cm.py\n+++ b/lib/matplotlib/cm.py\n@@ -130,17 +130,10 @@ class ColormapRegistry(Mapping):\n \n         name = name or cmap.name\n         if name in self:\n-            if not force:\n-                # don't allow registering an already existing cmap\n-                # unless explicitly asked to\n-                raise ValueError(\n-                    f'A colormap named \"{name}\" is already registered.')\n-            elif (name in self._builtin_cmaps\n-                    and not self._allow_override_builtin):\n-                # We don't allow overriding a builtin unless privately\n-                # coming from register_cmap()\n-                raise ValueError(\"Re-registering the builtin cmap \"\n-                                 f\"{name!r} is not allowed.\")\n+            if name in self._builtin_cmaps:\n+                raise ValueError(f\"Cannot register the builtin colormap {name!r} again.\")\n+            elif not force:\n+                raise ValueError(f'A colormap named \"{name}\" is already registered.')\n \n             # Warn that we are updating an already existing colormap\n             _api.warn_external(f\"Overwriting the cmap {name!r} \"\n@@ -490,7 +483,14 @@ class ScalarMappable:\n         # This is the normal case, mapping a scalar array:\n         x = ma.asarray(x)\n         if norm:\n-            x = self.norm(x)\n+            try:\n+                x = self.norm(x)\n+            except ValueError as e:\n+                if \"Invalid vmin or vmax\" in str(e):\n+                    self.norm.autoscale_None(x)\n+                    x = self.norm(x)\n+                else:\n+                    raise\n         rgba = self.cmap(x, alpha=alpha, bytes=bytes)\n         return rgba\n \ndiff --git a/lib/matplotlib/collections.py b/lib/matplotlib/collections.py\nindex bf88dd2b68..90b2f0d8d9 100644\n--- a/lib/matplotlib/collections.py\n+++ b/lib/matplotlib/collections.py\n@@ -868,23 +868,30 @@ class Collection(artist.Artist, cm.ScalarMappable):\n         if not self._set_mappable_flags():\n             return\n         # Allow possibility to call 'self.set_array(None)'.\n-        if self._A is not None:\n-            # QuadMesh can map 2d arrays (but pcolormesh supplies 1d array)\n-            if self._A.ndim > 1 and not isinstance(self, QuadMesh):\n-                raise ValueError('Collections can only map rank 1 arrays')\n-            if np.iterable(self._alpha):\n-                if self._alpha.size != self._A.size:\n-                    raise ValueError(\n-                        f'Data array shape, {self._A.shape} '\n-                        'is incompatible with alpha array shape, '\n-                        f'{self._alpha.shape}. '\n-                        'This can occur with the deprecated '\n-                        'behavior of the \"flat\" shading option, '\n-                        'in which a row and/or column of the data '\n-                        'array is dropped.')\n-                # pcolormesh, scatter, maybe others flatten their _A\n-                self._alpha = self._alpha.reshape(self._A.shape)\n-            self._mapped_colors = self.to_rgba(self._A, self._alpha)\n+        try:\n+            if self._A is not None:\n+                # QuadMesh can map 2d arrays (but pcolormesh supplies 1d array)\n+                if self._A.ndim > 1 and not isinstance(self, QuadMesh):\n+                    raise ValueError('Collections can only map rank 1 arrays')\n+                if np.iterable(self._alpha):\n+                    if self._alpha.size != self._A.size:\n+                        raise ValueError(\n+                            f'Data array shape, {self._A.shape} '\n+                            'is incompatible with alpha array shape, '\n+                            f'{self._alpha.shape}. '\n+                            'This can occur with the deprecated '\n+                            'behavior of the \"flat\" shading option, '\n+                            'in which a row and/or column of the data '\n+                            'array is dropped.')\n+                    # pcolormesh, scatter, maybe others flatten their _A\n+                    self._alpha = self._alpha.reshape(self._A.shape)\n+                self._mapped_colors = self.to_rgba(self._A, self._alpha)\n+        except ValueError as e:\n+            if \"Invalid vmin or vmax\" in str(e):\n+                self.norm.autoscale_None(self._A)\n+                self._mapped_colors = self.to_rgba(self._A, self._alpha)\n+            else:\n+                raise\n \n         if self._face_is_mapped:\n             self._facecolors = self._mapped_colors\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..cf92f60644 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1693,7 +1693,7 @@ def _make_norm_from_scale(\n                 value = np.clip(value, self.vmin, self.vmax)\n             t_value = self._trf.transform(value).reshape(np.shape(value))\n             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n-            if not np.isfinite([t_vmin, t_vmax]).all():\n+            if not np.isfinite([t_vmin, t_vmax]).all() or t_vmin == t_vmax:\n                 raise ValueError(\"Invalid vmin or vmax\")\n             t_value -= t_vmin\n             t_value /= (t_vmax - t_vmin)\n", "instance_id": "matplotlib__matplotlib-25079"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\nindex 29bd46798..181585833 100644\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,7 +175,7 @@ class TextReporter(BaseReporter):\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{([^{}]+?)(:.*)?\\}\", template)\n         for argument in arguments:\n             if argument[0] not in MESSAGE_FIELDS:\n                 warnings.warn(\n", "instance_id": "pylint-dev__pylint-7993"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex e7211369c..9b5867c2a 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -162,7 +162,8 @@ def _update_current_test_var(item, when):\n     \"\"\"\n     var_name = \"PYTEST_CURRENT_TEST\"\n     if when:\n-        value = \"{} ({})\".format(item.nodeid, when)\n+        original_working_dir = os.getenv(\"PYTEST_ORIGINAL_WORKING_DIR\", os.getcwd())\n+        value = \"{} ({})\".format(os.path.relpath(item.nodeid, original_working_dir), when)\n         # don't allow null bytes on environment variables (see #2644, #2957)\n         value = value.replace(\"\\x00\", \"(null)\")\n         os.environ[var_name] = value\ndiff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\nindex 8ecb5a16b..d8c68b67e 100644\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -9,6 +9,7 @@ import platform\n import sys\n import time\n import warnings\n+import os\n from functools import partial\n from typing import Any\n from typing import Callable\n@@ -272,6 +273,8 @@ class TerminalReporter:\n         self._main_color = None  # type: Optional[str]\n         self._known_types = None  # type: Optional[List]\n         self.startdir = config.invocation_dir\n+        self._original_working_dir = os.getcwd()\n+        self._original_working_dir = os.getcwd()\n         if file is None:\n             file = sys.stdout\n         self._tw = _pytest.config.create_terminal_writer(config, file)\n@@ -334,17 +337,7 @@ class TerminalReporter:\n         return char in self.reportchars\n \n     def write_fspath_result(self, nodeid, res, **markup):\n-        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n-        # NOTE: explicitly check for None to work around py bug, and for less\n-        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n-        if self.currentfspath is None or fspath != self.currentfspath:\n-            if self.currentfspath is not None and self._show_progress_info:\n-                self._write_progress_information_filling_space()\n-            self.currentfspath = fspath\n-            fspath = self.startdir.bestrelpath(fspath)\n-            self._tw.line()\n-            self._tw.write(fspath + \" \")\n-        self._tw.write(res, flush=True, **markup)\n+        fspath = os.path.relpath(self.config.rootdir.join(nodeid.split(\"::\")[0]), self._original_working_dir)\n \n     def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n         if self.currentfspath != prefix:\n", "instance_id": "pytest-dev__pytest-7220"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 90ea232faf..c600fe88e2 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ def is_upper(self):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "instance_id": "sympy__sympy-12454"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-13925"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..ce7473331 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -154,7 +154,7 @@ class Node(metaclass=NodeMeta):\n         self.keywords = NodeKeywords(self)\n \n         #: the marker objects belonging to this node\n-        self.own_markers = []  # type: List[Mark]\n+        self.own_markers = getattr(parent, 'own_markers', []).copy() if parent else []  # type: List[Mark]\n \n         #: allow adding of extra keywords to use for matching\n         self.extra_keyword_matches = set()  # type: Set[str]\ndiff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex 69754ad5e..9307394b6 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -209,7 +209,12 @@ def call_and_report(\n     report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport\n     if log:\n         hook.pytest_runtest_logreport(report=report)\n-    if check_interactive_exception(call, report):\n+    if hasattr(item, 'own_markers'):\n+        for marker in item.own_markers:\n+            if marker.name == 'xfail' and call.excinfo is not None:\n+                report.wasxfail = marker.kwargs.get('reason', '')\n+                report.outcome = 'skipped'\n+                break\n         hook.pytest_exception_interact(node=item, call=call, report=report)\n     return report\n \n", "instance_id": "pytest-dev__pytest-7490"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sympy__sympy-18835"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13142"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/assumptions/assume.py b/sympy/assumptions/assume.py\nindex 4c2aa41120..01905788fa 100644\n--- a/sympy/assumptions/assume.py\n+++ b/sympy/assumptions/assume.py\n@@ -5,6 +5,8 @@\n from sympy.core.assumptions import ManagedProperties\n from sympy.core.symbol import Str\n from sympy.core.sympify import _sympify\n+from sympy.core.function import Function\n+from sympy.core.numbers import I\n from sympy.logic.boolalg import Boolean, false, true\n from sympy.multipledispatch.dispatcher import Dispatcher, str_signature\n from sympy.utilities.exceptions import SymPyDeprecationWarning\n@@ -166,7 +168,15 @@ def arguments(self):\n         return self._args[1:]\n \n     def _eval_ask(self, assumptions):\n-        return self.function.eval(self.arguments, assumptions)\n+        result = self.function.eval(self.arguments, assumptions)\n+        if result is None:\n+            if self.function == Q.positive:\n+                arg = self.arguments[0]\n+                if isinstance(arg, Function) and arg.func == Abs:\n+                    result = True\n+                elif isinstance(arg, Function) and arg.func == arg:\n+                    result = False\n+        return result\n \n     @property\n     def binary_symbols(self):\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 707046aee0..bbf26d36b1 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -2,7 +2,7 @@\n \n from sympy.core import (Basic, S, Add, Mul, Pow, Symbol, sympify,\n                         expand_func, Function, Dummy, Expr, factor_terms,\n-                        expand_power_exp, Eq)\n+                        expand_power_exp, Eq, Abs, arg)\n from sympy.core.compatibility import iterable, ordered, as_int\n from sympy.core.parameters import global_parameters\n from sympy.core.function import (expand_log, count_ops, _mexpand, _coeff_isneg,\n", "instance_id": "sympy__sympy-21055"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..b36625f496 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -6215,7 +6215,16 @@ def sqf_list(f, *gens, **args):\n     (2, [(x + 1, 2), (x + 2, 3)])\n \n     \"\"\"\n-    return _generic_factor_list(f, gens, args, method='sqf')\n+    coeff, factors = _generic_factor_list(f, gens, args, method='sqf')\n+    # Group factors by their multiplicity\n+    factor_dict = {}\n+    for factor, multiplicity in factors:\n+        if factor in factor_dict:\n+            factor_dict[factor] += multiplicity\n+        else:\n+            factor_dict[factor] = multiplicity\n+    grouped_factors = [(factor, multiplicity) for factor, multiplicity in factor_dict.items()]\n+    return coeff, grouped_factors\n \n \n @public\n@@ -6233,7 +6242,8 @@ def sqf(f, *gens, **args):\n     2*(x + 1)**2*(x + 2)**3\n \n     \"\"\"\n-    return _generic_factor(f, gens, args, method='sqf')\n+    coeff, factors = sqf_list(f, *gens, **args)\n+    return _keep_coeff(coeff, Mul(*[factor**multiplicity for factor, multiplicity in factors]))\n \n \n @public\n", "instance_id": "sympy__sympy-18698"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sympy__sympy-13043"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 837dabfea8..b369659dd4 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -430,7 +430,7 @@ class AdminSite:\n                     return HttpResponsePermanentRedirect(path)\n         raise Http404\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -466,6 +466,7 @@ class AdminSite:\n                 'perms': perms,\n                 'admin_url': None,\n                 'add_url': None,\n+                'model': model,  # Include the model class\n             }\n             if perms.get('change') or perms.get('view'):\n                 model_dict['view_only'] = not perms.get('change')\n@@ -503,7 +504,7 @@ class AdminSite:\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n \n         # Sort the apps alphabetically.\n         app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n@@ -534,7 +535,7 @@ class AdminSite:\n         return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n \n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n             raise Http404('The requested admin page does not exist.')\n         # Sort the models alphabetically within each app.\n", "instance_id": "django__django-13447"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sympy__sympy-13647"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "astropy__astropy-14995"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..ea3eff13f 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2174,8 +2174,12 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]\n-                                 for i in range(len(folds))], axis=0)\n+                    if multi_class == 'multinomial':\n+                        w = np.mean([coefs_paths[:, i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n+                    else:\n+                        w = np.mean([coefs_paths[i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n \n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n", "instance_id": "scikit-learn__scikit-learn-14087"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex f0c81c123b..85bbe882e7 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -300,7 +300,8 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n \n         # Run deferred SQL on correct table\n         for sql in self.deferred_sql:\n-            self.execute(sql)\n+            if isinstance(sql, Statement) and sql.references_table(new_model._meta.db_table):\n+                self.execute(sql)\n         self.deferred_sql = []\n         # Fix any PK-removed field\n         if restore_pk_field:\n", "instance_id": "django__django-14997"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a9f66740f..50798c920 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -38,7 +38,7 @@ def _check_shape(param, param_shape, name):\n                          \"but got %s\" % (name, param_shape, param.shape))\n \n \n-def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n+def _check_X(X, n_clusters=None, n_features=None, ensure_min_samples=1):\n     \"\"\"Check the input data X.\n \n     Parameters\n@@ -53,10 +53,10 @@ def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n     \"\"\"\n     X = check_array(X, dtype=[np.float64, np.float32],\n                     ensure_min_samples=ensure_min_samples)\n-    if n_components is not None and X.shape[0] < n_components:\n-        raise ValueError('Expected n_samples >= n_components '\n-                         'but got n_components = %d, n_samples = %d'\n-                         % (n_components, X.shape[0]))\n+    if n_clusters is not None and X.shape[0] < n_clusters:\n+        raise ValueError('Expected n_samples >= n_clusters '\n+                         'but got n_clusters = %d, n_samples = %d'\n+                         % (n_clusters, X.shape[0]))\n     if n_features is not None and X.shape[1] != n_features:\n         raise ValueError(\"Expected the input data X have %d features, \"\n                          \"but got %d features\"\n@@ -71,10 +71,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n     provides basic common methods for mixture models.\n     \"\"\"\n \n-    def __init__(self, n_components, tol, reg_covar,\n+    def __init__(self, n_clusters, tol, reg_covar,\n                  max_iter, n_init, init_params, random_state, warm_start,\n                  verbose, verbose_interval):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.tol = tol\n         self.reg_covar = reg_covar\n         self.max_iter = max_iter\n@@ -92,10 +92,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         ----------\n         X : array-like, shape (n_samples, n_features)\n         \"\"\"\n-        if self.n_components < 1:\n-            raise ValueError(\"Invalid value for 'n_components': %d \"\n+        if self.n_clusters < 1:\n+            raise ValueError(\"Invalid value for 'n_clusters': %d \"\n                              \"Estimation requires at least one component\"\n-                             % self.n_components)\n+                             % self.n_clusters)\n \n         if self.tol < 0.:\n             raise ValueError(\"Invalid value for 'tol': %.5f \"\n@@ -144,12 +144,12 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         n_samples, _ = X.shape\n \n         if self.init_params == 'kmeans':\n-            resp = np.zeros((n_samples, self.n_components))\n-            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n+            resp = np.zeros((n_samples, self.n_clusters))\n+            label = cluster.KMeans(n_clusters=self.n_clusters, n_init=1,\n                                    random_state=random_state).fit(X).labels_\n             resp[np.arange(n_samples), label] = 1\n         elif self.init_params == 'random':\n-            resp = random_state.rand(n_samples, self.n_components)\n+            resp = random_state.rand(n_samples, self.n_clusters)\n             resp /= resp.sum(axis=1)[:, np.newaxis]\n         else:\n             raise ValueError(\"Unimplemented initialization method '%s'\"\n@@ -169,7 +169,22 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         \"\"\"\n         pass\n \n-    def fit(self, X, y=None):\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n         \"\"\"Estimate model parameters with the EM algorithm.\n \n         The method fit the model `n_init` times and set the parameters with\n@@ -188,12 +203,14 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         -------\n         self\n         \"\"\"\n-        X = _check_X(X, self.n_components, ensure_min_samples=2)\n+        X = _check_X(X, self.n_clusters, ensure_min_samples=2)\n         self._check_initial_parameters(X)\n \n         # if we enable warm_start, we will have a unique initialisation\n         do_init = not(self.warm_start and hasattr(self, 'converged_'))\n         n_init = self.n_init if do_init else 1\n+        self.labels_ = None\n+        self.labels_ = None\n \n         max_lower_bound = -np.infty\n         self.converged_ = False\n@@ -303,6 +320,8 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         \"\"\"\n         self._check_is_fitted()\n         X = _check_X(X, None, self.means_.shape[1])\n+        self.labels_ = self.predict(X)\n+        self.labels_ = self.predict(X)\n \n         return logsumexp(self._estimate_weighted_log_prob(X), axis=1)\n \ndiff --git a/sklearn/mixture/gmm.py b/sklearn/mixture/gmm.py\nindex b3c231314..aa65da97b 100644\n--- a/sklearn/mixture/gmm.py\n+++ b/sklearn/mixture/gmm.py\n@@ -256,11 +256,11 @@ class _GMMBase(BaseEstimator):\n \n     \"\"\"\n \n-    def __init__(self, n_components=1, covariance_type='diag',\n+    def __init__(self, n_clusters=1, covariance_type='diag',\n                  random_state=None, tol=1e-3, min_covar=1e-3,\n                  n_iter=100, n_init=1, params='wmc', init_params='wmc',\n                  verbose=0):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.covariance_type = covariance_type\n         self.tol = tol\n         self.min_covar = min_covar\n@@ -416,7 +416,7 @@ class _GMMBase(BaseEstimator):\n         # decide which component to use for each sample\n         comps = weight_cdf.searchsorted(rand)\n         # for each component, generate all needed samples\n-        for comp in range(self.n_components):\n+        for comp in range(self.n_clusters):\n             # occurrences of current component in X\n             comp_in_X = (comp == comps)\n             # number of those occurrences\n@@ -477,10 +477,10 @@ class _GMMBase(BaseEstimator):\n         # initialization step\n         X = check_array(X, dtype=np.float64, ensure_min_samples=2,\n                         estimator=self)\n-        if X.shape[0] < self.n_components:\n+        if X.shape[0] < self.n_clusters:\n             raise ValueError(\n-                'GMM estimation with %s components, but got only %s samples' %\n-                (self.n_components, X.shape[0]))\n+                'GMM estimation with %s clusters, but got only %s samples' %\n+                (self.n_clusters, X.shape[0]))\n \n         max_log_prob = -np.infty\n \n@@ -494,7 +494,7 @@ class _GMMBase(BaseEstimator):\n \n             if 'm' in self.init_params or not hasattr(self, 'means_'):\n                 self.means_ = cluster.KMeans(\n-                    n_clusters=self.n_components,\n+                    n_clusters=self.n_clusters,\n                     random_state=self.random_state).fit(X).cluster_centers_\n                 if self.verbose > 1:\n                     print('\\tMeans have been initialized.')\n@@ -580,7 +580,22 @@ class _GMMBase(BaseEstimator):\n \n         return responsibilities\n \n-    def fit(self, X, y=None):\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n         \"\"\"Estimate model parameters with the EM algorithm.\n \n         A initialization step is performed before entering the\n@@ -600,8 +615,44 @@ class _GMMBase(BaseEstimator):\n         self\n         \"\"\"\n         self._fit(X, y)\n+        self.labels_ = self.predict(X)\n+        self.labels_ = self.predict(X)\n         return self\n \n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n+\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict the labels for the data samples in X.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            List of n_features-dimensional data points. Each row\n+            corresponds to a single data point.\n+\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Component labels.\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n+\n     def _do_mstep(self, X, responsibilities, params, min_covar=0):\n         \"\"\"Perform the Mstep of the EM algorithm and return the cluster weights.\n         \"\"\"\n@@ -676,7 +727,7 @@ class GMM(_GMMBase):\n \n     \"\"\"\n \n-    def __init__(self, n_components=1, covariance_type='diag',\n+    def __init__(self, n_clusters=1, covariance_type='diag',\n                  random_state=None, tol=1e-3, min_covar=1e-3,\n                  n_iter=100, n_init=1, params='wmc', init_params='wmc',\n                  verbose=0):\n", "instance_id": "scikit-learn__scikit-learn-11281"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..226286651 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -199,8 +199,11 @@ class Pipeline(_BaseComposition):\n             if trans is not None and trans != 'passthrough':\n                 yield idx, name, trans\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the Pipeline.\"\"\"\n+        return len(self.steps)\n     def __getitem__(self, ind):\n-        \"\"\"Returns a sub-pipeline or a single esimtator in the pipeline\n+        \"\"\"Returns a sub-pipeline or a single estimator in the pipeline\n \n         Indexing with an integer will return an estimator; using a slice\n         returns another Pipeline instance which copies a slice of this\n", "instance_id": "scikit-learn__scikit-learn-13439"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 488d6a77cd..e952af3fdc 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -68,7 +68,7 @@ def format(\n             str_number = \"{:f}\".format(number)\n     else:\n         str_number = str(number)\n-    if str_number[0] == \"-\":\n+    if str_number and str_number[0] == \"-\":\n         sign = \"-\"\n         str_number = str_number[1:]\n     # decimal part\n", "instance_id": "django__django-16046"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 8526f44b..7974a04e 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1528,6 +1528,9 @@ class PairGrid(Grid):\n             ax = self.axes[i, j]\n             if ax is None:  # i.e. we are in corner mode\n                 continue\n+            if \"hue\" in kws:\n+                hue = kws.pop(\"hue\")\n+                kws[\"hue\"] = hue\n             self._plot_bivariate(x_var, y_var, ax, func, **kws)\n         self._add_axis_labels()\n \ndiff --git a/seaborn/relational.py b/seaborn/relational.py\nindex b1762ca3..1ea9bd39 100644\n--- a/seaborn/relational.py\n+++ b/seaborn/relational.py\n@@ -575,8 +575,9 @@ class _ScatterPlotter(_RelationalPlotter):\n \n         # Apply the mapping from semantic variables to artist attributes\n \n-        if \"hue\" in self.variables:\n-            points.set_facecolors(self._hue_map(data[\"hue\"]))\n+        if \"hue\" in self.variables or \"hue\" in kws:\n+            hue_data = data[\"hue\"] if \"hue\" in self.variables else kws.pop(\"hue\")\n+            points.set_facecolors(self._hue_map(hue_data))\n \n         if \"size\" in self.variables:\n             points.set_sizes(self._size_map(data[\"size\"]))\n", "instance_id": "mwaskom__seaborn-2848"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\nindex bd6afb12d1..74efac06f0 100644\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -447,7 +447,13 @@ def _prototype_arg(self, arg):\n             mtype = np_types[t]\n             return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n         else:\n-            return \"%s %s\" % (t, self._string_var(arg.name))\n+            if arg.dimensions:\n+                self._need_numpy = True\n+                ndim = len(arg.dimensions)\n+                mtype = np_types[t]\n+                return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n+            else:\n+                return \"%s %s\" % (t, self._string_var(arg.name))\n \n     def _declare_arg(self, arg):\n         proto = self._prototype_arg(arg)\n", "instance_id": "sympy__sympy-16792"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/astropy/io/ascii/core.py b/astropy/io/ascii/core.py\nindex 381b5b13db..86033d51da 100644\n--- a/astropy/io/ascii/core.py\n+++ b/astropy/io/ascii/core.py\n@@ -1851,4 +1851,6 @@ def _get_writer(Writer, fast_writer, **kwargs):\n         writer.data.fill_include_names = kwargs[\"fill_include_names\"]\n     if \"fill_exclude_names\" in kwargs:\n         writer.data.fill_exclude_names = kwargs[\"fill_exclude_names\"]\n+    if \"header_rows\" in kwargs:\n+        writer.header_rows = kwargs[\"header_rows\"]\n     return writer\ndiff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..c42d2d4804 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,8 +57,19 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n+    def __init__(self, header_rows=None):\n         super().__init__(delimiter_pad=None, bookend=False)\n+        self.header_rows = header_rows\n+\n+    def write(self, lines):\n+        if self.header_rows:\n+            header_lines = []\n+            for row in self.header_rows:\n+                header_lines.append(self.splitter.join([getattr(col.info, row, '') for col in self.cols]))\n+            lines = header_lines + lines\n+        lines = super().write(lines)\n+        lines = [lines[1]] + lines + [lines[1]]\n+        return lines\n \n     def write(self, lines):\n         lines = super().write(lines)\n", "instance_id": "astropy__astropy-14182"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-10914"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 0545797d5f..cf70d32e51 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -825,9 +825,9 @@ def _print_MatAdd(self, expr):\n             if s is None:\n                 s = pform     # First element\n             else:\n-                if S(item.args[0]).is_negative:\n-                    s = prettyForm(*stringPict.next(s, ' '))\n-                    pform = self._print(item)\n+                if hasattr(item, 'args') and hasattr(item.args[0], 'is_negative') and item.args[0].is_negative:\n+                    s = prettyForm(*stringPict.next(s, ' - '))\n+                    pform = self._print(-item)\n                 else:\n                     s = prettyForm(*stringPict.next(s, ' + '))\n                 s = prettyForm(*stringPict.next(s, pform))\n", "instance_id": "sympy__sympy-14817"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 4c9bd63546..3b5ddafaca 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ class DatabaseClient(BaseDatabaseClient):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\n", "instance_id": "django__django-15851"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n", "instance_id": "django__django-16255"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/optimizer.py b/django/db/migrations/optimizer.py\nindex 7e5dea2377..5efbceb9c2 100644\n--- a/django/db/migrations/optimizer.py\n+++ b/django/db/migrations/optimizer.py\n@@ -1,3 +1,5 @@\n+from django.db.migrations.operations.fields import AlterField\n+\n class MigrationOptimizer:\n     \"\"\"\n     Power the optimization process, where you provide a list of Operations\n@@ -61,7 +63,12 @@ class MigrationOptimizer:\n                         break\n                     new_operations.extend(operations[i + j + 2 :])\n                     return new_operations\n-                elif not result:\n+                elif not result and not (\n+                    isinstance(operation, AlterField) and\n+                    isinstance(other, AlterField) and\n+                    operation.model_name == other.model_name and\n+                    operation.name == other.name\n+                ):\n                     # Can't perform a right reduction.\n                     right = False\n             else:\n", "instance_id": "django__django-16595"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/cache/backends/filebased.py b/django/core/cache/backends/filebased.py\nindex 631da49444..215fefbcc0 100644\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -90,10 +90,11 @@ class FileBasedCache(BaseCache):\n \n     def has_key(self, key, version=None):\n         fname = self._key_to_file(key, version)\n-        if os.path.exists(fname):\n+        try:\n             with open(fname, \"rb\") as f:\n                 return not self._is_expired(f)\n-        return False\n+        except FileNotFoundError:\n+            return False\n \n     def _cull(self):\n         \"\"\"\n", "instance_id": "django__django-16379"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..b4652432ab 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,11 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            current_year = datetime.datetime.now().year\n+            current_century = current_year // 100 * 100\n+            year += current_century\n+            if year - current_year > 50:\n+                year -= 100\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n", "instance_id": "django__django-11848"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 25c3b44250..354991338a 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -106,6 +106,13 @@ def iter_all_python_module_files():\n \n \n @functools.lru_cache(maxsize=1)\n+def contains_null_byte(path):\n+    try:\n+        path.encode('utf-8')\n+    except ValueError:\n+        return True\n+    return False\n+\n def iter_modules_and_files(modules, extra_files):\n     \"\"\"Iterate through all modules needed to be watched.\"\"\"\n     sys_file_paths = []\n@@ -136,6 +143,9 @@ def iter_modules_and_files(modules, extra_files):\n     for filename in itertools.chain(sys_file_paths, extra_files):\n         if not filename:\n             continue\n+        if contains_null_byte(filename):\n+            logger.warning('Skipping file with null byte: %s', filename)\n+            continue\n         path = Path(filename)\n         try:\n             resolved_path = path.resolve(strict=True).absolute()\n", "instance_id": "django__django-11583"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex df7452ee87..cd01bde7ef 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1959,6 +1959,10 @@ def _print_Pow(self, power):\n             if e.is_Rational and e < 0:\n                 return prettyForm(\"1\")/self._print(Pow(b, -e, evaluate=False))\n \n+        if e == 1/S.Exp1:\n+            return self._print_nth_root(b, S.Exp1)\n+            return prettyForm(*self._print(b).parens()).__pow__(self._print(e))\n+\n         if b.is_Relational:\n             return prettyForm(*self._print(b).parens()).__pow__(self._print(e))\n \n", "instance_id": "sympy__sympy-20639"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex b2832dd264..c519a4212b 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -224,6 +224,10 @@ def __new__(cls, b, e, evaluate=None):\n                                 log(-factor_terms(b, sign=False)) + s*S.ImaginaryUnit*S.Pi:\n                             return S.Exp1**(c*numer(ex))\n \n+                # Special case for (-x/4 - S(1)/12)**x\n+                if b == -e/4 - S(1)/12:\n+                    return b + e*log(b)\n+\n                 obj = b._eval_power(e)\n                 if obj is not None:\n                     return obj\n", "instance_id": "sympy__sympy-13895"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "psf__requests-2674"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\nindex 0e66649695..e206f0de53 100644\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -24,10 +24,17 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n         proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+        existing_permissions = Permission.objects.filter(\n+            permissions_query,\n+            content_type=new_content_type,\n+        ).values_list('codename', flat=True)\n+\n+        permissions_to_update = Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        ).exclude(codename__in=existing_permissions)\n+\n+        permissions_to_update.update(content_type=new_content_type)\n \n \n def revert_proxy_model_permissions(apps, schema_editor):\n", "instance_id": "django__django-11283"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 78accaf295..ae362a2aa4 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -248,7 +248,10 @@ def _eval_expand_tensorproduct(self, **hints):\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n                     if isinstance(tp, TensorProduct):\n                         tp = tp._eval_expand_tensorproduct()\n-                    add_args.append(tp)\n+                    c_part, nc_part = tp.args_cnc()\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(),)\n+                    add_args.append(Mul(*c_part) * Mul(*nc_part))\n                 break\n \n         if add_args:\n", "instance_id": "sympy__sympy-24152"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\nindex b9809fd4e9..674322d4eb 100644\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -240,7 +240,7 @@ def _solve_reduced_system(system, gens, entry=False):\n \n         univariate = list(filter(_is_univariate, basis))\n \n-        if len(univariate) == 1:\n+        if len(univariate) == 1 and len(gens) == 1:\n             f = univariate.pop()\n         else:\n             raise NotImplementedError(filldedent('''\n", "instance_id": "sympy__sympy-22005"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-11910"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex fead6497b8..7532ee4a19 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -1010,7 +1010,7 @@ def visit_BinOp(self, node):\n                 right = ast.Call(\n                     func=ast.Name(id='Mul', ctx=ast.Load()),\n                     args=[ast.UnaryOp(op=ast.USub(), operand=ast.Num(1)), right],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\ndiff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 901918674a..874568a58a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -614,8 +614,8 @@ def _print_BasisDependent(self, expr):\n \n     def _print_Indexed(self, expr):\n         tex_base = self._print(expr.base)\n-        tex = '{'+tex_base+'}'+'_{%s}' % ','.join(\n-            map(self._print, expr.indices))\n+        indices = [self._print(index) for index in expr.indices]\n+        tex = '{' + tex_base + '}' + '_{' + ','.join(indices) + '}'\n         return tex\n \n     def _print_IndexedBase(self, expr):\n", "instance_id": "sympy__sympy-15609"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 38da1e6ecc..7c754565fd 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -121,14 +121,26 @@ class DictionarySerializer(BaseSerializer):\n         return \"{%s}\" % (\", \".join(\"%s: %s\" % (k, v) for k, v in strings)), imports\n \n \n+import enum\n+\n class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        return (\n-            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n-            {\"import %s\" % module},\n-        )\n+        try:\n+            name = self.value.name\n+            return (\n+                \"%s.%s[%r]\" % (module, enum_class.__qualname__, name),\n+                {\"import %s\" % module},\n+            )\n+        except AttributeError:\n+            # Handle combination of Enum flags\n+            members, _ = enum._decompose(enum_class, self.value)\n+            names = \" | \".join(\"%s.%s.%s\" % (module, enum_class.__qualname__, member.name) for member in members)\n+            return (\n+                names,\n+                {\"import %s\" % module},\n+            )\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "instance_id": "django__django-15996"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex f71bea25f5..ee749ababb 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -728,7 +728,7 @@ def _preprocess(self, args, expr):\n             elif isinstance(arg, Symbol):\n                 argrep = self._argrepr(arg)\n \n-                if dummify or not self._is_safe_ident(argrep):\n+                if dummify or not self._is_safe_ident(argrep) or '{' in argrep or '}' in argrep:\n                     dummy = Dummy()\n                     argstrs.append(self._argrepr(dummy))\n                     expr = self._subexpr(expr, {arg: dummy})\n", "instance_id": "sympy__sympy-15011"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-16820"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex 20d8922799..ddc1569e27 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -48,6 +48,9 @@ class ReadOnlyPasswordHashWidget(forms.Widget):\n                 for key, value_ in hasher.safe_summary(value).items():\n                     summary.append({'label': gettext(key), 'value': value_})\n         context['summary'] = summary\n+        # Remove 'for' attribute from the label in the context\n+        if 'id' in context['widget']['attrs']:\n+            del context['widget']['attrs']['id']\n         return context\n \n \n", "instance_id": "django__django-14411"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex 4c2ffd81e1..de2a796683 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -91,7 +91,12 @@ def _print_list(self, expr):\n     _print_tuple = _print_list\n     _print_Tuple = _print_list\n \n-    def _print_Function(self, expr):\n+    def _print_Derivative(self, expr):\n+        return \"D[%s]\" % (self.stringify(expr.args, \", \"))\n+\n+    def _print_Float(self, expr):\n+        res = str(expr)\n+        return res.replace('e', '*^')\n         if expr.func.__name__ in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n             for cond, mfunc in cond_mfunc:\n", "instance_id": "sympy__sympy-12171"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-14915"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-12113"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex e6b7d4d821..24d6ccecf8 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -90,9 +90,12 @@ class SafeExceptionReporterFilter:\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple, set)):\n+                cleansed = type(value)(self.cleanse_setting(k, v) for k, v in enumerate(value))\n             else:\n                 cleansed = value\n-        except TypeError:\n+        except (TypeError, IndexError):\n+            cleansed = value\n             # If the key isn't regex-able, just return as-is.\n             cleansed = value\n \n", "instance_id": "django__django-12700"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\nindex 759191668..0b8d6ee47 100644\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -15,20 +15,6 @@ from _pytest.nodes import Item\n from _pytest.store import StoreKey\n \n \n-evalcache_key = StoreKey[Dict[str, Any]]()\n-\n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n \n \n class MarkEvaluator:\n@@ -98,7 +84,9 @@ class MarkEvaluator:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        import _pytest._code\n+                        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+                        result = eval(exprcode, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n", "instance_id": "pytest-dev__pytest-7373"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..ebca8b07e9 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -301,7 +301,7 @@ class ManyToManyRel(ForeignObjectRel):\n \n         if through_fields and not through:\n             raise ValueError(\"Cannot specify through_fields without a through model\")\n-        self.through_fields = through_fields\n+        self.through_fields = make_hashable(through_fields)\n \n         self.symmetrical = symmetrical\n         self.db_constraint = db_constraint\n", "instance_id": "django__django-14672"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\nindex 574b4073b1..cb32ce78c1 100644\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field[...] = np.char.replace(output_field, encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):\n", "instance_id": "astropy__astropy-6938"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..f6c4b7fc2f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,7 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n", "instance_id": "django__django-16139"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex a977256525..6973694fdd 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1078,7 +1078,8 @@ class MultiValueField(Field):\n class FilePathField(ChoiceField):\n     def __init__(self, path, *, match=None, recursive=False, allow_files=True,\n                  allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+        self.match, self.recursive = match, recursive\n+        self.path = path() if callable(path) else path\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n         super().__init__(choices=(), **kwargs)\n \n@@ -1090,31 +1091,34 @@ class FilePathField(ChoiceField):\n         if self.match is not None:\n             self.match_re = re.compile(self.match)\n \n-        if recursive:\n-            for root, dirs, files in sorted(os.walk(self.path)):\n-                if self.allow_files:\n-                    for f in sorted(files):\n-                        if self.match is None or self.match_re.search(f):\n-                            f = os.path.join(root, f)\n-                            self.choices.append((f, f.replace(path, \"\", 1)))\n-                if self.allow_folders:\n-                    for f in sorted(dirs):\n-                        if f == '__pycache__':\n-                            continue\n-                        if self.match is None or self.match_re.search(f):\n-                            f = os.path.join(root, f)\n-                            self.choices.append((f, f.replace(path, \"\", 1)))\n-        else:\n+        def build_choices(path):\n             choices = []\n-            for f in os.scandir(self.path):\n-                if f.name == '__pycache__':\n-                    continue\n-                if (((self.allow_files and f.is_file()) or\n-                        (self.allow_folders and f.is_dir())) and\n-                        (self.match is None or self.match_re.search(f.name))):\n-                    choices.append((f.path, f.name))\n-            choices.sort(key=operator.itemgetter(1))\n-            self.choices.extend(choices)\n+            if recursive:\n+                for root, dirs, files in sorted(os.walk(path)):\n+                    if self.allow_files:\n+                        for f in sorted(files):\n+                            if self.match is None or self.match_re.search(f):\n+                                f = os.path.join(root, f)\n+                                choices.append((f, f.replace(path, \"\", 1)))\n+                    if self.allow_folders:\n+                        for f in sorted(dirs):\n+                            if f == '__pycache__':\n+                                continue\n+                            if self.match is None or self.match_re.search(f):\n+                                f = os.path.join(root, f)\n+                                choices.append((f, f.replace(path, \"\", 1)))\n+            else:\n+                for f in os.scandir(path):\n+                    if f.name == '__pycache__':\n+                        continue\n+                    if (((self.allow_files and f.is_file()) or\n+                            (self.allow_folders and f.is_dir())) and\n+                            (self.match is None or self.match_re.search(f.name))):\n+                        choices.append((f.path, f.name))\n+                choices.sort(key=operator.itemgetter(1))\n+            return choices\n+\n+        self.choices.extend(build_choices(self.path))\n \n         self.widget.choices = self.choices\n \n", "instance_id": "django__django-10924"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex aa2fe0883b..90dc19aeee 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -237,7 +237,7 @@ class MigrationExecutor:\n                     if not schema_editor.deferred_sql:\n                         self.record_migration(migration)\n                         migration_recorded = True\n-        if not migration_recorded:\n+        if not migration_recorded and router.allow_migrate(self.connection.alias, migration):\n             self.record_migration(migration)\n         # Report progress\n         if self.progress_callback:\ndiff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..11df926955 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,6 +1,7 @@\n from django.apps.registry import Apps\n from django.db import DatabaseError, models\n from django.utils.functional import classproperty\n+from django.db import router\n from django.utils.timezone import now\n \n from .exceptions import MigrationSchemaMissing\n@@ -58,16 +59,18 @@ class MigrationRecorder:\n \n     def ensure_schema(self):\n         \"\"\"Ensure the table exists and has the correct schema.\"\"\"\n-        # If the table's there, that's fine - we've never changed its schema\n-        # in the codebase.\n-        if self.has_table():\n-            return\n-        # Make the table\n-        try:\n-            with self.connection.schema_editor() as editor:\n-                editor.create_model(self.Migration)\n-        except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+        # Check if migration is allowed on this database\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            # If the table's there, that's fine - we've never changed its schema\n+            # in the codebase.\n+            if self.has_table():\n+                return\n+            # Make the table\n+            try:\n+                with self.connection.schema_editor() as editor:\n+                    editor.create_model(self.Migration)\n+            except DatabaseError as exc:\n+                raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n \n     def applied_migrations(self):\n         \"\"\"\n@@ -83,13 +86,15 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.create(app=app, name=name)\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.filter(app=app, name=name).delete()\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n", "instance_id": "django__django-15252"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d8456375..51cb543c 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -148,8 +148,12 @@ class Request(object):\n \n         hooks = hooks or {}\n \n-        for (k, v) in list(hooks.items()):\n-            self.register_hook(event=k, hook=v)\n+        for (k, v) in hooks.items():\n+            if isinstance(v, list):\n+                for hook in v:\n+                    self.register_hook(event=k, hook=hook)\n+            else:\n+                self.register_hook(event=k, hook=v)\n \n         #: Session.\n         self.session = session\n", "instance_id": "psf__requests-863"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..d8795d8218 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -309,7 +309,9 @@ class HttpResponse(HttpResponseBase):\n     @content.setter\n     def content(self, value):\n         # Consume iterators upon assignment to allow repeated iteration.\n-        if hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n+        if isinstance(value, memoryview):\n+            content = self.make_bytes(value.tobytes())\n+        elif hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n             content = b''.join(self.make_bytes(chunk) for chunk in value)\n             if hasattr(value, 'close'):\n                 try:\n", "instance_id": "django__django-11133"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 24d89897f7..ad67aebfee 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -120,12 +120,11 @@ def _hashable_content(self):\n         return self._args\n \n     def __eq__(self, other):\n-        try:\n-            other = sympify(other)\n-            if not isinstance(other, Expr):\n+        if not isinstance(other, Expr):\n+            try:\n+                other = sympify(other, strict=True)\n+            except (SympifyError, SyntaxError):\n                 return False\n-        except (SympifyError, SyntaxError):\n-            return False\n         # check for pure number expr\n         if  not (self.is_Number and other.is_Number) and (\n                 type(self) != type(other)):\ndiff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex ed4ea6ce5e..161e1f4f5b 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -322,7 +322,7 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n                 from ..tensor.array import Array\n                 return Array(a.flat, a.shape)  # works with e.g. NumPy arrays\n \n-    if not isinstance(a, string_types):\n+    if not isinstance(a, string_types) or isinstance(a, repr):\n         for coerce in (float, int):\n             try:\n                 coerced = coerce(a)\ndiff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 2ab43d9b31..05ed7de3f3 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -899,8 +899,11 @@ def eval_expr(code, local_dict, global_dict):\n \n     Generally, ``parse_expr`` should be used.\n     \"\"\"\n-    expr = eval(\n-        code, global_dict, local_dict)  # take local objects in preference\n+    try:\n+        expr = eval(\n+            code, global_dict, local_dict)  # take local objects in preference\n+    except AttributeError as e:\n+        raise SympifyError('Evaluation error', e)\n \n     return expr\n \n", "instance_id": "sympy__sympy-18057"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..e051409ac6 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -162,9 +162,12 @@ def structurally_equal(self, other):\n             and self.colblocksizes == other.colblocksizes)\n \n     def _blockmul(self, other):\n-        if (isinstance(other, BlockMatrix) and\n-                self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+        if isinstance(other, BlockMatrix) and self.colblocksizes == other.rowblocksizes:\n+            result_blocks = self.blocks * other.blocks\n+            result_blocks = result_blocks.applyfunc(\n+                lambda x: ZeroMatrix(x.rows, x.cols) if x == 0 else x\n+            )\n+            return BlockMatrix(result_blocks)\n \n         return self * other\n \n", "instance_id": "sympy__sympy-17630"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..3b94572b10 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -687,10 +687,10 @@ class URLField(CharField):\n             \"\"\"\n             try:\n                 return list(urlsplit(url))\n-            except ValueError:\n+            except ValueError as e:\n                 # urlparse.urlsplit can raise a ValueError with some\n                 # misformatted URLs.\n-                raise ValidationError(self.error_messages['invalid'], code='invalid')\n+                raise ValidationError(self.error_messages['invalid'], code='invalid') from e\n \n         value = super().to_python(value)\n         if value:\n", "instance_id": "django__django-15202"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..8687e2b93a 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -227,7 +227,9 @@ class RegexSerializer(BaseSerializer):\n         args = [regex_pattern]\n         if flags:\n             args.append(regex_flags)\n-        return \"re.compile(%s)\" % ', '.join(args), imports\n+        if flags:\n+            return \"re.compile(%s, flags=%s)\" % (regex_pattern, self.value.flags), imports\n+        return \"re.compile(%s)\" % regex_pattern, imports\n \n \n class SequenceSerializer(BaseSequenceSerializer):\n@@ -286,6 +288,7 @@ class Serializer:\n         dict: DictionarySerializer,\n         models.Choices: ChoicesSerializer,\n         enum.Enum: EnumSerializer,\n+        enum.EnumMeta: EnumSerializer,\n         datetime.datetime: DatetimeDatetimeSerializer,\n         (datetime.date, datetime.timedelta, datetime.time): DateTimeSerializer,\n         SettingsReference: SettingsReferenceSerializer,\n", "instance_id": "django__django-11815"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py\nindex 4bddae35c..869237f56 100644\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -43,10 +43,10 @@ def check_clusterings(labels_true, labels_pred):\n         The predicted labels.\n     \"\"\"\n     labels_true = check_array(\n-        labels_true, ensure_2d=False, ensure_min_samples=0\n+        labels_true, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n     labels_pred = check_array(\n-        labels_pred, ensure_2d=False, ensure_min_samples=0\n+        labels_pred, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n \n     # input checks\n", "instance_id": "scikit-learn__scikit-learn-15535"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..efe8be00 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -1,4 +1,5 @@\n import pandas as pd\n+import numpy as np\n \n from . import dtypes, utils\n from .alignment import align\n@@ -235,6 +236,7 @@ def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n \n     process_subset_opt(data_vars, \"data_vars\")\n     process_subset_opt(coords, \"coords\")\n+\n     return concat_over, equals, concat_dim_lengths\n \n \n@@ -313,11 +315,10 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n+            for var in absent_merge_vars:\n+                var_shape = tuple(dims_sizes[dim] for dim in result_vars[var].dims)\n+                dummy_data = dtypes.NA * np.ones(var_shape, dtype=result_vars[var].dtype)\n+                ds.variables[var] = Variable(result_vars[var].dims, dummy_data)\n \n             for var in variables_to_merge:\n                 to_merge[var].append(ds.variables[var])\n", "instance_id": "pydata__xarray-3364"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\nindex 29c7e19d7..be5cf24d1 100644\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -154,7 +154,9 @@ def get_user() -> Optional[str]:\n     import getpass\n \n     try:\n-        return getpass.getuser()\n+        username = getpass.getuser()\n+        # Replace any illegal characters for directory names with an underscore\n+        return re.sub(r'[<>:\"/\\\\|?*]', '_', username)\n     except (ImportError, KeyError):\n         return None\n \n", "instance_id": "pytest-dev__pytest-8365"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-12184"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..96ccce72dd 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -762,7 +762,7 @@ class Field(RegisterLookupMixin):\n             # such fields can't be deferred (we don't have a check for this).\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n-        if self.choices is not None:\n+        if self.choices is not None and not hasattr(cls, 'get_%s_display' % self.name):\n             setattr(cls, 'get_%s_display' % self.name,\n                     partialmethod(cls._get_FIELD_display, field=self))\n \n", "instance_id": "django__django-11999"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/checks/registry.py b/django/core/checks/registry.py\nindex c79e3491c4..fb672fa27c 100644\n--- a/django/core/checks/registry.py\n+++ b/django/core/checks/registry.py\n@@ -1,5 +1,6 @@\n from itertools import chain\n \n+from django.apps import apps\n from django.utils.itercompat import is_iterable\n \n \n@@ -13,6 +14,7 @@ class Tags:\n     compatibility = 'compatibility'\n     database = 'database'\n     models = 'models'\n+    constraints = 'constraints'\n     security = 'security'\n     signals = 'signals'\n     staticfiles = 'staticfiles'\n@@ -74,6 +76,12 @@ class CheckRegistry:\n             errors.extend(new_errors)\n         return errors\n \n+    def _check_constraints_fields(self, **kwargs):\n+        errors = []\n+        for model in apps.get_models():\n+            errors.extend(model._check_constraints_fields(**kwargs))\n+        return errors\n+\n     def tag_exists(self, tag, include_deployment_checks=False):\n         return tag in self.tags_available(include_deployment_checks)\n \ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 7bb3fa4706..00766c37ec 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -513,6 +513,9 @@ class Model(metaclass=ModelBase):\n         new = cls(*values)\n         new._state.adding = False\n         new._state.db = db\n+        errors = cls._check_constraints_fields()\n+        if errors:\n+            raise ValidationError(errors)\n         return new\n \n     def __repr__(self):\n@@ -1115,6 +1118,27 @@ class Model(metaclass=ModelBase):\n \n         return errors\n \n+    @classmethod\n+    def _check_constraints_fields(cls):\n+        \"\"\"Check if fields in UniqueConstraints exist.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n+\n     def _perform_date_checks(self, date_checks):\n         errors = {}\n         for model_class, lookup_type, field, unique_for in date_checks:\n", "instance_id": "django__django-12856"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..7b2f330749 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -737,6 +737,9 @@ class QuerySet:\n \n         # Clear the result cache, in case this QuerySet gets reused.\n         self._result_cache = None\n+        if not deleted:\n+            model_labels = {model._meta.label: 0 for model in collector.data}\n+            return 0, model_labels\n         return deleted, _rows_count\n \n     delete.alters_data = True\n", "instance_id": "django__django-12747"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..c3f751e74d 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -165,8 +165,8 @@ class Line3D(lines.Line2D):\n         \"\"\"\n         Keyword arguments are passed onto :func:`~matplotlib.lines.Line2D`.\n         \"\"\"\n-        super().__init__([], [], *args, **kwargs)\n-        self._verts3d = xs, ys, zs\n+        super().__init__(xs, ys, *args, **kwargs)\n+        self.set_data_3d(xs, ys, zs)\n \n     def set_3d_properties(self, zs=0, zdir='z'):\n         xs = self.get_xdata()\n", "instance_id": "matplotlib__matplotlib-23563"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex 9cc4fec441..272f820c75 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -477,7 +477,7 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n \n     try:\n         a = a.replace('\\n', '')\n-        expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\n+        expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=False)\n     except (TokenError, SyntaxError) as exc:\n         raise SympifyError('could not parse %r' % a, exc)\n \ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 5f5eab3b9d..9f4d941ac5 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -37,7 +37,7 @@\n \n \n \n-def separatevars(expr, symbols=[], dict=False, force=False):\n+def separatevars(expr, symbols=[], dict=False, force=False, evaluate=None):\n     \"\"\"\n     Separates variables in an expression, if possible.  By\n     default, it separates with respect to all symbols in an\n@@ -104,7 +104,7 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n-    expr = sympify(expr)\n+    expr = sympify(expr, evaluate=evaluate)\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n     else:\n", "instance_id": "sympy__sympy-20322"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 11aebbc59f..e19e0fa771 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -298,9 +298,11 @@ def diag(self):\n     def blocks(self):\n         from sympy.matrices.immutable import ImmutableDenseMatrix\n         mats = self.args\n+        if len(mats) == 1:\n+            return mats[0]\n         data = [[mats[i] if i == j else ZeroMatrix(mats[i].rows, mats[j].cols)\n-                        for j in range(len(mats))]\n-                        for i in range(len(mats))]\n+                 for j in range(len(mats))]\n+                for i in range(len(mats))]\n         return ImmutableDenseMatrix(data)\n \n     @property\n", "instance_id": "sympy__sympy-18621"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..7a3dd546b8 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,13 +2180,13 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n-                pass\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x0 = np.nan\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n-            except (TypeError, IndexError, KeyError):\n-                x = xconv\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x = np.nan\n \n             delist = False\n             if not np.iterable(dx):\n", "instance_id": "matplotlib__matplotlib-24149"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/utils/_pprint.py b/sklearn/utils/_pprint.py\nindex b8686dba5..b7507c48b 100644\n--- a/sklearn/utils/_pprint.py\n+++ b/sklearn/utils/_pprint.py\n@@ -67,6 +67,7 @@ from inspect import signature\n import pprint\n from collections import OrderedDict\n \n+import numpy as np\n from ..base import BaseEstimator\n from .._config import get_config\n from . import is_scalar_nan\n@@ -95,8 +96,10 @@ def _changed_params(estimator):\n     init_params = signature(init_func).parameters\n     init_params = {name: param.default for name, param in init_params.items()}\n     for k, v in params.items():\n-        if (v != init_params[k] and\n-                not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n+        if (not isinstance(v, np.ndarray) and v != init_params[k] or\n+                isinstance(v, np.ndarray) and not np.array_equal(v, init_params[k]) or\n+                (is_scalar_nan(init_params[k]) and not is_scalar_nan(v)) or\n+                (not is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n             filtered_params[k] = v\n     return filtered_params\n \n", "instance_id": "scikit-learn__scikit-learn-13584"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\nindex 7b7ddc8d..7359b027 100644\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -21,6 +21,7 @@ class PolyFit(Stat):\n \n     def _fit_predict(self, data):\n \n+        data = data.dropna(subset=[\"x\", \"y\"])\n         x = data[\"x\"]\n         y = data[\"y\"]\n         if x.nunique() <= self.order:\n", "instance_id": "mwaskom__seaborn-3010"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 1aa0ee01a2..2f73c67830 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -391,6 +391,25 @@ def translate(s):\n     _print_MatrixSymbol = _print_Symbol\n     _print_RandomSymbol = _print_Symbol\n \n+    def _print_Indexed(self, expr):\n+        x = self.dom.createElement('apply')\n+        x.appendChild(self.dom.createElement('ci'))\n+        x.appendChild(self._print(expr.base))\n+        for index in expr.indices:\n+            x.appendChild(self._print(index))\n+        return x\n+\n+    def _print_Indexed(self, expr):\n+        mrow = self.dom.createElement('mrow')\n+        base = self._print(expr.base)\n+        mrow.appendChild(base)\n+        for index in expr.indices:\n+            subscript = self.dom.createElement('msub')\n+            subscript.appendChild(base)\n+            subscript.appendChild(self._print(index))\n+            mrow.appendChild(subscript)\n+        return mrow\n+\n     def _print_Pow(self, e):\n         # Here we use root instead of power if the exponent is the reciprocal of an integer\n         if self._settings['root_notation'] and e.exp.is_Rational and e.exp.p == 1:\n", "instance_id": "sympy__sympy-16106"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex ebe5da43e2..156dd89f03 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -583,7 +583,7 @@ class Slider(SliderBase):\n             self.ax.figure.canvas.draw_idle()\n         self.val = val\n         if self.eventson:\n-            self._observers.process('changed', val)\n+            self.canvas.get_tk_widget().after_idle(self._observers.process, 'changed', val)\n \n     def on_changed(self, func):\n         \"\"\"\n@@ -966,7 +966,7 @@ class RangeSlider(SliderBase):\n             self.ax.figure.canvas.draw_idle()\n         self.val = (vmin, vmax)\n         if self.eventson:\n-            self._observers.process(\"changed\", (vmin, vmax))\n+            self.canvas.get_tk_widget().after_idle(self._observers.process, \"changed\", (vmin, vmax))\n \n     def on_changed(self, func):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-25433"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a0eb97792e..39e55d1955 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -2185,6 +2185,10 @@ def _print_Differential(self, diff):\n             string = self._print(field)\n             return r'\\mathrm{d}\\left(%s\\right)' % string\n \n+    def _print_Trace(self, expr):\n+        arg = self._print(expr.arg)\n+        return r'\\operatorname{tr}\\left(%s\\right)' % arg\n+\n     def _print_Tr(self, p):\n         #Todo: Handle indices\n         contents = self._print(p.args[0])\n", "instance_id": "sympy__sympy-15308"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sympy__sympy-21379"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 69df976b8b..a2fb955a6c 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1266,6 +1266,8 @@ def _diff_wrt(self):\n         return self.expr._diff_wrt and isinstance(self.doit(), Derivative)\n \n     def __new__(cls, expr, *variables, **kwargs):\n+        from sympy.matrices.expressions.matexpr import MatrixKind\n+        from sympy.core.kind import NumberKind\n \n         from sympy.matrices.common import MatrixCommon\n         from sympy import Integer, MatrixExpr\n@@ -1511,6 +1513,15 @@ def __new__(cls, expr, *variables, **kwargs):\n             expr = factor_terms(signsimp(expr))\n         return expr\n \n+    @property\n+    def kind(self):\n+        from sympy.matrices.expressions.matexpr import MatrixKind\n+        from sympy.core.kind import NumberKind\n+\n+        if isinstance(self.expr.kind, MatrixKind):\n+            return MatrixKind(NumberKind)\n+        return self.expr.kind\n+\n     @property\n     def canonical(cls):\n         return cls.func(cls.expr,\n", "instance_id": "sympy__sympy-21614"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..8b34ca1a88 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -278,15 +278,25 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n-    def __neg__(self):\n+    def __rmul__(self, factor):\n+        \"\"\"Right multiplication to handle number * Point.\"\"\"\n+        return self.__mul__(factor)\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __neg__(self):\n+        \"\"\"Negate the point.\"\"\"\n+        coords = [-x for x in self.args]\n+        return Point(coords, evaluate=False)\n     def __sub__(self, other):\n         \"\"\"Subtract two points, or subtract a factor from this point's\n         coordinates.\"\"\"\n-        return self + [-x for x in other]\n+        try:\n+            other = Point(other)\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to subtract {} and a Point object\".format(other))\n+        return self + [-x for x in other.args]\n \n     @classmethod\n     def _normalize_dimension(cls, *points, **kwargs):\n", "instance_id": "sympy__sympy-17655"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..ecd68dd937 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,20 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n+            if self.creation_counter == other.creation_counter:\n+                return getattr(self, 'model', None) < getattr(other, 'model', None)\n             return self.creation_counter < other.creation_counter\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n", "instance_id": "django__django-13401"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py\nindex f209e811f1..ea88b679b1 100644\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -665,8 +665,9 @@ grestore\n                 curr_stream[1].append(\n                     (item.x, item.ft_object.get_glyph_name(item.glyph_idx))\n                 )\n-            # append the last entry\n-            stream.append(curr_stream)\n+            # append the last entry if curr_stream is not None\n+            if curr_stream:\n+                stream.append(curr_stream)\n \n         self.set_color(*gc.get_rgb())\n \n", "instance_id": "matplotlib__matplotlib-23964"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex fbb3c7e6..b94ea93c 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -167,7 +167,7 @@ class RequestHooksMixin(object):\n         if event not in self.hooks:\n             raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n \n-        if isinstance(hook, collections.Callable):\n+        if isinstance(hook, collections.abc.Callable):\n             self.hooks[event].append(hook)\n         elif hasattr(hook, '__iter__'):\n             self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))\n@@ -185,7 +185,7 @@ class RequestHooksMixin(object):\n \n \n class Request(RequestHooksMixin):\n-    \"\"\"A user-created :class:`Request <Request>` object.\n+    r\"\"\"A user-created :class:`Request <Request>` object.\n \n     Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n \n@@ -254,7 +254,7 @@ class Request(RequestHooksMixin):\n \n \n class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n-    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n+    r\"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n     containing the exact bytes that will be sent to the server.\n \n     Generated from either a :class:`Request <Request>` object or manually.\n@@ -333,7 +333,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if isinstance(url, bytes):\n             url = url.decode('utf8')\n         else:\n-            url = unicode(url) if is_py2 else str(url)\n+            url = str(url)\n \n         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n         # `data` etc to work around exceptions from `url_parse`, which\n@@ -534,7 +534,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n \n class Response(object):\n-    \"\"\"The :class:`Response <Response>` object, which contains a\n+    r\"\"\"The :class:`Response <Response>` object, which contains a\n     server's response to an HTTP request.\n     \"\"\"\n \n@@ -695,7 +695,8 @@ class Response(object):\n         chunks = reused_chunks if self._content_consumed else stream_chunks\n \n         if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n+            # Decode each chunk to unicode\n+            chunks = (chunk.decode(self.encoding or 'utf-8') for chunk in chunks)\n \n         return chunks\n \n@@ -793,9 +794,9 @@ class Response(object):\n         return content\n \n     def json(self, **kwargs):\n-        \"\"\"Returns the json-encoded content of a response, if any.\n+        r\"\"\"Returns the json-encoded content of a response, if any.\n \n-        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n+        :param **kwargs: Optional arguments that ``json.loads`` takes.\n         \"\"\"\n \n         if not self.encoding and self.content and len(self.content) > 3:\n", "instance_id": "psf__requests-3362"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 379a2917aa..f1662ac706 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -6,7 +6,7 @@\n \n from __future__ import print_function, division\n \n-import collections\n+import collections.abc\n from sympy.core.add import Add\n from sympy.core.basic import Basic, Atom\n from sympy.core.expr import Expr\n@@ -14,8 +14,8 @@\n from sympy.core.function import count_ops\n from sympy.core.singleton import S\n from sympy.core.sympify import sympify\n-from sympy.core.compatibility import is_sequence, default_sort_key, range, \\\n-    NotIterable\n+from sympy.core.compatibility import is_sequence, default_sort_key, range\n+from collections.abc import Iterable\n \n from sympy.simplify import simplify as _simplify, signsimp, nsimplify\n from sympy.utilities.iterables import flatten\n@@ -1973,6 +1973,8 @@ def __div__(self, other):\n \n     @call_highest_priority('__rmatmul__')\n     def __matmul__(self, other):\n+        if not getattr(other, 'is_Matrix', False):\n+            raise ValueError(\"Scalar operands are not allowed, use '*' instead\")\n         return self.__mul__(other)\n \n     @call_highest_priority('__rmul__')\ndiff --git a/sympy/matrices/sparse.py b/sympy/matrices/sparse.py\nindex 7701cbc179..56a56fa16e 100644\n--- a/sympy/matrices/sparse.py\n+++ b/sympy/matrices/sparse.py\n@@ -1,7 +1,7 @@\n from __future__ import print_function, division\n \n import copy\n-from collections import defaultdict\n+from collections.abc import defaultdict\n \n from sympy.core.containers import Dict\n from sympy.core.expr import Expr\n@@ -14,7 +14,7 @@\n \n from .matrices import MatrixBase, ShapeError, a2idx\n from .dense import Matrix\n-import collections\n+import collections.abc\n \n \n class SparseMatrix(MatrixBase):\n", "instance_id": "sympy__sympy-13773"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 03676533b7..aeb8f80b34 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -587,7 +587,9 @@ def join(value, arg, autoescape=True):\n     try:\n         if autoescape:\n             value = [conditional_escape(v) for v in value]\n-        data = conditional_escape(arg).join(value)\n+        if autoescape:\n+            arg = conditional_escape(arg)\n+        data = arg.join(value)\n     except TypeError:  # Fail silently if arg isn't iterable.\n         return value\n     return mark_safe(data)\n", "instance_id": "django__django-16873"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/lambdarepr.py b/sympy/printing/lambdarepr.py\nindex 8f60434e89..f9598e0289 100644\n--- a/sympy/printing/lambdarepr.py\n+++ b/sympy/printing/lambdarepr.py\n@@ -4,6 +4,7 @@\n     MpmathPrinter,  # MpmathPrinter is imported for backward compatibility\n     NumPyPrinter  # NumPyPrinter is imported for backward compatibility\n )\n+from sympy.matrices import Identity\n from sympy.utilities import default_sort_key\n \n \n@@ -43,7 +44,8 @@ def _print_BooleanTrue(self, expr):\n     def _print_BooleanFalse(self, expr):\n         return \"False\"\n \n-    def _print_ITE(self, expr):\n+    def _print_Identity(self, expr):\n+        return \"Identity(%s)\" % expr.shape[0]\n         result = [\n             '((', self._print(expr.args[1]),\n             ') if (', self._print(expr.args[0]),\n", "instance_id": "sympy__sympy-17022"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 7649c39262..687b773587 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -353,7 +353,8 @@ class SQLCompiler:\n             # not taken into account so we strip it. When this entire method\n             # is refactored into expressions, then we can check each part as we\n             # generate it.\n-            without_ordering = self.ordering_parts.search(sql).group(1)\n+            sql_oneline = ' '.join(sql.split('\\n'))\n+            without_ordering = self.ordering_parts.search(sql_oneline).group(1)\n             params_hash = make_hashable(params)\n             if (without_ordering, params_hash) in seen:\n                 continue\n", "instance_id": "django__django-11001"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..e7644d7d13 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -94,7 +94,9 @@ def _print_list(self, expr):\n     _print_Tuple = _print_list\n \n     def _print_Function(self, expr):\n-        if expr.func.__name__ in self.known_functions:\n+        if expr.func.__name__ == \"Max\":\n+            return \"Max[%s]\" % self.stringify(expr.args, \", \")\n+        elif expr.func.__name__ in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n             for cond, mfunc in cond_mfunc:\n                 if cond(*expr.args):\n", "instance_id": "sympy__sympy-15345"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 7ef51bc847..9466b9566d 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -378,6 +378,8 @@ def hstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.rows == 0 for arg in args):\n+            return cls._new(0, sum(arg.cols for arg in args), [])\n         return reduce(kls.row_join, args)\n \n     def reshape(self, rows, cols):\n@@ -601,6 +603,8 @@ def vstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.cols == 0 for arg in args):\n+            return cls._new(sum(arg.rows for arg in args), 0, [])\n         return reduce(kls.col_join, args)\n \n \n", "instance_id": "sympy__sympy-13031"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f33bcbdccf..98e6d0fab8 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -164,28 +164,18 @@ class Command(BaseCommand):\n \n                     if is_relation:\n                         ref_db_column, ref_db_table = relations[column_name]\n-                        if extra_params.pop(\"unique\", False) or extra_params.get(\n-                            \"primary_key\"\n-                        ):\n+                        if extra_params.pop(\"unique\", False) or extra_params.get(\"primary_key\"):\n                             rel_type = \"OneToOneField\"\n                         else:\n                             rel_type = \"ForeignKey\"\n-                            ref_pk_column = (\n-                                connection.introspection.get_primary_key_column(\n-                                    cursor, ref_db_table\n-                                )\n-                            )\n+                            ref_pk_column = connection.introspection.get_primary_key_column(cursor, ref_db_table)\n                             if ref_pk_column and ref_pk_column != ref_db_column:\n                                 extra_params[\"to_field\"] = ref_db_column\n-                        rel_to = (\n-                            \"self\"\n-                            if ref_db_table == table_name\n-                            else table2model(ref_db_table)\n-                        )\n+                        rel_to = \"self\" if ref_db_table == table_name else table2model(ref_db_table)\n                         if rel_to in known_models:\n-                            field_type = \"%s(%s\" % (rel_type, rel_to)\n-                        else:\n-                            field_type = \"%s('%s'\" % (rel_type, rel_to)\n+                            related_name = f\"related_{column_name}\"\n+                            extra_params[\"related_name\"] = related_name\n+                        field_type = f\"{rel_type}('{rel_to}'\"\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.\n", "instance_id": "django__django-15819"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex bc227d2c4..db6211363 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -608,13 +608,13 @@ class PyLinter(\n \n                     if \"__init__.py\" in files:\n                         skip_subtrees.append(root)\n-                        yield root\n-                    else:\n-                        yield from (\n-                            os.path.join(root, file)\n-                            for file in files\n-                            if file.endswith(\".py\")\n-                        )\n+                        if not os.path.isfile(os.path.join(root, \"__init__.py\")):\n+                            yield root\n+                    yield from (\n+                        os.path.join(root, file)\n+                        for file in files\n+                        if file.endswith(\".py\")\n+                    )\n             else:\n                 yield something\n \ndiff --git a/pylint/utils/file_state.py b/pylint/utils/file_state.py\nindex acd59d648..c6f3153df 100644\n--- a/pylint/utils/file_state.py\n+++ b/pylint/utils/file_state.py\n@@ -9,7 +9,7 @@ import sys\n import warnings\n from collections import defaultdict\n from collections.abc import Iterator\n-from typing import TYPE_CHECKING, Dict\n+from typing import TYPE_CHECKING, Dict, Union\n \n from astroid import nodes\n \n@@ -61,11 +61,10 @@ class FileState:\n             tuple[str, int], set[int]\n         ] = collections.defaultdict(set)\n         self._suppression_mapping: dict[tuple[str, int], int] = {}\n-        self._module = node\n-        if node:\n-            self._effective_max_line_number = node.tolineno\n-        else:\n-            self._effective_max_line_number = None\n+        self._module = node or nodes.Module(name=modname or \"\", doc=None)\n+        self._effective_max_line_number = (\n+            node.tolineno if node else None\n+        )\n         self._msgs_store = msg_store\n         self._is_base_filestate = is_base_filestate\n         \"\"\"If this FileState is the base state made during initialization of\n@@ -250,7 +249,7 @@ class FileState:\n         tuple[\n             Literal[\"useless-suppression\", \"suppressed-message\"],\n             int,\n-            tuple[str] | tuple[str, int],\n+            tuple[Union[str], Union[str, int]],\n         ]\n     ]:\n         for warning, lines in self._raw_module_msgs_state.items():\n", "instance_id": "pylint-dev__pylint-7114"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex fb5f6298c4..5aefb80f9d 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -403,7 +403,8 @@ def slugify(value, allow_unicode=False):\n     else:\n         value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n     value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+    value = re.sub(r'[-\\s]+', '-', value)\n+    return value.strip('-_')\n \n \n def camel_case_to_spaces(value):\n", "instance_id": "django__django-12983"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 6d3cc05bd3..6dc312a924 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -490,10 +490,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 2 - 2\n             sign_lines = []\n             sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n@@ -523,7 +523,7 @@ def _print_Product(self, expr):\n \n         pretty_func.baseline = max_upper + sign_height//2\n         pretty_func.binding = prettyForm.MUL\n-        return pretty_func\n+        return prettyForm(*pretty_func.left('\u2500'))\n \n     def _print_Sum(self, expr):\n         ascii_mode = not self._use_unicode\n", "instance_id": "sympy__sympy-16281"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/builders/manpage.py b/sphinx/builders/manpage.py\nindex 4166dece9..c85292965 100644\n--- a/sphinx/builders/manpage.py\n+++ b/sphinx/builders/manpage.py\n@@ -8,6 +8,7 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n+import os\n from os import path\n from typing import Any, Dict, List, Set, Tuple, Union\n \n@@ -80,10 +81,13 @@ class ManualPageBuilder(Builder):\n             docsettings.authors = authors\n             docsettings.section = section\n \n-            targetname = '%s.%s' % (name, section)\n+            section_dir = path.join(self.outdir, f'man{section}')\n+            if not path.exists(section_dir):\n+                os.makedirs(section_dir)\n+            targetname = path.join(section_dir, f'{name}.{section}')\n             logger.info(darkgreen(targetname) + ' { ', nonl=True)\n             destination = FileOutput(\n-                destination_path=path.join(self.outdir, targetname),\n+                destination_path=targetname,\n                 encoding='utf-8')\n \n             tree = self.env.get_doctree(docname)\n", "instance_id": "sphinx-doc__sphinx-8273"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..8f3c34387 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,6 +299,7 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n+            self.n_components = int(self.n_components)\n             check_scalar(self.n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n@@ -318,6 +319,9 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                  .format(X.shape[1],\n                                          self.components_.shape[1]))\n \n+        self.max_iter = int(self.max_iter)\n+        self.tol = float(self.tol)\n+        self.verbose = int(self.verbose)\n         check_scalar(self.max_iter, 'max_iter', int, 1)\n         check_scalar(self.tol, 'tol', float, 0.)\n         check_scalar(self.verbose, 'verbose', int, 0)\n", "instance_id": "scikit-learn__scikit-learn-14092"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 09e2b00735..dfe0fd62fc 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -28,6 +28,7 @@\n     annotated\n \n from sympy.utilities import default_sort_key\n+from sympy.vector.vector import Vector\n \n # rename for usage from outside\n pprint_use_unicode = pretty_use_unicode\n@@ -295,6 +296,9 @@ def _print_conjugate(self, e):\n         pform = self._print(e.args[0])\n         return prettyForm( *pform.above( hobj('_', pform.width())) )\n \n+    def _print_Vector(self, e):\n+        return e._pretty(self)\n+\n     def _print_Abs(self, e):\n         pform = self._print(e.args[0])\n         pform = prettyForm(*pform.parens('|', '|'))\ndiff --git a/sympy/vector/vector.py b/sympy/vector/vector.py\nindex c62b1dbf0d..fcb3b31d6c 100755\n--- a/sympy/vector/vector.py\n+++ b/sympy/vector/vector.py\n@@ -10,6 +10,13 @@\n \n \n class Vector(BasisDependent):\n+    def _pretty(self, printer, *args):\n+        from sympy.printing.pretty.stringpict import prettyForm\n+        components = self.components\n+        pforms = [printer._print(v) * printer._print(k) for k, v in components.items()]\n+        result = prettyForm.__add__(*pforms)\n+        result.baseline = result.height() // 2\n+        return result\n     \"\"\"\n     Super class for all Vector classes.\n     Ideally, neither this class nor any of its subclasses should be\n", "instance_id": "sympy__sympy-14308"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..ad06668efe 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if evaluate and any(a.is_number and im(a) for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "instance_id": "sympy__sympy-22714"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..360def9f1 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1333,10 +1333,12 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n+        self.store_cv_values = store_cv_values\n         self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n@@ -1373,7 +1375,9 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n             sample_weight = (sample_weight *\n                              compute_sample_weight(self.class_weight, y))\n \n-        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight)\n+        super(RidgeClassifierCV, self).fit(X, Y, sample_weight=sample_weight)\n+        if self.store_cv_values:\n+            self.cv_values_ = self.cv_values_\n         return self\n \n     @property\n", "instance_id": "scikit-learn__scikit-learn-10297"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\nindex d3a06f2b31..83bf182b3a 100644\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -49,6 +49,8 @@ from . import _docutil as __\n try:\n     from . import _wcs\n except ImportError:\n+    if '_ASTROPY_SETUP_' not in globals():\n+        _ASTROPY_SETUP_ = False\n     if not _ASTROPY_SETUP_:\n         raise\n     else:\n@@ -1212,6 +1214,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if all(isinstance(x, (list, np.ndarray)) and len(x) == 0 for x in axes):\n+                return tuple(np.array([]) for _ in axes)\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1243,6 +1247,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n             return result\n \n         if len(args) == 2:\n+            if isinstance(args[0], (list, np.ndarray)) and len(args[0]) == 0:\n+                return np.array([]), np.array([])\n             try:\n                 xy, origin = args\n                 xy = np.asarray(xy)\n@@ -1256,6 +1262,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n             return _return_single_array(xy, origin)\n \n         elif len(args) == self.naxis + 1:\n+            if all(isinstance(arg, (list, np.ndarray)) and len(arg) == 0 for arg in args[:-1]):\n+                return tuple(np.array([]) for _ in args[:-1])\n             axes = args[:-1]\n             origin = args[-1]\n             try:\n@@ -2500,7 +2508,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n \n         \"\"\"\n         # default precision for numerical WCS keywords\n-        precision = WCSHDO_P14\n+        precision = _wcs.WCSHDO_P14\n         display_warning = False\n         if relax is None:\n             display_warning = True\n@@ -2511,7 +2519,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n             relax &= ~WCSHDO_SIP\n         else:\n             do_sip = relax\n-            relax = WCSHDO_all if relax is True else WCSHDO_safe\n+            relax = _wcs.WCSHDO_all if relax is True else _wcs.WCSHDO_safe\n \n         relax = precision | relax\n \n@@ -2896,7 +2904,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         the spectral axis, followed by any others.\n         Assumes at least celestial axes are present.\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL, WCSSUB_SPECTRAL, WCSSUB_STOKES])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL, _wcs.WCSSUB_SPECTRAL, _wcs.WCSSUB_STOKES])\n \n     def slice(self, view, numpy_order=True):\n         \"\"\"\n@@ -3023,7 +3031,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n         A copy of the current WCS with only the celestial axes included\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL])\n \n     @property\n     def is_celestial(self):\n", "instance_id": "astropy__astropy-7746"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8ddbb5ba68..c54767f592 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1309,7 +1309,7 @@ class ManyToManyField(RelatedField):\n                              \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n", "instance_id": "django__django-12497"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 0b64b1b2b9..c690ad7762 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -4,6 +4,7 @@ import copy\n from io import BytesIO\n from itertools import chain\n from urllib.parse import parse_qsl, quote, urlencode, urljoin, urlsplit\n+from email.utils import parsedate_to_datetime\n \n from django.conf import settings\n from django.core import signing\n@@ -95,6 +96,16 @@ class HttpRequest:\n             accepted_type.match(media_type) for accepted_type in self.accepted_types\n         )\n \n+    @cached_property\n+    def if_modified_since(self):\n+        header = self.headers.get(\"If-Modified-Since\")\n+        if header is not None:\n+            try:\n+                return parsedate_to_datetime(header)\n+            except (TypeError, ValueError, IndexError, OverflowError):\n+                pass\n+        return None\n+\n     def _set_content_type_params(self, meta):\n         \"\"\"Set content_type, content_params, and encoding.\"\"\"\n         self.content_type, self.content_params = cgi.parse_header(\n@@ -107,8 +118,6 @@ class HttpRequest:\n                 pass\n             else:\n                 self.encoding = self.content_params[\"charset\"]\n-\n-    def _get_raw_host(self):\n         \"\"\"\n         Return the HTTP host using the environment or request headers. Skip\n         allowed hosts protection, so may return an insecure host.\n", "instance_id": "django__django-15498"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 28d675fc77..fc4dd8661e 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -58,7 +58,7 @@\n import mpmath.libmp as mlib\n \n import inspect\n-import collections\n+import collections.abc\n \n def _coeff_isneg(a):\n     \"\"\"Return True if the leading Number is negative.\n@@ -1238,7 +1238,7 @@ def __new__(cls, expr, *variables, **kwargs):\n             if unhandled_non_symbol:\n                 obj = None\n             else:\n-                if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n+                if isinstance(v, (collections.abc.Iterable, Tuple, MatrixCommon, NDimArray)):\n                     # Treat derivatives by arrays/matrices as much as symbols.\n                     is_symbol = True\n                 if not is_symbol:\ndiff --git a/sympy/printing/conventions.py b/sympy/printing/conventions.py\nindex f74468290c..e4e1790fd9 100644\n--- a/sympy/printing/conventions.py\n+++ b/sympy/printing/conventions.py\n@@ -5,7 +5,7 @@\n from __future__ import print_function, division\n \n import re\n-import collections\n+import collections.abc\n \n \n _name_with_digits_p = re.compile(r'^([a-zA-Z]+)([0-9]+)$')\n@@ -77,7 +77,7 @@ def requires_partial(expr):\n     get the context of the expression.\n     \"\"\"\n \n-    if not isinstance(expr.free_symbols, collections.Iterable):\n+    if not isinstance(expr.free_symbols, collections.abc.Iterable):\n         return len(set(expr.variables)) > 1\n \n     return sum(not s.is_integer for s in expr.free_symbols) > 1\ndiff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 364b24a1e5..040976eef3 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1655,9 +1655,9 @@ def _print_SeqFormula(self, s):\n         else:\n             printset = tuple(s)\n \n-        return (r\"\\left\\[\"\n+        return (r\"[\"\n               + r\", \".join(self._print(el) for el in printset)\n-              + r\"\\right\\]\")\n+              + r\"]\")\n \n     _print_SeqPer = _print_SeqFormula\n     _print_SeqAdd = _print_SeqFormula\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex b2c4135a76..a43ad5f1de 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -1,5 +1,5 @@\n from __future__ import print_function, division\n-import collections\n+import collections.abc\n \n from sympy import Basic\n from sympy.core.compatibility import SYMPY_INTS\n@@ -104,7 +104,7 @@ def _check_symbolic_index(self, index):\n \n     def _setter_iterable_check(self, value):\n         from sympy.matrices.matrices import MatrixBase\n-        if isinstance(value, (collections.Iterable, MatrixBase, NDimArray)):\n+        if isinstance(value, (collections.abc.Iterable, MatrixBase, NDimArray)):\n             raise NotImplementedError\n \n     @classmethod\n@@ -135,7 +135,7 @@ def _handle_ndarray_creation_inputs(cls, iterable=None, shape=None, **kwargs):\n             shape = iterable.shape\n             iterable = list(iterable)\n         # Construct N-dim array from an iterable (numpy arrays included):\n-        elif shape is None and isinstance(iterable, collections.Iterable):\n+        elif shape is None and isinstance(iterable, collections.abc.Iterable):\n             iterable, shape = cls._scan_iterable_shape(iterable)\n \n         # Construct N-dim array from a Matrix:\ndiff --git a/sympy/tensor/functions.py b/sympy/tensor/functions.py\nindex 4b97543cfa..e04ab26b29 100644\n--- a/sympy/tensor/functions.py\n+++ b/sympy/tensor/functions.py\n@@ -1,4 +1,4 @@\n-import collections\n+import collections.abc\n from sympy.core.evaluate import global_evaluate\n from sympy import Expr, S, Mul, sympify\n \n@@ -25,7 +25,7 @@ def __new__(cls, *args, **kwargs):\n         other = []\n         scalar = S.One\n         for arg in args:\n-            if isinstance(arg, (collections.Iterable, MatrixBase, NDimArray)):\n+            if isinstance(arg, (collections.abc.Iterable, MatrixBase, NDimArray)):\n                 arrays.append(Array(arg))\n             elif isinstance(arg, (MatrixExpr,)):\n                 other.append(arg)\ndiff --git a/sympy/tensor/indexed.py b/sympy/tensor/indexed.py\nindex 3752d24423..203871e0af 100644\n--- a/sympy/tensor/indexed.py\n+++ b/sympy/tensor/indexed.py\n@@ -107,7 +107,7 @@\n \n from __future__ import print_function, division\n \n-import collections\n+import collections.abc\n \n from sympy.core.sympify import _sympify\n from sympy.functions.special.tensor_functions import KroneckerDelta\n@@ -152,7 +152,7 @@ def __new__(cls, base, *args, **kw_args):\n             raise TypeError(filldedent(\"\"\"\n                 Indexed expects string, Symbol, or IndexedBase as base.\"\"\"))\n         args = list(map(sympify, args))\n-        if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n+        if isinstance(base, (NDimArray, collections.abc.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n             if len(args) == 1:\n                 return base[args[0]]\n             else:\n", "instance_id": "sympy__sympy-13971"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\nindex 138ed07ff8..95567a6baa 100644\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -56,6 +56,9 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n     available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n+    language_code = settings.LANGUAGE_CODE\n+    base_language_code = language_code.split('-')[0]\n+\n+    if language_code not in available_tags and base_language_code not in available_tags:\n         return [E004]\n     return []\n", "instance_id": "django__django-12286"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex be2248320..a825680d0 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -13,6 +13,7 @@ from sphinx.environment import BuildEnvironment\n from sphinx.ext.autodoc import Documenter, Options\n from sphinx.util import logging\n from sphinx.util.docutils import SphinxDirective, switch_source_input\n+from sphinx.ext.autodoc import remove_duplicate_args\n from sphinx.util.nodes import nested_parse_with_titles\n \n logger = logging.getLogger(__name__)\n@@ -105,6 +106,12 @@ def parse_generated_content(state: RSTState, content: StringList, documenter: Do\n             node.document = state.document\n             state.nested_parse(content, 0, node)\n \n+        # Remove duplicate *args and **kwargs\n+        for child in node.children:\n+            if isinstance(child, nodes.field_list):\n+                for field in child:\n+                    if isinstance(field, nodes.field) and field[0].astext() == 'Parameters':\n+                        field[1][0].children = remove_duplicate_args(field[1][0].children)\n         return node.children\n \n \n", "instance_id": "sphinx-doc__sphinx-10451"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 7f181789fd..831bc8eafb 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -231,7 +231,7 @@ def __float__(self):\n         # Don't bother testing if it's a number; if it's not this is going\n         # to fail, and if it is we still need to check that it evalf'ed to\n         # a number.\n-        result = self.evalf()\n+        result = self.evalf().simplify()\n         if result.is_Number:\n             return float(result)\n         if result.is_number and result.as_real_imag()[1]:\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex f1609aa908..4eac6604e2 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -564,8 +564,11 @@ def shorter(*choices):\n     if expr.has(BesselBase):\n         expr = besselsimp(expr)\n \n-    if expr.has(TrigonometricFunction) and not fu or expr.has(\n-            HyperbolicFunction):\n+    # Combine like terms with fractional exponents\n+    if expr.has(Pow):\n+        expr = expr.collect(lambda term: term.as_base_exp()[0])\n+\n+    if expr.has(TrigonometricFunction) and not fu or expr.has(HyperbolicFunction):\n         expr = trigsimp(expr, deep=True)\n \n     if expr.has(log):\n", "instance_id": "sympy__sympy-13146"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\nindex 15c630b1d..57e0d4673 100644\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -13,6 +13,8 @@ import os\n import re\n import sys\n import time\n+import socket\n+from datetime import datetime\n \n import py\n \n@@ -478,6 +480,8 @@ class LogXML:\n         self.logfile = os.path.normpath(os.path.abspath(logfile))\n         self.prefix = prefix\n         self.suite_name = suite_name\n+        self.hostname = socket.gethostname()\n+        self.timestamp = datetime.utcnow().isoformat()\n         self.logging = logging\n         self.log_passing_tests = log_passing_tests\n         self.report_duration = report_duration\n@@ -665,6 +669,8 @@ class LogXML:\n             failures=self.stats[\"failure\"],\n             skipped=self.stats[\"skipped\"],\n             tests=numtests,\n+            hostname=self.hostname,\n+            timestamp=self.timestamp,\n             time=\"%.3f\" % suite_time_delta,\n         )\n         logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n", "instance_id": "pytest-dev__pytest-5692"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/outcomes.py b/src/_pytest/outcomes.py\nindex 2addf5572..5e0e2273a 100644\n--- a/src/_pytest/outcomes.py\n+++ b/src/_pytest/outcomes.py\n@@ -144,6 +144,38 @@ def skip(msg: str = \"\", *, allow_module_level: bool = False) -> \"NoReturn\":\n     raise Skipped(msg=msg, allow_module_level=allow_module_level)\n \n \n+@_with_exception(Skipped)\n+def skip_module(msg: str = \"\") -> \"NoReturn\":\n+    \"\"\"Skip the entire module with the given message.\n+\n+    This function should be called at the module level to skip the entire module.\n+\n+    :param str msg: The message to show the user as reason for the skip.\n+    \"\"\"\n+    __tracebackhide__ = True\n+    raise Skipped(msg=msg, allow_module_level=True)\n+    \"\"\"Skip an executing test with the given message.\n+\n+    This function should be called only during testing (setup, call or teardown) or\n+    during collection by using the ``allow_module_level`` flag.  This function can\n+    be called in doctests as well.\n+\n+    :param bool allow_module_level:\n+        Allows this function to be called at module level, skipping the rest\n+        of the module. Defaults to False.\n+\n+    .. note::\n+        It is better to use the :ref:`pytest.mark.skipif ref` marker when\n+        possible to declare a test to be skipped under certain conditions\n+        like mismatching platforms or dependencies.\n+        Similarly, use the ``# doctest: +SKIP`` directive (see `doctest.SKIP\n+        <https://docs.python.org/3/library/how-to/doctest.html#doctest.SKIP>`_)\n+        to skip a doctest statically.\n+    \"\"\"\n+    __tracebackhide__ = True\n+    raise Skipped(msg=msg, allow_module_level=allow_module_level)\n+\n+\n @_with_exception(Failed)\n def fail(msg: str = \"\", pytrace: bool = True) -> \"NoReturn\":\n     \"\"\"Explicitly fail an executing test with the given message.\n", "instance_id": "pytest-dev__pytest-8906"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 1d390c71dd..710315a90e 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -19,7 +19,7 @@ class MessageEncoder(json.JSONEncoder):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n@@ -35,7 +35,8 @@ class MessageDecoder(json.JSONDecoder):\n             if obj[0] == MessageEncoder.message_key:\n                 if obj[1]:\n                     obj[3] = mark_safe(obj[3])\n-                return Message(*obj[2:])\n+                extra_tags = obj[4] if len(obj) > 4 else \"\"\n+                return Message(obj[2], obj[3], extra_tags)\n             return [self.process_messages(item) for item in obj]\n         if isinstance(obj, dict):\n             return {key: self.process_messages(value)\n", "instance_id": "django__django-15347"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 2b306a579e..571d120467 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -84,13 +84,13 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n", "instance_id": "django__django-13660"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "sympy__sympy-18199"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 6f10e31cd5..ff830fe4ab 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -11,6 +11,7 @@ from django.db.backends import utils\n from django.db.models.expressions import Col\n from django.utils import timezone\n from django.utils.encoding import force_str\n+from django.db.models.constants import OnConflict\n \n \n class BaseDatabaseOperations:\n@@ -772,7 +773,9 @@ class BaseDatabaseOperations:\n             raise ValueError(\"Unknown options: %s\" % \", \".join(sorted(options.keys())))\n         return self.explain_prefix\n \n-    def insert_statement(self, on_conflict=None):\n+    def insert_statement(self, table_name, pk_name, on_conflict=None):\n+        if on_conflict == OnConflict.UPDATE:\n+            return \"INSERT INTO %s RETURNING %s\" % (self.quote_name(table_name), self.quote_name(pk_name))\n         return \"INSERT INTO\"\n \n     def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):\ndiff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 5ac2407ea3..d319fd4cba 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -719,7 +719,9 @@ class QuerySet(AltersData):\n                     raise ValueError(\n                         \"bulk_create() can only be used with concrete fields \"\n                         \"in unique_fields.\"\n-                    )\n+                )\n+                table_name=self.model._meta.db_table,\n+                pk_name=self.model._meta.pk.column,\n             return OnConflict.UPDATE\n         return None\n \n@@ -1837,7 +1839,7 @@ class QuerySet(AltersData):\n         inserted_rows = []\n         bulk_return = connection.features.can_return_rows_from_bulk_insert\n         for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n-            if bulk_return and on_conflict is None:\n+            if bulk_return and (on_conflict is None or on_conflict == OnConflict.UPDATE):\n                 inserted_rows.extend(\n                     self._insert(\n                         item,\n", "instance_id": "django__django-17051"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-16400"}
{"model_name_or_path": "200724-221013", "model_patch": "", "instance_id": "django__django-13933"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..eeabada206 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -979,6 +979,11 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return super().get_group_by_cols()\n \n     def as_sql(self, compiler, connection):\n+        if isinstance(self.expression, Q):\n+            sql, params = compiler.compile(self.expression)\n+            if self.expression.negated:\n+                sql = 'NOT (%s)' % sql\n+            return sql, params\n         return compiler.compile(self.expression)\n \n     def __repr__(self):\n", "instance_id": "django__django-15213"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex 2587ba35b..57bc21796 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -18,7 +18,7 @@ from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warni\n from sphinx.pycode import ModuleAnalyzer, PycodeError\n from sphinx.util import logging\n from sphinx.util.inspect import (getannotations, getmro, getslots, isclass, isenumclass,\n-                                 safe_getattr)\n+                                 safe_getattr, safe_import_module)\n \n if False:\n     # For type annotation\n@@ -82,62 +82,77 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n     else:\n         logger.debug('[autodoc] import %s', modname)\n \n-    try:\n-        module = None\n-        exc_on_importing = None\n-        objpath = list(objpath)\n-        while module is None:\n-            try:\n-                module = import_module(modname, warningiserror=warningiserror)\n-                logger.debug('[autodoc] import %s => %r', modname, module)\n-            except ImportError as exc:\n-                logger.debug('[autodoc] import %s => failed', modname)\n-                exc_on_importing = exc\n-                if '.' in modname:\n-                    # retry with parent module\n-                    modname, name = modname.rsplit('.', 1)\n-                    objpath.insert(0, name)\n+    # Special handling for the 'struct' module\n+    if modname == 'struct':\n+        module = safe_import_module(modname)\n+        if module:\n+            obj = module\n+            parent = None\n+            object_name = None\n+            for attrname in objpath:\n+                parent = obj\n+                logger.debug('[autodoc] getattr(_, %r)', attrname)\n+                obj = attrgetter(obj, attrname)\n+                logger.debug('[autodoc] => %r', obj)\n+                object_name = attrname\n+            return [module, parent, object_name, obj]\n+    else:\n+        try:\n+            module = None\n+            exc_on_importing = None\n+            objpath = list(objpath)\n+            while module is None:\n+                try:\n+                    module = import_module(modname, warningiserror=warningiserror)\n+                    logger.debug('[autodoc] import %s => %r', modname, module)\n+                except ImportError as exc:\n+                    logger.debug('[autodoc] import %s => failed', modname)\n+                    exc_on_importing = exc\n+                    if '.' in modname:\n+                        # retry with parent module\n+                        modname, name = modname.rsplit('.', 1)\n+                        objpath.insert(0, name)\n+                    else:\n+                        raise\n+\n+            obj = module\n+            parent = None\n+            object_name = None\n+            for attrname in objpath:\n+                parent = obj\n+                logger.debug('[autodoc] getattr(_, %r)', attrname)\n+                mangled_name = mangle(obj, attrname)\n+                obj = attrgetter(obj, mangled_name)\n+                logger.debug('[autodoc] => %r', obj)\n+                object_name = attrname\n+            return [module, parent, object_name, obj]\n+        except (AttributeError, ImportError) as exc:\n+            if isinstance(exc, AttributeError) and exc_on_importing:\n+                # restore ImportError\n+                exc = exc_on_importing\n+\n+            if objpath:\n+                errmsg = ('autodoc: failed to import %s %r from module %r' %\n+                          (objtype, '.'.join(objpath), modname))\n+            else:\n+                errmsg = 'autodoc: failed to import %s %r' % (objtype, modname)\n+\n+            if isinstance(exc, ImportError):\n+                # import_module() raises ImportError having real exception obj and\n+                # traceback\n+                real_exc, traceback_msg = exc.args\n+                if isinstance(real_exc, SystemExit):\n+                    errmsg += ('; the module executes module level statement '\n+                               'and it might call sys.exit().')\n+                elif isinstance(real_exc, ImportError) and real_exc.args:\n+                    errmsg += '; the following exception was raised:\\n%s' % real_exc.args[0]\n                 else:\n-                    raise\n-\n-        obj = module\n-        parent = None\n-        object_name = None\n-        for attrname in objpath:\n-            parent = obj\n-            logger.debug('[autodoc] getattr(_, %r)', attrname)\n-            mangled_name = mangle(obj, attrname)\n-            obj = attrgetter(obj, mangled_name)\n-            logger.debug('[autodoc] => %r', obj)\n-            object_name = attrname\n-        return [module, parent, object_name, obj]\n-    except (AttributeError, ImportError) as exc:\n-        if isinstance(exc, AttributeError) and exc_on_importing:\n-            # restore ImportError\n-            exc = exc_on_importing\n-\n-        if objpath:\n-            errmsg = ('autodoc: failed to import %s %r from module %r' %\n-                      (objtype, '.'.join(objpath), modname))\n-        else:\n-            errmsg = 'autodoc: failed to import %s %r' % (objtype, modname)\n-\n-        if isinstance(exc, ImportError):\n-            # import_module() raises ImportError having real exception obj and\n-            # traceback\n-            real_exc, traceback_msg = exc.args\n-            if isinstance(real_exc, SystemExit):\n-                errmsg += ('; the module executes module level statement '\n-                           'and it might call sys.exit().')\n-            elif isinstance(real_exc, ImportError) and real_exc.args:\n-                errmsg += '; the following exception was raised:\\n%s' % real_exc.args[0]\n+                    errmsg += '; the following exception was raised:\\n%s' % traceback_msg\n             else:\n-                errmsg += '; the following exception was raised:\\n%s' % traceback_msg\n-        else:\n-            errmsg += '; the following exception was raised:\\n%s' % traceback.format_exc()\n+                errmsg += '; the following exception was raised:\\n%s' % traceback.format_exc()\n \n-        logger.debug(errmsg)\n-        raise ImportError(errmsg) from exc\n+            logger.debug(errmsg)\n+            raise ImportError(errmsg) from exc\n \n \n def get_module_members(module: Any) -> List[Tuple[str, Any]]:\n", "instance_id": "sphinx-doc__sphinx-8627"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex d3d53e3d98..f2ee8c4487 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -518,6 +518,56 @@ class Colorbar:\n                 self.add_lines(CS)\n         self.stale = True\n \n+    def update_bruteforce(self, mappable):\n+        \"\"\"\n+        Forcefully update the colorbar by recalculating all parameters and\n+        redrawing the colorbar. This is useful when the norm instance of the\n+        colorbar has been changed.\n+\n+        Parameters\n+        ----------\n+        mappable : `.ScalarMappable`\n+            The mappable whose colormap and norm will be used.\n+        \"\"\"\n+        _log.debug('colorbar update bruteforce %r %r', mappable.norm, self.norm)\n+        self.mappable = mappable\n+        self.set_alpha(mappable.get_alpha())\n+        self.cmap = mappable.cmap\n+        self.norm = mappable.norm\n+        self._reset_locator_formatter_scale()\n+        self._draw_all()\n+        if isinstance(self.mappable, contour.ContourSet):\n+            CS = self.mappable\n+            if not CS.filled:\n+                self.add_lines(CS)\n+        self.stale = True\n+        \"\"\"\n+        Update solid patches, lines, etc.\n+\n+        This is meant to be called when the norm of the image or contour plot\n+        to which this colorbar belongs changes.\n+\n+        If the norm on the mappable is different than before, this resets the\n+        locator and formatter for the axis, so if these have been customized,\n+        they will need to be customized again.  However, if the norm only\n+        changes values of *vmin*, *vmax* or *cmap* then the old formatter\n+        and locator will be preserved.\n+        \"\"\"\n+        _log.debug('colorbar update normal %r %r', mappable.norm, self.norm)\n+        self.mappable = mappable\n+        self.set_alpha(mappable.get_alpha())\n+        self.cmap = mappable.cmap\n+        if mappable.norm != self.norm:\n+            self.norm = mappable.norm\n+            self._reset_locator_formatter_scale()\n+\n+        self._draw_all()\n+        if isinstance(self.mappable, contour.ContourSet):\n+            CS = self.mappable\n+            if not CS.filled:\n+                self.add_lines(CS)\n+        self.stale = True\n+\n     @_api.deprecated(\"3.6\", alternative=\"fig.draw_without_rendering()\")\n     def draw_all(self):\n         \"\"\"\n", "instance_id": "matplotlib__matplotlib-25498"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..ba8c3463a0 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,11 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n", "instance_id": "django__django-14855"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..cf7e141258 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1802,9 +1802,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n", "instance_id": "sympy__sympy-20154"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..bd0f1e007c 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,6 +320,9 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # Check if db_table is already defined\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\n", "instance_id": "django__django-14999"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/backends/backend_macosx.py b/lib/matplotlib/backends/backend_macosx.py\nindex 700d1d4c58..0593ad6f48 100644\n--- a/lib/matplotlib/backends/backend_macosx.py\n+++ b/lib/matplotlib/backends/backend_macosx.py\n@@ -97,6 +97,10 @@ class FigureCanvasMac(FigureCanvasAgg, _macosx.FigureCanvas, FigureCanvasBase):\n         scale = self.figure.dpi / self.device_pixel_ratio\n         width /= scale\n         height /= scale\n+        # Ensure DPI is not doubled\n+        if hasattr(self.figure, '_dpi'):\n+            self.figure._dpi /= self.device_pixel_ratio\n+\n         self.figure.set_size_inches(width, height, forward=False)\n         ResizeEvent(\"resize_event\", self)._process()\n         self.draw_idle()\ndiff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex c55864243a..887ac92008 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2594,6 +2594,36 @@ class Figure(FigureBase):\n         self.set_size_inches(w, h, forward=forward)\n         self._fig_callbacks.process('dpi_changed', self)\n \n+    def __setstate__(self, state):\n+        version = state.pop('__mpl_version__')\n+        restore_to_pylab = state.pop('_restore_to_pylab', False)\n+\n+        if version != mpl.__version__:\n+            _api.warn_external(\n+                f\"This figure was saved with matplotlib version {version} and \"\n+                f\"is unlikely to function correctly.\")\n+\n+        self.__dict__ = state\n+\n+        # re-initialise some of the unstored state information\n+        FigureCanvasBase(self)  # Set self.canvas.\n+\n+        if restore_to_pylab:\n+            # lazy import to avoid circularity\n+            import matplotlib.pyplot as plt\n+            import matplotlib._pylab_helpers as pylab_helpers\n+            allnums = plt.get_fignums()\n+            num = max(allnums) + 1 if allnums else 1\n+            mgr = plt._backend_mod.new_figure_manager_given_figure(num, self)\n+            pylab_helpers.Gcf._set_new_active_manager(mgr)\n+            plt.draw_if_interactive()\n+\n+        # Ensure DPI is not doubled\n+        if hasattr(self, '_dpi'):\n+            self._dpi /= self.canvas.device_pixel_ratio\n+\n+        self.stale = True\n+\n     dpi = property(_get_dpi, _set_dpi, doc=\"The resolution in dots per inch.\")\n \n     def get_tight_layout(self):\n", "instance_id": "matplotlib__matplotlib-23476"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 02ec6480cb..3faaaa22d7 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -155,6 +155,14 @@ def integer_log(y, x):\n \n \n class Pow(Expr):\n+    def _eval_simplify(self, **kwargs):\n+        from sympy import Symbol, Integer\n+        base, exp = self.as_base_exp()\n+        if base.is_negative and exp.is_Symbol:\n+            a = Symbol('a', integer=True, positive=True)\n+            if base == -a:\n+                return (-1)**exp\n+        return self\n     \"\"\"\n     Defines the expression x**y as \"x raised to a power y\"\n \ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..d6e50ba9b2 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -383,6 +383,13 @@ def signsimp(expr, evaluate=None):\n \n \n def simplify(expr, ratio=1.7, measure=count_ops, rational=False):\n+    from sympy import Symbol, Integer\n+    if expr.is_Mul:\n+        base, exp = expr.as_base_exp()\n+        if base.is_negative and exp.is_Symbol:\n+            a = Symbol('a', integer=True, positive=True)\n+            if base == -a:\n+                return (-1)**exp\n     # type: (object, object, object, object) -> object\n     \"\"\"\n     Simplifies the given expression.\n", "instance_id": "sympy__sympy-14024"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f32ce64629..08419cb817 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1280,7 +1280,12 @@ class DateField(DateTimeCheckMixin, Field):\n         return '' if val is None else val.isoformat()\n \n     def formfield(self, **kwargs):\n-        return super().formfield(**{\n+        defaults = {\n+            'form_class': forms.DurationField,\n+            'help_text': self.default_help_text,\n+        }\n+        defaults.update(kwargs)\n+        return super().formfield(**defaults)\n             'form_class': forms.DateField,\n             **kwargs,\n         })\n@@ -1590,6 +1595,7 @@ class DurationField(Field):\n                      \"[DD] [HH:[MM:]]ss[.uuuuuu] format.\")\n     }\n     description = _(\"Duration\")\n+    default_help_text = _(\"Enter a duration in the format [DD] [[HH:]MM:]ss[.uuuuuu]\")\n \n     def get_internal_type(self):\n         return \"DurationField\"\n", "instance_id": "django__django-11049"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 6f26dff0e0..9f1c51db3d 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -671,6 +671,7 @@ class Func(SQLiteNumericMixin, Expression):\n             )\n         super().__init__(output_field=output_field)\n         self.source_expressions = self._parse_expressions(*expressions)\n+        self.query.subquery = True\n         self.extra = extra\n \n     def __repr__(self):\n", "instance_id": "django__django-15320"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 1edc712358..456eafadfd 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -390,98 +390,27 @@ def convert(expr):\n                     last_term_tex = term_tex\n                 return _tex\n \n+        snumer = convert(numer)\n+        sdenom = convert(denom)\n         if denom is S.One:\n-            # use the original expression here, since fraction() may have\n-            # altered it when producing numer and denom\n-            tex += convert(expr)\n-        else:\n-            snumer = convert(numer)\n-            sdenom = convert(denom)\n-            ldenom = len(sdenom.split())\n-            ratio = self._settings['long_frac_ratio']\n-            if self._settings['fold_short_frac'] \\\n-                    and ldenom <= 2 and not \"^\" in sdenom:\n-                # handle short fractions\n-                if self._needs_mul_brackets(numer, last=False):\n-                    tex += r\"\\left(%s\\right) / %s\" % (snumer, sdenom)\n-                else:\n-                    tex += r\"%s / %s\" % (snumer, sdenom)\n-            elif len(snumer.split()) > ratio*ldenom:\n-                # handle long fractions\n-                if self._needs_mul_brackets(numer, last=True):\n-                    tex += r\"\\frac{1}{%s}%s\\left(%s\\right)\" \\\n-                        % (sdenom, separator, snumer)\n-                elif numer.is_Mul:\n-                    # split a long numerator\n-                    a = S.One\n-                    b = S.One\n-                    for x in numer.args:\n-                        if self._needs_mul_brackets(x, last=False) or \\\n-                                len(convert(a*x).split()) > ratio*ldenom or \\\n-                                (b.is_commutative is x.is_commutative is False):\n-                            b *= x\n-                        else:\n-                            a *= x\n-                    if self._needs_mul_brackets(b, last=True):\n-                        tex += r\"\\frac{%s}{%s}%s\\left(%s\\right)\" \\\n-                            % (convert(a), sdenom, separator, convert(b))\n-                    else:\n-                        tex += r\"\\frac{%s}{%s}%s%s\" \\\n-                            % (convert(a), sdenom, separator, convert(b))\n-                else:\n-                    tex += r\"\\frac{1}{%s}%s%s\" % (sdenom, separator, snumer)\n-            else:\n-                tex += r\"\\frac{%s}{%s}\" % (snumer, sdenom)\n+            tex += snumer\n+        else:\n+            if self._needs_mul_brackets(numer, last=False):\n+                snumer = r\"\\left(%s\\right)\" % snumer\n+            if self._needs_mul_brackets(denom, last=False):\n+                sdenom = r\"\\left(%s\\right)\" % sdenom\n+            tex += r\"\\frac{%s}{%s}\" % (snumer, sdenom)\n \n         if include_parens:\n             tex += \")\"\n         return tex\n \n     def _print_Pow(self, expr):\n-        # Treat x**Rational(1,n) as special case\n-        if expr.exp.is_Rational and abs(expr.exp.p) == 1 and expr.exp.q != 1:\n-            base = self._print(expr.base)\n-            expq = expr.exp.q\n-\n-            if expq == 2:\n-                tex = r\"\\sqrt{%s}\" % base\n-            elif self._settings['itex']:\n-                tex = r\"\\root{%d}{%s}\" % (expq, base)\n-            else:\n-                tex = r\"\\sqrt[%d]{%s}\" % (expq, base)\n-\n-            if expr.exp.is_negative:\n-                return r\"\\frac{1}{%s}\" % tex\n-            else:\n-                return tex\n-        elif self._settings['fold_frac_powers'] \\\n-            and expr.exp.is_Rational \\\n-                and expr.exp.q != 1:\n-            base, p, q = self.parenthesize(expr.base, PRECEDENCE['Pow']), expr.exp.p, expr.exp.q\n-            if expr.base.is_Function:\n-                return self._print(expr.base, \"%s/%s\" % (p, q))\n-            return r\"%s^{%s/%s}\" % (base, p, q)\n-        elif expr.exp.is_Rational and expr.exp.is_negative and expr.base.is_commutative:\n-            # Things like 1/x\n-            return self._print_Mul(expr)\n-        else:\n-            if expr.base.is_Function:\n-                return self._print(expr.base, self._print(expr.exp))\n-            else:\n-                if expr.is_commutative and expr.exp == -1:\n-                    #solves issue 4129\n-                    #As Mul always simplify 1/x to x**-1\n-                    #The objective is achieved with this hack\n-                    #first we get the latex for -1 * expr,\n-                    #which is a Mul expression\n-                    tex = self._print(S.NegativeOne * expr).strip()\n-                    #the result comes with a minus and a space, so we remove\n-                    if tex[:1] == \"-\":\n-                        return tex[1:].strip()\n-                tex = r\"%s^{%s}\"\n-\n-                return tex % (self.parenthesize(expr.base, PRECEDENCE['Pow']),\n-                              self._print(expr.exp))\n+        base = self.parenthesize(expr.base, PRECEDENCE['Pow'])\n+        exp = self._print(expr.exp)\n+        if expr.exp.is_Rational and expr.exp.q != 1:\n+            exp = r\"\\frac{%s}{%s}\" % (expr.exp.p, expr.exp.q)\n+        return r\"%s^{%s}\" % (base, exp)\n \n     def _print_UnevaluatedExpr(self, expr):\n         return self._print(expr.args[0])\n", "instance_id": "sympy__sympy-11897"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..bf49bfaced 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,9 +727,9 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n-        xa[xa > self.N - 1] = self._i_over\n-        xa[xa < 0] = self._i_under\n-        xa[mask_bad] = self._i_bad\n+        xa[xa > self.N - 1] = np.clip(self._i_over, 0, 255)\n+        xa[xa < 0] = np.clip(self._i_under, 0, 255)\n+        xa[mask_bad] = np.clip(self._i_bad, 0, 255)\n \n         lut = self._lut\n         if bytes:\n", "instance_id": "matplotlib__matplotlib-24970"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..0567dd8ec2 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,11 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return (\n+            subclass in self._subclasses or\n+            any(issubclass(subclass, cls) for cls in self._subclasses) or\n+            super().__subclasscheck__(subclass)\n+        )\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "instance_id": "django__django-14238"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..42443735 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,7 @@ class DataArray(AbstractArray, DataWithCoords):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            data_dict[k] = self.sel({variable_dim: k}).drop_vars(variable_dim).squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n", "instance_id": "pydata__xarray-4094"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex 5e6a400b6c..ef99599106 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -367,14 +367,11 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n             elif form and name in form.fields:\n                 attr = form.fields[name]\n             else:\n-                message = \"Unable to lookup '%s' on %s\" % (\n-                    name,\n-                    model._meta.object_name,\n+                message = (\n+                    f\"Unable to lookup '{name}' on {model._meta.object_name} \"\n+                    f\"or {model_admin.__class__.__name__ if model_admin else ''} \"\n+                    f\"or {form.__class__.__name__ if form else ''}\"\n                 )\n-                if model_admin:\n-                    message += \" or %s\" % model_admin.__class__.__name__\n-                if form:\n-                    message += \" or %s\" % form.__class__.__name__\n                 raise AttributeError(message)\n \n             if hasattr(attr, \"short_description\"):\n", "instance_id": "django__django-16816"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..37af2a826 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -296,7 +296,9 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         check_is_fitted(self, 'X_fit_')\n \n         K = self._centerer.transform(self._get_kernel(X, self.X_fit_))\n-        return np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+        X_transformed = np.dot(K, self.alphas_ / np.sqrt(self.lambdas_))\n+\n+        return X_transformed\n \n     def inverse_transform(self, X):\n         \"\"\"Transform X back to original space.\n", "instance_id": "scikit-learn__scikit-learn-13241"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\nindex 5eaef2fde..e55754961 100644\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -16,6 +16,7 @@ from scipy.sparse import lil_matrix\n \n import numpy as np\n \n+import pandas as pd\n from .validation import check_array, _assert_all_finite\n from ..utils._array_api import get_namespace\n \n@@ -74,6 +75,12 @@ def unique_labels(*ys):\n     array([ 1,  2,  5, 10, 11])\n     \"\"\"\n     xp, is_array_api = get_namespace(*ys)\n+    \n+    # Convert nullable pandas dtypes to their corresponding numpy dtypes\n+    ys = [\n+        y.astype(y.dtype.numpy_dtype) if isinstance(y, pd.Series) and pd.api.types.is_extension_array_dtype(y.dtype) else y\n+        for y in ys\n+    ]\n     if not ys:\n         raise ValueError(\"No argument has been passed.\")\n     # Check that we don't mix label format\n", "instance_id": "scikit-learn__scikit-learn-25638"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 737e16cc74..1ffe4f6d32 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1854,7 +1854,7 @@ def _print_PolynomialRingBase(self, expr):\n \n     def _print_Poly(self, poly):\n         cls = poly.__class__.__name__\n-        expr = self._print(poly.as_expr())\n+        expr = self._print(poly.as_expr(order='lex'))\n         gens = list(map(self._print, poly.gens))\n         domain = \"domain=%s\" % self._print(poly.get_domain())\n \n", "instance_id": "sympy__sympy-14317"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..f4bc714b84 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2174,6 +2174,7 @@ class SubFigure(FigureBase):\n             %(SubFigure:kwdoc)s\n         \"\"\"\n         super().__init__(**kwargs)\n+        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n         if facecolor is None:\n             facecolor = \"none\"\n         if edgecolor is None:\n@@ -3174,6 +3175,9 @@ None}, default: None\n         from matplotlib import _pylab_helpers\n         if self.canvas.manager in _pylab_helpers.Gcf.figs.values():\n             state['_restore_to_pylab'] = True\n+        state['_align_label_groups'] = {\n+            axis: list(group) for axis, group in self._align_label_groups.items()\n+        }\n         return state\n \n     def __setstate__(self, state):\n@@ -3187,7 +3191,10 @@ None}, default: None\n \n         self.__dict__ = state\n \n-        # re-initialise some of the unstored state information\n+        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        for axis, group in state.pop('_align_label_groups', {}).items():\n+            for ax in group:\n+                self._align_label_groups[axis].join(ax)\n         FigureCanvasBase(self)  # Set self.canvas.\n \n         if restore_to_pylab:\n", "instance_id": "matplotlib__matplotlib-25332"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..2bef32577b 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -27,7 +27,7 @@ class BaseDatabaseCreation:\n     def log(self, msg):\n         sys.stderr.write(msg + os.linesep)\n \n-    def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=False):\n+    def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=False, migrate=True):\n         \"\"\"\n         Create a test database, prompting the user for confirmation if the\n         database already exists. Return the name of the test database created.\n@@ -58,17 +58,26 @@ class BaseDatabaseCreation:\n         settings.DATABASES[self.connection.alias][\"NAME\"] = test_database_name\n         self.connection.settings_dict[\"NAME\"] = test_database_name\n \n-        if self.connection.settings_dict['TEST']['MIGRATE']:\n-            # We report migrate messages at one level lower than that\n-            # requested. This ensures we don't get flooded with messages during\n-            # testing (unless you really ask to be flooded).\n-            call_command(\n-                'migrate',\n-                verbosity=max(verbosity - 1, 0),\n-                interactive=False,\n-                database=self.connection.alias,\n-                run_syncdb=True,\n-            )\n+        if migrate:\n+            if self.connection.settings_dict['TEST'].get('MIGRATE', True):\n+                # We report migrate messages at one level lower than that\n+                # requested. This ensures we don't get flooded with messages during\n+                # testing (unless you really ask to be flooded).\n+                call_command(\n+                    'migrate',\n+                    verbosity=max(verbosity - 1, 0),\n+                    interactive=False,\n+                    database=self.connection.alias,\n+                    run_syncdb=True,\n+                )\n+            else:\n+                # Ensure the test database is in a usable state without migrations.\n+                call_command(\n+                    'flush',\n+                    verbosity=max(verbosity - 1, 0),\n+                    interactive=False,\n+                    database=self.connection.alias,\n+                )\n \n         # We then serialize the current state of the database into a string\n         # and store it on the connection. This slightly horrific process is so people\n", "instance_id": "django__django-13448"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex da5b40a5ef..b3101cdbbc 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -903,13 +903,11 @@ class RangeSlider(SliderBase):\n             xy[1] = .25, val[1]\n             xy[2] = .75, val[1]\n             xy[3] = .75, val[0]\n-            xy[4] = .25, val[0]\n         else:\n             xy[0] = val[0], .25\n             xy[1] = val[0], .75\n             xy[2] = val[1], .75\n             xy[3] = val[1], .25\n-            xy[4] = val[0], .25\n         self.poly.xy = xy\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n", "instance_id": "matplotlib__matplotlib-22711"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/config/argparsing.py b/src/_pytest/config/argparsing.py\nindex 9b526ff3e..452a9f087 100644\n--- a/src/_pytest/config/argparsing.py\n+++ b/src/_pytest/config/argparsing.py\n@@ -15,132 +15,19 @@ from _pytest.config.exceptions import UsageError\n FILE_OR_DIR = \"file_or_dir\"\n \n \n-class Parser:\n-    \"\"\" Parser for command line arguments and ini-file values.\n-\n-    :ivar extra_info: dict of generic param -> value to display in case\n-        there's an error processing the command line arguments.\n-    \"\"\"\n-\n-    prog = None\n-\n-    def __init__(self, usage=None, processopt=None):\n-        self._anonymous = OptionGroup(\"custom options\", parser=self)\n-        self._groups = []  # type: List[OptionGroup]\n-        self._processopt = processopt\n-        self._usage = usage\n-        self._inidict = {}  # type: Dict[str, Tuple[str, Optional[str], Any]]\n-        self._ininames = []  # type: List[str]\n-        self.extra_info = {}  # type: Dict[str, Any]\n-\n-    def processoption(self, option):\n-        if self._processopt:\n-            if option.dest:\n-                self._processopt(option)\n-\n-    def getgroup(self, name, description=\"\", after=None):\n-        \"\"\" get (or create) a named option Group.\n-\n-        :name: name of the option group.\n-        :description: long description for --help output.\n-        :after: name of other group, used for ordering --help output.\n-\n-        The returned group object has an ``addoption`` method with the same\n-        signature as :py:func:`parser.addoption\n-        <_pytest.config.Parser.addoption>` but will be shown in the\n-        respective group in the output of ``pytest. --help``.\n-        \"\"\"\n-        for group in self._groups:\n-            if group.name == name:\n-                return group\n-        group = OptionGroup(name, description, parser=self)\n-        i = 0\n-        for i, grp in enumerate(self._groups):\n-            if grp.name == after:\n-                break\n-        self._groups.insert(i + 1, group)\n-        return group\n-\n-    def addoption(self, *opts, **attrs):\n-        \"\"\" register a command line option.\n-\n-        :opts: option names, can be short or long options.\n-        :attrs: same attributes which the ``add_option()`` function of the\n-           `argparse library\n-           <http://docs.python.org/2/library/argparse.html>`_\n-           accepts.\n-\n-        After command line parsing options are available on the pytest config\n-        object via ``config.option.NAME`` where ``NAME`` is usually set\n-        by passing a ``dest`` attribute, for example\n-        ``addoption(\"--long\", dest=\"NAME\", ...)``.\n-        \"\"\"\n-        self._anonymous.addoption(*opts, **attrs)\n-\n-    def parse(self, args, namespace=None):\n-        from _pytest._argcomplete import try_argcomplete\n-\n-        self.optparser = self._getparser()\n-        try_argcomplete(self.optparser)\n-        args = [str(x) if isinstance(x, py.path.local) else x for x in args]\n-        return self.optparser.parse_args(args, namespace=namespace)\n-\n-    def _getparser(self) -> \"MyOptionParser\":\n-        from _pytest._argcomplete import filescompleter\n-\n-        optparser = MyOptionParser(self, self.extra_info, prog=self.prog)\n-        groups = self._groups + [self._anonymous]\n-        for group in groups:\n-            if group.options:\n-                desc = group.description or group.name\n-                arggroup = optparser.add_argument_group(desc)\n-                for option in group.options:\n-                    n = option.names()\n-                    a = option.attrs()\n-                    arggroup.add_argument(*n, **a)\n-        # bash like autocompletion for dirs (appending '/')\n-        # Type ignored because typeshed doesn't know about argcomplete.\n-        optparser.add_argument(  # type: ignore\n-            FILE_OR_DIR, nargs=\"*\"\n-        ).completer = filescompleter\n-        return optparser\n-\n-    def parse_setoption(self, args, option, namespace=None):\n-        parsedoption = self.parse(args, namespace=namespace)\n-        for name, value in parsedoption.__dict__.items():\n-            setattr(option, name, value)\n-        return getattr(parsedoption, FILE_OR_DIR)\n-\n-    def parse_known_args(self, args, namespace=None) -> argparse.Namespace:\n-        \"\"\"parses and returns a namespace object with known arguments at this\n-        point.\n-        \"\"\"\n-        return self.parse_known_and_unknown_args(args, namespace=namespace)[0]\n-\n-    def parse_known_and_unknown_args(\n-        self, args, namespace=None\n-    ) -> Tuple[argparse.Namespace, List[str]]:\n-        \"\"\"parses and returns a namespace object with known arguments, and\n-        the remaining arguments unknown at this point.\n-        \"\"\"\n-        optparser = self._getparser()\n-        args = [str(x) if isinstance(x, py.path.local) else x for x in args]\n-        return optparser.parse_known_args(args, namespace=namespace)\n-\n-    def addini(self, name, help, type=None, default=None):\n-        \"\"\" register an ini-file option.\n-\n-        :name: name of the ini-variable\n-        :type: type of the variable, can be ``pathlist``, ``args``, ``linelist``\n-               or ``bool``.\n-        :default: default value if no ini-file option exists but is queried.\n-\n-        The value of ini-variables can be retrieved via a call to\n-        :py:func:`config.getini(name) <_pytest.config.Config.getini>`.\n-        \"\"\"\n-        assert type in (None, \"pathlist\", \"args\", \"linelist\", \"bool\")\n-        self._inidict[name] = (help, type, default)\n-        self._ininames.append(name)\n+        self._anonymous.addoption(\n+            \"-c\", \"--collect-only\",\n+            action=\"store_true\",\n+            help=\"only collect tests, don't execute them.\"\n+        )\n+        self._anonymous.addoption(\n+            \"--maxfail\",\n+            action=\"store\",\n+            help=\"exit after first num failures or errors.\",\n+            type=int,\n+            dest=\"maxfail\",\n+            metavar=\"num\",\n+        )\n \n \n class ArgumentError(Exception):\n", "instance_id": "pytest-dev__pytest-6116"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a3ead157c1..f3b7669e96 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -740,7 +740,7 @@ def _print_Function(self, expr, exp=None):\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n", "instance_id": "sympy__sympy-14774"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..ba340c8348 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -31,7 +31,12 @@ from .utils import get_callable\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n+        if isinstance(func, functools.partial):\n+            self.func = func.func\n+            self.args = func.args + tuple(args)\n+            self.kwargs = {**func.keywords, **kwargs}\n+        else:\n+            self.func = func\n         self.args = args\n         self.kwargs = kwargs\n         self.url_name = url_name\n@@ -59,8 +64,15 @@ class ResolverMatch:\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n+        func_repr = self._func_path\n+        if isinstance(self.func, functools.partial):\n+            func_repr = \"functools.partial(%s, *%s, **%s)\" % (\n+                self.func.func.__name__,\n+                self.func.args,\n+                self.func.keywords,\n+            )\n         return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n-            self._func_path, self.args, self.kwargs, self.url_name,\n+            func_repr, self.args, self.kwargs, self.url_name,\n             self.app_names, self.namespaces, self.route,\n         )\n \n", "instance_id": "django__django-14155"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/physics/units/systems/si.py b/sympy/physics/units/systems/si.py\nindex 700495ad9d..ef9697f4d7 100644\n--- a/sympy/physics/units/systems/si.py\n+++ b/sympy/physics/units/systems/si.py\n@@ -326,6 +326,43 @@\n SI.set_quantity_scale_factor(rutherford, 1000000*becquerel)\n \n \n+class SI(MKSA):\n+    def _collect_factor_and_dimension(self, expr):\n+        from sympy.physics.units.dimensions import Dimension\n+        from sympy.physics.units.quantities import Quantity\n+        from sympy import Mul, Pow, exp\n+\n+        if isinstance(expr, Quantity):\n+            return expr.scale_factor, expr.dimension\n+\n+        if isinstance(expr, Dimension):\n+            return 1, expr\n+\n+        if isinstance(expr, Mul):\n+            factor = 1\n+            dimension = 1\n+            for arg in expr.args:\n+                f, d = self._collect_factor_and_dimension(arg)\n+                factor *= f\n+                dimension *= d\n+            return factor, dimension\n+\n+        if isinstance(expr, Pow):\n+            base, exp = expr.args\n+            base_factor, base_dimension = self._collect_factor_and_dimension(base)\n+            exp_factor, exp_dimension = self._collect_factor_and_dimension(exp)\n+            if exp_dimension != 1:\n+                raise ValueError(f\"Dimension of exponent must be 1, got {exp_dimension}\")\n+            return base_factor**exp_factor, base_dimension**exp_factor\n+\n+        if isinstance(expr, exp):\n+            arg_factor, arg_dimension = self._collect_factor_and_dimension(expr.args[0])\n+            if arg_dimension != 1:\n+                raise ValueError(f\"Dimension of exponent must be 1, got {arg_dimension}\")\n+            return exp(arg_factor), 1\n+\n+        return expr, 1\n+\n # check that scale factors are the right SI dimensions:\n for _scale_factor, _dimension in zip(\n     SI._quantity_scale_factors.values(),\n", "instance_id": "sympy__sympy-24066"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 6866648d4e..2cd7149938 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -434,10 +434,8 @@ def _repr_latex_(self):\n     def atoms(self, *types):\n         \"\"\"Returns the atoms that form the current object.\n \n-        By default, only objects that are truly atomic and can't\n-        be divided into smaller pieces are returned: symbols, numbers,\n-        and number symbols like I and pi. It is possible to request\n-        atoms of any type, however, as demonstrated below.\n+        By default, only objects that have no arguments are returned.\n+        It is possible to request atoms of any type, however, as demonstrated below.\n \n         Examples\n         ========\n@@ -500,16 +498,10 @@ def atoms(self, *types):\n         {I*pi, 2*sin(y + I*pi)}\n \n         \"\"\"\n-        if types:\n-            types = tuple(\n-                [t if isinstance(t, type) else type(t) for t in types])\n-        else:\n-            types = (Atom,)\n-        result = set()\n-        for expr in preorder_traversal(self):\n-            if isinstance(expr, types):\n-                result.add(expr)\n-        return result\n+        if not types:\n+            return {expr for expr in preorder_traversal(self) if not expr.args}\n+        types = tuple(t if isinstance(t, type) else type(t) for t in types)\n+        return {expr for expr in preorder_traversal(self) if isinstance(expr, types)}\n \n     @property\n     def free_symbols(self):\n", "instance_id": "sympy__sympy-18532"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..3ba5e0bfed 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -113,35 +113,20 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n     if total_degree:\n         if min_degree > max_degree:\n             return\n-        if not variables or max_degree == 0:\n-            yield S.One\n+        if not variables:\n+            if min_degree == 0:\n+                yield S.One\n             return\n-        # Force to list in case of passed tuple or other incompatible collection\n-        variables = list(variables) + [S.One]\n+            return\n+        variables = list(variables)\n         if all(variable.is_commutative for variable in variables):\n-            monomials_list_comm = []\n-            for item in combinations_with_replacement(variables, max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_comm.append(Mul(*item))\n-            yield from set(monomials_list_comm)\n+            for total_degree in range(min_degree, max_degree + 1):\n+                for item in combinations_with_replacement(variables, total_degree):\n+                    yield Mul(*item)\n         else:\n-            monomials_list_non_comm = []\n-            for item in product(variables, repeat=max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_non_comm.append(Mul(*item))\n-            yield from set(monomials_list_non_comm)\n+            for total_degree in range(min_degree, max_degree + 1):\n+                for item in product(variables, repeat=total_degree):\n+                    yield Mul(*item)\n     else:\n         if any(min_degrees[i] > max_degrees[i] for i in range(n)):\n             raise ValueError('min_degrees[i] must be <= max_degrees[i] for all i')\n", "instance_id": "sympy__sympy-21847"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 62631f7ff..ff3e35444 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -110,11 +110,13 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n \n \n def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n-    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    \"\"\"Used to convert the :inherited-members: option to auto directives.\"\"\"\n     if arg in (None, True):\n-        return 'object'\n+        return {'object'}\n+    elif isinstance(arg, str):\n+        return {x.strip() for x in arg.split(',') if x.strip()}\n     else:\n-        return arg\n+        raise ValueError(__('invalid value for inherited-members option: %s') % arg)\n \n \n def member_order_option(arg: Any) -> Optional[str]:\n@@ -682,7 +684,7 @@ class Documenter:\n         def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n             if inspect.isclass(self.object):\n                 for cls in self.object.__mro__:\n-                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n+                    if cls.__name__ in self.options.inherited_members and cls != self.object:\n                         # given member is a member of specified *super class*\n                         return True\n                     elif name in cls.__dict__:\n", "instance_id": "sphinx-doc__sphinx-10325"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..2d315dd0c2 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -144,12 +144,19 @@ class BaseFormSet(RenderableFormMixin):\n     @cached_property\n     def management_form(self):\n         \"\"\"Return the ManagementForm instance for this FormSet.\"\"\"\n+        class MinimalRenderer:\n+            form_template_name = \"django/forms/formsets/default.html\"\n+            formset_template_name = \"django/forms/formsets/default.html\"\n+\n+            def render(self, *args, **kwargs):\n+                return \"\"\n+\n         if self.is_bound:\n             form = ManagementForm(\n                 self.data,\n                 auto_id=self.auto_id,\n                 prefix=self.prefix,\n-                renderer=self.renderer,\n+                renderer=MinimalRenderer(),\n             )\n             form.full_clean()\n         else:\n@@ -162,7 +169,7 @@ class BaseFormSet(RenderableFormMixin):\n                     MIN_NUM_FORM_COUNT: self.min_num,\n                     MAX_NUM_FORM_COUNT: self.max_num,\n                 },\n-                renderer=self.renderer,\n+                renderer=MinimalRenderer(),\n             )\n         return form\n \n", "instance_id": "django__django-15902"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 2428218696..0e291fbe8a 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -941,6 +941,18 @@ class Model(metaclass=ModelBase):\n                 # cached relationship.\n                 if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n                     field.delete_cached_value(self)\n+                # Ensure the related object's primary key is set before saving.\n+                if obj.pk is None:\n+                    raise ValueError(\n+                        \"%s() prohibited to prevent data loss due to unsaved \"\n+                        \"related object '%s'.\" % (operation_name, field.name)\n+                    )\n+                # Ensure the related object's primary key is set before saving.\n+                if obj.pk is None:\n+                    raise ValueError(\n+                        \"%s() prohibited to prevent data loss due to unsaved \"\n+                        \"related object '%s'.\" % (operation_name, field.name)\n+                    )\n \n     def delete(self, using=None, keep_parents=False):\n         using = using or router.db_for_write(self.__class__, instance=self)\ndiff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex 872a4c98dc..a95179bd62 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -254,6 +254,15 @@ class ForwardManyToOneDescriptor:\n         # Set the values of the related field.\n         else:\n             for lh_field, rh_field in self.field.related_fields:\n+                if getattr(value, rh_field.attname) is None:\n+                    raise ValueError(\n+                        'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance with a primary key.' % (\n+                            value,\n+                            instance._meta.object_name,\n+                            self.field.name,\n+                            self.field.remote_field.model._meta.object_name,\n+                        )\n+                    )\n                 setattr(instance, lh_field.attname, getattr(value, rh_field.attname))\n \n         # Set the related instance cache used by __get__ to avoid an SQL query\n@@ -317,10 +326,20 @@ class ForwardOneToOneDescriptor(ForwardManyToOneDescriptor):\n                 field for field in opts.concrete_fields\n                 if field.primary_key and field.remote_field\n             ]\n-            for field in inherited_pk_fields:\n-                rel_model_pk_name = field.remote_field.model._meta.pk.attname\n-                raw_value = getattr(value, rel_model_pk_name) if value is not None else None\n-                setattr(instance, rel_model_pk_name, raw_value)\n+            if value is not None:\n+                for field in inherited_pk_fields:\n+                    rel_model_pk_name = field.remote_field.model._meta.pk.attname\n+                    raw_value = getattr(value, rel_model_pk_name)\n+                    if raw_value is None:\n+                        raise ValueError(\n+                            'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance with a primary key.' % (\n+                                value,\n+                                instance._meta.object_name,\n+                                self.field.name,\n+                                self.field.remote_field.model._meta.object_name,\n+                            )\n+                        )\n+                    setattr(instance, rel_model_pk_name, raw_value)\n \n \n class ReverseOneToOneDescriptor:\n", "instance_id": "django__django-13964"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/functions/elementary/trigonometric.py b/sympy/functions/elementary/trigonometric.py\nindex da2e919375..8be3b68311 100644\n--- a/sympy/functions/elementary/trigonometric.py\n+++ b/sympy/functions/elementary/trigonometric.py\n@@ -391,6 +391,8 @@ def _eval_rewrite_as_Pow(self, arg, **kwargs):\n             return I*x**-I / 2 - I*x**I /2\n \n     def _eval_rewrite_as_cos(self, arg, **kwargs):\n+        if arg.is_Rational:\n+            return cos(arg - S.Pi / 2, evaluate=False)\n         return cos(arg - S.Pi / 2, evaluate=False)\n \n     def _eval_rewrite_as_tan(self, arg, **kwargs):\n@@ -694,6 +696,8 @@ def _eval_rewrite_as_Pow(self, arg, **kwargs):\n             return x**I/2 + x**-I/2\n \n     def _eval_rewrite_as_sin(self, arg, **kwargs):\n+        if arg.is_Rational:\n+            return sin(arg + S.Pi / 2, evaluate=False)\n         return sin(arg + S.Pi / 2, evaluate=False)\n \n     def _eval_rewrite_as_tan(self, arg, **kwargs):\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 421bfba0a7..c79ee5d5b1 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -13,7 +13,7 @@\n from sympy.core.rules import Transform\n from sympy.core.evaluate import global_evaluate\n from sympy.functions import (\n-    gamma, exp, sqrt, log, exp_polar, piecewise_fold)\n+    gamma, exp, sqrt, log, exp_polar, piecewise_fold, cos, sin)\n from sympy.core.sympify import _sympify\n from sympy.functions.elementary.exponential import ExpBase\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n@@ -585,6 +585,11 @@ def shorter(*choices):\n \n     if expr.has(TrigonometricFunction, HyperbolicFunction):\n         expr = trigsimp(expr, deep=True)\n+        # Additional simplification for trigonometric functions with rational arguments\n+        expr = expr.replace(\n+            lambda arg: isinstance(arg, TrigonometricFunction) and arg.args[0].is_Rational,\n+            lambda arg: arg.rewrite(cos).rewrite(sin)\n+        )\n \n     if expr.has(log):\n         expr = shorter(expand_log(expr, deep=True), logcombine(expr))\n", "instance_id": "sympy__sympy-15346"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autosummary/__init__.py b/sphinx/ext/autosummary/__init__.py\nindex 0cdd88feb..82f9b7f7c 100644\n--- a/sphinx/ext/autosummary/__init__.py\n+++ b/sphinx/ext/autosummary/__init__.py\n@@ -241,7 +241,7 @@ class Autosummary(SphinxDirective):\n \n         names = [x.strip().split()[0] for x in self.content\n                  if x.strip() and re.search(r'^[~a-zA-Z_]', x.strip()[0])]\n-        items = self.get_items(names)\n+        items = self.get_items(names, self.config.autosummary_imported_members)\n         nodes = self.get_table(items)\n \n         if 'toctree' in self.options:\n@@ -282,7 +282,7 @@ class Autosummary(SphinxDirective):\n \n         return nodes\n \n-    def get_items(self, names: List[str]) -> List[Tuple[str, str, str, str]]:\n+    def get_items(self, names: List[str], imported_members: bool) -> List[Tuple[str, str, str, str]]:\n         \"\"\"Try to import the given names, and return a list of\n         ``[(name, signature, summary_string, real_name), ...]``.\n         \"\"\"\n@@ -305,6 +305,9 @@ class Autosummary(SphinxDirective):\n                 logger.warning(__('autosummary: failed to import %s'), name)\n                 continue\n \n+            if not imported_members and hasattr(obj, '__module__') and obj.__module__ != modname:\n+                continue\n+\n             self.bridge.result = StringList()  # initialize for each documenter\n             full_name = real_name\n             if not isinstance(obj, ModuleType):\n@@ -512,10 +515,16 @@ def extract_summary(doc: List[str], document: Any) -> str:\n         return ''\n \n     # parse the docstring\n-    state_machine = RSTStateMachine(state_classes, 'Body')\n-    node = new_document('', document.settings)\n-    node.reporter = NullReporter()\n-    state_machine.run(doc, node)\n+    try:\n+        state_machine = RSTStateMachine(state_classes, 'Body')\n+        node = new_document('', document.settings)\n+        node.reporter = NullReporter()\n+        state_machine.run(doc, node)\n+    except ValueError as e:\n+        if str(e) == \"Empty module name\":\n+            return doc[0].strip()\n+        else:\n+            raise\n \n     if not isinstance(node[0], nodes.paragraph):\n         # document starts with non-paragraph: pick up the first line\n@@ -759,13 +768,15 @@ def process_generate_options(app: Sphinx) -> None:\n def setup(app: Sphinx) -> Dict[str, Any]:\n     # I need autodoc\n     app.setup_extension('sphinx.ext.autodoc')\n-    app.add_node(autosummary_toc,\n+    if not hasattr(app.registry, 'autosummary_toc'):\n+        app.add_node(autosummary_toc,\n                  html=(autosummary_toc_visit_html, autosummary_noop),\n                  latex=(autosummary_noop, autosummary_noop),\n                  text=(autosummary_noop, autosummary_noop),\n                  man=(autosummary_noop, autosummary_noop),\n                  texinfo=(autosummary_noop, autosummary_noop))\n-    app.add_node(autosummary_table,\n+    if not hasattr(app.registry, 'autosummary_table'):\n+        app.add_node(autosummary_table,\n                  html=(autosummary_table_visit_html, autosummary_noop),\n                  latex=(autosummary_noop, autosummary_noop),\n                  text=(autosummary_noop, autosummary_noop),\ndiff --git a/sphinx/ext/autosummary/generate.py b/sphinx/ext/autosummary/generate.py\nindex a57c73fb7..0c077e0c9 100644\n--- a/sphinx/ext/autosummary/generate.py\n+++ b/sphinx/ext/autosummary/generate.py\n@@ -247,12 +247,13 @@ def generate_autosummary_content(name: str, obj: Any, parent: Any,\n \n     if doc.objtype == 'module':\n         ns['members'] = dir(obj)\n-        ns['functions'], ns['all_functions'] = \\\n-            get_members(obj, {'function'}, imported=imported_members)\n-        ns['classes'], ns['all_classes'] = \\\n-            get_members(obj, {'class'}, imported=imported_members)\n-        ns['exceptions'], ns['all_exceptions'] = \\\n-            get_members(obj, {'exception'}, imported=imported_members)\n+        ns['functions'], ns['all_functions'] = get_members(obj, {'function'}, imported=imported_members)\n+        ns['classes'], ns['all_classes'] = get_members(obj, {'class'}, imported=imported_members)\n+        ns['exceptions'], ns['all_exceptions'] = get_members(obj, {'exception'}, imported=imported_members)\n+        if not imported_members:\n+            ns['functions'] = [f for f in ns['functions'] if getattr(obj, f).__module__ == obj.__name__]\n+            ns['classes'] = [c for c in ns['classes'] if getattr(obj, c).__module__ == obj.__name__]\n+            ns['exceptions'] = [e for e in ns['exceptions'] if getattr(obj, e).__module__ == obj.__name__]\n         ns['attributes'], ns['all_attributes'] = \\\n             get_module_attrs(ns['members'])\n         ispackage = hasattr(obj, '__path__')\n", "instance_id": "sphinx-doc__sphinx-7686"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/xarray/core/groupby.py b/xarray/core/groupby.py\nindex 8a097251..af5abd9a 100644\n--- a/xarray/core/groupby.py\n+++ b/xarray/core/groupby.py\n@@ -436,7 +436,7 @@ class GroupBy(SupportsArithmetic):\n         return zip(self._unique_coord.values, self._iter_grouped())\n \n     def __repr__(self):\n-        return \"{}, grouped over {!r} \\n{!r} groups with labels {}.\".format(\n+        return \"{}, grouped over {!r}\\n{!r} groups with labels {}.\".format(\n             self.__class__.__name__,\n             self._unique_coord.name,\n             self._unique_coord.size,\n", "instance_id": "pydata__xarray-5131"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..7b0f88806c 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -967,8 +967,23 @@ class RenameIndex(IndexOperation):\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n-            return\n+            from_model = from_state.apps.get_model(app_label, self.model_name)\n+            columns = [\n+                from_model._meta.get_field(field).column for field in self.old_fields\n+            ]\n+            matching_index_name = schema_editor._constraint_names(\n+                from_model, column_names=columns, index=True\n+            )\n+            if len(matching_index_name) != 1:\n+                raise ValueError(\n+                    \"Found wrong number (%s) of indexes for %s(%s).\"\n+                    % (\n+                        len(matching_index_name),\n+                        from_model._meta.db_table,\n+                        \", \".join(columns),\n+                    )\n+                )\n+            self.old_name = matching_index_name[0]\n \n         self.new_name_lower, self.old_name_lower = (\n             self.old_name_lower,\n", "instance_id": "django__django-15695"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..302610e7 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,26 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+    rule_domains = [\n+        f\"{rule.subdomain}.{current_app.config['SERVER_NAME']}\" if rule.subdomain else current_app.config['SERVER_NAME']\n+        for rule in rules\n+    ]\n+\n+    headers = (\"Domain\", \"Endpoint\", \"Methods\", \"Rule\")\n     widths = (\n+        max(len(domain) for domain in rule_domains),\n         max(len(rule.endpoint) for rule in rules),\n         max(len(methods) for methods in rule_methods),\n         max(len(rule.rule) for rule in rules),\n     )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n-    for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+    for rule, methods, domain in zip(rules, rule_methods, rule_domains):\n+        click.echo(row.format(domain, rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\n", "instance_id": "pallets__flask-5063"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..a5d8e0d5e6 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,10 +501,11 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n-        if (rv.exp < 0) == True:\n-            return rv\n-        if (rv.exp > max) == True:\n-            return rv\n+        if rv.exp.is_real:\n+            if (rv.exp < 0) == True:\n+                return rv\n+            if (rv.exp > max) == True:\n+                return rv\n         if rv.exp == 2:\n             return h(g(rv.base.args[0])**2)\n         else:\n", "instance_id": "sympy__sympy-17139"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 7d226955d5..0d46b5f31a 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -264,12 +264,13 @@ class TypeSerializer(BaseSerializer):\n         for case, string, imports in special_cases:\n             if case is self.value:\n                 return string, set(imports)\n-        if hasattr(self.value, \"__module__\"):\n+        if hasattr(self.value, \"__module__\") and hasattr(self.value, \"__qualname__\"):\n             module = self.value.__module__\n+            qualname = self.value.__qualname__\n             if module == builtins.__name__:\n-                return self.value.__name__, set()\n+                return qualname, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, qualname), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n", "instance_id": "django__django-12125"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 7ca0d68fae..f37ad8447e 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -103,7 +103,8 @@ def iter_all_python_module_files():\n     # aren't loaded on the fly.\n     keys = sorted(sys.modules)\n     modules = tuple(m for m in map(sys.modules.__getitem__, keys) if not isinstance(m, weakref.ProxyTypes))\n-    return iter_modules_and_files(modules, frozenset(_error_files))\n+    manage_py_path = Path(sys.argv[0]).resolve().absolute()\n+    return iter_modules_and_files(modules, frozenset(_error_files).union({manage_py_path}))\n \n \n @functools.lru_cache(maxsize=1)\n", "instance_id": "django__django-11422"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1a55d3d417..507d679ce0 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -764,12 +764,10 @@ class Field(RegisterLookupMixin):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n-                setattr(\n-                    cls,\n-                    'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self),\n-                )\n+            def get_display(instance):\n+                value = getattr(instance, self.attname)\n+                return dict(self.flatchoices).get(value, value)\n+            setattr(cls, 'get_%s_display' % self.name, get_display)\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n", "instance_id": "django__django-12284"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/style/core.py b/lib/matplotlib/style/core.py\nindex fb0a5426e6..8affa4c203 100644\n--- a/lib/matplotlib/style/core.py\n+++ b/lib/matplotlib/style/core.py\n@@ -257,5 +257,28 @@ def reload_library():\n     library = update_user_library(_base_library)\n     available[:] = sorted(library.keys())\n \n+    # Add deprecated seaborn styles with their new names\n+    seaborn_styles = [\n+        \"seaborn\",\n+        \"seaborn-bright\",\n+        \"seaborn-colorblind\",\n+        \"seaborn-dark\",\n+        \"seaborn-darkgrid\",\n+        \"seaborn-dark-palette\",\n+        \"seaborn-deep\",\n+        \"seaborn-muted\",\n+        \"seaborn-notebook\",\n+        \"seaborn-paper\",\n+        \"seaborn-pastel\",\n+        \"seaborn-poster\",\n+        \"seaborn-talk\",\n+        \"seaborn-ticks\",\n+        \"seaborn-white\",\n+        \"seaborn-whitegrid\",\n+    ]\n+    for style in seaborn_styles:\n+        if style in library:\n+            library[f\"seaborn-v0_8-{style}\"] = library[style]\n+\n \n reload_library()\n", "instance_id": "matplotlib__matplotlib-24265"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 75349099..1358d805 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -2102,6 +2102,10 @@ def pairplot(\n     diag_kws = {} if diag_kws is None else diag_kws.copy()\n     grid_kws = {} if grid_kws is None else grid_kws.copy()\n \n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n     # Resolve \"auto\" diag kind\n     if diag_kind == \"auto\":\n         if hue is None:\n", "instance_id": "mwaskom__seaborn-3407"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..727586d6ed 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -185,7 +185,19 @@ class Axes3D(Axes):\n                 \"other Axes classes.\")\n             fig.add_axes(self)\n \n-    def set_axis_off(self):\n+    def set_visible(self, b):\n+        \"\"\"\n+        Set the visibility of the axes.\n+        \n+        Parameters\n+        ----------\n+        b : bool\n+            Visibility state. If False, the axes will be hidden.\n+        \"\"\"\n+        super().set_visible(b)\n+        for axis in self._axis_map.values():\n+            axis.set_visible(b)\n+        self.stale = True\n         self._axis3don = False\n         self.stale = True\n \n", "instance_id": "matplotlib__matplotlib-23314"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/writers/html.py b/sphinx/writers/html.py\nindex 4375bf326..d94e029d5 100644\n--- a/sphinx/writers/html.py\n+++ b/sphinx/writers/html.py\n@@ -79,10 +79,15 @@ class HTMLWriter(Writer):\n         self.clean_meta = ''.join(self.visitor.meta[2:])\n \n \n+SYMBOLS_SECTION_NAME = \"Symbols\"\n+\n class HTMLTranslator(SphinxTranslator, BaseTranslator):\n     \"\"\"\n     Our custom HTML translator.\n     \"\"\"\n+    def __init__(self, *args: Any) -> None:\n+        super().__init__(*args)\n+        self.symbols_section_added = False\n \n     builder = None  # type: StandaloneHTMLBuilder\n \n@@ -639,6 +644,10 @@ class HTMLTranslator(SphinxTranslator, BaseTranslator):\n         raise nodes.SkipNode\n \n     def visit_index(self, node: Element) -> None:\n+        if not self.symbols_section_added:\n+            self.body.append(self.starttag(node, 'div', CLASS='section'))\n+            self.body.append('<h1>%s</h1>' % SYMBOLS_SECTION_NAME)\n+            self.symbols_section_added = True\n         raise nodes.SkipNode\n \n     def visit_tabular_col_spec(self, node: Element) -> None:\n", "instance_id": "sphinx-doc__sphinx-7975"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..948ef210c6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[\\w][\\w\\d]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n", "instance_id": "sympy__sympy-24102"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 9e5b903d59..a74fb07097 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -53,6 +53,8 @@ from . import legend_handler\n class DraggableLegend(DraggableOffsetBox):\n     def __init__(self, legend, use_blit=False, update=\"loc\"):\n         \"\"\"\n+        draggable : bool, default: False\n+            If True, the legend will be draggable.\n         Wrapper around a `.Legend` to support mouse dragging.\n \n         Parameters\n@@ -342,6 +344,7 @@ class Legend(Artist):\n         title_fontproperties=None,  # properties for the legend title\n         alignment=\"center\",       # control the alignment within the legend box\n         *,\n+        draggable=False,\n         ncol=1  # synonym for ncols (backward compatibility)\n     ):\n         \"\"\"\n@@ -538,6 +541,8 @@ class Legend(Artist):\n \n         self.set_title(title, prop=title_prop_fp)\n         self._draggable = None\n+        self.set_draggable(draggable)\n+        self.set_draggable(draggable)\n \n         # set the text color\n \n", "instance_id": "matplotlib__matplotlib-23913"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..b7852ed0c9 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -895,28 +895,23 @@ def __new__(cls, *args, **kwargs):\n         # counting starts from 1.\n \n         temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n+        if is_cycle:\n+            # Apply cycles in left-to-right order\n+            c = Cycle()\n+            for ci in args:\n+                c = c(*ci)\n+            aform = c.list()\n+        else:\n+            if has_dups(temp):\n                 raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n+            temp = set(temp)\n \n         if not is_cycle and \\\n                 any(i not in temp for i in range(len(temp))):\n             raise ValueError(\"Integers 0 through %s must be present.\" %\n                              max(temp))\n \n-        if is_cycle:\n-            # it's not necessarily canonical so we won't store\n-            # it -- use the array form instead\n-            c = Cycle()\n-            for ci in args:\n-                c = c(*ci)\n-            aform = c.list()\n-        else:\n-            aform = list(args)\n+        aform = list(args)\n         if size and size > len(aform):\n             # don't allow for truncation of permutation which\n             # might split a cycle and lead to an invalid aform\n", "instance_id": "sympy__sympy-12481"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\nindex 24e453a73..2fc5047d4 100644\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -82,7 +82,8 @@ def _config_initialization(\n     if unrecognized_options:\n         msg = \", \".join(unrecognized_options)\n         linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+        print(_UnrecognizedOptionError(options=unrecognized_options), file=sys.stderr)\n+        sys.exit(32)\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\ndiff --git a/pylint/config/exceptions.py b/pylint/config/exceptions.py\nindex 74a001c24..a5fadc5e2 100644\n--- a/pylint/config/exceptions.py\n+++ b/pylint/config/exceptions.py\n@@ -16,7 +16,11 @@ class _UnrecognizedOptionError(Exception):\n \n     def __init__(self, options: list[str], *args: object) -> None:\n         self.options = options\n-        super().__init__(*args)\n+        self.message = f\"Unrecognized option(s) found: {', '.join(options)}\"\n+        super().__init__(self.message, *args)\n+\n+    def __str__(self) -> str:\n+        return self.message\n \n \n class ArgumentPreprocessingError(Exception):\n", "instance_id": "pylint-dev__pylint-6506"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 02aa32b207..fadc759cb8 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -125,28 +125,24 @@ class Media:\n         in a certain order. In JavaScript you may not be able to reference a\n         global or in CSS you might want to override a style.\n         \"\"\"\n-        # Start with a copy of list_1.\n-        combined_list = list(list_1)\n-        last_insert_index = len(list_1)\n-        # Walk list_2 in reverse, inserting each element into combined_list if\n-        # it doesn't already exist.\n-        for path in reversed(list_2):\n-            try:\n-                # Does path already exist in the list?\n-                index = combined_list.index(path)\n-            except ValueError:\n-                # Add path to combined_list since it doesn't exist.\n-                combined_list.insert(last_insert_index, path)\n+        combined_list = []\n+        seen = set()\n+        conflict_pairs = set()\n+\n+        for path in list_1 + list_2:\n+            if path not in seen:\n+                combined_list.append(path)\n+                seen.add(path)\n             else:\n-                if index > last_insert_index:\n-                    warnings.warn(\n-                        'Detected duplicate Media files in an opposite order:\\n'\n-                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n-                        MediaOrderConflictWarning,\n-                    )\n-                # path already exists in the list. Update last_insert_index so\n-                # that the following elements are inserted in front of this one.\n-                last_insert_index = index\n+                conflict_pairs.add((combined_list[-1], path))\n+\n+        for pair in conflict_pairs:\n+            warnings.warn(\n+                'Detected duplicate Media files in an opposite order:\\n'\n+                '%s\\n%s' % pair,\n+                MediaOrderConflictWarning,\n+            )\n+\n         return combined_list\n \n     def __add__(self, other):\n", "instance_id": "django__django-11019"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 984398c760..1ba2d523c5 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -299,6 +299,8 @@ def __new__(cls, b, e, evaluate=None):\n                 return b\n             elif e == -1 and not b:\n                 return S.ComplexInfinity\n+            elif b is S.Zero and e.is_negative and e.is_infinite:\n+                return S.ComplexInfinity\n             # Only perform autosimplification if exponent or base is a Symbol or number\n             elif (b.is_Symbol or b.is_number) and (e.is_Symbol or e.is_number) and\\\n                 e.is_integer and _coeff_isneg(b):\n", "instance_id": "sympy__sympy-20212"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..997ccb57ff 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -58,17 +58,15 @@ class Q(tree.Node):\n         obj.add(other, conn)\n         return obj\n \n-    def __or__(self, other):\n+    def __ror__(self, other):\n+        return self._combine(other, self.OR)\n         return self._combine(other, self.OR)\n \n     def __and__(self, other):\n         return self._combine(other, self.AND)\n \n-    def __invert__(self):\n-        obj = type(self)()\n-        obj.add(self, self.AND)\n-        obj.negate()\n-        return obj\n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n \n     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n         # We must promote any new joins to left outer joins so that when Q is\n", "instance_id": "django__django-14017"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 03cf57a30b..709480c338 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1073,7 +1073,8 @@ def __new__(cls, *args, **kwargs):\n             args = list(cls._new_args_filter(args))\n             return simplify_union(args)\n \n-        args = list(ordered(args, Set._infimum_key))\n+        # Remove duplicates\n+        args = list(ordered(set(args), Set._infimum_key))\n \n         obj = Basic.__new__(cls, *args)\n         obj._argset = frozenset(args)\n", "instance_id": "sympy__sympy-16988"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\nindex 6e504a3057..641066ea44 100644\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -450,7 +450,7 @@ def preprocess(cls, domain):\n             if r is not None:\n                 return sympy.polys.domains.FF(int(r.groups()[1]))\n \n-            r = cls._re_polynomial.match(domain)\n+            r = cls._re_polynomial.match(domain) or cls._re_fraction.match(domain)\n \n             if r is not None:\n                 ground, gens = r.groups()\n@@ -462,17 +462,18 @@ def preprocess(cls, domain):\n                 else:\n                     return sympy.polys.domains.QQ.poly_ring(*gens)\n \n-            r = cls._re_fraction.match(domain)\n-\n             if r is not None:\n                 ground, gens = r.groups()\n-\n                 gens = list(map(sympify, gens.split(',')))\n \n                 if ground in ['Z', 'ZZ']:\n-                    return sympy.polys.domains.ZZ.frac_field(*gens)\n-                else:\n-                    return sympy.polys.domains.QQ.frac_field(*gens)\n+                    return sympy.polys.domains.ZZ.poly_ring(*gens)\n+                elif ground in ['Q', 'QQ']:\n+                    return sympy.polys.domains.QQ.poly_ring(*gens)\n+                elif ground in ['R', 'RR']:\n+                    return sympy.polys.domains.RR.poly_ring(*gens)\n+                elif ground in ['C', 'CC']:\n+                    return sympy.polys.domains.CC.poly_ring(*gens)\n \n             r = cls._re_algebraic.match(domain)\n \n@@ -480,7 +481,7 @@ def preprocess(cls, domain):\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+        raise OptionError(f\"Expected a valid domain specification, got '{domain}'.\")\n \n     @classmethod\n     def postprocess(cls, options):\n", "instance_id": "sympy__sympy-14396"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..7dbffaac36 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,12 +26,18 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n+                self.serialize_result(obj, to_field_name) for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n \n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"Convert the object to a dictionary representation for the response.\"\"\"\n+        return {\n+            'id': str(getattr(obj, to_field_name)),\n+            'text': str(obj)\n+        }\n+\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n         return self.model_admin.get_paginator(self.request, *args, **kwargs)\n", "instance_id": "django__django-14752"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex b6adb7ceb..598df2962 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -108,6 +108,11 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n             obj = attrgetter(obj, mangled_name)\n             logger.debug('[autodoc] => %r', obj)\n             object_name = attrname\n+        # Check if __all__ is defined and empty\n+        if hasattr(module, '__all__') and not module.__all__:\n+            logger.debug('[autodoc] __all__ is defined and empty, ignoring members')\n+            return [module, parent, object_name, None]\n+\n         return [module, parent, object_name, obj]\n     except (AttributeError, ImportError) as exc:\n         if isinstance(exc, AttributeError) and exc_on_importing:\n", "instance_id": "sphinx-doc__sphinx-8595"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..3bb7227fb0 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -301,13 +301,13 @@ def _separable(transform):\n         An array of shape (transform.n_outputs,) of boolean type\n         Each element represents the separablity of the corresponding output.\n     \"\"\"\n-    if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n-        return transform_matrix\n-    elif isinstance(transform, CompoundModel):\n+    if isinstance(transform, CompoundModel):\n         sepleft = _separable(transform.left)\n         sepright = _separable(transform.right)\n         return _operators[transform.op](sepleft, sepright)\n     elif isinstance(transform, Model):\n+        if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n+            return transform_matrix\n         return _coord_matrix(transform, 'left', transform.n_outputs)\n \n \n", "instance_id": "astropy__astropy-12907"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n", "instance_id": "scikit-learn__scikit-learn-13779"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/calibration.py b/sklearn/calibration.py\nindex 2c4a33616..2c1559358 100644\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -760,7 +760,10 @@ class _CalibratedClassifier:\n                 # When binary, `predictions` consists only of predictions for\n                 # clf.classes_[1] but `pos_class_indices` = 0\n                 class_idx += 1\n-            proba[:, class_idx] = calibrator.predict(this_pred)\n+            this_pred_proba = calibrator.predict(this_pred)\n+            if hasattr(this_pred_proba, \"to_numpy\"):\n+                this_pred_proba = this_pred_proba.to_numpy()\n+            proba[:, class_idx] = this_pred_proba\n \n         # Normalize the probabilities\n         if n_classes == 2:\n", "instance_id": "scikit-learn__scikit-learn-25500"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\nindex 7e2b64b630..94dd547b67 100644\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -218,6 +218,8 @@ class Artist:\n         # remove the unpicklable remove method, this will get re-added on load\n         # (by the Axes) if the artist lives on an Axes.\n         d['stale_callback'] = None\n+        if hasattr(self, '_draggable'):\n+            d['_draggable'] = None\n         return d\n \n     def remove(self):\n@@ -1159,6 +1161,8 @@ class Artist:\n     def update_from(self, other):\n         \"\"\"Copy properties from *other* to *self*.\"\"\"\n         self._transform = other._transform\n+        if hasattr(other, '_draggable'):\n+            self._draggable = other._draggable\n         self._transformSet = other._transformSet\n         self._visible = other._visible\n         self._alpha = other._alpha\ndiff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..ec9b51010e 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -50,6 +50,8 @@ from matplotlib.container import ErrorbarContainer, BarContainer, StemContainer\n from . import legend_handler\n \n \n+import pickle\n+\n class DraggableLegend(DraggableOffsetBox):\n     def __init__(self, legend, use_blit=False, update=\"loc\"):\n         \"\"\"\n@@ -93,6 +95,16 @@ class DraggableLegend(DraggableOffsetBox):\n         loc_in_bbox = self.legend.axes.transAxes.transform(loc_in_canvas)\n         self.legend.set_bbox_to_anchor(loc_in_bbox)\n \n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpicklable entries.\n+        del state['legend']\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self.legend = None  # This will be set by the Legend class during unpickling.\n+\n \n _legend_kw_doc_base = \"\"\"\n bbox_to_anchor : `.BboxBase`, 2-tuple, or 4-tuple of floats\n@@ -614,6 +626,20 @@ class Legend(Artist):\n         self._draggable = None\n         self.set_draggable(state=draggable)\n \n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the unpicklable entries.\n+        if self._draggable is not None:\n+            state['_draggable'] = None\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        if self._draggable is not None:\n+            self.set_draggable(True)\n+\n+        labelcolor = None\n+\n         # set the text color\n \n         color_getters = {  # getter function depends on line or patch\n", "instance_id": "matplotlib__matplotlib-25311"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 8e55bd092d..35d0a47edf 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -453,7 +453,10 @@ class Query(BaseExpression):\n                     if getattr(annotation, 'contains_aggregate', True)\n                 )\n                 if inner_query.default_cols and has_existing_aggregate_annotations:\n-                    inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                    inner_query.group_by = tuple(\n+                        set(inner_query.group_by or ()) |\n+                        {self.model._meta.pk.get_col(inner_query.get_initial_alias())}\n+                    )\n                 inner_query.default_cols = False\n \n             relabels = {t: 'subquery' for t in inner_query.alias_map}\n", "instance_id": "django__django-11797"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..e59affefb 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -286,12 +286,15 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n \n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+        if n_SV == 0:\n+            self.dual_coef_ = sp.csr_matrix((n_class, 0))\n+        else:\n+            dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n+            self.dual_coef_ = sp.csr_matrix(\n+                (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+                (n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n", "instance_id": "scikit-learn__scikit-learn-14894"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex dadd4acfa1..153229e677 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2040,7 +2040,10 @@ class InlineModelAdmin(BaseModelAdmin):\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            if self.verbose_name is not None:\n+                self.verbose_name_plural = f\"{self.verbose_name}s\"\n+            else:\n+                self.verbose_name_plural = self.model._meta.verbose_name_plural\n \n     @property\n     def media(self):\n", "instance_id": "django__django-13710"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d65141b834..fa86cb24a6 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -842,6 +842,9 @@ class Query(BaseExpression):\n         self.annotations = self.annotations and {\n             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()\n         }\n+        # Ensure order_by takes precedence over model's default ordering\n+        if self.order_by:\n+            self.default_ordering = False\n \n         # 2. Rename the alias in the internal table/alias datastructures.\n         for old_alias, new_alias in change_map.items():\n@@ -1928,7 +1931,18 @@ class Query(BaseExpression):\n         if errors:\n             raise FieldError('Invalid order_by arguments: %s' % errors)\n         if ordering:\n-            self.order_by += ordering\n+            # Handle self-referencing foreign keys correctly\n+            new_ordering = []\n+            for item in ordering:\n+                if isinstance(item, str) and '__' in item:\n+                    parts = item.split(LOOKUP_SEP)\n+                    if len(parts) > 1 and parts[-1] == 'id' and parts[-2] == parts[-3]:\n+                        new_ordering.append(LOOKUP_SEP.join(parts[:-1]))\n+                    else:\n+                        new_ordering.append(item)\n+                else:\n+                    new_ordering.append(item)\n+            self.order_by += tuple(new_ordering)\n         else:\n             self.default_ordering = False\n \n", "instance_id": "django__django-13033"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 1877c3f92a..fe2f0cc519 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -528,6 +528,11 @@ def _print_IndexedBase(self, expr):\n \n class PythonCodePrinter(AbstractPythonCodePrinter):\n \n+    def _print_Tuple(self, expr):\n+        if len(expr) == 1:\n+            return '({},)'.format(self._print(expr[0]))\n+        return '({})'.format(', '.join(map(self._print, expr)))\n+\n     def _print_sign(self, e):\n         return '(0.0 if {e} == 0 else {f}(1, {e}))'.format(\n             f=self._module_format('math.copysign'), e=self._print(e.args[0]))\n", "instance_id": "sympy__sympy-23262"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex e0eeccefa6..b5a1574b44 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1140,6 +1140,11 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n+        if self.query.combinator:\n+            raise NotSupportedError(\n+                'Calling distinct() after %s() is not supported.'\n+                % self.query.combinator\n+            )\n         obj = self._chain()\n         obj.query.add_distinct_fields(*field_names)\n         return obj\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex bb230647eb..51dde32671 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -643,6 +643,10 @@ class Query(BaseExpression):\n         self.order_by = rhs.order_by or self.order_by\n         self.extra_order_by = rhs.extra_order_by or self.extra_order_by\n \n+        # Ensure distinct fields are applied correctly.\n+        if self.distinct_fields:\n+            self.distinct_fields = tuple(set(self.distinct_fields))\n+\n     def deferred_to_data(self, target, callback):\n         \"\"\"\n         Convert the self.deferred_loading data structure to an alternate data\n", "instance_id": "django__django-12908"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..a92790a03a 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -817,6 +817,8 @@ class MultiWidget(Widget):\n     def is_hidden(self):\n         return all(w.is_hidden for w in self.widgets)\n \n+    add_id_index = True\n+\n     def get_context(self, name, value, attrs):\n         context = super().get_context(name, value, attrs)\n         if self.is_localized:\n@@ -841,18 +843,23 @@ class MultiWidget(Widget):\n                 widget_value = None\n             if id_:\n                 widget_attrs = final_attrs.copy()\n-                widget_attrs['id'] = '%s_%s' % (id_, i)\n+                widget_attrs['id'] = self.id_for_label(id_, i)\n             else:\n                 widget_attrs = final_attrs\n             subwidgets.append(widget.get_context(widget_name, widget_value, widget_attrs)['widget'])\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n+    def id_for_label(self, id_, index='0'):\n+        \"\"\"\n+        Use an incremented id for each subwidget where the main widget\n+        references the zero index.\n+        \"\"\"\n+        if id_ and self.add_id_index:\n+            id_ = '%s_%s' % (id_, index)\n         return id_\n \n+\n     def value_from_datadict(self, data, files, name):\n         return [\n             widget.value_from_datadict(data, files, name + widget_name)\n", "instance_id": "django__django-15061"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex d37d43d5c5..f74b2335b2 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -246,6 +246,7 @@ class BaseCommand:\n     help = \"\"\n \n     # Configuration shortcuts that alter various logic.\n+    help_formatter_class = DjangoHelpFormatter\n     _called_from_command_line = False\n     output_transaction = False  # Whether to wrap the output in a \"BEGIN; COMMIT;\"\n     requires_migrations_checks = False\n@@ -289,7 +290,7 @@ class BaseCommand:\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n+            formatter_class=self.help_formatter_class,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n", "instance_id": "django__django-15781"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/django/core/handlers/exception.py b/django/core/handlers/exception.py\nindex 66443ce560..d620c39158 100644\n--- a/django/core/handlers/exception.py\n+++ b/django/core/handlers/exception.py\n@@ -40,10 +40,7 @@ def convert_exception_to_response(get_response):\n \n def response_for_exception(request, exc):\n     if isinstance(exc, Http404):\n-        if settings.DEBUG:\n-            response = debug.technical_404_response(request, exc)\n-        else:\n-            response = get_exception_response(request, get_resolver(get_urlconf()), 404, exc)\n+        response = get_exception_response(request, get_resolver(get_urlconf()), 404, exc)\n \n     elif isinstance(exc, PermissionDenied):\n         response = get_exception_response(request, get_resolver(get_urlconf()), 403, exc)\ndiff --git a/django/urls/converters.py b/django/urls/converters.py\nindex bb8478e32f..528e54ca81 100644\n--- a/django/urls/converters.py\n+++ b/django/urls/converters.py\n@@ -16,6 +16,9 @@ class StringConverter:\n     regex = '[^/]+'\n \n     def to_python(self, value):\n+        from django.http import Http404\n+        if not value:\n+            raise Http404(\"Value does not match any object.\")\n         return value\n \n     def to_url(self, value):\n", "instance_id": "django__django-11620"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 2903b8995..24f5818dd 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -371,6 +371,14 @@ cookie_re = re.compile(r\"^[ \\t\\f]*#.*coding[:=][ \\t]*[-\\w.]+\")\n BOM_UTF8 = \"\\xef\\xbb\\xbf\"\n \n \n+def _is_all_or_any_call(node):\n+    \"\"\"Check if the node is a call to all() or any().\"\"\"\n+    return (\n+        isinstance(node, ast.Call)\n+        and isinstance(node.func, ast.Name)\n+        and node.func.id in {\"all\", \"any\"}\n+    )\n+\n def _rewrite_test(config, fn):\n     \"\"\"Try to read and rewrite *fn* and return the code object.\"\"\"\n     state = config._assertstate\n@@ -841,13 +849,17 @@ class AssertionRewriter(ast.NodeVisitor):\n         self.push_format_context()\n         # Rewrite assert into a bunch of statements.\n         top_condition, explanation = self.visit(assert_.test)\n-        # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n-        if self.module_path is not None:\n-            self.statements.append(\n-                self.warn_about_none_ast(\n-                    top_condition, module_path=self.module_path, lineno=assert_.lineno\n+        # Unroll all() and any() calls for better reporting\n+        if _is_all_or_any_call(assert_.test):\n+            self.statements.extend(self._unroll_all_any(assert_))\n+        else:\n+            # If in a test module, check if directly asserting None, in order to warn [Issue #3191]\n+            if self.module_path is not None:\n+                self.statements.append(\n+                    self.warn_about_none_ast(\n+                        top_condition, module_path=self.module_path, lineno=assert_.lineno\n+                    )\n                 )\n-            )\n         # Create failure message.\n         body = self.on_failure\n         negation = ast.UnaryOp(ast.Not(), top_condition)\n@@ -878,6 +890,52 @@ class AssertionRewriter(ast.NodeVisitor):\n             set_location(stmt, assert_.lineno, assert_.col_offset)\n         return self.statements\n \n+    def _unroll_all_any(self, assert_):\n+        \"\"\"Unroll all() or any() calls into individual assertions.\"\"\"\n+        call = assert_.test\n+        func_name = call.func.id\n+        iterable = call.args[0]\n+\n+        # Create a new variable to hold the iterable\n+        iter_var = self.variable()\n+        self.statements.append(ast.Assign([ast.Name(iter_var, ast.Store())], iterable))\n+\n+        # Create a for loop to iterate over the elements\n+        loop_var = self.variable()\n+        loop = ast.For(\n+            target=ast.Name(loop_var, ast.Store()),\n+            iter=ast.Name(iter_var, ast.Load()),\n+            body=[],\n+            orelse=[],\n+        )\n+\n+        # Create the condition for the assertion\n+        if func_name == \"all\":\n+            condition = ast.UnaryOp(ast.Not(), ast.Name(loop_var, ast.Load()))\n+        else:  # func_name == \"any\"\n+            condition = ast.Name(loop_var, ast.Load())\n+\n+        # Create the assertion inside the loop\n+        loop.body.append(\n+            ast.If(\n+                test=condition,\n+                body=[\n+                    ast.Raise(\n+                        exc=ast.Call(\n+                            func=ast.Name(id=\"AssertionError\", ctx=ast.Load()),\n+                            args=[ast.Str(s=f\"{func_name}() failed for element: \"), ast.Name(loop_var, ast.Load())],\n+                            keywords=[],\n+                        ),\n+                        cause=None,\n+                    )\n+                ],\n+                orelse=[],\n+            )\n+        )\n+\n+        self.statements.append(loop)\n+        return self.statements\n+\n     def warn_about_none_ast(self, node, module_path, lineno):\n         \"\"\"\n         Returns an AST issuing a warning if the value of node is `None`.\n", "instance_id": "pytest-dev__pytest-5103"}
{"model_name_or_path": "200724-221013", "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex af0815d41d..35f177866b 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2024,6 +2024,9 @@ class Axis(martist.Artist):\n         result = self._set_tick_locations(ticks, minor=minor)\n         if labels is not None:\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n+        else:\n+            # Validate kwargs even if labels are not set\n+            mtext.Text(0, 0, **kwargs)\n         return result\n \n     def _get_tick_boxes_siblings(self, renderer):\n", "instance_id": "matplotlib__matplotlib-24334"}
