{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..e59affefb 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -286,12 +286,15 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n \n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+        if n_SV == 0:\n+            self.dual_coef_ = sp.csr_matrix((n_class, 0))\n+        else:\n+            dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n+            dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                                         dual_coef_indices.size / n_class)\n+            self.dual_coef_ = sp.csr_matrix(\n+                (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+                (n_class, n_SV))\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n", "instance_id": "scikit-learn__scikit-learn-14894"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 157903faf..4beeee1c8 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -667,7 +667,7 @@ class AssertionRewriter(ast.NodeVisitor):\n         # docstrings and __future__ imports, so first figure out where that is.\n         doc = getattr(mod, \"docstring\", None)\n         expect_docstring = doc is None\n-        if doc is not None and self.is_rewrite_disabled(doc):\n+        if isinstance(doc, str) and self.is_rewrite_disabled(doc):\n             return\n         pos = 0\n         item = None\n", "instance_id": "pytest-dev__pytest-11143"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\nindex 1e05aba59..cdd614965 100644\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -111,7 +111,12 @@ class _BaseEncoder(BaseEstimator, TransformerMixin):\n                     # removed later.\n                     X_mask[:, i] = valid_mask\n                     Xi = Xi.copy()\n-                    Xi[~valid_mask] = self.categories_[i][0]\n+                    if X.dtype.kind in {'U', 'S'} and len(self.categories_[i][0]) > X.dtype.itemsize:\n+                        X = X.astype(object)\n+                        Xi = X[:, i]\n+                        Xi[~valid_mask] = self.categories_[i][0]\n+                    else:\n+                        Xi[~valid_mask] = self.categories_[i][0]\n             _, encoded = _encode(Xi, self.categories_[i], encode=True)\n             X_int[:, i] = encoded\n \n", "instance_id": "scikit-learn__scikit-learn-12471"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/parsing/latex/_antlr/latexparser.py b/sympy/parsing/latex/_antlr/latexparser.py\nindex 0fc7e5a7a6..cb0e7c39b9 100644\n--- a/sympy/parsing/latex/_antlr/latexparser.py\n+++ b/sympy/parsing/latex/_antlr/latexparser.py\n@@ -2298,33 +2298,35 @@ def getRuleIndex(self):\n \n \n \n-    def frac(self):\n-\n-        localctx = LaTeXParser.FracContext(self, self._ctx, self.state)\n-        self.enterRule(localctx, 52, self.RULE_frac)\n-        try:\n-            self.enterOuterAlt(localctx, 1)\n-            self.state = 305\n-            self.match(LaTeXParser.CMD_FRAC)\n-            self.state = 306\n-            self.match(LaTeXParser.L_BRACE)\n-            self.state = 307\n-            localctx.upper = self.expr()\n-            self.state = 308\n-            self.match(LaTeXParser.R_BRACE)\n-            self.state = 309\n-            self.match(LaTeXParser.L_BRACE)\n-            self.state = 310\n-            localctx.lower = self.expr()\n-            self.state = 311\n-            self.match(LaTeXParser.R_BRACE)\n-        except RecognitionException as re:\n-            localctx.exception = re\n-            self._errHandler.reportError(self, re)\n-            self._errHandler.recover(self, re)\n-        finally:\n-            self.exitRule()\n-        return localctx\n+def frac(self):\n+\n+    localctx = LaTeXParser.FracContext(self, self._ctx, self.state)\n+    self.enterRule(localctx, 52, self.RULE_frac)\n+    try:\n+        self.enterOuterAlt(localctx, 1)\n+        self.state = 305\n+        self.match(LaTeXParser.CMD_FRAC)\n+        self.state = 306\n+        self.match(LaTeXParser.L_BRACE)\n+        self.state = 307\n+        localctx.upper = self.expr()\n+        self.state = 308\n+        self.match(LaTeXParser.R_BRACE)\n+        self.state = 309\n+        self.match(LaTeXParser.L_BRACE)\n+        self.state = 310\n+        localctx.lower = self.expr()\n+        self.state = 311\n+        self.match(LaTeXParser.R_BRACE)\n+        self.state = 312\n+        self.match(LaTeXParser.R_BRACE)\n+    except RecognitionException as re:\n+        localctx.exception = re\n+        self._errHandler.reportError(self, re)\n+        self._errHandler.recover(self, re)\n+    finally:\n+        self.exitRule()\n+    return localctx\n \n \n     class BinomContext(ParserRuleContext):\n", "instance_id": "sympy__sympy-21612"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 1a55d3d417..e5ce7231de 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -765,11 +765,10 @@ class Field(RegisterLookupMixin):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n             if not hasattr(cls, 'get_%s_display' % self.name):\n-                setattr(\n-                    cls,\n-                    'get_%s_display' % self.name,\n-                    partialmethod(cls._get_FIELD_display, field=self),\n-                )\n+                def get_display(instance):\n+                    value = getattr(instance, self.attname)\n+                    return str(dict(self.flatchoices).get(value, value)) if value in dict(self.flatchoices) else value\n+                setattr(cls, 'get_%s_display' % self.name, get_display)\n \n     def get_filter_kwargs_for_object(self, obj):\n         \"\"\"\n", "instance_id": "django__django-12284"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-12184"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 583c2be647..9fb87dae47 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -18,6 +18,7 @@ import django\n from django.apps import apps\n from django.core.signals import request_finished\n from django.dispatch import Signal\n+from django.conf import settings\n from django.utils.functional import cached_property\n from django.utils.version import get_version_tuple\n \n@@ -294,6 +295,9 @@ class BaseReloader:\n         \"\"\"\n         yield from iter_all_python_module_files()\n         yield from self.extra_files\n+        # Include directories specified in TEMPLATES setting\n+        for template_dir in settings.TEMPLATES[0].get('DIRS', []):\n+            yield Path(template_dir).resolve()\n         if include_globs:\n             for directory, patterns in self.directory_globs.items():\n                 for pattern in patterns:\n", "instance_id": "django__django-15388"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..3ff092f4d0 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -737,6 +737,9 @@ class QuerySet:\n \n         # Clear the result cache, in case this QuerySet gets reused.\n         self._result_cache = None\n+        if not deleted and not _rows_count:\n+            model_labels = {self.model._meta.label}\n+            _rows_count = {label: 0 for label in model_labels}\n         return deleted, _rows_count\n \n     delete.alters_data = True\n", "instance_id": "django__django-12747"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 7bb3fa4706..17d692ff59 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1115,6 +1115,27 @@ class Model(metaclass=ModelBase):\n \n         return errors\n \n+    @classmethod\n+    def _check_unique_constraints_fields(cls):\n+        \"\"\"Check if the fields in UniqueConstraints exist.\"\"\"\n+        errors = []\n+        for constraint in cls._meta.constraints:\n+            if isinstance(constraint, UniqueConstraint):\n+                for field_name in constraint.fields:\n+                    try:\n+                        cls._meta.get_field(field_name)\n+                    except FieldDoesNotExist:\n+                        errors.append(\n+                            checks.Error(\n+                                \"'%s' refers to the nonexistent field '%s'.\" % (\n+                                    constraint.name, field_name,\n+                                ),\n+                                obj=cls,\n+                                id='models.E012',\n+                            )\n+                        )\n+        return errors\n+\n     def _perform_date_checks(self, date_checks):\n         errors = {}\n         for model_class, lookup_type, field, unique_for in date_checks:\n@@ -1280,6 +1301,7 @@ class Model(metaclass=ModelBase):\n                 *cls._check_indexes(databases),\n                 *cls._check_ordering(),\n                 *cls._check_constraints(databases),\n+                *cls._check_unique_constraints_fields(),\n             ]\n \n         return errors\ndiff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 64bd60484e..48070cd5f9 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -78,6 +78,7 @@ class Deferrable(Enum):\n \n class UniqueConstraint(BaseConstraint):\n     def __init__(self, *, fields, name, condition=None, deferrable=None):\n+        from django.core.exceptions import FieldDoesNotExist\n         if not fields:\n             raise ValueError('At least one field is required to define a unique constraint.')\n         if not isinstance(condition, (type(None), Q)):\n@@ -93,6 +94,19 @@ class UniqueConstraint(BaseConstraint):\n         self.fields = tuple(fields)\n         self.condition = condition\n         self.deferrable = deferrable\n+        self.name = name\n+        self._validate_fields()\n+\n+    def _validate_fields(self):\n+        from django.apps import apps\n+        from django.core.exceptions import FieldDoesNotExist\n+\n+        model = apps.get_model(self.model._meta.app_label, self.model._meta.model_name)\n+        for field_name in self.fields:\n+            try:\n+                model._meta.get_field(field_name)\n+            except FieldDoesNotExist:\n+                raise ValueError(f\"Field '{field_name}' does not exist in model '{model._meta.object_name}'\")\n         super().__init__(name)\n \n     def _get_condition_sql(self, model, schema_editor):\n", "instance_id": "django__django-12856"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_list.py b/django/contrib/admin/templatetags/admin_list.py\nindex 9bff84d501..b9afa61a7f 100644\n--- a/django/contrib/admin/templatetags/admin_list.py\n+++ b/django/contrib/admin/templatetags/admin_list.py\n@@ -16,7 +16,7 @@ from django.contrib.admin.views.main import (\n     PAGE_VAR,\n     SEARCH_VAR,\n )\n-from django.core.exceptions import ObjectDoesNotExist\n+from django.core.exceptions import ObjectDoesNotExist, FieldDoesNotExist\n from django.db import models\n from django.template import Library\n from django.template.loader import get_template\n@@ -87,9 +87,12 @@ def result_headers(cl):\n     \"\"\"\n     ordering_field_columns = cl.get_ordering_field_columns()\n     for i, field_name in enumerate(cl.list_display):\n-        text, attr = label_for_field(\n-            field_name, cl.model, model_admin=cl.model_admin, return_attr=True\n-        )\n+        try:\n+            text, attr = label_for_field(\n+                field_name, cl.model, model_admin=cl.model_admin, return_attr=True\n+            )\n+        except FieldDoesNotExist:\n+            text, attr = field_name, None\n         is_field_sortable = cl.sortable_by is None or field_name in cl.sortable_by\n         if attr:\n             field_name = _coerce_field_name(field_name, i)\ndiff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex 5e6a400b6c..c99702d7db 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -376,6 +376,7 @@ def label_for_field(name, model, model_admin=None, return_attr=False, form=None)\n                 if form:\n                     message += \" or %s\" % form.__class__.__name__\n                 raise AttributeError(message)\n+            raise FieldDoesNotExist()\n \n             if hasattr(attr, \"short_description\"):\n                 label = attr.short_description\n", "instance_id": "django__django-16816"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\nindex 02efc7172..03fd0f890 100644\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -30,8 +30,7 @@ import py\n \n import _pytest\n from _pytest._io import TerminalWriter\n-from _pytest._io.saferepr import safeformat\n-from _pytest._io.saferepr import saferepr\n+from _pytest._io.saferepr import safeformat, saferepr, _format_repr_exception\n from _pytest.compat import ATTRS_EQ_FIELD\n from _pytest.compat import overload\n from _pytest.compat import TYPE_CHECKING\n@@ -691,7 +690,10 @@ class FormattedExcinfo:\n         if self.funcargs:\n             args = []\n             for argname, argvalue in entry.frame.getargs(var=True):\n-                args.append((argname, saferepr(argvalue)))\n+                try:\n+                    args.append((argname, saferepr(argvalue)))\n+                except Exception as exc:\n+                    args.append((argname, _format_repr_exception(exc, argvalue)))\n             return ReprFuncArgs(args)\n         return None\n \ndiff --git a/src/_pytest/_io/saferepr.py b/src/_pytest/_io/saferepr.py\nindex 23af4d0bb..96d31ced7 100644\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -79,7 +79,10 @@ def saferepr(obj: Any, maxsize: int = 240) -> str:\n     care to never raise exceptions itself.  This function is a wrapper\n     around the Repr/reprlib functionality of the standard 2.6 lib.\n     \"\"\"\n-    return SafeRepr(maxsize).repr(obj)\n+    try:\n+        return SafeRepr(maxsize).repr(obj)\n+    except Exception as exc:\n+        return _format_repr_exception(exc, obj)\n \n \n class AlwaysDispatchingPrettyPrinter(pprint.PrettyPrinter):\n", "instance_id": "pytest-dev__pytest-7168"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/physics/units/systems/si.py b/sympy/physics/units/systems/si.py\nindex 700495ad9d..20eb85feee 100644\n--- a/sympy/physics/units/systems/si.py\n+++ b/sympy/physics/units/systems/si.py\n@@ -7,7 +7,7 @@\n \n from typing import List\n \n-from sympy.physics.units import DimensionSystem, Dimension, dHg0\n+from sympy.physics.units import DimensionSystem, Dimension, dHg0, Dimensionless\n \n from sympy.physics.units.quantities import Quantity\n \n", "instance_id": "sympy__sympy-24066"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/apps/registry.py b/django/apps/registry.py\nindex 408964a146..2e8b64ead0 100644\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -259,6 +259,12 @@ class Apps:\n         if candidates:\n             return sorted(candidates, key=lambda ac: -len(ac.name))[0]\n \n+    def is_registered_model(self, app_label, model_name):\n+        \"\"\"\n+        Check if a model is registered in the app registry.\n+        \"\"\"\n+        return model_name in self.all_models[app_label]\n+\n     def get_registered_model(self, app_label, model_name):\n         \"\"\"\n         Similar to get_model(), but doesn't require that an app exists with\ndiff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 18ee0b4911..fc46c02ac2 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -313,7 +313,9 @@ class ModelBase(type):\n             return new_class\n \n         new_class._prepare()\n-        new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n+        # Register the model only if it doesn't already exist in the app registry.\n+        if not new_class._meta.apps.is_registered_model(new_class._meta.app_label, new_class._meta.model_name):\n+            new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n         return new_class\n \n     def add_to_class(cls, name, value):\n@@ -1089,6 +1091,31 @@ class Model(metaclass=ModelBase):\n                     key = NON_FIELD_ERRORS\n                 errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))\n \n+        # Allow different apps to have models with the same table name.\n+        seen_db_tables = {}\n+        for model in self.apps.get_models(include_auto_created=True):\n+            if model._meta.db_table in seen_db_tables:\n+                seen_db_tables[model._meta.db_table].append(model)\n+            else:\n+                seen_db_tables[model._meta.db_table] = [model]\n+\n+        for db_table, models in seen_db_tables.items():\n+            if len(models) > 1:\n+                app_labels = {model._meta.app_label for model in models}\n+                if len(app_labels) > 1:\n+                    errors.append(\n+                        checks.Error(\n+                            \"db_table '%s' is used by multiple models: %s.\" % (\n+                                db_table,\n+                                ', '.join(\n+                                    '%s.%s' % (model._meta.app_label, model._meta.object_name)\n+                                    for model in models\n+                                ),\n+                            ),\n+                            obj=models[0],\n+                            id='models.E028',\n+                        )\n+                    )\n         return errors\n \n     def _perform_date_checks(self, date_checks):\n", "instance_id": "django__django-11630"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/lambdarepr.py b/sympy/printing/lambdarepr.py\nindex 8f60434e89..ed586a1940 100644\n--- a/sympy/printing/lambdarepr.py\n+++ b/sympy/printing/lambdarepr.py\n@@ -43,7 +43,8 @@ def _print_BooleanTrue(self, expr):\n     def _print_BooleanFalse(self, expr):\n         return \"False\"\n \n-    def _print_ITE(self, expr):\n+    def _print_Identity(self, expr):\n+        return \"np.eye(%s)\" % expr.shape[0]\n         result = [\n             '((', self._print(expr.args[1]),\n             ') if (', self._print(expr.args[0]),\n", "instance_id": "sympy__sympy-17022"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 89cb000271..61a49269ec 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -727,6 +727,8 @@ class BaseModelFormSet(BaseFormSet):\n                 kwargs[\"initial\"] = self.initial_extra[i - self.initial_form_count()]\n             except IndexError:\n                 pass\n+        if 'empty_permitted' in kwargs:\n+            del kwargs['empty_permitted']\n         form = super()._construct_form(i, **kwargs)\n         if pk_required:\n             form.fields[self.model._meta.pk.name].required = True\n", "instance_id": "django__django-16041"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex c268a56724..51ad60d734 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -1168,6 +1168,11 @@ if os.environ.get('MPLBACKEND'):\n \n \n def get_backend():\n+    from matplotlib import _pylab_helpers\n+    current_figures = _pylab_helpers.Gcf.figs.copy()\n+    backend = rcParams['backend']\n+    _pylab_helpers.Gcf.figs.update(current_figures)\n+    return backend\n     \"\"\"\n     Return the name of the current backend.\n \ndiff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..0ef9107e85 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -207,6 +207,112 @@ def _get_backend_mod():\n \n \n def switch_backend(newbackend):\n+    global _backend_mod\n+    # make sure the init is pulled up so we can assign to it later\n+    import matplotlib.backends\n+    from matplotlib import _pylab_helpers\n+\n+    # Preserve the current figures\n+    current_figures = _pylab_helpers.Gcf.figs.copy()\n+\n+    close(\"all\")\n+\n+    if newbackend is rcsetup._auto_backend_sentinel:\n+        current_framework = cbook._get_running_interactive_framework()\n+        mapping = {'qt': 'qtagg',\n+                   'gtk3': 'gtk3agg',\n+                   'gtk4': 'gtk4agg',\n+                   'wx': 'wxagg',\n+                   'tk': 'tkagg',\n+                   'macosx': 'macosx',\n+                   'headless': 'agg'}\n+\n+        best_guess = mapping.get(current_framework, None)\n+        if best_guess is not None:\n+            candidates = [best_guess]\n+        else:\n+            candidates = []\n+        candidates += [\n+            \"macosx\", \"qtagg\", \"gtk4agg\", \"gtk3agg\", \"tkagg\", \"wxagg\"]\n+\n+        for candidate in candidates:\n+            try:\n+                switch_backend(candidate)\n+            except ImportError:\n+                continue\n+            else:\n+                rcParamsOrig['backend'] = candidate\n+                _pylab_helpers.Gcf.figs.update(current_figures)\n+                return\n+        else:\n+            switch_backend(\"agg\")\n+            rcParamsOrig[\"backend\"] = \"agg\"\n+            _pylab_helpers.Gcf.figs.update(current_figures)\n+            return\n+\n+    backend_mod = importlib.import_module(\n+        cbook._backend_module_name(newbackend))\n+    canvas_class = backend_mod.FigureCanvas\n+\n+    required_framework = _get_required_interactive_framework(backend_mod)\n+    if required_framework is not None:\n+        current_framework = cbook._get_running_interactive_framework()\n+        if (current_framework and required_framework\n+                and current_framework != required_framework):\n+            raise ImportError(\n+                \"Cannot load backend {!r} which requires the {!r} interactive \"\n+                \"framework, as {!r} is currently running\".format(\n+                    newbackend, required_framework, current_framework))\n+\n+    # Load the new_figure_manager(), draw_if_interactive(), and show()\n+    # functions from the backend.\n+\n+    # Classically, backends can directly export these functions.  This should\n+    # keep working for backcompat.\n+    new_figure_manager = getattr(backend_mod, \"new_figure_manager\", None)\n+    # draw_if_interactive = getattr(backend_mod, \"draw_if_interactive\", None)\n+    # show = getattr(backend_mod, \"show\", None)\n+    # In that classical approach, backends are implemented as modules, but\n+    # \"inherit\" default method implementations from backend_bases._Backend.\n+    # This is achieved by creating a \"class\" that inherits from\n+    # backend_bases._Backend and whose body is filled with the module globals.\n+    class backend_mod(matplotlib.backend_bases._Backend):\n+        locals().update(vars(backend_mod))\n+\n+    # However, the newer approach for defining new_figure_manager (and, in\n+    # the future, draw_if_interactive and show) is to derive them from canvas\n+    # methods.  In that case, also update backend_mod accordingly.\n+    if new_figure_manager is None:\n+        def new_figure_manager_given_figure(num, figure):\n+            return canvas_class.new_manager(figure, num)\n+\n+        def new_figure_manager(num, *args, FigureClass=Figure, **kwargs):\n+            fig = FigureClass(*args, **kwargs)\n+            return new_figure_manager_given_figure(num, fig)\n+\n+        backend_mod.new_figure_manager_given_figure = \\\n+            new_figure_manager_given_figure\n+        backend_mod.new_figure_manager = new_figure_manager\n+\n+    _log.debug(\"Loaded backend %s version %s.\",\n+               newbackend, backend_mod.backend_version)\n+\n+    rcParams['backend'] = rcParamsDefault['backend'] = newbackend\n+    _backend_mod = backend_mod\n+    for func_name in [\"new_figure_manager\", \"draw_if_interactive\", \"show\"]:\n+        globals()[func_name].__signature__ = inspect.signature(\n+            getattr(backend_mod, func_name))\n+\n+    # Need to keep a global reference to the backend for compatibility reasons.\n+    # See https://github.com/matplotlib/matplotlib/issues/6092\n+    matplotlib.backends.backend = newbackend\n+\n+    # make sure the repl display hook is installed in case we become\n+    # interactive\n+    install_repl_displayhook()\n+\n+    # Restore the figures\n+    _pylab_helpers.Gcf.figs.update(current_figures)\n     \"\"\"\n     Close all open figures and set the Matplotlib backend.\n \n", "instance_id": "matplotlib__matplotlib-23299"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/mark/__init__.py b/src/_pytest/mark/__init__.py\nindex 0dc3718e8..844e19c6e 100644\n--- a/src/_pytest/mark/__init__.py\n+++ b/src/_pytest/mark/__init__.py\n@@ -204,7 +204,7 @@ def deselect_by_keyword(items: \"List[Item]\", config: Config) -> None:\n         expression = Expression.compile(keywordexpr)\n     except ParseError as e:\n         raise UsageError(\n-            f\"Wrong expression passed to '-k': {keywordexpr}: {e}\"\n+            \"Using pytest.skip outside of a test is not allowed. To decorate a test function, use the @pytest.mark.skip or @pytest.mark.skipif decorators instead, and to skip a module use `pytestmark = pytest.mark.{skip,skipif}`. Alternatively, you can use `pytest.skip(msg=\\\"reason\\\", allow_module_level=True)` or the new `pytest.skip_module(\\\"reason\\\")` API.\"\n         ) from None\n \n     remaining = []\ndiff --git a/src/_pytest/outcomes.py b/src/_pytest/outcomes.py\nindex 2addf5572..8ec8eba07 100644\n--- a/src/_pytest/outcomes.py\n+++ b/src/_pytest/outcomes.py\n@@ -144,18 +144,16 @@ def skip(msg: str = \"\", *, allow_module_level: bool = False) -> \"NoReturn\":\n     raise Skipped(msg=msg, allow_module_level=allow_module_level)\n \n \n-@_with_exception(Failed)\n-def fail(msg: str = \"\", pytrace: bool = True) -> \"NoReturn\":\n-    \"\"\"Explicitly fail an executing test with the given message.\n-\n-    :param str msg:\n-        The message to show the user as reason for the failure.\n-    :param bool pytrace:\n-        If False, msg represents the full failure information and no\n-        python traceback will be reported.\n+@_with_exception(Skipped)\n+def skip_module(msg: str = \"\") -> \"NoReturn\":\n+    \"\"\"Skip the entire module with the given message.\n+\n+    This function should be called at the module level to skip the entire module.\n+\n+    :param str msg: The message to show the user as reason for the skip.\n     \"\"\"\n     __tracebackhide__ = True\n-    raise Failed(msg=msg, pytrace=pytrace)\n+    raise Skipped(msg=msg, allow_module_level=True)\n \n \n class XFailed(Failed):\n", "instance_id": "pytest-dev__pytest-8906"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/astropy/wcs/wcs.py b/astropy/wcs/wcs.py\nindex d3a06f2b31..7e75bcf619 100644\n--- a/astropy/wcs/wcs.py\n+++ b/astropy/wcs/wcs.py\n@@ -49,6 +49,11 @@ from . import _docutil as __\n try:\n     from . import _wcs\n except ImportError:\n+    try:\n+        _ASTROPY_SETUP_\n+    except NameError:\n+        _ASTROPY_SETUP_ = False\n+\n     if not _ASTROPY_SETUP_:\n         raise\n     else:\n@@ -1212,6 +1217,8 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n \n         def _return_list_of_arrays(axes, origin):\n+            if any(ax is None or not hasattr(ax, '__len__') or len(ax) == 0 for ax in axes):\n+                return [np.array([]) for _ in range(self.naxis)]\n             try:\n                 axes = np.broadcast_arrays(*axes)\n             except ValueError:\n@@ -1231,7 +1238,9 @@ reduce these to 2 dimensions using the naxis kwarg.\n                     for i in range(output.shape[1])]\n \n         def _return_single_array(xy, origin):\n-            if xy.shape[-1] != self.naxis:\n+            if xy is None or not hasattr(xy, 'shape') or xy.shape[-1] != self.naxis:\n+                if xy is None or not hasattr(xy, 'size') or xy.size == 0:\n+                    return np.empty((0, self.naxis))\n                 raise ValueError(\n                     \"When providing two arguments, the array must be \"\n                     \"of shape (N, {0})\".format(self.naxis))\n@@ -1276,6 +1285,14 @@ reduce these to 2 dimensions using the naxis kwarg.\n                 self.naxis, self.naxis + 1, len(args)))\n \n     def all_pix2world(self, *args, **kwargs):\n+        if len(args) == 0 or all(arg is None or not hasattr(arg, '__len__') or len(arg) == 0 for arg in args):\n+            return np.array([]), np.array([])\n+        if len(args) == 0 or all(len(arg) == 0 for arg in args):\n+            return np.array([]), np.array([])\n+        if len(args) == 0 or all(len(arg) == 0 for arg in args):\n+            return np.array([]), np.array([])\n+        if len(args) == 0 or all(len(arg) == 0 for arg in args):\n+            return np.array([]), np.array([])\n         return self._array_converter(\n             self._all_pix2world, 'output', *args, **kwargs)\n     all_pix2world.__doc__ = \"\"\"\n@@ -2500,7 +2517,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n \n         \"\"\"\n         # default precision for numerical WCS keywords\n-        precision = WCSHDO_P14\n+        precision = _wcs.WCSHDO_P14\n         display_warning = False\n         if relax is None:\n             display_warning = True\n@@ -2511,7 +2528,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n             relax &= ~WCSHDO_SIP\n         else:\n             do_sip = relax\n-            relax = WCSHDO_all if relax is True else WCSHDO_safe\n+            relax = _wcs.WCSHDO_all if relax is True else _wcs.WCSHDO_safe\n \n         relax = precision | relax\n \n@@ -2896,7 +2913,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         the spectral axis, followed by any others.\n         Assumes at least celestial axes are present.\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL, WCSSUB_SPECTRAL, WCSSUB_STOKES])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL, _wcs.WCSSUB_SPECTRAL, _wcs.WCSSUB_STOKES])\n \n     def slice(self, view, numpy_order=True):\n         \"\"\"\n@@ -3023,7 +3040,7 @@ reduce these to 2 dimensions using the naxis kwarg.\n         \"\"\"\n         A copy of the current WCS with only the celestial axes included\n         \"\"\"\n-        return self.sub([WCSSUB_CELESTIAL])\n+        return self.sub([_wcs.WCSSUB_CELESTIAL])\n \n     @property\n     def is_celestial(self):\n", "instance_id": "astropy__astropy-7746"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..1b2bfb018d 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -179,10 +179,13 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n                 raise TypeError(\n                     'syms should be given as a sequence, e.g. a list')\n             syms = [i for i in syms if i in var]\n-            if syms != var:\n-                dict_sym_index = dict(zip(syms, range(len(syms))))\n-                return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+            dict_sym_index = dict(zip(syms, range(len(syms))))\n+            base_solutions = diophantine(eq, param)\n+            permuted_solutions = set()\n+            for sol in base_solutions:\n+                permuted_solutions.update(signed_permutations(sol))\n+            return {tuple([t[dict_sym_index[i]] for i in var])\n+                        for t in permuted_solutions}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n@@ -330,24 +333,21 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n     # if there is no solution, return trivial solution\n     if not sols and eq.subs(zip(var, null)).is_zero:\n         sols.add(null)\n-    final_soln = set([])\n+    final_soln = set()\n     for sol in sols:\n         if all(_is_int(s) for s in sol):\n             if do_permute_signs:\n-                permuted_sign = set(permute_signs(sol))\n-                final_soln.update(permuted_sign)\n+                final_soln.update(permute_signs(sol))\n             elif permute_few_signs:\n                 lst = list(permute_signs(sol))\n                 lst = list(filter(lambda x: x[0]*x[1] == sol[1]*sol[0], lst))\n-                permuted_sign = set(lst)\n-                final_soln.update(permuted_sign)\n+                final_soln.update(lst)\n             elif do_permute_signs_var:\n-                permuted_sign_var = set(signed_permutations(sol))\n-                final_soln.update(permuted_sign_var)\n+                final_soln.update(signed_permutations(sol))\n             else:\n                 final_soln.add(sol)\n         else:\n-                final_soln.add(sol)\n+            final_soln.add(sol)\n     return final_soln\n \n \n", "instance_id": "sympy__sympy-18189"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex ac45127fde..c0a09070b0 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -13,7 +13,7 @@ from django.db.models.constants import LOOKUP_SEP\n from django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL\n from django.db.models.query_utils import PathInfo\n from django.db.models.utils import make_model_tuple\n-from django.utils.functional import cached_property\n+from django.utils.functional import cached_property, make_hashable\n from django.utils.translation import gettext_lazy as _\n \n from . import Field\n", "instance_id": "django__django-14672"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 9e5b903d59..17f804d532 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -341,6 +341,7 @@ class Legend(Artist):\n         handler_map=None,\n         title_fontproperties=None,  # properties for the legend title\n         alignment=\"center\",       # control the alignment within the legend box\n+        draggable=False,\n         *,\n         ncol=1  # synonym for ncols (backward compatibility)\n     ):\n@@ -538,6 +539,9 @@ class Legend(Artist):\n \n         self.set_title(title, prop=title_prop_fp)\n         self._draggable = None\n+        if draggable:\n+            self.set_draggable(True)\n+        self._draggable = None\n \n         # set the text color\n \n", "instance_id": "matplotlib__matplotlib-23913"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-15738"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 397146a354..8281dad328 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -986,9 +986,16 @@ class ForeignKey(ForeignObject):\n             raise ValueError(\"Cannot create form field for %r yet, because \"\n                              \"its related model %r has not been loaded yet\" %\n                              (self.name, self.remote_field.model))\n+        queryset = self.remote_field.model._default_manager.using(using)\n+        limit_choices_to = self.get_limit_choices_to()\n+        if limit_choices_to:\n+            if isinstance(limit_choices_to, dict):\n+                queryset = queryset.filter(**limit_choices_to).distinct()\n+            else:\n+                queryset = queryset.filter(limit_choices_to).distinct()\n         return super().formfield(**{\n             'form_class': forms.ModelChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n+            'queryset': queryset,\n             'to_field_name': self.remote_field.field_name,\n             **kwargs,\n             'blank': self.blank,\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..24cf79f0fd 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,10 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            if isinstance(limit_choices_to, dict):\n+                formfield.queryset = formfield.queryset.filter(**limit_choices_to).distinct()\n+            else:\n+                formfield.queryset = formfield.queryset.filter(limit_choices_to).distinct()\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n", "instance_id": "django__django-13315"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\nindex 28eaae5f..78a95fe8 100644\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -283,7 +283,15 @@ def summarize_variable(\n         dims_str = \"({}) \".format(\", \".join(map(str, var.dims)))\n     else:\n         dims_str = \"\"\n-    front_str = f\"{first_col}{dims_str}{var.dtype} \"\n+    \n+    # Add units to the summary if available\n+    units = var.attrs.get(\"units\", \"\")\n+    if units:\n+        units_str = f\", in {units}\"\n+    else:\n+        units_str = \"\"\n+\n+    front_str = f\"{first_col}{units_str} {dims_str}{var.dtype} \"\n \n     values_width = max_width - len(front_str)\n     values_str = inline_variable_array_repr(var, values_width)\n@@ -675,4 +683,4 @@ def diff_dataset_repr(a, b, compat):\n     if compat == \"identical\":\n         summary.append(diff_attrs_repr(a.attrs, b.attrs, compat))\n \n-    return \"\\n\".join(summary)\n+    return \"\\n.join(summary)\ndiff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex d13de439..34aaf28f 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -291,7 +291,41 @@ class Variable(\n     they can use more complete metadata in context of coordinate labels.\n     \"\"\"\n \n-    __slots__ = (\"_dims\", \"_data\", \"_attrs\", \"_encoding\")\n+    __slots__ = (\"_dims\", \"_data\", \"_attrs\", \"_encoding\", \"_units\")\n+\n+    def __init__(self, dims, data, attrs=None, encoding=None, units=None, fastpath=False):\n+        \"\"\"\n+        Parameters\n+        ----------\n+        dims : str or sequence of str\n+            Name(s) of the the data dimension(s). Must be either a string (only\n+            for 1D data) or a sequence of strings with length equal to the\n+            number of dimensions.\n+        data : array_like\n+            Data array which supports numpy-like data access.\n+        attrs : dict_like or None, optional\n+            Attributes to assign to the new variable. If None (default), an\n+            empty attribute dictionary is initialized.\n+        encoding : dict_like or None, optional\n+            Dictionary specifying how to encode this array's data into a\n+            serialized format like netCDF4. Currently used keys (for netCDF)\n+            include '_FillValue', 'scale_factor', 'add_offset' and 'dtype'.\n+            Well-behaved code to serialize a Variable should ignore\n+            unrecognized encoding items.\n+        units : str or None, optional\n+            Units of the variable. If None (default), no units are assigned.\n+        \"\"\"\n+        self._data = as_compatible_data(data, fastpath=fastpath)\n+        self._dims = self._parse_dimensions(dims)\n+        self._attrs = None\n+        self._encoding = None\n+        self._units = units\n+        if attrs is not None:\n+            self.attrs = attrs\n+        if encoding is not None:\n+            self.encoding = encoding\n+        if units is not None:\n+            self.attrs['units'] = units\n \n     def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n         \"\"\"\n", "instance_id": "pydata__xarray-4248"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..933bb73006 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -707,6 +707,8 @@ class Poly3DCollection(PolyCollection):\n             if any(len(np.shape(vert)) != 2 for vert in verts):\n                 raise ValueError('verts must be a list of (N, 3) array-like')\n         self.set_zsort(zsort)\n+        self._facecolors2d = np.empty((0, 4))\n+        self._edgecolors2d = np.empty((0, 4))\n         self._codes3d = None\n \n     _zsort_functions = {\n", "instance_id": "matplotlib__matplotlib-23562"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex 8ddbb5ba68..c54767f592 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1309,7 +1309,7 @@ class ManyToManyField(RelatedField):\n                              \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n", "instance_id": "django__django-12497"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py\nindex 1541843066..919ffb4b60 100644\n--- a/django/core/management/commands/migrate.py\n+++ b/django/core/management/commands/migrate.py\n@@ -5,6 +5,7 @@ from importlib import import_module\n from django.apps import apps\n from django.core.management.base import BaseCommand, CommandError, no_translations\n from django.core.management.sql import emit_post_migrate_signal, emit_pre_migrate_signal\n+from django.contrib.auth.management import create_permissions\n from django.db import DEFAULT_DB_ALIAS, connections, router\n from django.db.migrations.autodetector import MigrationAutodetector\n from django.db.migrations.executor import MigrationExecutor\n@@ -378,6 +379,10 @@ class Command(BaseCommand):\n             [ModelState.from_model(apps.get_model(*model)) for model in model_keys]\n         )\n \n+        # Create permissions for all apps.\n+        for app_config in apps.get_app_configs():\n+            create_permissions(app_config, verbosity=self.verbosity, using=database)\n+\n         # Send the post_migrate signal, so individual apps can do whatever they need\n         # to do at this point.\n         emit_post_migrate_signal(\n", "instance_id": "django__django-16400"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..c5bf64e405 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -920,7 +920,11 @@ def subs(self, *args, **kwargs):\n                 rv = rv._subs(old, new, **kwargs)\n                 if not isinstance(rv, Basic):\n                     break\n-            return rv\n+            # Check if the result is undefined\n+            if rv.has(S.ComplexInfinity, S.NaN, S.Infinity, S.NegativeInfinity):\n+                return S.NaN\n+            else:\n+                return rv\n \n     @cacheit\n     def _subs(self, old, new, **hints):\n@@ -1419,7 +1423,11 @@ def rec_replace(expr):\n                 rv = rv.xreplace(r)\n \n         if not map:\n-            return rv\n+            # Check if the result is undefined\n+            if rv.has(S.ComplexInfinity, S.NaN, S.Infinity, S.NegativeInfinity):\n+                return S.NaN\n+            else:\n+                return rv\n         else:\n             if simultaneous:\n                 # restore subexpressions in mapping\n", "instance_id": "sympy__sympy-13915"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..1a8b298b3c 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -66,9 +66,9 @@ def _line_type(line, delimiter=None):\n     if delimiter is None:\n         sep = r\"\\s+\"\n     _new_re = rf\"NO({sep}NO)+\"\n-    _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n-    _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan)*)\"\n+    _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?)\\s*(\\!(?P<comment>.*))?\\s*$\"\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n     line = line.strip()\n     if not line:\n         return \"comment\"\n", "instance_id": "astropy__astropy-14365"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\nindex 759191668..0b8d6ee47 100644\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -15,20 +15,6 @@ from _pytest.nodes import Item\n from _pytest.store import StoreKey\n \n \n-evalcache_key = StoreKey[Dict[str, Any]]()\n-\n-\n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n \n \n class MarkEvaluator:\n@@ -98,7 +84,9 @@ class MarkEvaluator:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        import _pytest._code\n+                        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+                        result = eval(exprcode, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n", "instance_id": "pytest-dev__pytest-7373"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/_code/code.py b/src/_pytest/_code/code.py\nindex b19ee7c64..0612fdb3a 100644\n--- a/src/_pytest/_code/code.py\n+++ b/src/_pytest/_code/code.py\n@@ -215,7 +215,7 @@ class TracebackEntry:\n \n     @property\n     def relline(self) -> int:\n-        return self.lineno - self.frame.code.firstlineno\n+        return self.lineno - self.frame.code.firstlineno + 1\n \n     def __repr__(self) -> str:\n         return \"<TracebackEntry %s:%d>\" % (self.frame.code.path, self.lineno + 1)\ndiff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 456681ab2..0748828b6 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -709,12 +709,7 @@ class AssertionRewriter(ast.NodeVisitor):\n             else:\n                 break\n             pos += 1\n-        # Special case: for a decorated function, set the lineno to that of the\n-        # first decorator, not the `def`. Issue #4984.\n-        if isinstance(item, ast.FunctionDef) and item.decorator_list:\n-            lineno = item.decorator_list[0].lineno\n-        else:\n-            lineno = item.lineno\n+        lineno = item.lineno\n         # Now actually insert the special imports.\n         if sys.version_info >= (3, 10):\n             aliases = [\n", "instance_id": "pytest-dev__pytest-9359"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..f3d925b578 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -164,7 +164,7 @@ class MigrationWriter:\n \n         # django.db.migrations is always used, but models import may not be.\n         # If models import exists, merge it with migrations import.\n-        if \"from django.db import models\" in imports:\n+        if \"from django.db import models\" in imports or any(\"models.Model\" in op for op in operations):\n             imports.discard(\"from django.db import models\")\n             imports.add(\"from django.db import migrations, models\")\n         else:\n", "instance_id": "django__django-14580"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex da5b40a5ef..b9f9c58411 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -709,7 +709,7 @@ class RangeSlider(SliderBase):\n                 facecolor=track_color\n             )\n             ax.add_patch(self.track)\n-            self.poly = ax.axhspan(valinit[0], valinit[1], 0, 1, **kwargs)\n+            self.poly = ax.axhspan(valmin, valmax, 0, 1, **kwargs)\n             handleXY_1 = [.5, valinit[0]]\n             handleXY_2 = [.5, valinit[1]]\n         else:\n@@ -719,7 +719,7 @@ class RangeSlider(SliderBase):\n                 facecolor=track_color\n             )\n             ax.add_patch(self.track)\n-            self.poly = ax.axvspan(valinit[0], valinit[1], 0, 1, **kwargs)\n+            self.poly = ax.axvspan(valmin, valmax, 0, 1, **kwargs)\n             handleXY_1 = [valinit[0], .5]\n             handleXY_2 = [valinit[1], .5]\n         self._handles = [\n@@ -903,13 +903,11 @@ class RangeSlider(SliderBase):\n             xy[1] = .25, val[1]\n             xy[2] = .75, val[1]\n             xy[3] = .75, val[0]\n-            xy[4] = .25, val[0]\n         else:\n             xy[0] = val[0], .25\n             xy[1] = val[0], .75\n             xy[2] = val[1], .75\n             xy[3] = val[1], .25\n-            xy[4] = val[0], .25\n         self.poly.xy = xy\n         self.valtext.set_text(self._format(val))\n         if self.drawon:\n", "instance_id": "matplotlib__matplotlib-22711"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 7bc96e68eb..b4e17d151b 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1042,7 +1042,7 @@ def __new__(cls, num, dps=None, prec=None, precision=None):\n                 # it's a hexadecimal (coming from a pickled object)\n                 # assume that it is in standard form\n                 num = list(num)\n-                num[1] = long(num[1], 16)\n+                num[1] = int(num[1], 16)\n                 _mpf_ = tuple(num)\n             else:\n                 if len(num) == 4:\n", "instance_id": "sympy__sympy-13471"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 6c7202c6..4116b740 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -13,6 +13,7 @@ from collections import abc\n from collections.abc import Callable, Generator\n from typing import Any, List, Optional, cast\n \n+import numpy as np\n from cycler import cycler\n import pandas as pd\n from pandas import DataFrame, Series, Index\n@@ -876,9 +877,7 @@ class Plotter:\n \n         self._pyplot = pyplot\n         self._theme = theme\n-        self._legend_contents: list[tuple[\n-            tuple[str, str | int], list[Artist], list[str],\n-        ]] = []\n+        self._legend_contents: list[tuple[tuple[str, str | int], list[Artist], list[str]]] = []\n         self._scales: dict[str, Scale] = {}\n \n     def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n@@ -1215,6 +1214,10 @@ class Plotter:\n                     parts.append(df.filter(cols))\n             var_df = pd.concat(parts, ignore_index=True)\n \n+            # Convert boolean data to integers for proper scaling\n+            if np.issubdtype(var_df[var].dtype, np.bool_):\n+                var_df[var] = var_df[var].astype(int)\n+\n             prop = PROPERTIES[prop_key]\n             scale = self._get_scale(p, scale_key, prop, var_df[var])\n \n@@ -1595,9 +1598,7 @@ class Plotter:\n         # Combine artists representing same information across layers\n         # Input list has an entry for each distinct variable in each layer\n         # Output dict has an entry for each distinct variable\n-        merged_contents: dict[\n-            tuple[str, str | int], tuple[list[Artist], list[str]],\n-        ] = {}\n+        merged_contents: dict[tuple[str, str | int], tuple[list[Artist], list[str]]] = {}\n         for key, new_artists, labels in self._legend_contents:\n             # Key is (name, id); we need the id to resolve variable uniqueness,\n             # but will need the name in the next step to title the legend\ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 6c9ecbc9..b36d12cc 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -350,8 +350,12 @@ class ContinuousBase(Scale):\n             a = forward(vmin)\n             b = forward(vmax) - forward(vmin)\n \n-            def normalize(x):\n-                return (x - a) / b\n+            if np.issubdtype(data.dtype, np.bool_):\n+                def normalize(x):\n+                    return x.astype(float)\n+            else:\n+                def normalize(x):\n+                    return (x - a) / b\n \n         else:\n             normalize = vmin = vmax = None\n", "instance_id": "mwaskom__seaborn-3190"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..ea3eff13f 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2174,8 +2174,12 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]\n-                                 for i in range(len(folds))], axis=0)\n+                    if multi_class == 'multinomial':\n+                        w = np.mean([coefs_paths[:, i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n+                    else:\n+                        w = np.mean([coefs_paths[i, best_indices[i], :]\n+                                     for i in range(len(folds))], axis=0)\n \n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n", "instance_id": "scikit-learn__scikit-learn-14087"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\nindex 138ed07ff8..7766e76ed9 100644\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -56,6 +56,7 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n     available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n+    base_language_code = settings.LANGUAGE_CODE.split('-')[0]\n+    if settings.LANGUAGE_CODE not in available_tags and base_language_code not in available_tags:\n         return [E004]\n     return []\n", "instance_id": "django__django-12286"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\nindex f0b663222a..b51d1739a4 100644\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -56,7 +56,7 @@ class Command(BaseCommand):\n         targets = [(app_label, migration.name)]\n \n         # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n", "instance_id": "django__django-11039"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f33bcbdccf..f918af93a8 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -186,16 +186,12 @@ class Command(BaseCommand):\n                             field_type = \"%s(%s\" % (rel_type, rel_to)\n                         else:\n                             field_type = \"%s('%s'\" % (rel_type, rel_to)\n-                    else:\n-                        # Calling `get_field_type` to get the field type string and any\n-                        # additional parameters and notes.\n-                        field_type, field_params, field_notes = self.get_field_type(\n-                            connection, table_name, row\n-                        )\n-                        extra_params.update(field_params)\n-                        comment_notes.extend(field_notes)\n-\n-                        field_type += \"(\"\n+                        # Add related_name to avoid reverse accessor clashes\n+                        related_name = f\"'{att_name}_set'\"\n+                        if rel_to in known_models:\n+                            field_type = \"%s(%s, related_name=%s\" % (rel_type, rel_to, related_name)\n+                        else:\n+                            field_type = \"%s('%s', related_name=%s\" % (rel_type, rel_to, related_name)\n \n                     # Don't output 'id = meta.AutoField(primary_key=True)', because\n                     # that's assumed if it doesn't exist.\n@@ -222,7 +218,7 @@ class Command(BaseCommand):\n                         field_type,\n                     )\n                     if field_type.startswith((\"ForeignKey(\", \"OneToOneField(\")):\n-                        field_desc += \", models.DO_NOTHING\"\n+                        field_desc += \", models.DO_NOTHING, related_name=%s\" % related_name\n \n                     if extra_params:\n                         if not field_desc.endswith(\"(\"):\n", "instance_id": "django__django-15819"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 0dc55568..79c82f75 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -22,7 +22,7 @@ from .packages.urllib3.util import parse_url\n from .packages.urllib3.exceptions import DecodeError\n from .exceptions import (\n     HTTPError, RequestException, MissingSchema, InvalidURL,\n-    ChunkedEncodingError, ContentDecodingError)\n+    ChunkedEncodingError, ContentDecodingError, ConnectionError)\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n@@ -634,8 +634,11 @@ class Response(object):\n             try:\n                 # Special case for urllib3.\n                 try:\n-                    for chunk in self.raw.stream(chunk_size, decode_content=True):\n-                        yield chunk\n+                    try:\n+                        for chunk in self.raw.stream(chunk_size, decode_content=True):\n+                            yield chunk\n+                    except socket.error as e:\n+                        raise ConnectionError(e)\n                 except IncompleteRead as e:\n                     raise ChunkedEncodingError(e)\n                 except DecodeError as e:\n", "instance_id": "psf__requests-2148"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-20442"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex 6490a655a4..e90ac2b063 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -191,12 +191,12 @@ def _setter_iterable_check(self, value):\n     @classmethod\n     def _scan_iterable_shape(cls, iterable):\n         def f(pointer):\n-            if not isinstance(pointer, Iterable):\n-                return [pointer], ()\n+            if not isinstance(pointer, Iterable) or not pointer:\n+                return [pointer], (0,) if not pointer else ()\n \n             result = []\n             elems, shapes = zip(*[f(i) for i in pointer])\n-            if len(set(shapes)) != 1:\n+            if len(set(shapes)) != 1 and shapes != ((),):\n                 raise ValueError(\"could not determine shape unambiguously\")\n             for i in elems:\n                 result.extend(i)\n", "instance_id": "sympy__sympy-23117"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\nindex bb91d0cbb..8e82e6a4a 100644\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -280,6 +280,10 @@ class KernelPCA(BaseEstimator, TransformerMixin, _UnstableOn32BitMixin):\n         if self.fit_inverse_transform:\n             self._fit_inverse_transform(X_transformed, X)\n \n+        # Ensure consistent sign for the principal components\n+        signs = np.sign(X_transformed[0, :])\n+        X_transformed *= signs\n+\n         return X_transformed\n \n     def transform(self, X):\n", "instance_id": "scikit-learn__scikit-learn-13241"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..8ac507f6c9 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -6,7 +6,8 @@\n \n from __future__ import print_function, division\n \n-import collections\n+from collections.abc import Iterable, Mapping, MutableMapping, MutableSet, Callable\n+from collections import defaultdict\n from sympy.core.add import Add\n from sympy.core.basic import Basic, Atom\n from sympy.core.expr import Expr\n@@ -86,10 +87,9 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n \n-        return self._new(self.rows, self.cols + other.cols,\n-                         lambda i, j: entry(i, j))\n+        return self._new(self.rows, self.cols + other.cols, entry)\n \n     def _eval_col_join(self, other):\n         rows = self.rows\n@@ -741,7 +741,7 @@ def size(m):\n                                                                          diag_rows, diag_cols))\n \n         # fill a default dict with the diagonal entries\n-        diag_entries = collections.defaultdict(lambda: S.Zero)\n+        diag_entries = defaultdict(lambda: S.Zero)\n         row_pos, col_pos = 0, 0\n         for m in args:\n             if hasattr(m, 'rows'):\n", "instance_id": "sympy__sympy-13647"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..8f2cb3a102 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -94,7 +94,8 @@ class PasswordResetTokenGenerator:\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n         login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+        email = '' if user.email is None else user.email\n+        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp) + email\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n", "instance_id": "django__django-13551"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 6f26dff0e0..313ed8ac56 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -671,6 +671,7 @@ class Func(SQLiteNumericMixin, Expression):\n             )\n         super().__init__(output_field=output_field)\n         self.source_expressions = self._parse_expressions(*expressions)\n+        self.query.subquery = True\n         self.extra = extra\n \n     def __repr__(self):\n@@ -1076,6 +1077,7 @@ class Case(SQLiteNumericMixin, Expression):\n         if not all(isinstance(case, When) for case in cases):\n             raise TypeError(\"Positional arguments must all be When objects.\")\n         super().__init__(output_field)\n+        self.query.subquery = True\n         self.cases = list(cases)\n         self.default = self._parse_expressions(default)[0]\n         self.extra = extra\n", "instance_id": "django__django-15320"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 7ca0d68fae..8ebf21d633 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -1,4 +1,5 @@\n import functools\n+from pathlib import Path\n import itertools\n import logging\n import os\n@@ -580,6 +581,8 @@ def run_with_reloader(main_func, *args, **kwargs):\n         if os.environ.get(DJANGO_AUTORELOAD_ENV) == 'true':\n             reloader = get_reloader()\n             logger.info('Watching for file changes with %s', reloader.__class__.__name__)\n+            # Ensure manage.py is watched\n+            reloader.watch_file(Path(sys.argv[0]).resolve())\n             start_django(reloader, main_func, *args, **kwargs)\n         else:\n             exit_code = restart_with_reloader()\n", "instance_id": "django__django-11422"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..b8beb5628b 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -162,10 +162,11 @@ def structurally_equal(self, other):\n             and self.colblocksizes == other.colblocksizes)\n \n     def _blockmul(self, other):\n-        if (isinstance(other, BlockMatrix) and\n-                self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n-\n+        if isinstance(other, BlockMatrix):\n+            if self.colblocksizes == other.rowblocksizes:\n+                blocks = self.blocks * other.blocks\n+                blocks = blocks.applyfunc(lambda x: ZeroMatrix(x.rows, x.cols) if x == 0 else x)\n+                return BlockMatrix(blocks)\n         return self * other\n \n     def _blockadd(self, other):\n", "instance_id": "sympy__sympy-17630"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex dc413b5c2..3d794b639 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -786,6 +786,13 @@ class Documenter:\n                     # ignore undocumented members if :undoc-members: is not given\n                     keep = has_doc or self.options.undoc_members\n \n+            if not keep and self.options.inherited_members:\n+                # Check if the member is an annotation-only member in a superclass\n+                for cls in self.object.__mro__[1:]:\n+                    if membername in cls.__annotations__:\n+                        keep = True\n+                        break\n+\n             if isinstance(obj, ObjectMember) and obj.skipped:\n                 # forcedly skipped member (ex. a module attribute not defined in __all__)\n                 keep = False\n", "instance_id": "sphinx-doc__sphinx-8801"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..d33449e9d 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -56,8 +56,6 @@ def doctree_read(app: Sphinx, doctree: Node) -> None:\n         env._viewcode_modules = {}  # type: ignore\n     if app.builder.name == \"singlehtml\":\n         return\n-    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n-        return\n \n     def has_tag(modname: str, fullname: str, docname: str, refname: str) -> bool:\n         entry = env._viewcode_modules.get(modname, None)  # type: ignore\n@@ -182,6 +180,8 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n", "instance_id": "sphinx-doc__sphinx-8721"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..7969f5e746 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -692,22 +692,25 @@ class URLField(CharField):\n                 # misformatted URLs.\n                 raise ValidationError(self.error_messages['invalid'], code='invalid')\n \n-        value = super().to_python(value)\n-        if value:\n-            url_fields = split_url(value)\n-            if not url_fields[0]:\n-                # If no URL scheme given, assume http://\n-                url_fields[0] = 'http'\n-            if not url_fields[1]:\n-                # Assume that if no domain is provided, that the path segment\n-                # contains the domain.\n-                url_fields[1] = url_fields[2]\n-                url_fields[2] = ''\n-                # Rebuild the url_fields list, since the domain segment may now\n-                # contain the path too.\n-                url_fields = split_url(urlunsplit(url_fields))\n-            value = urlunsplit(url_fields)\n-        return value\n+        try:\n+            value = super().to_python(value)\n+            if value:\n+                url_fields = split_url(value)\n+                if not url_fields[0]:\n+                    # If no URL scheme given, assume http://\n+                    url_fields[0] = 'http'\n+                if not url_fields[1]:\n+                    # Assume that if no domain is provided, that the path segment\n+                    # contains the domain.\n+                    url_fields[1] = url_fields[2]\n+                    url_fields[2] = ''\n+                    # Rebuild the url_fields list, since the domain segment may now\n+                    # contain the path too.\n+                    url_fields = split_url(urlunsplit(url_fields))\n+                value = urlunsplit(url_fields)\n+            return value\n+        except ValueError:\n+            raise ValidationError(self.error_messages['invalid'], code='invalid')\n \n \n class BooleanField(Field):\n", "instance_id": "django__django-15202"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/staticfiles/handlers.py b/django/contrib/staticfiles/handlers.py\nindex 711d8864ad..5ecf7447cf 100644\n--- a/django/contrib/staticfiles/handlers.py\n+++ b/django/contrib/staticfiles/handlers.py\n@@ -46,6 +46,12 @@ class StaticFilesHandlerMixin:\n         \"\"\"Serve the request path.\"\"\"\n         return serve(request, self.file_path(request.path), insecure=True)\n \n+    async def get_response_async(self, request):\n+        try:\n+            return await self.serve(request)\n+        except Http404 as e:\n+            return response_for_exception(request, e)\n+\n     def get_response(self, request):\n         try:\n             return self.serve(request)\n@@ -83,6 +89,9 @@ class ASGIStaticFilesHandler(StaticFilesHandlerMixin, ASGIHandler):\n         if scope['type'] == 'http' and self._should_handle(scope['path']):\n             # Serve static content\n             # (the one thing super() doesn't do is __call__, apparently)\n-            return await super().__call__(scope, receive, send)\n+            request = self.request_class(scope, receive)\n+            response = await self.get_response_async(request)\n+            await response(scope, receive, send)\n+            return\n         # Hand off to the main app\n         return await self.application(scope, receive, send)\ndiff --git a/staticfiles_tests/__init__.py b/staticfiles_tests/__init__.py\nnew file mode 100644\nindex 0000000000..35a44cf563\n--- /dev/null\n+++ b/staticfiles_tests/__init__.py\n@@ -0,0 +1,2 @@\n+# This file is required to make Python treat the directory as a package.\n+# This file is required to make Python treat the directory as a package.\n", "instance_id": "django__django-12915"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex ba3b62620d..f4208a84dd 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -139,6 +139,12 @@ class HashedFilesMixin:\n                 urlparts[2] += '?'\n             final_url = urlunsplit(urlparts)\n \n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        if self.base_url is not None:\n+            return unquote(script_name + final_url)\n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        if self.base_url is not None:\n+            return unquote(script_name + final_url)\n         return unquote(final_url)\n \n     def url(self, name, force=False):\ndiff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex 4c27fce605..4ce4a9266d 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -332,7 +332,14 @@ class FileSystemStorage(Storage):\n         url = filepath_to_uri(name)\n         if url is not None:\n             url = url.lstrip('/')\n-        return urljoin(self.base_url, url)\n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+        if self.base_url is not None:\n+            script_name = getattr(settings, 'FORCE_SCRIPT_NAME', '')\n+            if self.base_url is not None:\n+                return urljoin(script_name + self.base_url, url)\n+            return urljoin(script_name, url)\n+        return urljoin(script_name, url)\n \n     def _datetime_from_timestamp(self, ts):\n         \"\"\"\ndiff --git a/django/template/defaulttags.py b/django/template/defaulttags.py\nindex 602e8b2a15..502533819b 100644\n--- a/django/template/defaulttags.py\n+++ b/django/template/defaulttags.py\n@@ -452,6 +452,13 @@ class URLNode(Node):\n         else:\n             if context.autoescape:\n                 url = conditional_escape(url)\n+            script_name = context.request.META.get('SCRIPT_NAME', '')\n+            script_name = context.request.META.get('SCRIPT_NAME', '')\n+            if url is not None:\n+                script_name = context.request.META.get('SCRIPT_NAME', '')\n+                if url is not None:\n+                    return script_name + url\n+                return url\n             return url\n \n \n", "instance_id": "django__django-11564"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py\nindex 5eaef2fde..35d0e33c0 100644\n--- a/sklearn/utils/multiclass.py\n+++ b/sklearn/utils/multiclass.py\n@@ -74,8 +74,18 @@ def unique_labels(*ys):\n     array([ 1,  2,  5, 10, 11])\n     \"\"\"\n     xp, is_array_api = get_namespace(*ys)\n+    import pandas as pd\n+\n+    import pandas as pd\n+\n     if not ys:\n         raise ValueError(\"No argument has been passed.\")\n+\n+    # Convert nullable pandas dtypes to their corresponding numpy dtypes\n+    ys = [\n+        y.astype(y.dtype.numpy_dtype) if isinstance(y, pd.Series) and y.dtype.name in [\"Int64\", \"Float64\", \"boolean\"] else y\n+        for y in ys\n+    ]\n     # Check that we don't mix label format\n \n     ys_types = set(type_of_target(x) for x in ys)\n", "instance_id": "scikit-learn__scikit-learn-25638"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex af0815d41d..35f177866b 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2024,6 +2024,9 @@ class Axis(martist.Artist):\n         result = self._set_tick_locations(ticks, minor=minor)\n         if labels is not None:\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n+        else:\n+            # Validate kwargs even if labels are not set\n+            mtext.Text(0, 0, **kwargs)\n         return result\n \n     def _get_tick_boxes_siblings(self, renderer):\n", "instance_id": "matplotlib__matplotlib-24334"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/pylint/config/arguments_manager.py b/pylint/config/arguments_manager.py\nindex eda1a583d..ca45bb215 100644\n--- a/pylint/config/arguments_manager.py\n+++ b/pylint/config/arguments_manager.py\n@@ -11,7 +11,7 @@ import configparser\n import copy\n import optparse  # pylint: disable=deprecated-module\n import os\n-import re\n+import regex as re\n import sys\n import textwrap\n import warnings\ndiff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\nindex 7b412f9c2..476f83185 100644\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -5,6 +5,7 @@\n from __future__ import annotations\n \n import sys\n+import regex as re\n from pathlib import Path\n from typing import TYPE_CHECKING\n \n", "instance_id": "pylint-dev__pylint-7228"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/pylint/checkers/imports.py b/pylint/checkers/imports.py\nindex 7cab78586..149f386ba 100644\n--- a/pylint/checkers/imports.py\n+++ b/pylint/checkers/imports.py\n@@ -806,7 +806,9 @@ class ImportsChecker(DeprecatedMixin, BaseChecker):\n                 \"syntax-error\", line=importnode.lineno, args=message, confidence=HIGH\n             )\n \n-        except astroid.AstroidBuildingError:\n+        except astroid.AstroidBuildingError as exc:\n+            if modname and modname.split(\".\")[-1] == os.path.splitext(os.path.basename(importnode.root().file))[0]:\n+                return None\n             if not self.linter.is_message_enabled(\"import-error\"):\n                 return None\n             if _ignore_import_failure(importnode, modname, self._ignored_modules):\n@@ -979,7 +981,7 @@ class ImportsChecker(DeprecatedMixin, BaseChecker):\n     def _check_wildcard_imports(\n         self, node: nodes.ImportFrom, imported_module: nodes.Module | None\n     ) -> None:\n-        if node.root().package:\n+        if node.root().name == \"__init__\":\n             # Skip the check if in __init__.py issue #2026\n             return\n \ndiff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex bc227d2c4..572de3a89 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -786,7 +786,14 @@ class PyLinter(\n             if key == \"fatal\":\n                 message = str(error[\"ex\"]).replace(os.getcwd() + os.sep, \"\")\n             self.add_message(key, args=message)\n-        return result\n+        # Filter out modules that are the same as their containing package\n+        filtered_result = [\n+            res for res in result if not any(\n+                res[\"name\"] == os.path.splitext(os.path.basename(res[\"path\"]))[0]\n+                for res in result\n+            )\n+        ]\n+        return filtered_result\n \n     def set_current_module(\n         self, modname: str | None, filepath: str | None = None\n", "instance_id": "pylint-dev__pylint-7114"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..cf3e3b5541 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -268,7 +268,18 @@ class MigrationWriter:\n \n     @classmethod\n     def serialize(cls, value):\n-        return serializer_factory(value).serialize()\n+        serialized_value, imports = serializer_factory(value).serialize()\n+        if isinstance(value, type) and value.__module__:\n+            module = value.__module__\n+            if hasattr(value, '__qualname__'):\n+                qualname = value.__qualname__\n+                if '.' in qualname:\n+                    # Handle inner class paths\n+                    parts = qualname.split('.')\n+                    if len(parts) > 1:\n+                        module += '.' + '.'.join(parts[:-1])\n+                        serialized_value = \"%s.%s\" % (module, parts[-1])\n+        return serialized_value, imports\n \n     @classmethod\n     def register_serializer(cls, type_, serializer):\n", "instance_id": "django__django-12125"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\nindex 1d278b6e1..34e0c947e 100644\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -299,6 +299,7 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n+            self.n_components = int(self.n_components)\n             check_scalar(self.n_components, 'n_components', int, 1)\n \n             if self.n_components > X.shape[1]:\n@@ -319,6 +320,9 @@ class NeighborhoodComponentsAnalysis(BaseEstimator, TransformerMixin):\n                                          self.components_.shape[1]))\n \n         check_scalar(self.max_iter, 'max_iter', int, 1)\n+        self.tol = float(self.tol)\n+        self.tol = float(self.tol)\n+        self.tol = float(self.tol)\n         check_scalar(self.tol, 'tol', float, 0.)\n         check_scalar(self.verbose, 'verbose', int, 0)\n \n", "instance_id": "scikit-learn__scikit-learn-14092"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py\nindex 4bddae35c..869237f56 100644\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -43,10 +43,10 @@ def check_clusterings(labels_true, labels_pred):\n         The predicted labels.\n     \"\"\"\n     labels_true = check_array(\n-        labels_true, ensure_2d=False, ensure_min_samples=0\n+        labels_true, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n     labels_pred = check_array(\n-        labels_pred, ensure_2d=False, ensure_min_samples=0\n+        labels_pred, ensure_2d=False, ensure_min_samples=0, dtype=None\n     )\n \n     # input checks\n", "instance_id": "scikit-learn__scikit-learn-15535"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/axes_grid.py b/lib/mpl_toolkits/axes_grid1/axes_grid.py\nindex 2b1b1d3200..101628cd95 100644\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -13,8 +13,12 @@ from .mpl_axes import Axes\n def _tick_only(ax, bottom_on, left_on):\n     bottom_off = not bottom_on\n     left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    if isinstance(ax.axis, dict):\n+        ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n+        ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    else:\n+        ax.tick_params(axis='x', labelbottom=bottom_on)\n+        ax.tick_params(axis='y', labelleft=left_on)\n \n \n class CbarAxesBase:\n", "instance_id": "matplotlib__matplotlib-26020"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex 2903b8995..a7951afc2 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -965,6 +965,8 @@ warn_explicit(\n         return res, explanation\n \n     def visit_Call_35(self, call):\n+        if isinstance(call.func, ast.Name) and call.func.id in {\"all\", \"any\"}:\n+            return self.visit_AllAny(call)\n         \"\"\"\n         visit `ast.Call` nodes on Python3.5 and after\n         \"\"\"\n@@ -1027,7 +1029,53 @@ warn_explicit(\n         outer_expl = \"%s\\n{%s = %s\\n}\" % (res_expl, res_expl, expl)\n         return res, outer_expl\n \n-    # ast.Call signature changed on 3.5,\n+    def visit_AllAny(self, call):\n+        \"\"\"Unrolls the iterable for all/any calls to get better reports.\"\"\"\n+        func_name = call.func.id\n+        new_func, func_expl = self.visit(call.func)\n+        arg_expls = []\n+        new_args = []\n+        for arg in call.args:\n+            res, expl = self.visit(arg)\n+            arg_expls.append(expl)\n+            new_args.append(res)\n+\n+        # Create a for loop to iterate over the elements\n+        loop_var = self.variable()\n+        loop_body = []\n+        self.push_format_context()\n+        for res, expl in zip(new_args, arg_expls):\n+            loop_body.append(\n+                ast.If(\n+                    test=ast.UnaryOp(\n+                        op=ast.Not() if func_name == \"all\" else ast.Is(),\n+                        operand=res,\n+                    ),\n+                    body=[\n+                        ast.Raise(\n+                            exc=ast.Call(\n+                                func=ast.Name(id=\"AssertionError\", ctx=ast.Load()),\n+                                args=[ast.Str(s=f\"{func_name}({expl}) failed\")],\n+                                keywords=[],\n+                            ),\n+                            cause=None,\n+                        )\n+                    ],\n+                    orelse=[],\n+                )\n+            )\n+        self.pop_format_context(ast.Str(s=\"\"))\n+\n+        # Create the for loop\n+        loop = ast.For(\n+            target=ast.Name(id=loop_var, ctx=ast.Store()),\n+            iter=new_args[0],\n+            body=loop_body,\n+            orelse=[],\n+        )\n+\n+        self.statements.append(loop)\n+        return ast.Name(id=loop_var, ctx=ast.Load()), f\"{func_name}({', '.join(arg_expls)})\"\n     # conditionally change  which methods is named\n     # visit_Call depending on Python version\n     if sys.version_info >= (3, 5):\n", "instance_id": "pytest-dev__pytest-5103"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex 187e14b1b7..f1ee75f8f8 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -2,6 +2,7 @@ import base64\n import logging\n import string\n import warnings\n+import binascii\n from datetime import datetime, timedelta\n \n from django.conf import settings\n@@ -121,7 +122,7 @@ class SessionBase:\n             return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n         # RemovedInDjango40Warning: when the deprecation ends, handle here\n         # exceptions similar to what _legacy_decode() does now.\n-        except Exception:\n+        except (signing.BadSignature, binascii.Error):\n             return self._legacy_decode(session_data)\n \n     def _legacy_encode(self, session_dict):\n@@ -141,7 +142,7 @@ class SessionBase:\n                 raise SuspiciousSession(\"Session data corrupted\")\n             else:\n                 return self.serializer().loads(serialized)\n-        except Exception as e:\n+        except (Exception, binascii.Error) as e:\n             # ValueError, SuspiciousOperation, unpickling exceptions. If any of\n             # these happen, just return an empty dictionary (an empty session).\n             if isinstance(e, SuspiciousOperation):\n", "instance_id": "django__django-13321"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/python_api.py b/src/_pytest/python_api.py\nindex 011181a40..bbccb1aaa 100644\n--- a/src/_pytest/python_api.py\n+++ b/src/_pytest/python_api.py\n@@ -713,6 +713,9 @@ class RaisesContext:\n         self.match_expr = match_expr\n         self.excinfo = None\n \n+    def __str__(self):\n+        return str(self.excinfo.value) if self.excinfo else super().__str__()\n+\n     def __enter__(self):\n         self.excinfo = _pytest._code.ExceptionInfo.for_later()\n         return self.excinfo\n", "instance_id": "pytest-dev__pytest-5413"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c2623f099f..9c2d71cc86 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -8,7 +8,7 @@ circular import difficulties.\n import copy\n import functools\n import inspect\n-from collections import namedtuple\n+from collections import namedtuple, abc\n \n from django.core.exceptions import FieldError\n from django.db.models.constants import LOOKUP_SEP\n@@ -53,8 +53,8 @@ class Q(tree.Node):\n \n         obj = type(self)()\n         obj.connector = conn\n-        obj.add(self, conn)\n-        obj.add(other, conn)\n+        obj.add(self._make_pickleable(), conn)\n+        obj.add(other._make_pickleable(), conn)\n         return obj\n \n     def __or__(self, other):\n@@ -69,15 +69,17 @@ class Q(tree.Node):\n         obj.negate()\n         return obj\n \n-    def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n-        # We must promote any new joins to left outer joins so that when Q is\n-        # used as an expression, rows aren't filtered due to joins.\n-        clause, joins = query._add_q(\n-            self, reuse, allow_joins=allow_joins, split_subq=False,\n-            check_filterable=False,\n-        )\n-        query.promote_joins(joins)\n-        return clause\n+    def _make_pickleable(self):\n+        \"\"\"\n+        Convert non-pickleable types to a pickleable type.\n+        \"\"\"\n+        def make_pickleable(value):\n+            if isinstance(value, abc.KeysView):\n+                return list(value)\n+            return value\n+\n+        children = [(k, make_pickleable(v)) for k, v in self.children]\n+        return type(self)(*children, _connector=self.connector, _negated=self.negated)\n \n     def deconstruct(self):\n         path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)\n", "instance_id": "django__django-14016"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 8376b487..f39a626b 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -1877,7 +1877,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n         chunks: Union[\n             Number,\n             str,\n-            Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]],\n+            Mapping[Hashable, Union[None, Number, str, Tuple[Number, ...]]]\n         ] = {},  # {} even though it's technically unsafe, is being used intentionally here (#4667)\n         name_prefix: str = \"xarray-\",\n         token: str = None,\n@@ -3907,7 +3907,11 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             dataset.\n         \"\"\"\n         merge_result = dataset_update_method(self, other)\n-        return self._replace(inplace=True, **merge_result._asdict())\n+        variables = {\n+            k: (v.chunk() if is_duck_dask_array(v.data) else v)\n+            for k, v in merge_result.variables.items()\n+        }\n+        return self._replace(inplace=True, variables=variables, **merge_result._asdict())\n \n     def merge(\n         self,\n", "instance_id": "pydata__xarray-4493"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..57ace1140d 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -73,6 +73,7 @@ def method_decorator(decorator, name=''):\n                 \"%s (%s).\" % (name, obj, method)\n             )\n         _wrapper = _multi_decorate(decorator, method)\n+        update_wrapper(_wrapper, method)\n         setattr(obj, name, _wrapper)\n         return obj\n \n", "instance_id": "django__django-14787"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex d37d43d5c5..bfccf99ad1 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -257,6 +257,8 @@ class BaseCommand:\n     stealth_options = ()\n     suppressed_base_arguments = set()\n \n+    formatter_class = DjangoHelpFormatter\n+\n     def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False):\n         self.stdout = OutputWrapper(stdout or sys.stdout)\n         self.stderr = OutputWrapper(stderr or sys.stderr)\n@@ -289,7 +291,7 @@ class BaseCommand:\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n+            formatter_class=self.formatter_class,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n", "instance_id": "django__django-15781"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex b821c42845..c67bad8a5e 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -234,17 +234,17 @@ def transpose(self):\n \n     def _entry(self, i, j, **kwargs):\n         # Find row entry\n-        for row_block, numrows in enumerate(self.rowblocksizes):\n-            if (i < numrows) != False:\n-                break\n-            else:\n-                i -= numrows\n-        for col_block, numcols in enumerate(self.colblocksizes):\n-            if (j < numcols) != False:\n-                break\n-            else:\n-                j -= numcols\n-        return self.blocks[row_block, col_block][i, j]\n+        row_block, row_offset = self._find_block_index(i, self.rowblocksizes)\n+        col_block, col_offset = self._find_block_index(j, self.colblocksizes)\n+        return self.blocks[row_block, col_block]._entry(row_offset, col_offset)\n+\n+    def _find_block_index(self, index, blocksizes):\n+        from sympy import Ge\n+        for block_index, block_size in enumerate(blocksizes):\n+            if Ge(index, block_size) == False:\n+                return block_index, index\n+            index -= block_size\n+        raise IndexError(\"Index out of bounds\")\n \n     @property\n     def is_Identity(self):\n", "instance_id": "sympy__sympy-19007"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 24d89897f7..4c9a6f7431 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -120,12 +120,13 @@ def _hashable_content(self):\n         return self._args\n \n     def __eq__(self, other):\n-        try:\n-            other = sympify(other)\n-            if not isinstance(other, Expr):\n+        if not isinstance(other, Expr):\n+            try:\n+                other = sympify(other)\n+                if not isinstance(other, Expr):\n+                    return False\n+            except (SympifyError, SyntaxError):\n                 return False\n-        except (SympifyError, SyntaxError):\n-            return False\n         # check for pure number expr\n         if  not (self.is_Number and other.is_Number) and (\n                 type(self) != type(other)):\ndiff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex ed4ea6ce5e..6023aebaab 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -322,71 +322,12 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n                 from ..tensor.array import Array\n                 return Array(a.flat, a.shape)  # works with e.g. NumPy arrays\n \n-    if not isinstance(a, string_types):\n-        for coerce in (float, int):\n-            try:\n-                coerced = coerce(a)\n-            except (TypeError, ValueError):\n-                continue\n-            # XXX: AttributeError only needed here for Py2\n-            except AttributeError:\n-                continue\n-            try:\n-                return sympify(coerced)\n-            except SympifyError:\n-                continue\n-\n-    if strict:\n-        raise SympifyError(a)\n-\n-    if iterable(a):\n+    if isinstance(a, string_types):\n+        from sympy.parsing.sympy_parser import parse_expr, TokenError, standard_transformations\n         try:\n-            return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\n-                rational=rational) for x in a])\n-        except TypeError:\n-            # Not all iterables are rebuildable with their type.\n-            pass\n-    if isinstance(a, dict):\n-        try:\n-            return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\n-                rational=rational) for x in a.items()])\n-        except TypeError:\n-            # Not all iterables are rebuildable with their type.\n-            pass\n-\n-    # At this point we were given an arbitrary expression\n-    # which does not inherit from Basic and doesn't implement\n-    # _sympy_ (which is a canonical and robust way to convert\n-    # anything to SymPy expression).\n-    #\n-    # As a last chance, we try to take \"a\"'s normal form via unicode()\n-    # and try to parse it. If it fails, then we have no luck and\n-    # return an exception\n-    try:\n-        from .compatibility import unicode\n-        a = unicode(a)\n-    except Exception as exc:\n-        raise SympifyError(a, exc)\n-\n-    from sympy.parsing.sympy_parser import (parse_expr, TokenError,\n-                                            standard_transformations)\n-    from sympy.parsing.sympy_parser import convert_xor as t_convert_xor\n-    from sympy.parsing.sympy_parser import rationalize as t_rationalize\n-\n-    transformations = standard_transformations\n-\n-    if rational:\n-        transformations += (t_rationalize,)\n-    if convert_xor:\n-        transformations += (t_convert_xor,)\n-\n-    try:\n-        a = a.replace('\\n', '')\n-        expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\n-    except (TokenError, SyntaxError) as exc:\n-        raise SympifyError('could not parse %r' % a, exc)\n-\n-    return expr\n+            return parse_expr(a, local_dict=locals, transformations=standard_transformations, evaluate=evaluate)\n+        except (SyntaxError, TokenError):\n+            raise SympifyError(a)\n \n \n def _sympify(a):\ndiff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 2ab43d9b31..88c346368b 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -899,8 +899,11 @@ def eval_expr(code, local_dict, global_dict):\n \n     Generally, ``parse_expr`` should be used.\n     \"\"\"\n-    expr = eval(\n-        code, global_dict, local_dict)  # take local objects in preference\n+    try:\n+        expr = eval(\n+            code, global_dict, local_dict)  # take local objects in preference\n+    except AttributeError as e:\n+        raise ValueError(\"Unsafe code evaluation: %s\" % e)\n \n     return expr\n \n", "instance_id": "sympy__sympy-18057"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-13925"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..7a3dd546b8 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,13 +2180,13 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n-                pass\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x0 = np.nan\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n-            except (TypeError, IndexError, KeyError):\n-                x = xconv\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x = np.nan\n \n             delist = False\n             if not np.iterable(dx):\n", "instance_id": "matplotlib__matplotlib-24149"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 755088ca5..fef75816c 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -682,7 +682,11 @@ class GoogleDocstring:\n         return self._parse_generic_section(_('Notes'), use_admonition)\n \n     def _parse_other_parameters_section(self, section: str) -> List[str]:\n-        return self._format_fields(_('Other Parameters'), self._consume_fields())\n+        fields = self._consume_fields()\n+        if self._config.napoleon_use_param:\n+            return self._format_docutils_params(fields)\n+        else:\n+            return self._format_fields(_('Other Parameters'), fields)\n \n     def _parse_parameters_section(self, section: str) -> List[str]:\n         if self._config.napoleon_use_param:\n@@ -926,28 +930,28 @@ def _token_type(token: str, location: str = None) -> str:\n             (token.startswith(\"'\") and token.endswith(\"'\"))\n     ):\n         type_ = \"literal\"\n-    elif token.startswith(\"{\"):\n+    elif token.startswith(\"{\") and not token.endswith(\"}\"):\n         logger.warning(\n             __(\"invalid value set (missing closing brace): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.endswith(\"}\"):\n+    elif token.endswith(\"}\") and not token.startswith(\"{\"):\n         logger.warning(\n             __(\"invalid value set (missing opening brace): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.startswith(\"'\") or token.startswith('\"'):\n+    elif (token.startswith(\"'\") and not token.endswith(\"'\")) or (token.startswith('\"') and not token.endswith('\"')):\n         logger.warning(\n             __(\"malformed string literal (missing closing quote): %s\"),\n             token,\n             location=location,\n         )\n         type_ = \"literal\"\n-    elif token.endswith(\"'\") or token.endswith('\"'):\n+    elif (token.endswith(\"'\") and not token.startswith(\"'\")) or (token.endswith('\"') and not token.startswith('\"')):\n         logger.warning(\n             __(\"malformed string literal (missing opening quote): %s\"),\n             token,\n", "instance_id": "sphinx-doc__sphinx-8713"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..4513562c5 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1333,8 +1333,9 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n-        super(RidgeClassifierCV, self).__init__(\n+                 normalize=False, scoring=None, cv=None, class_weight=None,\n+                 store_cv_values=False):\n+        super(RidgeClassifierCV, self).__init__( \n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n             scoring=scoring, cv=cv)\n         self.class_weight = class_weight\n@@ -1374,6 +1375,8 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n                              compute_sample_weight(self.class_weight, y))\n \n         _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight)\n+        if self.store_cv_values:\n+            self.cv_values_ = self.cv_values_\n         return self\n \n     @property\n", "instance_id": "scikit-learn__scikit-learn-10297"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/physics/vector/point.py b/sympy/physics/vector/point.py\nindex d4e3cfcc90..10e94c7a46 100644\n--- a/sympy/physics/vector/point.py\n+++ b/sympy/physics/vector/point.py\n@@ -518,7 +518,11 @@ def vel(self, frame):\n         \"\"\"\n \n         _check_frame(frame)\n-        if not (frame in self._vel_dict):\n+        if frame not in self._vel_dict:\n+            # Attempt to calculate the velocity if not defined\n+            for point, vel in self._vel_dict.items():\n+                if point in self._pos_dict:\n+                    return vel + self._pos_dict[point].dt(frame)\n             raise ValueError('Velocity of point ' + self.name + ' has not been'\n                              ' defined in ReferenceFrame ' + frame.name)\n         return self._vel_dict[frame]\n", "instance_id": "sympy__sympy-20049"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 02aa32b207..4c77269555 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -125,17 +125,12 @@ class Media:\n         in a certain order. In JavaScript you may not be able to reference a\n         global or in CSS you might want to override a style.\n         \"\"\"\n-        # Start with a copy of list_1.\n         combined_list = list(list_1)\n         last_insert_index = len(list_1)\n-        # Walk list_2 in reverse, inserting each element into combined_list if\n-        # it doesn't already exist.\n         for path in reversed(list_2):\n             try:\n-                # Does path already exist in the list?\n                 index = combined_list.index(path)\n             except ValueError:\n-                # Add path to combined_list since it doesn't exist.\n                 combined_list.insert(last_insert_index, path)\n             else:\n                 if index > last_insert_index:\n@@ -144,8 +139,6 @@ class Media:\n                         '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n                         MediaOrderConflictWarning,\n                     )\n-                # path already exists in the list. Update last_insert_index so\n-                # that the following elements are inserted in front of this one.\n                 last_insert_index = index\n         return combined_list\n \n", "instance_id": "django__django-11019"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 03676533b7..671971a846 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -587,7 +587,8 @@ def join(value, arg, autoescape=True):\n     try:\n         if autoescape:\n             value = [conditional_escape(v) for v in value]\n-        data = conditional_escape(arg).join(value)\n+            arg = conditional_escape(arg)\n+        data = arg.join(value)\n     except TypeError:  # Fail silently if arg isn't iterable.\n         return value\n     return mark_safe(data)\n", "instance_id": "django__django-16873"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 62631f7ff..41ccf4801 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -110,11 +110,13 @@ def exclude_members_option(arg: Any) -> Union[object, Set[str]]:\n \n \n def inherited_members_option(arg: Any) -> Union[object, Set[str]]:\n-    \"\"\"Used to convert the :members: option to auto directives.\"\"\"\n+    \"\"\"Used to convert the :inherited-members: option to auto directives.\"\"\"\n     if arg in (None, True):\n-        return 'object'\n+        return {'object'}\n+    elif isinstance(arg, str):\n+        return {x.strip() for x in arg.split(',') if x.strip()}\n     else:\n-        return arg\n+        return set(arg)\n \n \n def member_order_option(arg: Any) -> Optional[str]:\n@@ -682,15 +684,16 @@ class Documenter:\n         def is_filtered_inherited_member(name: str, obj: Any) -> bool:\n             if inspect.isclass(self.object):\n                 for cls in self.object.__mro__:\n-                    if cls.__name__ == self.options.inherited_members and cls != self.object:\n-                        # given member is a member of specified *super class*\n-                        return True\n-                    elif name in cls.__dict__:\n-                        return False\n-                    elif name in self.get_attr(cls, '__annotations__', {}):\n-                        return False\n-                    elif isinstance(obj, ObjectMember) and obj.class_ is cls:\n-                        return False\n+                    for inherited_cls in self.options.inherited_members:\n+                        if cls.__name__ == inherited_cls and cls != self.object:\n+                            # given member is a member of specified *super class*\n+                            return True\n+                        elif name in cls.__dict__:\n+                            return False\n+                        elif name in self.get_attr(cls, '__annotations__', {}):\n+                            return False\n+                        elif isinstance(obj, ObjectMember) and obj.class_ is cls:\n+                            return False\n \n             return False\n \ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 2eb25536d..6a681a24d 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -71,8 +71,7 @@ class DocumenterBridge:\n         return self._reporter\n \n \n-def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict\n-                               ) -> Options:\n+def process_documenter_options(documenter: Type[Documenter], config: Config, options: Dict) -> Options:\n     \"\"\"Recognize options of Documenter from user input.\"\"\"\n     for name in AUTODOC_DEFAULT_OPTIONS:\n         if name not in documenter.option_spec:\n@@ -94,6 +93,10 @@ def process_documenter_options(documenter: Type[Documenter], config: Config, opt\n                 # remove '+' from option argument if there's nothing to merge it with\n                 options[name] = options[name].lstrip('+')\n \n+    # Ensure inherited-members is processed as a list\n+    if 'inherited-members' in options and isinstance(options['inherited-members'], str):\n+        options['inherited-members'] = {x.strip() for x in options['inherited-members'].split(',') if x.strip()}\n+\n     return Options(assemble_option_dict(options.items(), documenter.option_spec))\n \n \n", "instance_id": "sphinx-doc__sphinx-10325"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..866a43afe3 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -895,13 +895,16 @@ def __new__(cls, *args, **kwargs):\n         # counting starts from 1.\n \n         temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n+        if is_cycle:\n+            # Apply cycles in left-to-right order\n+            c = Cycle()\n+            for ci in args:\n+                c = c(*ci)\n+            aform = c.list()\n+        else:\n+            if has_dups(temp):\n                 raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n+            temp = set(temp)\n \n         if not is_cycle and \\\n                 any(i not in temp for i in range(len(temp))):\n", "instance_id": "sympy__sympy-12481"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 9ce46e3f73..3e0d236406 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -207,8 +207,41 @@ class Field(RegisterLookupMixin):\n             *self._check_backend_specific_checks(**kwargs),\n             *self._check_validators(),\n             *self._check_deprecation_details(),\n+            *self._check_max_length_with_choices(),\n         ]\n \n+    def _check_max_length_with_choices(self):\n+        \"\"\"\n+        Check if max_length is large enough to fit the longest value in choices.\n+        \"\"\"\n+        if self.choices is not None and self.max_length is not None:\n+            def get_longest_choice(choices):\n+                longest = 0\n+                for choice in choices:\n+                    if isinstance(choice, (list, tuple)):\n+                        if len(choice) == 2 and isinstance(choice[1], (list, tuple)):\n+                            longest = max(longest, get_longest_choice(choice[1]))\n+                        else:\n+                            longest = max(longest, len(str(choice[0])))\n+                    else:\n+                        longest = max(longest, len(str(choice)))\n+                return longest\n+\n+            if isinstance(self.choices, collections.abc.Iterable) and not isinstance(self.choices, str):\n+                longest_choice = get_longest_choice(self.choices)\n+            else:\n+                longest_choice = 0\n+            if longest_choice > self.max_length:\n+                return [\n+                    checks.Error(\n+                        f\"'max_length' is too small to fit the longest value in 'choices'. \"\n+                        f\"Longest value has {longest_choice} characters, but 'max_length' is {self.max_length}.\",\n+                        obj=self,\n+                        id='fields.E009',\n+                    )\n+                ]\n+        return []\n+\n     def _check_field_name(self):\n         \"\"\"\n         Check if field name is valid, i.e. 1) does not end with an\n", "instance_id": "django__django-11742"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 71a52fb754..2a3fb44d77 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1222,6 +1222,43 @@ class QuerySet:\n             clone.query.clear_deferred_loading()\n         else:\n             clone.query.add_deferred_loading(fields)\n+        # Clear deferred fields if only() was called before defer()\n+        if clone.query.deferred_loading[0]:\n+            clone.query.clear_deferred_loading()\n+        return clone\n+\n+    def only(self, *fields):\n+        \"\"\"\n+        Essentially, the opposite of defer(). Only the fields passed into this\n+        method and that are not already specified as deferred are loaded\n+        immediately when the queryset is evaluated.\n+        \"\"\"\n+        self._not_support_combined_queries('only')\n+        if self._fields is not None:\n+            raise TypeError(\"Cannot call only() after .values() or .values_list()\")\n+        if fields == (None,):\n+            # Can only pass None to defer(), not only(), as the rest option.\n+            # That won't stop people trying to do this, so let's be explicit.\n+            raise TypeError(\"Cannot pass None as an argument to only().\")\n+        for field in fields:\n+            field = field.split(LOOKUP_SEP, 1)[0]\n+            if field in self.query._filtered_relations:\n+                raise ValueError('only() is not supported with FilteredRelation.')\n+        clone = self._chain()\n+        clone.query.clear_deferred_loading()\n+        clone.query.add_immediate_loading(fields)\n+        return clone\n+        self._not_support_combined_queries('defer')\n+        if self._fields is not None:\n+            raise TypeError(\"Cannot call defer() after .values() or .values_list()\")\n+        clone = self._chain()\n+        if fields == (None,):\n+            clone.query.clear_deferred_loading()\n+        else:\n+            clone.query.add_deferred_loading(fields)\n+        # Clear deferred fields if only() was called before defer()\n+        if clone.query.deferred_loading[0]:\n+            clone.query.clear_deferred_loading()\n         return clone\n \n     def only(self, *fields):\n@@ -1242,6 +1279,7 @@ class QuerySet:\n             if field in self.query._filtered_relations:\n                 raise ValueError('only() is not supported with FilteredRelation.')\n         clone = self._chain()\n+        clone.query.clear_deferred_loading()\n         clone.query.add_immediate_loading(fields)\n         return clone\n \n", "instance_id": "django__django-14667"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 4806afee9..e04c1fe7c 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -200,6 +200,7 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n     else:\n         if verbose:\n             print(\"Did not converge\")\n+        converged = False\n \n     I = np.flatnonzero(E)\n     K = I.size  # Identify exemplars\n@@ -226,9 +227,9 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         cluster_centers_indices = []\n \n     if return_n_iter:\n-        return cluster_centers_indices, labels, it + 1\n+        return cluster_centers_indices, labels, it + 1, converged\n     else:\n-        return cluster_centers_indices, labels\n+        return cluster_centers_indices, labels, converged\n \n \n ###############################################################################\n@@ -382,7 +383,7 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n                              \"'euclidean'. Got %s instead\"\n                              % str(self.affinity))\n \n-        self.cluster_centers_indices_, self.labels_, self.n_iter_ = \\\n+        self.cluster_centers_indices_, self.labels_, self.n_iter_, self.converged_ = \\\n             affinity_propagation(\n                 self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                 convergence_iter=self.convergence_iter, damping=self.damping,\n@@ -440,4 +441,5 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n         labels : ndarray, shape (n_samples,)\n             Cluster labels.\n         \"\"\"\n-        return super().fit_predict(X, y)\n+        self.fit(X, y)\n+        return self.labels_\n", "instance_id": "scikit-learn__scikit-learn-15512"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 63ca817355..c753b89565 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -6,7 +6,7 @@ from itertools import chain\n from django.core.exceptions import EmptyResultSet, FieldError\n from django.db import DatabaseError, NotSupportedError\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value\n+from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value, Subquery\n from django.db.models.functions import Cast\n from django.db.models.query_utils import Q, select_related_descend\n from django.db.models.sql.constants import (\n@@ -117,9 +117,12 @@ class SQLCompiler:\n             # by reference.\n             if expr in ref_sources:\n                 continue\n-            cols = expr.get_group_by_cols()\n-            for col in cols:\n-                expressions.append(col)\n+            if isinstance(expr, Subquery):\n+                expressions.append(expr)\n+            else:\n+                cols = expr.get_group_by_cols()\n+                for col in cols:\n+                    expressions.append(col)\n         for expr, (sql, params, is_ref) in order_by:\n             # Skip References to the select clause, as all expressions in the\n             # select clause are already part of the group by.\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 78c4f47b5b..30e8ae115d 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -23,7 +23,7 @@ from django.core.exceptions import (\n from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n from django.db.models.aggregates import Count\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref\n+from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref, Subquery\n from django.db.models.fields import Field\n from django.db.models.fields.related_lookups import MultiColSource\n from django.db.models.lookups import Lookup\n@@ -1930,20 +1930,23 @@ class Query(BaseExpression):\n         group_by = list(self.select)\n         if self.annotation_select:\n             for alias, annotation in self.annotation_select.items():\n-                signature = inspect.signature(annotation.get_group_by_cols)\n-                if 'alias' not in signature.parameters:\n-                    annotation_class = annotation.__class__\n-                    msg = (\n-                        '`alias=None` must be added to the signature of '\n-                        '%s.%s.get_group_by_cols().'\n-                    ) % (annotation_class.__module__, annotation_class.__qualname__)\n-                    warnings.warn(msg, category=RemovedInDjango40Warning)\n-                    group_by_cols = annotation.get_group_by_cols()\n+                if isinstance(annotation, Subquery):\n+                    group_by.append(annotation)\n                 else:\n-                    if not allow_aliases:\n-                        alias = None\n-                    group_by_cols = annotation.get_group_by_cols(alias=alias)\n-                group_by.extend(group_by_cols)\n+                    signature = inspect.signature(annotation.get_group_by_cols)\n+                    if 'alias' not in signature.parameters:\n+                        annotation_class = annotation.__class__\n+                        msg = (\n+                            '`alias=None` must be added to the signature of '\n+                            '%s.%s.get_group_by_cols().'\n+                        ) % (annotation_class.__module__, annotation_class.__qualname__)\n+                        warnings.warn(msg, category=RemovedInDjango40Warning)\n+                        group_by_cols = annotation.get_group_by_cols()\n+                    else:\n+                        if not allow_aliases:\n+                            alias = None\n+                        group_by_cols = annotation.get_group_by_cols(alias=alias)\n+                    group_by.extend(group_by_cols)\n         self.group_by = tuple(group_by)\n \n     def add_select_related(self, fields):\n", "instance_id": "django__django-12589"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..ad06668efe 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if evaluate and any(a.is_number and im(a) for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n", "instance_id": "sympy__sympy-22714"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-12113"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..ecd68dd937 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,20 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n+            if self.creation_counter == other.creation_counter:\n+                return getattr(self, 'model', None) < getattr(other, 'model', None)\n             return self.creation_counter < other.creation_counter\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n", "instance_id": "django__django-13401"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "astropy__astropy-14995"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 7ef51bc847..5443d8ddc7 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -378,6 +378,9 @@ def hstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.rows == 0 for arg in args):\n+            total_cols = sum(arg.cols for arg in args)\n+            return cls._new(0, total_cols, [])\n         return reduce(kls.row_join, args)\n \n     def reshape(self, rows, cols):\n@@ -601,6 +604,9 @@ def vstack(cls, *args):\n             return cls._new()\n \n         kls = type(args[0])\n+        if all(arg.cols == 0 for arg in args):\n+            total_rows = sum(arg.rows for arg in args)\n+            return cls._new(total_rows, 0, [])\n         return reduce(kls.col_join, args)\n \n \n", "instance_id": "sympy__sympy-13031"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py\nindex 3e5e729c2..fbbb7862e 100644\n--- a/sklearn/neighbors/base.py\n+++ b/sklearn/neighbors/base.py\n@@ -107,6 +107,9 @@ class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n                  algorithm='auto', leaf_size=30, metric='minkowski',\n                  p=2, metric_params=None, n_jobs=1):\n \n+        if n_neighbors is not None:\n+            if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+                raise ValueError(\"n_neighbors must be a positive integer, got %s\" % n_neighbors)\n         self.n_neighbors = n_neighbors\n         self.radius = radius\n         self.algorithm = algorithm\n@@ -327,6 +330,8 @@ class KNeighborsMixin(object):\n \n         if n_neighbors is None:\n             n_neighbors = self.n_neighbors\n+        if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got %s\" % n_neighbors)\n \n         if X is not None:\n             query_is_train = False\ndiff --git a/sklearn/neighbors/kde.py b/sklearn/neighbors/kde.py\nindex 3cfdbc630..857fdd7c6 100644\n--- a/sklearn/neighbors/kde.py\n+++ b/sklearn/neighbors/kde.py\n@@ -127,6 +127,8 @@ class KernelDensity(BaseEstimator):\n         kwargs = self.metric_params\n         if kwargs is None:\n             kwargs = {}\n+        if not isinstance(self.leaf_size, int) or self.leaf_size <= 0:\n+            raise ValueError(\"leaf_size must be a positive integer, got %s\" % self.leaf_size)\n         self.tree_ = TREE_DICT[algorithm](X, metric=self.metric,\n                                           leaf_size=self.leaf_size,\n                                           **kwargs)\ndiff --git a/sklearn/neighbors/lof.py b/sklearn/neighbors/lof.py\nindex f7f1a16eb..14c834929 100644\n--- a/sklearn/neighbors/lof.py\n+++ b/sklearn/neighbors/lof.py\n@@ -138,11 +138,13 @@ class LocalOutlierFactor(NeighborsBase, KNeighborsMixin, UnsupervisedMixin,\n     def __init__(self, n_neighbors=20, algorithm='auto', leaf_size=30,\n                  metric='minkowski', p=2, metric_params=None,\n                  contamination=\"legacy\", n_jobs=1):\n+        if not isinstance(n_neighbors, int) or n_neighbors <= 0:\n+            raise ValueError(\"n_neighbors must be a positive integer, got %s\" % n_neighbors)\n         super(LocalOutlierFactor, self).__init__(\n-              n_neighbors=n_neighbors,\n-              algorithm=algorithm,\n-              leaf_size=leaf_size, metric=metric, p=p,\n-              metric_params=metric_params, n_jobs=n_jobs)\n+            n_neighbors=n_neighbors,\n+            algorithm=algorithm,\n+            leaf_size=leaf_size, metric=metric, p=p,\n+            metric_params=metric_params, n_jobs=n_jobs)\n \n         if contamination == \"legacy\":\n             warnings.warn('default contamination parameter 0.1 will change '\ndiff --git a/sklearn/neighbors/nearest_centroid.py b/sklearn/neighbors/nearest_centroid.py\nindex 48cd7a18f..d3c737006 100644\n--- a/sklearn/neighbors/nearest_centroid.py\n+++ b/sklearn/neighbors/nearest_centroid.py\n@@ -95,6 +95,8 @@ class NearestCentroid(BaseEstimator, ClassifierMixin):\n         y : array, shape = [n_samples]\n             Target values (integers)\n         \"\"\"\n+        if not isinstance(self.shrink_threshold, (int, float)) or (self.shrink_threshold is not None and self.shrink_threshold < 0):\n+            raise ValueError(\"shrink_threshold must be a non-negative number, got %s\" % self.shrink_threshold)\n         if self.metric == 'precomputed':\n             raise ValueError(\"Precomputed is not supported.\")\n         # If X is sparse and the metric is \"manhattan\", store it in a csc\n", "instance_id": "scikit-learn__scikit-learn-11040"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..730b8f4223 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -727,9 +727,9 @@ class Colormap:\n                 xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n-        xa[xa > self.N - 1] = self._i_over\n-        xa[xa < 0] = self._i_under\n-        xa[mask_bad] = self._i_bad\n+        xa[xa > self.N - 1] = int(self._i_over)\n+        xa[xa < 0] = int(self._i_under)\n+        xa[mask_bad] = int(self._i_bad)\n \n         lut = self._lut\n         if bytes:\n", "instance_id": "matplotlib__matplotlib-24970"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..095ad0ccf0 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ class ManagementUtility:\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n", "instance_id": "django__django-13658"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-21055"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 6866648d4e..2cd7149938 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -434,10 +434,8 @@ def _repr_latex_(self):\n     def atoms(self, *types):\n         \"\"\"Returns the atoms that form the current object.\n \n-        By default, only objects that are truly atomic and can't\n-        be divided into smaller pieces are returned: symbols, numbers,\n-        and number symbols like I and pi. It is possible to request\n-        atoms of any type, however, as demonstrated below.\n+        By default, only objects that have no arguments are returned.\n+        It is possible to request atoms of any type, however, as demonstrated below.\n \n         Examples\n         ========\n@@ -500,16 +498,10 @@ def atoms(self, *types):\n         {I*pi, 2*sin(y + I*pi)}\n \n         \"\"\"\n-        if types:\n-            types = tuple(\n-                [t if isinstance(t, type) else type(t) for t in types])\n-        else:\n-            types = (Atom,)\n-        result = set()\n-        for expr in preorder_traversal(self):\n-            if isinstance(expr, types):\n-                result.add(expr)\n-        return result\n+        if not types:\n+            return {expr for expr in preorder_traversal(self) if not expr.args}\n+        types = tuple(t if isinstance(t, type) else type(t) for t in types)\n+        return {expr for expr in preorder_traversal(self) if isinstance(expr, types)}\n \n     @property\n     def free_symbols(self):\n", "instance_id": "sympy__sympy-18532"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/http/request.py b/django/http/request.py\nindex 0b64b1b2b9..aed4f74698 100644\n--- a/django/http/request.py\n+++ b/django/http/request.py\n@@ -22,7 +22,7 @@ from django.utils.datastructures import (\n )\n from django.utils.encoding import escape_uri_path, iri_to_uri\n from django.utils.functional import cached_property\n-from django.utils.http import is_same_domain\n+from django.utils.http import is_same_domain, parse_http_date_safe\n from django.utils.regex_helper import _lazy_re_compile\n \n from .multipartparser import parse_header\n@@ -126,8 +126,22 @@ class HttpRequest:\n                 host = \"%s:%s\" % (host, server_port)\n         return host\n \n-    def get_host(self):\n-        \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n+    @cached_property\n+    def if_modified_since(self):\n+        \"\"\"\n+        Return the parsed If-Modified-Since header as a datetime object or\n+        None if the header is missing or invalid.\n+        \"\"\"\n+        header = self.headers.get(\"If-Modified-Since\")\n+        if header is not None and header != \"\":\n+            try:\n+                return parse_http_date_safe(header)\n+            except (ValueError, OverflowError):\n+                pass\n+        return None\n+        \"\"\"\n+        Return the HTTP host using the environment or request headers.\n+        \"\"\"\n         host = self._get_raw_host()\n \n         # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n", "instance_id": "django__django-15498"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 3894f4fd1c..4bc7247b5a 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -949,6 +949,8 @@ def subs(self, *args, **kwargs):\n                 rv = rv._subs(old, new, **kwargs)\n                 if not isinstance(rv, Basic):\n                     break\n+                if isinstance(rv, Piecewise):\n+                    rv = piecewise_fold(rv)\n             return rv\n \n     @cacheit\ndiff --git a/sympy/functions/elementary/exponential.py b/sympy/functions/elementary/exponential.py\nindex bdedc455c2..107d42c726 100644\n--- a/sympy/functions/elementary/exponential.py\n+++ b/sympy/functions/elementary/exponential.py\n@@ -365,6 +365,8 @@ def eval(cls, arg):\n                     out.append(newa)\n             if out or argchanged:\n                 return Mul(*out)*cls(Add(*add), evaluate=False)\n+        if isinstance(arg, Piecewise):\n+            return Piecewise(*[(cls(e), c) for e, c in arg.args])\n \n         if arg.is_zero:\n             return S.One\ndiff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 860989f7c1..97ecdba540 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -137,6 +137,8 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     return sinh(m)*cosh(x) + cosh(m)*sinh(x)\n+            if isinstance(arg, Piecewise):\n+                return Piecewise(*[(cls(e), c) for e, c in arg.args])\n \n             if arg.is_zero:\n                 return S.Zero\ndiff --git a/sympy/functions/elementary/piecewise.py b/sympy/functions/elementary/piecewise.py\nindex 91bfceafaa..0067cb94aa 100644\n--- a/sympy/functions/elementary/piecewise.py\n+++ b/sympy/functions/elementary/piecewise.py\n@@ -822,7 +822,11 @@ def _eval_subs(self, old, new):\n                 break\n         if not args_exist:\n             args = ((Undefined, True),)\n-        return self.func(*args)\n+        rv = self.func(*args)\n+        if isinstance(rv, Piecewise):\n+            from sympy.functions.elementary.piecewise import piecewise_fold\n+            rv = piecewise_fold(rv)\n+        return rv\n \n     def _eval_transpose(self):\n         return self.func(*[(e.transpose(), c) for e, c in self.args])\n", "instance_id": "sympy__sympy-21379"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-15851"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..c9f1e2b1ba 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,9 +501,9 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_number and rv.exp < 0:\n             return rv\n-        if (rv.exp > max) == True:\n+        if rv.exp.is_number and rv.exp > max:\n             return rv\n         if rv.exp == 2:\n             return h(g(rv.base.args[0])**2)\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 7f055da80e..23a48d8f4f 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -1067,14 +1067,24 @@ def walk(e, *target):\n                 yield w\n \n \n-def bottom_up(rv, F, atoms=False, nonbasic=False):\n+import time\n+\n+def bottom_up(rv, F, atoms=False, nonbasic=False, timeout=30):\n+    \"\"\"Apply ``F`` to all expressions in an expression tree from the\n+    bottom up. If ``atoms`` is True, apply ``F`` even if there are no args;\n+    if ``nonbasic`` is True, try to apply ``F`` to non-Basic objects.\n+    \"\"\"\n+    start_time = time.time()\n     \"\"\"Apply ``F`` to all expressions in an expression tree from the\n     bottom up. If ``atoms`` is True, apply ``F`` even if there are no args;\n     if ``nonbasic`` is True, try to apply ``F`` to non-Basic objects.\n     \"\"\"\n     args = getattr(rv, 'args', None)\n+    print(f\"Processing: {rv}\")\n     if args is not None:\n-        if args:\n+        if time.time() - start_time > timeout:\n+            raise TimeoutError(\"bottom_up function timed out\")\n+        elif args:\n             args = tuple([bottom_up(a, F, atoms, nonbasic) for a in args])\n             if args != rv.args:\n                 rv = rv.func(*args)\n@@ -1088,6 +1098,7 @@ def bottom_up(rv, F, atoms=False, nonbasic=False):\n             except TypeError:\n                 pass\n \n+    print(f\"Processed: {rv}\")\n     return rv\n \n \n", "instance_id": "sympy__sympy-17139"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..e9429a8e 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,6 +425,14 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n         method = builtin_str(method)\n \n         # Create the Request.\n", "instance_id": "psf__requests-2317"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..a824ba3da2 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -23,7 +23,7 @@ from django.core.exceptions import (\n from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n from django.db.models.aggregates import Count\n from django.db.models.constants import LOOKUP_SEP\n-from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref\n+from django.db.models.expressions import BaseExpression, Col, CombinedExpression, F, OuterRef, Ref\n from django.db.models.fields import Field\n from django.db.models.fields.related_lookups import MultiColSource\n from django.db.models.lookups import Lookup\n@@ -1077,10 +1077,16 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n-                self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n-                for sub_value in value\n-            )\n+            if hasattr(value, '_fields'):  # Check if it's a namedtuple\n+                return type(value)(*[\n+                    self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n+                    for sub_value in value\n+                ])\n+            else:\n+                return type(value)([\n+                    self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n+                    for sub_value in value\n+                ])\n         return value\n \n     def solve_lookup_type(self, lookup):\n", "instance_id": "django__django-13590"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-18199"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex e16ab8ce5..4189d8aee 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1274,6 +1274,9 @@ class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # typ\n             self.env.app.emit('autodoc-before-process-signature', self.object, False)\n             sig = inspect.signature(self.object, type_aliases=self.config.autodoc_type_aliases)\n             args = stringify_signature(sig, **kwargs)\n+            # Remove duplicated *args and **kwargs\n+            if self.config.autodoc_typehints == \"description\":\n+                args = args.replace('*args, ', '').replace('**kwargs', '')\n         except TypeError as exc:\n             logger.warning(__(\"Failed to get a function signature for %s: %s\"),\n                            self.fullname, exc)\ndiff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex be2248320..f3f6d452c 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -88,7 +88,14 @@ def process_documenter_options(documenter: Type[Documenter], config: Config, opt\n                 # remove '+' from option argument if there's nothing to merge it with\n                 options[name] = options[name].lstrip('+')\n \n-    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    options_dict = assemble_option_dict(options.items(), documenter.option_spec)\n+    # Remove duplicated *args and **kwargs\n+    if config.autodoc_typehints == \"description\":\n+        if 'args' in options_dict:\n+            del options_dict['args']\n+        if 'kwargs' in options_dict:\n+            del options_dict['kwargs']\n+    return Options(options_dict)\n \n \n def parse_generated_content(state: RSTState, content: StringList, documenter: Documenter\n", "instance_id": "sphinx-doc__sphinx-10451"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..3e19b220c0 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -392,7 +392,11 @@ def display_for_field(value, field, empty_value_display):\n         return formats.localize(timezone.template_localtime(value))\n     elif isinstance(field, (models.DateField, models.TimeField)):\n         return formats.localize(value)\n-    elif isinstance(field, models.DecimalField):\n+    elif isinstance(field, models.JSONField):\n+        try:\n+            return field.value_to_string(None, value)\n+        except Exception:\n+            return empty_value_display\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n", "instance_id": "django__django-12308"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex f88662de12..a05bd0dc9f 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -121,6 +121,16 @@ class ModelIterable(BaseIterable):\n             obj = model_cls.from_db(\n                 db, init_list, row[model_fields_start:model_fields_end]\n             )\n+            # Add the known related objects to the model before populating related fields.\n+            for field, rel_objs, rel_getter in known_related_objects:\n+                rel_obj_id = rel_getter(obj)\n+                try:\n+                    rel_obj = rel_objs[rel_obj_id]\n+                except KeyError:\n+                    pass  # May happen in qs1 | qs2 scenarios.\n+                else:\n+                    setattr(obj, field.name, rel_obj)\n+\n             for rel_populator in related_populators:\n                 rel_populator.populate(row, obj)\n             if annotation_col_map:\n", "instance_id": "django__django-16408"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\nindex 8fe6e7a9c1..c3f751e74d 100644\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -165,8 +165,8 @@ class Line3D(lines.Line2D):\n         \"\"\"\n         Keyword arguments are passed onto :func:`~matplotlib.lines.Line2D`.\n         \"\"\"\n-        super().__init__([], [], *args, **kwargs)\n-        self._verts3d = xs, ys, zs\n+        super().__init__(xs, ys, *args, **kwargs)\n+        self.set_data_3d(xs, ys, zs)\n \n     def set_3d_properties(self, zs=0, zdir='z'):\n         xs = self.get_xdata()\n", "instance_id": "matplotlib__matplotlib-23563"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex f50d8200e..c2c11dc57 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -396,6 +396,9 @@ def _call_reprcompare(ops, results, expls, each_obj):\n         custom = util._reprcompare(ops[i], each_obj[i], each_obj[i + 1])\n         if custom is not None:\n             return custom\n+    # Handle byte string comparisons more clearly\n+    if isinstance(each_obj[i], bytes) and isinstance(each_obj[i + 1], bytes):\n+        return f\"{each_obj[i]!r} != {each_obj[i + 1]!r}\"\n     return expl\n \n \n", "instance_id": "pytest-dev__pytest-5495"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/cache/backends/filebased.py b/django/core/cache/backends/filebased.py\nindex 631da49444..215fefbcc0 100644\n--- a/django/core/cache/backends/filebased.py\n+++ b/django/core/cache/backends/filebased.py\n@@ -90,10 +90,11 @@ class FileBasedCache(BaseCache):\n \n     def has_key(self, key, version=None):\n         fname = self._key_to_file(key, version)\n-        if os.path.exists(fname):\n+        try:\n             with open(fname, \"rb\") as f:\n                 return not self._is_expired(f)\n-        return False\n+        except FileNotFoundError:\n+            return False\n \n     def _cull(self):\n         \"\"\"\n", "instance_id": "django__django-16379"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "pytest-dev__pytest-6116"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/files/storage.py b/django/core/files/storage.py\nindex cbdab1de47..09515d36b6 100644\n--- a/django/core/files/storage.py\n+++ b/django/core/files/storage.py\n@@ -179,7 +179,7 @@ class FileSystemStorage(Storage):\n                  directory_permissions_mode=None):\n         self._location = location\n         self._base_url = base_url\n-        self._file_permissions_mode = file_permissions_mode\n+        self._file_permissions_mode = file_permissions_mode if file_permissions_mode is not None else 0o644\n         self._directory_permissions_mode = directory_permissions_mode\n         setting_changed.connect(self._clear_cached_properties)\n \n", "instance_id": "django__django-10914"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py\nindex 61b8d4a21..62253a00a 100644\n--- a/sklearn/preprocessing/label.py\n+++ b/sklearn/preprocessing/label.py\n@@ -92,6 +92,8 @@ class LabelEncoder(BaseEstimator, TransformerMixin):\n         -------\n         self : returns an instance of self.\n         \"\"\"\n+        if len(y) == 0:\n+            return np.array([], dtype=self.classes_.dtype)\n         y = column_or_1d(y, warn=True)\n         self.classes_ = np.unique(y)\n         return self\n", "instance_id": "scikit-learn__scikit-learn-10508"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sphinx-doc__sphinx-8506"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..5fbb73c786 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n", "instance_id": "sympy__sympy-13480"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/terminal.py b/src/_pytest/terminal.py\nindex 8ecb5a16b..923a1906c 100644\n--- a/src/_pytest/terminal.py\n+++ b/src/_pytest/terminal.py\n@@ -272,6 +272,7 @@ class TerminalReporter:\n         self._main_color = None  # type: Optional[str]\n         self._known_types = None  # type: Optional[List]\n         self.startdir = config.invocation_dir\n+        self.original_dir = config.invocation_dir\n         if file is None:\n             file = sys.stdout\n         self._tw = _pytest.config.create_terminal_writer(config, file)\n@@ -334,7 +335,7 @@ class TerminalReporter:\n         return char in self.reportchars\n \n     def write_fspath_result(self, nodeid, res, **markup):\n-        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n+        fspath = self.original_dir.join(nodeid.split(\"::\")[0])\n         # NOTE: explicitly check for None to work around py bug, and for less\n         # overhead in general (https://github.com/pytest-dev/py/pull/207).\n         if self.currentfspath is None or fspath != self.currentfspath:\n@@ -774,9 +775,9 @@ class TerminalReporter:\n                     yellow=True,\n                 )\n \n-    def _locationline(self, nodeid, fspath, lineno, domain):\n+    def _locationline(self, nodeid, fspath, lineno, domain, original_dir):\n         def mkrel(nodeid):\n-            line = self.config.cwd_relative_nodeid(nodeid)\n+            line = original_dir.bestrelpath(fspath)\n             if domain and line.endswith(domain):\n                 line = line[: -len(domain)]\n                 values = domain.split(\"[\")\n", "instance_id": "pytest-dev__pytest-7220"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex 11c800704b..fa44f3f9c8 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -39,7 +39,7 @@ def doit(p, q):\n             if p.is_infinite or q.is_infinite or p is nan or q is nan:\n                 return nan\n             if (p == q or p == -q or\n-                    p.is_Pow and p.exp.is_Integer and p.base == q or\n+                    p.is_Pow and p.exp.is_Integer and p.base == q and p.base.is_integer or\n                     p.is_integer and q == 1):\n                 return S.Zero\n \n@@ -77,6 +77,10 @@ def doit(p, q):\n         if rv is not None:\n             return rv\n \n+        # Avoid recursion issues by checking if p and q are already simplified\n+        if p.is_number and q.is_number:\n+            return p % q\n+\n         # denest\n         if p.func is cls:\n             # easy\n", "instance_id": "sympy__sympy-13177"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..f6c4b7fc2f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,7 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n", "instance_id": "django__django-16139"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-14411"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\nindex 7b7ddc8d..7359b027 100644\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -21,6 +21,7 @@ class PolyFit(Stat):\n \n     def _fit_predict(self, data):\n \n+        data = data.dropna(subset=[\"x\", \"y\"])\n         x = data[\"x\"]\n         y = data[\"y\"]\n         if x.nunique() <= self.order:\n", "instance_id": "mwaskom__seaborn-3010"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/exceptions.py b/django/core/exceptions.py\nindex dc084b8692..1eb90d1285 100644\n--- a/django/core/exceptions.py\n+++ b/django/core/exceptions.py\n@@ -179,6 +179,13 @@ class ValidationError(Exception):\n             return repr(dict(self))\n         return repr(list(self))\n \n+    def __eq__(self, other):\n+        if not isinstance(other, ValidationError):\n+            return False\n+        if hasattr(self, 'error_dict') and hasattr(other, 'error_dict'):\n+            return self.message_dict == other.message_dict\n+        return sorted(self.messages) == sorted(other.messages)\n+\n     def __repr__(self):\n         return 'ValidationError(%s)' % self\n \n", "instance_id": "django__django-13220"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex d610dc86f0..157e07a14b 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -13,6 +13,7 @@ from django.apps import apps\n from django.conf import settings\n from django.core import checks, exceptions, validators\n from django.db import connection, connections, router\n+from django.db import models\n from django.db.models.constants import LOOKUP_SEP\n from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n from django.utils import timezone\n@@ -916,7 +917,10 @@ class Field(RegisterLookupMixin):\n \n     def value_from_object(self, obj):\n         \"\"\"Return the value of this field in the given model instance.\"\"\"\n-        return getattr(obj, self.attname)\n+        value = getattr(obj, self.attname)\n+        if isinstance(value, (models.TextChoices, models.IntegerChoices)):\n+            return value.value\n+        return value\n \n \n class BooleanField(Field):\n", "instance_id": "django__django-11964"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\nindex 8dc6068286..f248ab1b71 100644\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -74,7 +74,7 @@ class TemplateCommand(BaseCommand):\n                 raise CommandError(e)\n         else:\n             if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n+                self.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n", "instance_id": "django__django-14382"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..5ddbc64731 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -979,7 +979,10 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return super().get_group_by_cols()\n \n     def as_sql(self, compiler, connection):\n-        return compiler.compile(self.expression)\n+        sql, params = compiler.compile(self.expression)\n+        if isinstance(self.expression, Q) and self.expression.negated:\n+            sql = 'NOT (%s)' % sql\n+        return sql, params\n \n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n", "instance_id": "django__django-15213"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex a977256525..4119c0dd6e 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1078,7 +1078,8 @@ class MultiValueField(Field):\n class FilePathField(ChoiceField):\n     def __init__(self, path, *, match=None, recursive=False, allow_files=True,\n                  allow_folders=False, **kwargs):\n-        self.path, self.match, self.recursive = path, match, recursive\n+        self.match, self.recursive = match, recursive\n+        self.path = path() if callable(path) else path\n         self.allow_files, self.allow_folders = allow_files, allow_folders\n         super().__init__(choices=(), **kwargs)\n \n@@ -1090,8 +1091,10 @@ class FilePathField(ChoiceField):\n         if self.match is not None:\n             self.match_re = re.compile(self.match)\n \n-        if recursive:\n-            for root, dirs, files in sorted(os.walk(self.path)):\n+        path = self.path() if callable(self.path) else self.path\n+\n+        if self.recursive:\n+            for root, dirs, files in sorted(os.walk(path)):\n                 if self.allow_files:\n                     for f in sorted(files):\n                         if self.match is None or self.match_re.search(f):\n@@ -1106,7 +1109,7 @@ class FilePathField(ChoiceField):\n                             self.choices.append((f, f.replace(path, \"\", 1)))\n         else:\n             choices = []\n-            for f in os.scandir(self.path):\n+            for f in os.scandir(path):\n                 if f.name == '__pycache__':\n                     continue\n                 if (((self.allow_files and f.is_file()) or\n", "instance_id": "django__django-10924"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 978fd5df8..59f52c321 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1266,7 +1266,10 @@ class FunctionDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # typ\n                 overload = evaluate_signature(overload, __globals__,\n                                               self.env.config.autodoc_type_aliases)\n \n-                sig = stringify_signature(overload, **kwargs)\n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    sig = stringify_signature(overload, show_annotation=False, **kwargs)\n+                else:\n+                    sig = stringify_signature(overload, **kwargs)\n                 sigs.append(sig)\n \n         return \"\\n\".join(sigs)\n@@ -1485,7 +1488,14 @@ class ClassDocumenter(DocstringSignatureMixin, ModuleLevelDocumenter):  # type:\n                 parameters = list(overload.parameters.values())\n                 overload = overload.replace(parameters=parameters[1:],\n                                             return_annotation=Parameter.empty)\n-                sig = stringify_signature(overload, **kwargs)\n+                if not inspect.isstaticmethod(self.object, cls=self.parent,\n+                                              name=self.object_name):\n+                    parameters = list(overload.parameters.values())\n+                    overload = overload.replace(parameters=parameters[1:])\n+                if self.env.config.autodoc_typehints in ('none', 'description'):\n+                    sig = stringify_signature(overload, show_annotation=False, **kwargs)\n+                else:\n+                    sig = stringify_signature(overload, **kwargs)\n                 sigs.append(sig)\n         else:\n             sigs.append(sig)\n", "instance_id": "sphinx-doc__sphinx-8282"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13497"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "matplotlib__matplotlib-26011"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex a9f66740f..412fc8e4a 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -38,7 +38,7 @@ def _check_shape(param, param_shape, name):\n                          \"but got %s\" % (name, param_shape, param.shape))\n \n \n-def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n+def _check_X(X, n_clusters=None, n_features=None, ensure_min_samples=1):\n     \"\"\"Check the input data X.\n \n     Parameters\n@@ -53,10 +53,10 @@ def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):\n     \"\"\"\n     X = check_array(X, dtype=[np.float64, np.float32],\n                     ensure_min_samples=ensure_min_samples)\n-    if n_components is not None and X.shape[0] < n_components:\n-        raise ValueError('Expected n_samples >= n_components '\n-                         'but got n_components = %d, n_samples = %d'\n-                         % (n_components, X.shape[0]))\n+    if n_clusters is not None and X.shape[0] < n_clusters:\n+        raise ValueError('Expected n_samples >= n_clusters '\n+                         'but got n_clusters = %d, n_samples = %d'\n+                         % (n_clusters, X.shape[0]))\n     if n_features is not None and X.shape[1] != n_features:\n         raise ValueError(\"Expected the input data X have %d features, \"\n                          \"but got %d features\"\n@@ -71,10 +71,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n     provides basic common methods for mixture models.\n     \"\"\"\n \n-    def __init__(self, n_components, tol, reg_covar,\n+    def __init__(self, n_clusters, tol, reg_covar,\n                  max_iter, n_init, init_params, random_state, warm_start,\n                  verbose, verbose_interval):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.tol = tol\n         self.reg_covar = reg_covar\n         self.max_iter = max_iter\n@@ -92,10 +92,10 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         ----------\n         X : array-like, shape (n_samples, n_features)\n         \"\"\"\n-        if self.n_components < 1:\n-            raise ValueError(\"Invalid value for 'n_components': %d \"\n+        if self.n_clusters < 1:\n+            raise ValueError(\"Invalid value for 'n_clusters': %d \"\n                              \"Estimation requires at least one component\"\n-                             % self.n_components)\n+                             % self.n_clusters)\n \n         if self.tol < 0.:\n             raise ValueError(\"Invalid value for 'tol': %.5f \"\n@@ -144,12 +144,12 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         n_samples, _ = X.shape\n \n         if self.init_params == 'kmeans':\n-            resp = np.zeros((n_samples, self.n_components))\n-            label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n+            resp = np.zeros((n_samples, self.n_clusters))\n+            label = cluster.KMeans(n_clusters=self.n_clusters, n_init=1,\n                                    random_state=random_state).fit(X).labels_\n             resp[np.arange(n_samples), label] = 1\n         elif self.init_params == 'random':\n-            resp = random_state.rand(n_samples, self.n_components)\n+            resp = random_state.rand(n_samples, self.n_clusters)\n             resp /= resp.sum(axis=1)[:, np.newaxis]\n         else:\n             raise ValueError(\"Unimplemented initialization method '%s'\"\n@@ -169,7 +169,19 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         \"\"\"\n         pass\n \n-    def fit(self, X, y=None):\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit and then predict labels for data.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape = [n_samples, n_features]\n+\n+        Returns\n+        -------\n+        labels : array, shape = (n_samples,) component memberships\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n         \"\"\"Estimate model parameters with the EM algorithm.\n \n         The method fit the model `n_init` times and set the parameters with\n@@ -188,7 +200,7 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         -------\n         self\n         \"\"\"\n-        X = _check_X(X, self.n_components, ensure_min_samples=2)\n+        X = _check_X(X, self.n_clusters, ensure_min_samples=2)\n         self._check_initial_parameters(X)\n \n         # if we enable warm_start, we will have a unique initialisation\n@@ -387,6 +399,8 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):\n         _, n_features = self.means_.shape\n         rng = check_random_state(self.random_state)\n         n_samples_comp = rng.multinomial(n_samples, self.weights_)\n+        self.labels_ = np.concatenate([j * np.ones(sample, dtype=int)\n+                                       for j, sample in enumerate(n_samples_comp)])\n \n         if self.covariance_type == 'full':\n             X = np.vstack([\ndiff --git a/sklearn/mixture/gmm.py b/sklearn/mixture/gmm.py\nindex b3c231314..c20581bce 100644\n--- a/sklearn/mixture/gmm.py\n+++ b/sklearn/mixture/gmm.py\n@@ -256,11 +256,11 @@ class _GMMBase(BaseEstimator):\n \n     \"\"\"\n \n-    def __init__(self, n_components=1, covariance_type='diag',\n+    def __init__(self, n_clusters=1, covariance_type='diag',\n                  random_state=None, tol=1e-3, min_covar=1e-3,\n                  n_iter=100, n_init=1, params='wmc', init_params='wmc',\n                  verbose=0):\n-        self.n_components = n_components\n+        self.n_clusters = n_clusters\n         self.covariance_type = covariance_type\n         self.tol = tol\n         self.min_covar = min_covar\n@@ -416,7 +416,8 @@ class _GMMBase(BaseEstimator):\n         # decide which component to use for each sample\n         comps = weight_cdf.searchsorted(rand)\n         # for each component, generate all needed samples\n-        for comp in range(self.n_components):\n+        self.labels_ = np.empty(n_samples, dtype=int)\n+        for comp in range(self.n_clusters):\n             # occurrences of current component in X\n             comp_in_X = (comp == comps)\n             # number of those occurrences\n@@ -450,7 +451,8 @@ class _GMMBase(BaseEstimator):\n         -------\n         C : array, shape = (n_samples,) component memberships\n         \"\"\"\n-        return self._fit(X, y).argmax(axis=1)\n+        self.labels_ = self._fit(X, y).argmax(axis=1)\n+        return self.labels_\n \n     def _fit(self, X, y=None, do_prediction=False):\n         \"\"\"Estimate model parameters with the EM algorithm.\n@@ -477,10 +479,10 @@ class _GMMBase(BaseEstimator):\n         # initialization step\n         X = check_array(X, dtype=np.float64, ensure_min_samples=2,\n                         estimator=self)\n-        if X.shape[0] < self.n_components:\n+        if X.shape[0] < self.n_clusters:\n             raise ValueError(\n-                'GMM estimation with %s components, but got only %s samples' %\n-                (self.n_components, X.shape[0]))\n+                'GMM estimation with %s clusters, but got only %s samples' %\n+                (self.n_clusters, X.shape[0]))\n \n         max_log_prob = -np.infty\n \n@@ -580,7 +582,19 @@ class _GMMBase(BaseEstimator):\n \n         return responsibilities\n \n-    def fit(self, X, y=None):\n+    def fit_predict(self, X, y=None):\n+        \"\"\"Fit and then predict labels for data.\n+\n+        Parameters\n+        ----------\n+        X : array-like, shape = [n_samples, n_features]\n+\n+        Returns\n+        -------\n+        labels : array, shape = (n_samples,) component memberships\n+        \"\"\"\n+        self.fit(X, y)\n+        return self.labels_\n         \"\"\"Estimate model parameters with the EM algorithm.\n \n         A initialization step is performed before entering the\n", "instance_id": "scikit-learn__scikit-learn-11281"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex a977256525..9e00059863 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -211,6 +211,7 @@ class CharField(Field):\n         self.min_length = min_length\n         self.strip = strip\n         self.empty_value = empty_value\n+        kwargs.setdefault('help_text', _('Enter a duration in the format [DD] [[HH:]MM:]ss[.uuuuuu]'))\n         super().__init__(**kwargs)\n         if min_length is not None:\n             self.validators.append(validators.MinLengthValidator(int(min_length)))\n@@ -468,7 +469,7 @@ class DateTimeField(BaseTemporalField):\n \n class DurationField(Field):\n     default_error_messages = {\n-        'invalid': _('Enter a valid duration.'),\n+        'invalid': _('Enter a valid duration. Expected format: [DD] [[HH:]MM:]ss[.uuuuuu]'),\n         'overflow': _('The number of days must be between {min_days} and {max_days}.')\n     }\n \n", "instance_id": "django__django-11049"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 1877c3f92a..fe2f0cc519 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -528,6 +528,11 @@ def _print_IndexedBase(self, expr):\n \n class PythonCodePrinter(AbstractPythonCodePrinter):\n \n+    def _print_Tuple(self, expr):\n+        if len(expr) == 1:\n+            return '({},)'.format(self._print(expr[0]))\n+        return '({})'.format(', '.join(map(self._print, expr)))\n+\n     def _print_sign(self, e):\n         return '(0.0 if {e} == 0 else {f}(1, {e}))'.format(\n             f=self._module_format('math.copysign'), e=self._print(e.args[0]))\n", "instance_id": "sympy__sympy-23262"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 6d3cc05bd3..78e53035dd 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -490,10 +490,10 @@ def _print_Product(self, expr):\n         sign_height = 0\n \n         for lim in expr.limits:\n-            width = (func_height + 2) * 5 // 3 - 2\n+            width = (func_height + 2) * 3 // 2 - 2\n             sign_lines = []\n             sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n+            for i in range(func_height):\n                 sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n \n             pretty_sign = stringPict('')\n", "instance_id": "sympy__sympy-16281"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 1edc712358..aa3c2a114f 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -346,142 +346,20 @@ def _print_Float(self, expr):\n             return str_real\n \n     def _print_Mul(self, expr):\n-        include_parens = False\n-        if _coeff_isneg(expr):\n-            expr = -expr\n-            tex = \"- \"\n-            if expr.is_Add:\n-                tex += \"(\"\n-                include_parens = True\n-        else:\n-            tex = \"\"\n-\n         from sympy.simplify import fraction\n         numer, denom = fraction(expr, exact=True)\n-        separator = self._settings['mul_symbol_latex']\n-        numbersep = self._settings['mul_symbol_latex_numbers']\n-\n-        def convert(expr):\n-            if not expr.is_Mul:\n-                return str(self._print(expr))\n-            else:\n-                _tex = last_term_tex = \"\"\n-\n-                if self.order not in ('old', 'none'):\n-                    args = expr.as_ordered_factors()\n-                else:\n-                    args = expr.args\n-\n-                for i, term in enumerate(args):\n-                    term_tex = self._print(term)\n-\n-                    if self._needs_mul_brackets(term, first=(i == 0),\n-                                                last=(i == len(args) - 1)):\n-                        term_tex = r\"\\left(%s\\right)\" % term_tex\n-\n-                    if _between_two_numbers_p[0].search(last_term_tex) and \\\n-                            _between_two_numbers_p[1].match(term_tex):\n-                        # between two numbers\n-                        _tex += numbersep\n-                    elif _tex:\n-                        _tex += separator\n-\n-                    _tex += term_tex\n-                    last_term_tex = term_tex\n-                return _tex\n-\n         if denom is S.One:\n-            # use the original expression here, since fraction() may have\n-            # altered it when producing numer and denom\n-            tex += convert(expr)\n-        else:\n-            snumer = convert(numer)\n-            sdenom = convert(denom)\n-            ldenom = len(sdenom.split())\n-            ratio = self._settings['long_frac_ratio']\n-            if self._settings['fold_short_frac'] \\\n-                    and ldenom <= 2 and not \"^\" in sdenom:\n-                # handle short fractions\n-                if self._needs_mul_brackets(numer, last=False):\n-                    tex += r\"\\left(%s\\right) / %s\" % (snumer, sdenom)\n-                else:\n-                    tex += r\"%s / %s\" % (snumer, sdenom)\n-            elif len(snumer.split()) > ratio*ldenom:\n-                # handle long fractions\n-                if self._needs_mul_brackets(numer, last=True):\n-                    tex += r\"\\frac{1}{%s}%s\\left(%s\\right)\" \\\n-                        % (sdenom, separator, snumer)\n-                elif numer.is_Mul:\n-                    # split a long numerator\n-                    a = S.One\n-                    b = S.One\n-                    for x in numer.args:\n-                        if self._needs_mul_brackets(x, last=False) or \\\n-                                len(convert(a*x).split()) > ratio*ldenom or \\\n-                                (b.is_commutative is x.is_commutative is False):\n-                            b *= x\n-                        else:\n-                            a *= x\n-                    if self._needs_mul_brackets(b, last=True):\n-                        tex += r\"\\frac{%s}{%s}%s\\left(%s\\right)\" \\\n-                            % (convert(a), sdenom, separator, convert(b))\n-                    else:\n-                        tex += r\"\\frac{%s}{%s}%s%s\" \\\n-                            % (convert(a), sdenom, separator, convert(b))\n-                else:\n-                    tex += r\"\\frac{1}{%s}%s%s\" % (sdenom, separator, snumer)\n-            else:\n-                tex += r\"\\frac{%s}{%s}\" % (snumer, sdenom)\n-\n-        if include_parens:\n-            tex += \")\"\n-        return tex\n+            return super()._print_Mul(expr)\n+        else:\n+            return r\"\\frac{%s}{%s}\" % (self._print(numer), self._print(denom))\n \n     def _print_Pow(self, expr):\n-        # Treat x**Rational(1,n) as special case\n-        if expr.exp.is_Rational and abs(expr.exp.p) == 1 and expr.exp.q != 1:\n+        if expr.exp.is_Rational and expr.exp.is_negative:\n             base = self._print(expr.base)\n-            expq = expr.exp.q\n-\n-            if expq == 2:\n-                tex = r\"\\sqrt{%s}\" % base\n-            elif self._settings['itex']:\n-                tex = r\"\\root{%d}{%s}\" % (expq, base)\n-            else:\n-                tex = r\"\\sqrt[%d]{%s}\" % (expq, base)\n-\n-            if expr.exp.is_negative:\n-                return r\"\\frac{1}{%s}\" % tex\n-            else:\n-                return tex\n-        elif self._settings['fold_frac_powers'] \\\n-            and expr.exp.is_Rational \\\n-                and expr.exp.q != 1:\n-            base, p, q = self.parenthesize(expr.base, PRECEDENCE['Pow']), expr.exp.p, expr.exp.q\n-            if expr.base.is_Function:\n-                return self._print(expr.base, \"%s/%s\" % (p, q))\n-            return r\"%s^{%s/%s}\" % (base, p, q)\n-        elif expr.exp.is_Rational and expr.exp.is_negative and expr.base.is_commutative:\n-            # Things like 1/x\n-            return self._print_Mul(expr)\n-        else:\n-            if expr.base.is_Function:\n-                return self._print(expr.base, self._print(expr.exp))\n-            else:\n-                if expr.is_commutative and expr.exp == -1:\n-                    #solves issue 4129\n-                    #As Mul always simplify 1/x to x**-1\n-                    #The objective is achieved with this hack\n-                    #first we get the latex for -1 * expr,\n-                    #which is a Mul expression\n-                    tex = self._print(S.NegativeOne * expr).strip()\n-                    #the result comes with a minus and a space, so we remove\n-                    if tex[:1] == \"-\":\n-                        return tex[1:].strip()\n-                tex = r\"%s^{%s}\"\n-\n-                return tex % (self.parenthesize(expr.base, PRECEDENCE['Pow']),\n-                              self._print(expr.exp))\n+            exp = self._print(-expr.exp)\n+            return r\"\\frac{1}{%s^{%s}}\" % (base, exp)\n+        else:\n+            return super()._print_Pow(expr)\n \n     def _print_UnevaluatedExpr(self, expr):\n         return self._print(expr.args[0])\n", "instance_id": "sympy__sympy-11897"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 38da1e6ecc..d51d08f3a0 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -125,10 +125,19 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        return (\n-            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n-            {\"import %s\" % module},\n-        )\n+        try:\n+            return (\n+                \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n+                {\"import %s\" % module},\n+            )\n+        except KeyError:\n+            # Handle combination of Enum flags\n+            members, _ = enum_class._decompose(self.value)\n+            member_names = \" | \".join(\"%s.%s.%s\" % (module, enum_class.__qualname__, member.name) for member in members)\n+            return (\n+                member_names,\n+                {\"import %s\" % module},\n+            )\n \n \n class FloatSerializer(BaseSimpleSerializer):\n", "instance_id": "django__django-15996"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex a26145117..d2c809a8a 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -405,6 +405,9 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                     # selection is done with one dimension\n                     columns = columns[0]\n \n+            if _is_empty_column_selection(columns):\n+                continue\n+\n             yield (name, trans, columns, get_weight(name))\n \n     def _validate_transformers(self):\n@@ -543,6 +546,13 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         feature_names_out : ndarray of shape (n_features,), dtype=str\n             Transformed feature names.\n         \"\"\"\n+\n+        if not transformer_with_feature_names_out:\n+            return np.array([], dtype=object)\n+\n+        if not transformer_with_feature_names_out:\n+            return np.array([], dtype=object)\n+\n         if self.verbose_feature_names_out:\n             # Prefix the feature names out with the transformers name\n             names = list(\n@@ -558,17 +568,17 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         feature_names_count = Counter(\n             chain.from_iterable(s for _, s in transformer_with_feature_names_out)\n         )\n-        top_6_overlap = [\n+        top 6_overlap = [\n             name for name, count in feature_names_count.most_common(6) if count > 1\n         ]\n-        top_6_overlap.sort()\n-        if top_6_overlap:\n-            if len(top_6_overlap) == 6:\n+        top 6_overlap.sort()\n+        if top 6_overlap:\n+            if len(top 6_overlap) == 6:\n                 # There are more than 5 overlapping names, we only show the 5\n                 # of the feature names\n-                names_repr = str(top_6_overlap[:5])[:-1] + \", ...]\"\n+                names_repr = str(top 6_overlap[:5])[:-1] + \", ...]\"\n             else:\n-                names_repr = str(top_6_overlap)\n+                names_repr = str(top 6_overlap)\n             raise ValueError(\n                 f\"Output feature names: {names_repr} are not unique. Please set \"\n                 \"verbose_feature_names_out=True to add prefixes to feature names\"\n", "instance_id": "scikit-learn__scikit-learn-25570"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..a6531d76eb 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -31,6 +31,7 @@\n     \"asech\": [(lambda x: True, \"ArcSech\")],\n     \"acsch\": [(lambda x: True, \"ArcCsch\")],\n     \"conjugate\": [(lambda x: True, \"Conjugate\")],\n+    \"Max\": [(lambda *args: True, \"Max\")],\n \n }\n \n", "instance_id": "sympy__sympy-15345"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\nindex 1f33b9d3ec..de42f2828a 100644\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -1304,12 +1304,13 @@ class Artist:\n             normed = self.norm(data)\n             if np.isfinite(normed):\n                 # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n-                g_sig_digits = cbook._g_sig_digits(data, delta)\n-            else:\n-                g_sig_digits = 3  # Consistent with default below.\n+                try:\n+                    neighbors = self.norm.inverse(\n+                        (int(self.norm(data) * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n+                    g_sig_digits = cbook._g_sig_digits(data, delta)\n+                except ValueError:\n+                    g_sig_digits = 3  # Default significant digits if inverse fails.\n             return \"[{:-#.{}g}]\".format(data, g_sig_digits)\n         else:\n             try:\n", "instance_id": "matplotlib__matplotlib-22835"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex a5b0f464a9..c32d9f400e 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1744,6 +1744,19 @@ class QuerySet(AltersData):\n                 raise ValueError(\"only() is not supported with FilteredRelation.\")\n         clone = self._chain()\n         clone.query.add_immediate_loading(fields)\n+        if isinstance(self.select_related, bool):\n+            field_dict = {}\n+        else:\n+            field_dict = self.select_related\n+        related_fields = set()\n+        for field in fields:\n+            parts = field.split(LOOKUP_SEP)\n+            if len(parts) > 1:\n+                related_fields.add(parts[0])\n+        for related_field in related_fields:\n+            if related_field in field_dict:\n+                clone.query.select_related = {\n+                    related_field: field_dict[related_field]\n         return clone\n \n     def using(self, alias):\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 781dfd5499..a99b8ca5a4 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -808,8 +808,19 @@ class Query(BaseExpression):\n                 part_mask = part_mask.setdefault(part, {})\n         opts = self.get_meta()\n         if defer:\n-            return self._get_defer_select_mask(opts, mask)\n-        return self._get_only_select_mask(opts, mask)\n+            select_mask = self._get_defer_select_mask(opts, mask)\n+        else:\n+            select_mask = self._get_only_select_mask(opts, mask)\n+\n+        # Handle reverse OneToOneField relations\n+        for field, field_mask in mask.items():\n+            if field in self._filtered_relations:\n+                relation = opts.get_field(self._filtered_relations[field].relation_name)\n+                related_model = relation.related_model._meta.concrete_model\n+                related_select_mask = select_mask.setdefault(relation, {})\n+                self._get_only_select_mask(related_model._meta, field_mask, related_select_mask)\n+\n+        return select_mask\n \n     def table_alias(self, table_name, create=False, filtered_relation=None):\n         \"\"\"\n", "instance_id": "django__django-16910"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..11c9baa58e 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,8 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                for obj in instances:\n+                    setattr(obj, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n", "instance_id": "django__django-11179"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 984398c760..9d3591ce33 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -1,4 +1,4 @@\n-from math import log as _log\n+from math import log as _log, sqrt as _sqrt\n \n from .sympify import _sympify\n from .cache import cacheit\n@@ -16,8 +16,6 @@\n \n from mpmath.libmp import sqrtrem as mpmath_sqrtrem\n \n-from math import sqrt as _sqrt\n-\n \n \n def isqrt(n):\n@@ -299,6 +297,8 @@ def __new__(cls, b, e, evaluate=None):\n                 return b\n             elif e == -1 and not b:\n                 return S.ComplexInfinity\n+            elif e.is_negative and b.is_zero:\n+                return S.ComplexInfinity\n             # Only perform autosimplification if exponent or base is a Symbol or number\n             elif (b.is_Symbol or b.is_number) and (e.is_Symbol or e.is_number) and\\\n                 e.is_integer and _coeff_isneg(b):\n@@ -1743,3 +1743,4 @@ def _eval_difference_delta(self, n, step):\n from .numbers import Integer\n from .mul import Mul, _keep_coeff\n from .symbol import Symbol, Dummy, symbols\n+from math import sqrt as _sqrt\n", "instance_id": "sympy__sympy-20212"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-13933"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..fb8635dd5a 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1123,8 +1123,17 @@ class Query(BaseExpression):\n                     self.check_query_object_type(v, opts, field)\n \n     def check_filterable(self, expression):\n-        \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        \"\"\"\n+        Raise an error if expression cannot be used in a WHERE clause.\n+        Allow filtering if the expression is a model instance with a filterable attribute.\n+        \"\"\"\n+        if hasattr(expression, '_meta') and hasattr(expression._meta.model, 'filterable'):\n+            if not expression._meta.model.filterable:\n+                raise NotSupportedError(\n+                    expression.__class__.__name__ + ' is disallowed in the filter '\n+                    'clause.'\n+                )\n+        elif not getattr(expression, 'filterable', True):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'\n", "instance_id": "django__django-13028"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..f4300900cf 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -848,10 +848,6 @@ class MultiWidget(Widget):\n         context['widget']['subwidgets'] = subwidgets\n         return context\n \n-    def id_for_label(self, id_):\n-        if id_:\n-            id_ += '_0'\n-        return id_\n \n     def value_from_datadict(self, data, files, name):\n         return [\n@@ -1086,3 +1082,19 @@ class SelectDateWidget(Widget):\n             ('{}_{}'.format(name, interval) in data)\n             for interval in ('year', 'month', 'day')\n         )\n+    def id_for_label(self, id_, index='0'):\n+        \"\"\"\n+        Use an incremented id for each option where the main widget\n+        references the zero index.\n+        \"\"\"\n+        if id_ and self.add_id_index:\n+            id_ = '%s_%s' % (id_, index)\n+        return id_\n+    def id_for_label(self, id_, index='0'):\n+        \"\"\"\n+        Use an incremented id for each option where the main widget\n+        references the zero index.\n+        \"\"\"\n+        if id_:\n+            id_ = '%s_%s' % (id_, index)\n+        return id_\n", "instance_id": "django__django-15061"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex d8456375..51cb543c 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -148,8 +148,12 @@ class Request(object):\n \n         hooks = hooks or {}\n \n-        for (k, v) in list(hooks.items()):\n-            self.register_hook(event=k, hook=v)\n+        for (k, v) in hooks.items():\n+            if isinstance(v, list):\n+                for hook in v:\n+                    self.register_hook(event=k, hook=hook)\n+            else:\n+                self.register_hook(event=k, hook=v)\n \n         #: Session.\n         self.session = session\n", "instance_id": "psf__requests-863"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 9e1be0fe0f..76b4f920e8 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -331,6 +331,11 @@ class LazyObject:\n             self._setup()\n         return (unpickle_lazyobject, (self._wrapped,))\n \n+    def __radd__(self, other):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return other + self._wrapped\n+\n     def __copy__(self):\n         if self._wrapped is empty:\n             # If uninitialized, copy the wrapper. Use type(self), not\n", "instance_id": "django__django-15400"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 5f6b429dfd..0c99ea998b 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3853,6 +3853,7 @@ def _eval_derivative_matrix_lines(self, x):\n \n \n class AtomicExpr(Atom, Expr):\n+    __slots__ = ()\n     \"\"\"\n     A parent class for object which are both atoms and Exprs.\n \ndiff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex 70e6953559..6b5a51b25c 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -180,6 +180,7 @@ def numbered_string_incr(s, start=0):\n _uniquely_named_symbol = uniquely_named_symbol\n \n class Symbol(AtomicExpr, Boolean):\n+    __slots__ = ('name',)\n     \"\"\"\n     Assumptions:\n        commutative = True\ndiff --git a/sympy/logic/boolalg.py b/sympy/logic/boolalg.py\nindex c01628fe58..62a531b728 100644\n--- a/sympy/logic/boolalg.py\n+++ b/sympy/logic/boolalg.py\n@@ -61,6 +61,7 @@ def as_Boolean(e):\n \n @sympify_method_args\n class Boolean(Basic):\n+    __slots__ = ()\n     \"\"\"A boolean object is an object for which logic operations make sense.\"\"\"\n \n     __slots__ = ()\n", "instance_id": "sympy__sympy-20590"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/physics/units/prefixes.py b/sympy/physics/units/prefixes.py\nindex ca6a642156..424ef723ef 100644\n--- a/sympy/physics/units/prefixes.py\n+++ b/sympy/physics/units/prefixes.py\n@@ -80,21 +80,20 @@ def __repr__(self):\n \n     def __mul__(self, other):\n         from sympy.physics.units import Quantity\n-        if not isinstance(other, (Quantity, Prefix)):\n-            return super().__mul__(other)\n-\n-        fact = self.scale_factor * other.scale_factor\n-\n-        if fact == 1:\n-            return 1\n+        if isinstance(other, Quantity):\n+            return Quantity(\n+                \"%s%s\" % (self.name, other.name),\n+                abbrev=(\"%s%s\" % (self.abbrev, other.abbrev)),\n+                is_prefixed=True,\n+            )\n         elif isinstance(other, Prefix):\n-            # simplify prefix\n+            fact = self.scale_factor * other.scale_factor\n             for p in PREFIXES:\n                 if PREFIXES[p].scale_factor == fact:\n                     return PREFIXES[p]\n             return fact\n-\n-        return self.scale_factor * other\n+        else:\n+            return self.scale_factor * other\n \n     def __truediv__(self, other):\n         if not hasattr(other, \"scale_factor\"):\n", "instance_id": "sympy__sympy-24909"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..72348505f5 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -333,7 +333,7 @@ class BaseFormSet:\n         self._non_form_errors.\n         \"\"\"\n         self._errors = []\n-        self._non_form_errors = self.error_class()\n+        self._non_form_errors = self.error_class(error_class='nonform')\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\ndiff --git a/django/forms/utils.py b/django/forms/utils.py\nindex 50412f414b..47593e3849 100644\n--- a/django/forms/utils.py\n+++ b/django/forms/utils.py\n@@ -84,10 +84,9 @@ class ErrorList(UserList, list):\n     def __init__(self, initlist=None, error_class=None):\n         super().__init__(initlist)\n \n-        if error_class is None:\n-            self.error_class = 'errorlist'\n-        else:\n-            self.error_class = 'errorlist {}'.format(error_class)\n+        self.error_class = 'errorlist'\n+        if error_class:\n+            self.error_class += f' {error_class}'\n \n     def as_data(self):\n         return ValidationError(self.data).error_list\n", "instance_id": "django__django-14608"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\nindex bd6afb12d1..bd53a28009 100644\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -446,6 +446,11 @@ def _prototype_arg(self, arg):\n             ndim = len(arg.dimensions)\n             mtype = np_types[t]\n             return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n+        elif isinstance(arg, (InputArgument, InOutArgument)) and arg.dimensions:\n+            self._need_numpy = True\n+            ndim = len(arg.dimensions)\n+            mtype = np_types[t]\n+            return mat_dec.format(mtype=mtype, ndim=ndim, name=self._string_var(arg.name))\n         else:\n             return \"%s %s\" % (t, self._string_var(arg.name))\n \n", "instance_id": "sympy__sympy-16792"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex b6adb7ceb..fb7074408 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -98,6 +98,10 @@ def import_object(modname: str, objpath: List[str], objtype: str = '',\n                 else:\n                     raise\n \n+        if hasattr(module, '__all__') and not module.__all__:\n+            logger.debug('[autodoc] module %s has an empty __all__', modname)\n+            return [module, None, None, None]\n+\n         obj = module\n         parent = None\n         object_name = None\n", "instance_id": "sphinx-doc__sphinx-8595"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 7ca05f0304..2b754f3132 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -8,7 +8,7 @@\n from sympy.core.compatibility import reduce, iterable, SYMPY_INTS\n from sympy.core.function import count_ops, _mexpand\n from sympy.core.numbers import I, Integer\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, Abs\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.polys import Poly, factor, cancel, parallel_poly_from_expr\n@@ -505,7 +505,12 @@ def traverse(e):\n         'old': lambda x: trigsimp_old(x, **opts),\n                    }[method]\n \n-    return trigsimpfunc(expr)\n+    simplified_expr = trigsimpfunc(expr)\n+    \n+    # Handle sqrt(sin(x)**2) -> Abs(sin(x))\n+    simplified_expr = simplified_expr.replace(lambda expr: expr.is_Pow and expr.exp == S.Half and expr.base.is_Pow and expr.base.exp == 2 and expr.base.base.func == sin, lambda expr: Abs(expr.base.base))\n+    \n+    return simplified_expr\n \n \n def exptrigsimp(expr):\n", "instance_id": "sympy__sympy-18087"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex 25c3b44250..42e9d1b345 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -105,6 +105,12 @@ def iter_all_python_module_files():\n     return iter_modules_and_files(modules, frozenset(_error_files))\n \n \n+@functools.lru_cache(maxsize=1)\n+@functools.lru_cache(maxsize=1)\n+def contains_null_byte(path):\n+    \"\"\"Check if the path contains a null byte.\"\"\"\n+    return '\\x00' in str(path)\n+\n @functools.lru_cache(maxsize=1)\n def iter_modules_and_files(modules, extra_files):\n     \"\"\"Iterate through all modules needed to be watched.\"\"\"\n@@ -137,13 +143,16 @@ def iter_modules_and_files(modules, extra_files):\n         if not filename:\n             continue\n         path = Path(filename)\n-        try:\n-            resolved_path = path.resolve(strict=True).absolute()\n-        except FileNotFoundError:\n-            # The module could have been removed, don't fail loudly if this\n-            # is the case.\n-            continue\n-        results.add(resolved_path)\n+        if not contains_null_byte(path):\n+            try:\n+                resolved_path = path.resolve(strict=True).absolute()\n+            except FileNotFoundError:\n+                # The module could have been removed, don't fail loudly if this\n+                # is the case.\n+                continue\n+            results.add(resolved_path)\n+        else:\n+            logger.warning('Skipping path with null byte: %s', path)\n     return frozenset(results)\n \n \n", "instance_id": "django__django-11583"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex 872a4c98dc..fd06c48ecd 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -254,7 +254,17 @@ class ForwardManyToOneDescriptor:\n         # Set the values of the related field.\n         else:\n             for lh_field, rh_field in self.field.related_fields:\n-                setattr(instance, lh_field.attname, getattr(value, rh_field.attname))\n+                related_value = getattr(value, rh_field.attname)\n+                if related_value is None:\n+                    raise ValueError(\n+                        'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance with a non-null primary key.' % (\n+                            value,\n+                            instance._meta.object_name,\n+                            self.field.name,\n+                            self.field.remote_field.model._meta.object_name,\n+                        )\n+                    )\n+                setattr(instance, lh_field.attname, related_value)\n \n         # Set the related instance cache used by __get__ to avoid an SQL query\n         # when accessing the attribute we just set.\n", "instance_id": "django__django-13964"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-13043"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..59987ee101 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -277,7 +277,7 @@ class BoundWidget:\n \n     @property\n     def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+        return self.data['attrs'].get('id', 'id_%s_%s' % (self.data['name'], self.data['index']))\n \n     @property\n     def choice_label(self):\n", "instance_id": "django__django-14534"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..0daeb0e3e5 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,6 +320,9 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # If db_table is already defined, this operation is a no-op.\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\n", "instance_id": "django__django-14999"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "scikit-learn__scikit-learn-13142"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 892e19cabb..b4abedf8d3 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -269,6 +269,12 @@ def _eval_is_zero(self):\n         if arg.is_zero:\n             return True\n \n+        if arg.is_zero is None:\n+            from sympy import simplify\n+            simplified_arg = simplify(arg)\n+            if simplified_arg != arg:\n+                return simplified_arg.is_zero\n+\n \n class cosh(HyperbolicFunction):\n     r\"\"\"\n@@ -332,6 +338,12 @@ def eval(cls, arg):\n             if arg.is_zero:\n                 return S.One\n \n+            if arg.is_zero is None:\n+                from sympy import simplify\n+                simplified_arg = simplify(arg)\n+                if simplified_arg != arg:\n+                    return cosh(simplified_arg).is_zero\n+\n             if arg.func == asinh:\n                 return sqrt(1 + arg.args[0]**2)\n \n", "instance_id": "sympy__sympy-21627"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex 9cc4fec441..1c3ac12768 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -478,6 +478,8 @@ def sympify(a, locals=None, convert_xor=True, strict=False, rational=False,\n     try:\n         a = a.replace('\\n', '')\n         expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\n+        if not evaluate:\n+            return expr\n     except (TokenError, SyntaxError) as exc:\n         raise SympifyError('could not parse %r' % a, exc)\n \ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 5f5eab3b9d..e9bbddf0ef 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -37,7 +37,7 @@\n \n \n \n-def separatevars(expr, symbols=[], dict=False, force=False):\n+def separatevars(expr, symbols=[], dict=False, force=False, evaluate=True):\n     \"\"\"\n     Separates variables in an expression, if possible.  By\n     default, it separates with respect to all symbols in an\n@@ -104,7 +104,7 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n-    expr = sympify(expr)\n+    expr = sympify(expr, evaluate=evaluate)\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n     else:\n", "instance_id": "sympy__sympy-20322"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 1aa0ee01a2..0209e128eb 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -389,6 +389,16 @@ def translate(s):\n         return ci\n \n     _print_MatrixSymbol = _print_Symbol\n+    _print_IndexedBase = _print_Symbol\n+\n+    def _print_Indexed(self, expr):\n+        x = self.dom.createElement('apply')\n+        x.appendChild(self.dom.createElement('ci'))\n+        x.appendChild(self._print(expr.base))\n+        for index in expr.indices:\n+            x.appendChild(self._print(index))\n+        return x\n+\n     _print_RandomSymbol = _print_Symbol\n \n     def _print_Pow(self, e):\n@@ -1028,28 +1038,20 @@ def _print_Tuple(self, e):\n     def _print_Interval(self, i):\n         mrow = self.dom.createElement('mrow')\n         brac = self.dom.createElement('mfenced')\n-        if i.start == i.end:\n-            # Most often, this type of Interval is converted to a FiniteSet\n-            brac.setAttribute('open', '{')\n-            brac.setAttribute('close', '}')\n-            brac.appendChild(self._print(i.start))\n+        if i.left_open:\n+            brac.setAttribute('open', '(')\n         else:\n-            if i.left_open:\n-                brac.setAttribute('open', '(')\n-            else:\n-                brac.setAttribute('open', '[')\n-\n-            if i.right_open:\n-                brac.setAttribute('close', ')')\n-            else:\n-                brac.setAttribute('close', ']')\n-            brac.appendChild( self._print(i.start))\n-            brac.appendChild( self._print(i.end))\n-\n+            brac.setAttribute('open', '[')\n+        if i.right_open:\n+            brac.setAttribute('close', ')')\n+        else:\n+            brac.setAttribute('close', ']')\n+        brac.appendChild(self._print(i.start))\n+        brac.appendChild(self._print(i.end))\n         mrow.appendChild(brac)\n         return mrow\n \n-    def _print_Abs(self, expr, exp=None):\n+    def _print_Abs(self, expr):\n         mrow = self.dom.createElement('mrow')\n         x = self.dom.createElement('mfenced')\n         x.setAttribute('open', '|')\n@@ -1058,7 +1060,14 @@ def _print_Abs(self, expr, exp=None):\n         mrow.appendChild(x)\n         return mrow\n \n-    _print_Determinant = _print_Abs\n+    def _print_Determinant(self, expr):\n+        mrow = self.dom.createElement('mrow')\n+        x = self.dom.createElement('mfenced')\n+        x.setAttribute('open', '|')\n+        x.setAttribute('close', '|')\n+        x.appendChild(self._print(expr.args[0]))\n+        mrow.appendChild(x)\n+        return mrow\n \n     def _print_re_im(self, c, expr):\n         mrow = self.dom.createElement('mrow')\n@@ -1109,6 +1118,30 @@ def _print_Complement(self, expr):\n     def _print_SymmetricDifference(self, expr):\n         return self._print_SetOp(expr, '&#x2206;')\n \n+    def _print_Union(self, expr):\n+        return self._print_SetOp(expr, '&#x222A;')\n+\n+    def _print_Intersection(self, expr):\n+        return self._print_SetOp(expr, '&#x2229;')\n+\n+    def _print_Complement(self, expr):\n+        return self._print_SetOp(expr, '&#x2216;')\n+\n+    def _print_SymmetricDifference(self, expr):\n+        return self._print_SetOp(expr, '&#x2206;')\n+\n+    def _print_Union(self, expr):\n+        return self._print_SetOp(expr, '&#x222A;')\n+\n+    def _print_Intersection(self, expr):\n+        return self._print_SetOp(expr, '&#x2229;')\n+\n+    def _print_Complement(self, expr):\n+        return self._print_SetOp(expr, '&#x2216;')\n+\n+    def _print_SymmetricDifference(self, expr):\n+        return self._print_SetOp(expr, '&#x2206;')\n+\n     def _print_FiniteSet(self, s):\n         return self._print_set(s.args)\n \n@@ -1121,6 +1154,9 @@ def _print_set(self, s):\n             brac.appendChild(self._print(item))\n         return brac\n \n+    def _print_FiniteSet(self, s):\n+        return self._print_set(s)\n+\n     _print_frozenset = _print_set\n \n     def _print_LogOp(self, args, symbol):\n@@ -1235,20 +1271,20 @@ def _print_EmptySet(self, e):\n \n \n     def _print_floor(self, e):\n-        mrow =  self.dom.createElement('mrow')\n+        mrow = self.dom.createElement('mrow')\n         x = self.dom.createElement('mfenced')\n-        x.setAttribute('open', u'\\u230A')\n-        x.setAttribute('close', u'\\u230B')\n+        x.setAttribute('open', '&#8970;')\n+        x.setAttribute('close', '&#8971;')\n         x.appendChild(self._print(e.args[0]))\n         mrow.appendChild(x)\n         return mrow\n \n \n     def _print_ceiling(self, e):\n-        mrow =  self.dom.createElement('mrow')\n+        mrow = self.dom.createElement('mrow')\n         x = self.dom.createElement('mfenced')\n-        x.setAttribute('open', u'\\u2308')\n-        x.setAttribute('close', u'\\u2309')\n+        x.setAttribute('open', '&#8968;')\n+        x.setAttribute('close', '&#8969;')\n         x.appendChild(self._print(e.args[0]))\n         mrow.appendChild(x)\n         return mrow\n", "instance_id": "sympy__sympy-16106"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 77768e7383..d02a6b3420 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1508,7 +1508,7 @@ class DraggableBase:\n         ]\n \n     # A property, not an attribute, to maintain picklability.\n-    canvas = property(lambda self: self.ref_artist.figure.canvas)\n+    canvas = property(lambda self: self.ref_artist.figure.canvas if self.ref_artist.figure else None)\n \n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n@@ -1559,13 +1559,17 @@ class DraggableBase:\n     def disconnect(self):\n         \"\"\"Disconnect the callbacks.\"\"\"\n         for cid in self.cids:\n-            self.canvas.mpl_disconnect(cid)\n+            if self.canvas:\n+                if self.canvas:\n+                    self.canvas.mpl_disconnect(cid)\n         try:\n             c1 = self._c1\n         except AttributeError:\n             pass\n         else:\n-            self.canvas.mpl_disconnect(c1)\n+            if self.canvas:\n+                if self.canvas:\n+                    self.canvas.mpl_disconnect(c1)\n \n     def save_offset(self):\n         pass\n", "instance_id": "matplotlib__matplotlib-25442"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 09e2b00735..fde65641ad 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -19,6 +19,7 @@\n from sympy.core.add import Add\n \n from sympy.printing.printer import Printer\n+from sympy.vector.vector import Vector\n from sympy.printing.str import sstr\n from sympy.printing.conventions import requires_partial\n \n@@ -1501,7 +1502,64 @@ def pretty_negative(pform, index):\n \n         return prettyForm.__add__(*pforms)\n \n+    def _print_Vector(self, e):\n+        return e._pretty(self)\n+\n     def _print_Mul(self, product):\n+        a = []  # items in the numerator\n+        b = []  # items that are in the denominator (if any)\n+\n+        if self.order not in ('old', 'none'):\n+            args = product.as_ordered_factors()\n+        else:\n+            args = list(product.args)\n+\n+        # If quantities are present append them at the back\n+        args = sorted(args, key=lambda x: isinstance(x, Quantity) or\n+                     (isinstance(x, Pow) and isinstance(x.base, Quantity)))\n+\n+        # Gather terms for numerator/denominator\n+        for item in args:\n+            if item.is_commutative and item.is_Pow and item.exp.is_Rational and item.exp.is_negative:\n+                if item.exp != -1:\n+                    b.append(Pow(item.base, -item.exp, evaluate=False))\n+                else:\n+                    b.append(Pow(item.base, -item.exp))\n+            elif item.is_Rational and item is not S.Infinity:\n+                if item.p != 1:\n+                    a.append( Rational(item.p) )\n+                if item.q != 1:\n+                    b.append( Rational(item.q) )\n+            else:\n+                a.append(item)\n+\n+        from sympy import Integral, Piecewise, Product, Sum\n+\n+        # Convert to pretty forms. Add parens to Add instances if there\n+        # is more than one term in the numer/denom\n+        for i in range(0, len(a)):\n+            if (a[i].is_Add and len(a) > 1) or (i != len(a) - 1 and\n+                    isinstance(a[i], (Integral, Piecewise, Product, Sum))):\n+                a[i] = prettyForm(*self._print(a[i]).parens())\n+            elif a[i].is_Relational:\n+                a[i] = prettyForm(*self._print(a[i]).parens())\n+            else:\n+                a[i] = self._print(a[i])\n+\n+        for i in range(0, len(b)):\n+            if (b[i].is_Add and len(b) > 1) or (i != len(b) - 1 and\n+                    isinstance(b[i], (Integral, Piecewise, Product, Sum))):\n+                b[i] = prettyForm(*self._print(b[i]).parens())\n+            else:\n+                b[i] = self._print(b[i])\n+\n+        # Construct a pretty form\n+        if len(b) == 0:\n+            return prettyForm.__mul__(*a)\n+        else:\n+            if len(a) == 0:\n+                a.append( self._print(S.One) )\n+            return prettyForm.__mul__(*a)/prettyForm.__mul__(*b)\n         from sympy.physics.units import Quantity\n         a = []  # items in the numerator\n         b = []  # items that are in the denominator (if any)\ndiff --git a/sympy/vector/vector.py b/sympy/vector/vector.py\nindex c62b1dbf0d..18ebcd4e26 100755\n--- a/sympy/vector/vector.py\n+++ b/sympy/vector/vector.py\n@@ -2,7 +2,8 @@\n from sympy.core import S, Pow, sympify\n from sympy.core.expr import AtomicExpr, Expr\n from sympy.core.compatibility import range, default_sort_key\n-from sympy import sqrt, ImmutableMatrix as Matrix, Add\n+from sympy.core.power import sqrt\n+from sympy import ImmutableMatrix as Matrix, Add\n from sympy.vector.coordsysrect import CoordSys3D\n from sympy.vector.basisdependent import (BasisDependent, BasisDependentAdd,\n                                          BasisDependentMul, BasisDependentZero)\n@@ -10,6 +11,21 @@\n \n \n class Vector(BasisDependent):\n+    def _pretty(self, printer, *args):\n+        from sympy.printing.pretty.stringpict import prettyForm\n+        from sympy.printing.pretty.pretty_symbology import pretty_symbol\n+        components = self.components\n+        items = sorted(components.items(), key=lambda x: x[0].__str__())\n+        pforms = []\n+        for base, measure in items:\n+            pform = printer._print(measure)\n+            if pform.height() > 1:\n+                pform = prettyForm(*pform.parens())\n+            pform = prettyForm(*pform.right(pretty_symbol(base._pretty_form)))\n+            pforms.append(pform)\n+        result = prettyForm.__add__(*pforms)\n+        result.baseline = result.height() // 2\n+        return result\n     \"\"\"\n     Super class for all Vector classes.\n     Ideally, neither this class nor any of its subclasses should be\n", "instance_id": "sympy__sympy-14308"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 43f9e6ad8d..b97d53582a 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1968,10 +1968,12 @@ def _print_DiracDelta(self, expr, exp=None):\n             tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n-    def _print_SingularityFunction(self, expr):\n+    def _print_SingularityFunction(self, expr, exp=None):\n         shift = self._print(expr.args[0] - expr.args[1])\n         power = self._print(expr.args[2])\n         tex = r\"{\\left\\langle %s \\right\\rangle}^{%s}\" % (shift, power)\n+        if exp is not None:\n+            tex = r\"\\left(%s\\right)^{%s}\" % (tex, exp)\n         return tex\n \n     def _print_Heaviside(self, expr, exp=None):\n", "instance_id": "sympy__sympy-21171"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..ffe7d027f3 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -233,7 +233,9 @@ class HttpResponseBase:\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n-        # Handle non-string types.\n+        # Handle memoryview types.\n+        if isinstance(value, memoryview):\n+            return value.tobytes()\n         return str(value).encode(self.charset)\n \n     # These methods partially implement the file-like object interface.\n", "instance_id": "django__django-11133"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/compat.py b/requests/compat.py\nindex 70edff78..d1471426 100644\n--- a/requests/compat.py\n+++ b/requests/compat.py\n@@ -40,6 +40,7 @@ if is_py2:\n     from Cookie import Morsel\n     from StringIO import StringIO\n     from .packages.urllib3.packages.ordered_dict import OrderedDict\n+    unicode = unicode\n \n     builtin_str = str\n     bytes = str\n@@ -54,6 +55,7 @@ elif is_py3:\n     from http.cookies import Morsel\n     from io import StringIO\n     from collections import OrderedDict\n+    unicode = str\n \n     builtin_str = str\n     str = str\ndiff --git a/requests/models.py b/requests/models.py\nindex fbb3c7e6..7fff47c2 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -29,7 +29,7 @@ from .utils import (\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n     iter_slices, guess_json_utf, super_len, to_native_string)\n from .compat import (\n-    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,\n+    cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO, unicode,\n     is_py2, chardet, builtin_str, basestring)\n from .compat import json as complexjson\n from .status_codes import codes\n@@ -332,8 +332,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         #: https://github.com/kennethreitz/requests/pull/2238\n         if isinstance(url, bytes):\n             url = url.decode('utf8')\n+        elif is_py2:\n+            url = unicode(url)\n         else:\n-            url = unicode(url) if is_py2 else str(url)\n+            url = str(url)\n \n         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n         # `data` etc to work around exceptions from `url_parse`, which\n@@ -666,6 +668,8 @@ class Response(object):\n             if hasattr(self.raw, 'stream'):\n                 try:\n                     for chunk in self.raw.stream(chunk_size, decode_content=True):\n+                        if decode_unicode:\n+                            chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                         yield chunk\n                 except ProtocolError as e:\n                     raise ChunkedEncodingError(e)\n@@ -679,6 +683,8 @@ class Response(object):\n                     chunk = self.raw.read(chunk_size)\n                     if not chunk:\n                         break\n+                    if decode_unicode:\n+                        chunk = chunk.decode(self.encoding or 'utf-8', errors='replace')\n                     yield chunk\n \n             self._content_consumed = True\n@@ -694,9 +700,6 @@ class Response(object):\n \n         chunks = reused_chunks if self._content_consumed else stream_chunks\n \n-        if decode_unicode:\n-            chunks = stream_decode_response_unicode(chunks, self)\n-\n         return chunks\n \n     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n", "instance_id": "psf__requests-3362"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..2aaa5d8e03 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -64,11 +64,19 @@ class Q(tree.Node):\n     def __and__(self, other):\n         return self._combine(other, self.AND)\n \n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n+\n+    def __ror__(self, other):\n+        return self._combine(other, self.OR)\n+\n     def __invert__(self):\n         obj = type(self)()\n         obj.add(self, self.AND)\n         obj.negate()\n         return obj\n+    def __rand__(self, other):\n+        return self._combine(other, self.AND)\n \n     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n         # We must promote any new joins to left outer joins so that when Q is\n", "instance_id": "django__django-14017"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/assumptions/sathandlers.py b/sympy/assumptions/sathandlers.py\nindex 61d62d04cf..881a5f9ba8 100644\n--- a/sympy/assumptions/sathandlers.py\n+++ b/sympy/assumptions/sathandlers.py\n@@ -1,6 +1,7 @@\n from __future__ import print_function, division\n \n-from collections import MutableMapping, defaultdict\n+from collections.abc import MutableMapping\n+from collections import defaultdict\n \n from sympy.core import (Add, Mul, Pow, Integer, Number, NumberSymbol,)\n from sympy.core.numbers import ImaginaryUnit\ndiff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex d4ca323e0d..b42fd1d75c 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -1,6 +1,7 @@\n \"\"\"Base class for all the objects in SymPy\"\"\"\n from __future__ import print_function, division\n-from collections import Mapping, defaultdict\n+from collections.abc import Mapping\n+from collections import defaultdict\n from itertools import chain\n \n from .assumptions import BasicMeta, ManagedProperties\ndiff --git a/sympy/core/containers.py b/sympy/core/containers.py\nindex 15abd93e3a..8ac11e7ecd 100644\n--- a/sympy/core/containers.py\n+++ b/sympy/core/containers.py\n@@ -268,7 +268,7 @@ def _sorted_args(self):\n         return tuple(sorted(self.args, key=default_sort_key))\n \n \n-class OrderedSet(collections.MutableSet):\n+class OrderedSet(collections.abc.MutableSet):\n     def __init__(self, iterable=None):\n         if iterable:\n             self.map = collections.OrderedDict((item, None) for item in iterable)\ndiff --git a/sympy/core/function.py b/sympy/core/function.py\nindex cef70f1589..245abf3173 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1238,7 +1238,7 @@ def __new__(cls, expr, *variables, **assumptions):\n             elif not count.is_Integer:\n                 obj = None\n             else:\n-                if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n+                if isinstance(v, (collections.abc.Iterable, Tuple, MatrixCommon, NDimArray)):\n                     deriv_fun = derive_by_array\n                     is_symbol = True\n                 else:\ndiff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 379a2917aa..e68c8cb588 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -6,7 +6,7 @@\n \n from __future__ import print_function, division\n \n-import collections\n+import collections.abc\n from sympy.core.add import Add\n from sympy.core.basic import Basic, Atom\n from sympy.core.expr import Expr\ndiff --git a/sympy/matrices/dense.py b/sympy/matrices/dense.py\nindex 00395585b9..f9940274af 100644\n--- a/sympy/matrices/dense.py\n+++ b/sympy/matrices/dense.py\n@@ -410,6 +410,11 @@ class MutableDenseMatrix(DenseMatrix, MatrixBase):\n     def __new__(cls, *args, **kwargs):\n         return cls._new(*args, **kwargs)\n \n+    def __matmul__(self, other):\n+        if not isinstance(other, MatrixBase):\n+            raise ValueError(\"Scalar operands are not allowed, use '*' instead\")\n+        return self * other\n+\n     @classmethod\n     def _new(cls, *args, **kwargs):\n         # if the `copy` flag is set to False, the input\ndiff --git a/sympy/plotting/plot.py b/sympy/plotting/plot.py\nindex b3b0237d19..0b959a43a4 100644\n--- a/sympy/plotting/plot.py\n+++ b/sympy/plotting/plot.py\n@@ -25,7 +25,7 @@\n from __future__ import print_function, division\n \n import inspect\n-from collections import Callable\n+from collections.abc import Callable\n import warnings\n import sys\n \n", "instance_id": "sympy__sympy-13773"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex d0bc97be80..04cc460ac3 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -59,15 +59,13 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=DjangoJSONEncoder):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n     the escaped JSON in a script tag.\n     \"\"\"\n-    from django.core.serializers.json import DjangoJSONEncoder\n-\n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    json_str = json.dumps(value, cls=encoder).translate(_json_script_escapes)\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n", "instance_id": "django__django-15789"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 94d9465d7..9056fcaad 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -1224,7 +1224,12 @@ class FeatureUnion(TransformerMixin, _BaseComposition):\n         Xs, transformers = zip(*results)\n         self._update_transformer_list(transformers)\n \n-        return self._hstack(Xs)\n+        Xs = self._hstack(Xs)\n+        config = _get_output_config(\"transform\", self)\n+        if config[\"dense\"] == \"pandas\":\n+            pd = check_pandas_support(\"transform\")\n+            return pd.DataFrame(Xs, index=X.index)\n+        return Xs\n \n     def _log_message(self, name, idx, total):\n         if not self.verbose:\ndiff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..100244645 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -52,7 +52,7 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n-    if isinstance(data_to_wrap, pd.DataFrame):\n+    if isinstance(data_to_wrap, (pd.DataFrame, pd.Series)):\n         if columns is not None:\n             data_to_wrap.columns = columns\n         if index is not None:\n", "instance_id": "scikit-learn__scikit-learn-25747"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\nindex 75349099..44f3b486 100644\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -2102,6 +2102,22 @@ def pairplot(\n     diag_kws = {} if diag_kws is None else diag_kws.copy()\n     grid_kws = {} if grid_kws is None else grid_kws.copy()\n \n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n+    # Flatten MultiIndex columns if present\n+    if isinstance(data.columns, pd.MultiIndex):\n+        data.columns = ['_'.join(map(str, col)).strip() for col in data.columns]\n+\n     # Resolve \"auto\" diag kind\n     if diag_kind == \"auto\":\n         if hue is None:\n", "instance_id": "mwaskom__seaborn-3407"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/cm.py b/lib/matplotlib/cm.py\nindex 0f3b25d4e4..3a80e242b3 100644\n--- a/lib/matplotlib/cm.py\n+++ b/lib/matplotlib/cm.py\n@@ -634,6 +634,9 @@ class ScalarMappable:\n         on the colorbar to default.\n         \"\"\"\n         self.norm = norm\n+        if self.colorbar:\n+            self.colorbar.set_norm(norm)\n+            self.colorbar.update_normal(self)\n \n     def autoscale(self):\n         \"\"\"\ndiff --git a/lib/matplotlib/collections.py b/lib/matplotlib/collections.py\nindex bf88dd2b68..5276f45f00 100644\n--- a/lib/matplotlib/collections.py\n+++ b/lib/matplotlib/collections.py\n@@ -895,6 +895,8 @@ class Collection(artist.Artist, cm.ScalarMappable):\n         else:\n             self._set_edgecolor(self._original_edgecolor)\n         self.stale = True\n+        if self.colorbar:\n+            self.colorbar.update_normal(self)\n \n     def get_fill(self):\n         \"\"\"Return whether face is colored.\"\"\"\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..383b01d9a7 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1853,14 +1853,16 @@ class AsinhNorm(Normalize):\n         self._scale.linear_width = value\n \n \n-class PowerNorm(Normalize):\n+class LogNorm(Normalize):\n     \"\"\"\n-    Linearly map a given value to the 0-1 range and then apply\n-    a power-law normalization over that range.\n+    Normalize a given value to the 0-1 range on a log scale.\n     \"\"\"\n-    def __init__(self, gamma, vmin=None, vmax=None, clip=False):\n+    def __init__(self, vmin=None, vmax=None, clip=False):\n         super().__init__(vmin, vmax, clip)\n-        self.gamma = gamma\n+        if vmin is not None and vmin <= 0:\n+            raise ValueError(\"vmin must be positive\")\n+        if vmax is not None and vmax <= 0:\n+            raise ValueError(\"vmax must be positive\")\n \n     def __call__(self, value, clip=None):\n         if clip is None:\n@@ -1869,12 +1871,13 @@ class PowerNorm(Normalize):\n         result, is_scalar = self.process_value(value)\n \n         self.autoscale_None(result)\n-        gamma = self.gamma\n         vmin, vmax = self.vmin, self.vmax\n-        if vmin > vmax:\n-            raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n-        elif vmin == vmax:\n-            result.fill(0)\n+        if vmin is None or vmax is None:\n+            raise ValueError(\"minvalue and maxvalue must be set\")\n+        if vmin <= 0 or vmax <= 0:\n+            raise ValueError(\"minvalue and maxvalue must be positive\")\n+        if vmin == vmax:\n+            result.fill(0)  # Or should it be all masked?  Or 0.5?\n         else:\n             if clip:\n                 mask = np.ma.getmask(result)\n@@ -1883,8 +1886,8 @@ class PowerNorm(Normalize):\n             resdat = result.data\n             resdat -= vmin\n             resdat[resdat < 0] = 0\n-            np.power(resdat, gamma, resdat)\n-            resdat /= (vmax - vmin) ** gamma\n+            np.log(resdat, out=resdat)\n+            resdat /= np.log(vmax / vmin)\n \n             result = np.ma.array(resdat, mask=result.mask, copy=False)\n         if is_scalar:\n@@ -1894,14 +1897,12 @@ class PowerNorm(Normalize):\n     def inverse(self, value):\n         if not self.scaled():\n             raise ValueError(\"Not invertible until scaled\")\n-        gamma = self.gamma\n         vmin, vmax = self.vmin, self.vmax\n-\n-        if np.iterable(value):\n-            val = np.ma.asarray(value)\n-            return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n-        else:\n-            return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n+        if vmin is None or vmax is None:\n+            raise ValueError(\"minvalue and maxvalue must be set\")\n+        if vmin <= 0 or vmax <= 0:\n+            raise ValueError(\"minvalue and maxvalue must be positive\")\n+        return vmin * np.exp(value * np.log(vmax / vmin))\n \n \n class BoundaryNorm(Normalize):\n", "instance_id": "matplotlib__matplotlib-25079"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 8e55bd092d..014a16d655 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -453,7 +453,9 @@ class Query(BaseExpression):\n                     if getattr(annotation, 'contains_aggregate', True)\n                 )\n                 if inner_query.default_cols and has_existing_aggregate_annotations:\n-                    inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)\n+                    inner_query.group_by = tuple(\n+                        inner_query.get_meta().concrete_fields\n+                    )\n                 inner_query.default_cols = False\n \n             relabels = {t: 'subquery' for t in inner_query.alias_map}\n", "instance_id": "django__django-11797"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 03cf57a30b..c1fc825804 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1065,6 +1065,7 @@ def zero(self):\n     def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n+        print(\"Intersection __new__ called with args:\", args)\n         # flatten inputs to merge intersections and iterables\n         args = _sympify(args)\n \n@@ -1158,16 +1159,12 @@ def boundary_of_set(i):\n         return Union(*map(boundary_of_set, range(len(self.args))))\n \n     def _contains(self, other):\n-        try:\n-            d = Dummy()\n-            r = self.as_relational(d).subs(d, other)\n-            b = tfn[r]\n-            if b is None and not any(isinstance(i.contains(other), Contains)\n-                    for i in self.args):\n-                return r\n-            return b\n-        except (TypeError, NotImplementedError):\n-            return Or(*[s.contains(other) for s in self.args])\n+        from sympy import Piecewise, Eq\n+\n+        conditions = [set.contains(other) for set in self.args]\n+        if len(conditions) != len(set(conditions)):\n+            return Piecewise((self.args[0], Eq(self.args[0], other)), (S.EmptySet, True))\n+        return And(*conditions)\n \n     def as_relational(self, symbol):\n         \"\"\"Rewrite a Union in terms of equalities and logic operators. \"\"\"\n@@ -1262,6 +1259,9 @@ def __new__(cls, *args, **kwargs):\n         # flatten inputs to merge intersections and iterables\n         args = _sympify(args)\n \n+        # Remove duplicates\n+        args = list(ordered(set(args), Set._infimum_key))\n+\n         # Reduce sets using known rules\n         if evaluate:\n             args = list(cls._new_args_filter(args))\n@@ -1291,7 +1291,13 @@ def _sup(self):\n         raise NotImplementedError()\n \n     def _contains(self, other):\n-        return And(*[set.contains(other) for set in self.args])\n+        print(\"Intersection _contains called with other:\", other)\n+        from sympy import Piecewise, Eq\n+\n+        conditions = [set.contains(other) for set in self.args]\n+        if len(conditions) != len(set(conditions)):\n+            return Piecewise((self.args[0], Eq(self.args[0], other)), (S.EmptySet, True))\n+        return And(*conditions)\n \n     def __iter__(self):\n         no_iter = True\n", "instance_id": "sympy__sympy-16988"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..ef5944f413 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -185,6 +185,15 @@ class Axes3D(Axes):\n                 \"other Axes classes.\")\n             fig.add_axes(self)\n \n+    def set_visible(self, b):\n+        \"\"\"\n+        Set the visibility of the axes.\n+        \"\"\"\n+        self._axis3don = b\n+        for child in self.get_children():\n+            child.set_visible(b)\n+        self.stale = True\n+\n     def set_axis_off(self):\n         self._axis3don = False\n         self.stale = True\n", "instance_id": "matplotlib__matplotlib-23314"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex abbb1e37cb..c356148d42 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -328,6 +328,14 @@ class SQLCompiler:\n                     expr = Cast(expr, expr.output_field)\n                 order_by.append((OrderBy(expr, descending=descending), False))\n                 continue\n+            if col.endswith('_id') and '__' in field:\n+                # Handle self-referencing foreign key ordering\n+                related_field = field.split('__')[-1]\n+                if related_field == 'id':\n+                    order_by.append((\n+                        OrderBy(F(col), descending=descending),\n+                        False))\n+                    continue\n \n             if '.' in field:\n                 # This came in through an extra(order_by=...) addition. Pass it\n", "instance_id": "django__django-13033"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\nindex 68ffb0bfe0..eb439306fa 100644\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -199,7 +199,9 @@ class Feed:\n             if updateddate and is_naive(updateddate):\n                 updateddate = make_aware(updateddate, tz)\n \n+            comments = self._get_dynamic_attr('item_comments', item)\n             feed.add_item(\n+                comments=comments,\n                 title=title,\n                 link=link,\n                 description=description,\ndiff --git a/django/utils/feedgenerator.py b/django/utils/feedgenerator.py\nindex f08e89b25c..c1dd970263 100644\n--- a/django/utils/feedgenerator.py\n+++ b/django/utils/feedgenerator.py\n@@ -94,7 +94,7 @@ class SyndicationFeed:\n         def to_str(s):\n             return str(s) if s is not None else s\n         categories = categories and [to_str(c) for c in categories]\n-        self.items.append({\n+        item = {\n             'title': to_str(title),\n             'link': iri_to_uri(link),\n             'description': to_str(description),\n@@ -111,7 +111,10 @@ class SyndicationFeed:\n             'item_copyright': to_str(item_copyright),\n             'ttl': to_str(ttl),\n             **kwargs,\n-        })\n+        }\n+        if comments is not None:\n+            item['comments'] = to_str(comments)\n+        self.items.append(item)\n \n     def num_items(self):\n         return len(self.items)\n", "instance_id": "django__django-13230"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..53ca4c181d 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1738,20 +1738,6 @@ def partitions(n, m=None, k=None, size=False):\n     {2: 1, 4: 1}\n     {3: 2}\n \n-    Note that the _same_ dictionary object is returned each time.\n-    This is for speed:  generating each partition goes quickly,\n-    taking constant time, independent of n.\n-\n-    >>> [p for p in partitions(6, k=2)]\n-    [{1: 6}, {1: 6}, {1: 6}, {1: 6}]\n-\n-    If you want to build a list of the returned dictionaries then\n-    make a copy of them:\n-\n-    >>> [p.copy() for p in partitions(6, k=2)]  # doctest: +SKIP\n-    [{2: 3}, {1: 2, 2: 2}, {1: 4, 2: 1}, {1: 6}]\n-    >>> [(M, p.copy()) for M, p in partitions(6, k=2, size=True)]  # doctest: +SKIP\n-    [(3, {2: 3}), (4, {1: 2, 2: 2}), (5, {1: 4, 2: 1}), (6, {1: 6})]\n \n     References\n     ==========\n@@ -1802,9 +1788,9 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n \n     while keys != [1]:\n         # Reuse any 1's.\n", "instance_id": "sympy__sympy-20154"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..272cd5c937 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,11 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            current_year = datetime.datetime.utcnow().year\n+            current_century = current_year // 100 * 100\n+            year += current_century\n+            if year > current_year + 50:\n+                year -= 100\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n", "instance_id": "django__django-11848"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n", "instance_id": "scikit-learn__scikit-learn-13779"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/utils/_pprint.py b/sklearn/utils/_pprint.py\nindex b8686dba5..b7507c48b 100644\n--- a/sklearn/utils/_pprint.py\n+++ b/sklearn/utils/_pprint.py\n@@ -67,6 +67,7 @@ from inspect import signature\n import pprint\n from collections import OrderedDict\n \n+import numpy as np\n from ..base import BaseEstimator\n from .._config import get_config\n from . import is_scalar_nan\n@@ -95,8 +96,10 @@ def _changed_params(estimator):\n     init_params = signature(init_func).parameters\n     init_params = {name: param.default for name, param in init_params.items()}\n     for k, v in params.items():\n-        if (v != init_params[k] and\n-                not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n+        if (not isinstance(v, np.ndarray) and v != init_params[k] or\n+                isinstance(v, np.ndarray) and not np.array_equal(v, init_params[k]) or\n+                (is_scalar_nan(init_params[k]) and not is_scalar_nan(v)) or\n+                (not is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n             filtered_params[k] = v\n     return filtered_params\n \n", "instance_id": "scikit-learn__scikit-learn-13584"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/functions/elementary/trigonometric.py b/sympy/functions/elementary/trigonometric.py\nindex da2e919375..442be9dec2 100644\n--- a/sympy/functions/elementary/trigonometric.py\n+++ b/sympy/functions/elementary/trigonometric.py\n@@ -337,6 +337,9 @@ def eval(cls, arg):\n             if m:\n                 return sin(m)*cos(x) + cos(m)*sin(x)\n \n+        if isinstance(arg, Rational):\n+            return sin(arg.evalf())\n+\n         if isinstance(arg, asin):\n             return arg.args[0]\n \n@@ -640,6 +643,9 @@ def eval(cls, arg):\n             if m:\n                 return cos(m)*cos(x) - sin(m)*sin(x)\n \n+        if isinstance(arg, Rational):\n+            return cos(arg.evalf())\n+\n         if isinstance(arg, acos):\n             return arg.args[0]\n \ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 421bfba0a7..54e6d94394 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -641,6 +641,13 @@ def shorter(*choices):\n     if floats and rational is None:\n         expr = nfloat(expr, exponent=False)\n \n+    # Simplify trigonometric functions with Rational arguments\n+    if expr.has(TrigonometricFunction):\n+        expr = expr.replace(\n+            lambda x: isinstance(x, TrigonometricFunction) and isinstance(x.args[0], Rational),\n+            lambda x: x.func(x.args[0].evalf())\n+        )\n+\n     return expr\n \n \n", "instance_id": "sympy__sympy-15346"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/messages/storage/base.py b/django/contrib/messages/storage/base.py\nindex 01422066a6..3f1b1eff73 100644\n--- a/django/contrib/messages/storage/base.py\n+++ b/django/contrib/messages/storage/base.py\n@@ -14,7 +14,7 @@ class Message:\n     def __init__(self, level, message, extra_tags=None):\n         self.level = int(level)\n         self.message = message\n-        self.extra_tags = extra_tags\n+        self.extra_tags = extra_tags if extra_tags is not None else \"\"\n \n     def _prepare(self):\n         \"\"\"\ndiff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 1d390c71dd..e48d4edb08 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -19,7 +19,7 @@ class MessageEncoder(json.JSONEncoder):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n", "instance_id": "django__django-15347"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\nindex fe1f7236e..bb74064ba 100644\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -25,6 +25,7 @@ from ..exceptions import NonBLASDotWarning\n from ..exceptions import NotFittedError\n from ..exceptions import DataConversionWarning\n from ..externals.joblib import Memory\n+import pandas as pd\n \n \n FLOAT_DTYPES = (np.float64, np.float32, np.float16)\n@@ -495,7 +496,14 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n         estimator_name = \"Estimator\"\n     context = \" by %s\" % estimator_name if estimator is not None else \"\"\n \n-    if sp.issparse(array):\n+    if isinstance(array, pd.DataFrame):\n+        dtype_orig = array.dtypes\n+        array = array.to_numpy(dtype=dtype, copy=copy)\n+        if warn_on_dtype and not all(dtype_orig == array.dtypes):\n+            msg = (\"Data with input dtype {} was converted to {}{}.\"\n+                   .format(dtype_orig, array.dtype, context))\n+            warnings.warn(msg, DataConversionWarning)\n+    elif sp.issparse(array):\n         _ensure_no_complex_data(array)\n         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n                                       dtype=dtype, copy=copy,\n", "instance_id": "scikit-learn__scikit-learn-10949"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/seaborn/relational.py b/seaborn/relational.py\nindex b1762ca3..311ab291 100644\n--- a/seaborn/relational.py\n+++ b/seaborn/relational.py\n@@ -643,6 +643,12 @@ def lineplot(\n     color = kwargs.pop(\"color\", kwargs.pop(\"c\", None))\n     kwargs[\"color\"] = _default_color(ax.plot, hue, color, kwargs)\n \n+    if \"hue\" in kwargs:\n+        hue = kwargs.pop(\"hue\")\n+        if isinstance(hue, pd.Series):\n+            hue = hue.loc[data.index]\n+        kwargs[\"hue\"] = hue\n+\n     p.plot(ax, kwargs)\n     return ax\n \n", "instance_id": "mwaskom__seaborn-2848"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 11aebbc59f..967840a6e9 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -296,12 +296,15 @@ def diag(self):\n \n     @property\n     def blocks(self):\n-        from sympy.matrices.immutable import ImmutableDenseMatrix\n-        mats = self.args\n-        data = [[mats[i] if i == j else ZeroMatrix(mats[i].rows, mats[j].cols)\n-                        for j in range(len(mats))]\n-                        for i in range(len(mats))]\n-        return ImmutableDenseMatrix(data)\n+        if len(self.args) == 1:\n+            return self.args[0]\n+        else:\n+            from sympy.matrices.immutable import ImmutableDenseMatrix\n+            mats = self.args\n+            data = [[mats[i] if i == j else ZeroMatrix(mats[i].rows, mats[j].cols)\n+                            for j in range(len(mats))]\n+                            for i in range(len(mats))]\n+            return ImmutableDenseMatrix(data)\n \n     @property\n     def shape(self):\n", "instance_id": "sympy__sympy-18621"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 02ec6480cb..8cc0bac90e 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -286,6 +286,13 @@ def __new__(cls, b, e, evaluate=None):\n                 obj = b._eval_power(e)\n                 if obj is not None:\n                     return obj\n+\n+            # Handle the specific case of (-a)**x * a**(-x)\n+            if b.is_negative and e.is_Add:\n+                terms = e.as_ordered_terms()\n+                if len(terms) == 2 and terms[0] == -terms[1]:\n+                    return (-1)**terms[1]\n+\n         obj = Expr.__new__(cls, b, e)\n         obj = cls._exec_constructor_postprocessors(obj)\n         if not isinstance(obj, Pow):\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..988933ba64 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -554,6 +554,13 @@ def shorter(*choices):\n         expr = nsimplify(expr, rational=True)\n \n     expr = bottom_up(expr, lambda w: w.normal())\n+    if expr.has(Pow):\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Pow) and p.base.is_negative and p.exp.is_integer,\n+            lambda p: (-1)**p.exp * (-p.base)**p.exp)\n+        expr = expr.replace(\n+            lambda p: isinstance(p, Mul) and any(isinstance(arg, Pow) and arg.base.is_negative for arg in p.args),\n+            lambda p: Mul(*[(-1)**arg.exp if isinstance(arg, Pow) and arg.base.is_negative else arg for arg in p.args]))\n     expr = Mul(*powsimp(expr).as_content_primitive())\n     _e = cancel(expr)\n     expr1 = shorter(_e, _mexpand(_e).cancel())  # issue 6829\n", "instance_id": "sympy__sympy-14024"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-12236"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "pytest-dev__pytest-11148"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 488d6a77cd..e952af3fdc 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -68,7 +68,7 @@ def format(\n             str_number = \"{:f}\".format(number)\n     else:\n         str_number = str(number)\n-    if str_number[0] == \"-\":\n+    if str_number and str_number[0] == \"-\":\n         sign = \"-\"\n         str_number = str_number[1:]\n     # decimal part\n", "instance_id": "django__django-16046"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\nindex ecae2566..96cfa5d5 100644\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -16,6 +16,8 @@ def concat(\n     positions=None,\n     fill_value=dtypes.NA,\n     join=\"outer\",\n+    ignore_missing_vars=False,\n+    ignore_missing_vars=False,\n ):\n     \"\"\"Concatenate xarray objects along a new or existing dimension.\n \n@@ -128,7 +130,7 @@ def concat(\n             \"can only concatenate xarray Dataset and DataArray \"\n             \"objects, got %s\" % type(first_obj)\n         )\n-    return f(objs, dim, data_vars, coords, compat, positions, fill_value, join)\n+    return f(objs, dim, data_vars, coords, compat, positions, fill_value, join, ignore_missing_vars)\n \n \n def _calc_concat_dim_coord(dim):\n@@ -155,7 +157,7 @@ def _calc_concat_dim_coord(dim):\n     return dim, coord\n \n \n-def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat):\n+def _calc_concat_over(datasets, dim, dim_names, data_vars, coords, compat, ignore_missing_vars=False):\n     \"\"\"\n     Determine which dataset variables need to be concatenated in the result,\n     \"\"\"\n@@ -301,9 +303,18 @@ def _dataset_concat(\n \n     # determine which variables to concatentate\n     concat_over, equals, concat_dim_lengths = _calc_concat_over(\n-        datasets, dim, dim_names, data_vars, coords, compat\n+        datasets, dim, dim_names, data_vars, coords, compat, ignore_missing_vars\n     )\n \n+    if ignore_missing_vars:\n+        all_vars = set()\n+        for ds in datasets:\n+            all_vars.update(ds.variables)\n+        for var in all_vars - concat_over:\n+            for ds in datasets:\n+                if var not in ds.variables:\n+                    ds[var] = Variable((), fill_value)\n+\n     # determine which variables to merge, and then merge them according to compat\n     variables_to_merge = (coord_names | data_names) - concat_over - dim_names\n \n@@ -313,9 +324,10 @@ def _dataset_concat(\n \n         for ds in datasets:\n             absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n+            if absent_merge_vars and not ignore_missing_vars:\n                 raise ValueError(\n                     \"variables %r are present in some datasets but not others. \"\n+                    \"Use ignore_missing_vars=True to ignore these variables.\"\n                     % absent_merge_vars\n                 )\n \n", "instance_id": "pydata__xarray-3364"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/style/core.py b/lib/matplotlib/style/core.py\nindex fb0a5426e6..8affa4c203 100644\n--- a/lib/matplotlib/style/core.py\n+++ b/lib/matplotlib/style/core.py\n@@ -257,5 +257,28 @@ def reload_library():\n     library = update_user_library(_base_library)\n     available[:] = sorted(library.keys())\n \n+    # Add deprecated seaborn styles with their new names\n+    seaborn_styles = [\n+        \"seaborn\",\n+        \"seaborn-bright\",\n+        \"seaborn-colorblind\",\n+        \"seaborn-dark\",\n+        \"seaborn-darkgrid\",\n+        \"seaborn-dark-palette\",\n+        \"seaborn-deep\",\n+        \"seaborn-muted\",\n+        \"seaborn-notebook\",\n+        \"seaborn-paper\",\n+        \"seaborn-pastel\",\n+        \"seaborn-poster\",\n+        \"seaborn-talk\",\n+        \"seaborn-ticks\",\n+        \"seaborn-white\",\n+        \"seaborn-whitegrid\",\n+    ]\n+    for style in seaborn_styles:\n+        if style in library:\n+            library[f\"seaborn-v0_8-{style}\"] = library[style]\n+\n \n reload_library()\n", "instance_id": "matplotlib__matplotlib-24265"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 66461181d0..fc50bb9401 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1100,97 +1100,16 @@ def _print_BasisDependent(self, expr):\n \n         if expr == expr.zero:\n             return prettyForm(expr.zero._pretty_form)\n-        o1 = []\n-        vectstrs = []\n-        if isinstance(expr, Vector):\n-            items = expr.separate().items()\n-        else:\n-            items = [(0, expr)]\n-        for system, vect in items:\n-            inneritems = list(vect.components.items())\n-            inneritems.sort(key = lambda x: x[0].__str__())\n-            for k, v in inneritems:\n-                #if the coef of the basis vector is 1\n-                #we skip the 1\n-                if v == 1:\n-                    o1.append(\"\" +\n-                              k._pretty_form)\n-                #Same for -1\n-                elif v == -1:\n-                    o1.append(\"(-1) \" +\n-                              k._pretty_form)\n-                #For a general expr\n-                else:\n-                    #We always wrap the measure numbers in\n-                    #parentheses\n-                    arg_str = self._print(\n-                        v).parens()[0]\n-\n-                    o1.append(arg_str + ' ' + k._pretty_form)\n-                vectstrs.append(k._pretty_form)\n-\n-        #outstr = u(\"\").join(o1)\n-        if o1[0].startswith(\" + \"):\n-            o1[0] = o1[0][3:]\n-        elif o1[0].startswith(\" \"):\n-            o1[0] = o1[0][1:]\n-        #Fixing the newlines\n-        lengths = []\n-        strs = ['']\n-        flag = []\n-        for i, partstr in enumerate(o1):\n-            flag.append(0)\n-            # XXX: What is this hack?\n-            if '\\n' in partstr:\n-                tempstr = partstr\n-                tempstr = tempstr.replace(vectstrs[i], '')\n-                if '\\N{right parenthesis extension}' in tempstr:   # If scalar is a fraction\n-                    for paren in range(len(tempstr)):\n-                        flag[i] = 1\n-                        if tempstr[paren] == '\\N{right parenthesis extension}':\n-                            tempstr = tempstr[:paren] + '\\N{right parenthesis extension}'\\\n-                                         + ' '  + vectstrs[i] + tempstr[paren + 1:]\n-                            break\n-                elif '\\N{RIGHT PARENTHESIS LOWER HOOK}' in tempstr:\n-                    flag[i] = 1\n-                    tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS LOWER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS LOWER HOOK}'\n-                                        + ' ' + vectstrs[i])\n-                else:\n-                    tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                        + ' ' + vectstrs[i])\n-                o1[i] = tempstr\n-\n-        o1 = [x.split('\\n') for x in o1]\n-        n_newlines = max([len(x) for x in o1])  # Width of part in its pretty form\n-\n-        if 1 in flag:                           # If there was a fractional scalar\n-            for i, parts in enumerate(o1):\n-                if len(parts) == 1:             # If part has no newline\n-                    parts.insert(0, ' ' * (len(parts[0])))\n-                    flag[i] = 1\n-\n-        for i, parts in enumerate(o1):\n-            lengths.append(len(parts[flag[i]]))\n-            for j in range(n_newlines):\n-                if j+1 <= len(parts):\n-                    if j >= len(strs):\n-                        strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n-                    if j == flag[i]:\n-                        strs[flag[i]] += parts[flag[i]] + ' + '\n-                    else:\n-                        strs[j] += parts[j] + ' '*(lengths[-1] -\n-                                                   len(parts[j])+\n-                                                   3)\n-                else:\n-                    if j >= len(strs):\n-                        strs.append(' ' * (sum(lengths[:-1]) +\n-                                           3*(len(lengths)-1)))\n-                    strs[j] += ' '*(lengths[-1]+3)\n-\n-        return prettyForm('\\n'.join([s[:-3] for s in strs]))\n+        components = expr.components\n+        items = sorted(components.items(), key=lambda x: x[0].__str__())\n+        pforms = []\n+        for base, measure in items:\n+            pform = self._print(measure)\n+            if pform.height() > 1:\n+                pform = prettyForm(*pform.parens())\n+            pform = prettyForm(*pform.right(' ' + base._pretty_form))\n+            pforms.append(pform)\n+        return prettyForm.__add__(*pforms)\n \n     def _print_NDimArray(self, expr):\n         from sympy.matrices.immutable import ImmutableMatrix\ndiff --git a/sympy/vector/vector.py b/sympy/vector/vector.py\nindex 87320d0366..23126daacf 100644\n--- a/sympy/vector/vector.py\n+++ b/sympy/vector/vector.py\n@@ -50,9 +50,10 @@ def components(self):\n         {C.i: 3, C.j: 4, C.k: 5}\n \n         \"\"\"\n-        # The '_components' attribute is defined according to the\n-        # subclass of Vector the instance belongs to.\n-        return self._components\n+        if isinstance(self, VectorZero):\n+            return {self: S.Zero}\n+        base_vec = self._sys.base_vectors()\n+        return {vec: self._components[vec] for vec in base_vec if vec in self._components}\n \n     def magnitude(self):\n         \"\"\"\n", "instance_id": "sympy__sympy-23191"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..b7f84dbc52 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -1193,14 +1193,10 @@ class Legend(Artist):\n             If *state* is ``True`` this returns the `.DraggableLegend` helper\n             instance. Otherwise this returns *None*.\n         \"\"\"\n-        if state:\n-            if self._draggable is None:\n-                self._draggable = DraggableLegend(self,\n-                                                  use_blit,\n-                                                  update=update)\n-        else:\n-            if self._draggable is not None:\n-                self._draggable.disconnect()\n+        if state and self._draggable is None:\n+            self._draggable = DraggableLegend(self, use_blit, update=update)\n+        elif not state and self._draggable is not None:\n+            self._draggable.disconnect()\n             self._draggable = None\n         return self._draggable\n \ndiff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 1dee8a23d9..144781f95c 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1507,12 +1507,8 @@ class DraggableBase:\n         self.got_artist = False\n         self.canvas = self.ref_artist.figure.canvas\n         self._use_blit = use_blit and self.canvas.supports_blit\n-        self.cids = [\n-            self.canvas.callbacks._connect_picklable(\n-                'pick_event', self.on_pick),\n-            self.canvas.callbacks._connect_picklable(\n-                'button_release_event', self.on_release),\n-        ]\n+        self.cids = []\n+        self._connect()\n \n     def on_motion(self, evt):\n         if self._check_still_parented() and self.got_artist:\n@@ -1560,7 +1556,22 @@ class DraggableBase:\n         else:\n             return True\n \n-    def disconnect(self):\n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        state['cids'] = []  # Remove cids for pickling\n+        return state\n+\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        self._connect()\n+\n+    def _connect(self):\n+        self.cids = [\n+            self.canvas.callbacks._connect_picklable(\n+                'pick_event', self.on_pick),\n+            self.canvas.callbacks._connect_picklable(\n+                'button_release_event', self.on_release),\n+        ]\n         \"\"\"Disconnect the callbacks.\"\"\"\n         for cid in self.cids:\n             self.canvas.mpl_disconnect(cid)\n", "instance_id": "matplotlib__matplotlib-25311"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 95a991b17..1afa6358e 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -13,6 +13,7 @@\n import re\n import warnings\n from inspect import Parameter, Signature\n+import struct\n from types import ModuleType\n from typing import (Any, Callable, Dict, Iterator, List, Optional, Sequence, Set, Tuple, Type,\n                     TypeVar, Union)\n@@ -33,7 +34,7 @@ from sphinx.pycode import ModuleAnalyzer, PycodeError\n from sphinx.util import inspect, logging\n from sphinx.util.docstrings import extract_metadata, prepare_docstring\n from sphinx.util.inspect import (evaluate_signature, getdoc, object_description, safe_getattr,\n-                                 stringify_signature)\n+                                 stringify_signature, isstructclass)\n from sphinx.util.typing import get_type_hints, restify\n from sphinx.util.typing import stringify as stringify_typehint\n \n@@ -900,7 +901,10 @@ class Documenter:\n \n         # now, import the module and get object to document\n         if not self.import_object():\n-            return\n+            if isstructclass(self.object):\n+                self.object = struct.Struct\n+            else:\n+                return\n \n         # If there is no real module defined, figure out which to use.\n         # The real module is used in the module analyzer to look up the module\ndiff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex 2587ba35b..5f6465b57 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -18,7 +18,7 @@ from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warni\n from sphinx.pycode import ModuleAnalyzer, PycodeError\n from sphinx.util import logging\n from sphinx.util.inspect import (getannotations, getmro, getslots, isclass, isenumclass,\n-                                 safe_getattr)\n+                                 safe_getattr, isstructclass)\n \n if False:\n     # For type annotation\n@@ -216,16 +216,17 @@ def get_object_members(subject: Any, objpath: List[str], attrgetter: Callable,\n     except (AttributeError, TypeError, ValueError):\n         pass\n \n-    # other members\n-    for name in dir(subject):\n-        try:\n-            value = attrgetter(subject, name)\n-            directly_defined = name in obj_dict\n-            name = unmangle(subject, name)\n-            if name and name not in members:\n-                members[name] = Attribute(name, directly_defined, value)\n-        except AttributeError:\n-            continue\n+    # handle struct.Struct members\n+    if isstructclass(subject):\n+        for name in dir(subject):\n+            try:\n+                value = attrgetter(subject, name)\n+                directly_defined = name in obj_dict\n+                name = unmangle(subject, name)\n+                if name and name not in members:\n+                    members[name] = Attribute(name, directly_defined, value)\n+            except AttributeError:\n+                continue\n \n     # annotation only member (ex. attr: int)\n     for i, cls in enumerate(getmro(subject)):\n", "instance_id": "sphinx-doc__sphinx-8627"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 9344979c56..6cacd6af54 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -463,6 +463,8 @@ class IsNull(BuiltinLookup):\n     prepare_rhs = False\n \n     def as_sql(self, compiler, connection):\n+        if not isinstance(self.rhs, bool):\n+            raise ValueError(\"The value for __isnull must be a boolean.\")\n         sql, params = compiler.compile(self.lhs)\n         if self.rhs:\n             return \"%s IS NULL\" % sql, params\n", "instance_id": "django__django-11905"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a3ead157c1..f3b7669e96 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -740,7 +740,7 @@ def _print_Function(self, expr, exp=None):\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n", "instance_id": "sympy__sympy-14774"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 90ea232faf..c600fe88e2 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ def is_upper(self):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "instance_id": "sympy__sympy-12454"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\nindex 34a3bab3fc..191e1700c7 100644\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -10,7 +10,7 @@\n from sympy.core.function import count_ops, _mexpand\n from sympy.functions.elementary.trigonometric import TrigonometricFunction\n from sympy.functions.elementary.hyperbolic import HyperbolicFunction\n-from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth\n+from sympy.functions import sin, cos, exp, cosh, tanh, sinh, tan, cot, coth, sinc\n \n from sympy.strategies.core import identity\n from sympy.strategies.tree import greedy\n@@ -21,6 +21,7 @@\n from sympy.polys.domains import ZZ\n from sympy.polys import factor, cancel, parallel_poly_from_expr\n \n+import signal\n from sympy.utilities.misc import debug\n \n \n@@ -426,6 +427,33 @@ def analyse_gens(gens, hints):\n \n \n def trigsimp(expr, **opts):\n+    \"\"\"\n+    Simplify trigonometric expressions.\n+\n+    Parameters\n+    ----------\n+    expr : Expr\n+        The expression to simplify.\n+    opts : dict\n+        Additional options for simplification.\n+\n+    Returns\n+    -------\n+    Expr\n+        The simplified expression.\n+    \"\"\"\n+    def handler(signum, frame):\n+        raise TimeoutError(\"trigsimp timed out\")\n+\n+    signal.signal(signal.SIGALRM, handler)\n+    signal.alarm(10)  # Set a 10-second timeout\n+\n+    try:\n+        result = _trigsimp(expr, **opts)\n+    finally:\n+        signal.alarm(0)  # Disable the alarm\n+\n+    return result\n     \"\"\"\n     reduces expression by using known trig identities\n \n@@ -501,7 +529,17 @@ def traverse(e):\n             return new\n         return trigsimp_groebner(new, **opts)\n \n+    def exp_to_trig(expr):\n+        \"\"\"\n+        Convert exponential expressions to trigonometric expressions.\n+        \"\"\"\n+        expr = expr.rewrite(sin)\n+        expr = expr.rewrite(cos)\n+        expr = expr.rewrite(sinc)\n+        return expr\n+\n     trigsimpfunc = {\n+        'exp_to_trig': (lambda x: exp_to_trig(x)),\n         'fu': (lambda x: fu(x, **opts)),\n         'matching': (lambda x: futrig(x)),\n         'groebner': (lambda x: groebnersimp(x, **opts)),\n@@ -669,6 +707,7 @@ def trigsimp_old(expr, **opts):\n \n         trigsyms = set().union(*[t.free_symbols for t in expr.atoms(*_trigs)])\n         if len(trigsyms) > 1:\n+            from sympy.simplify.simplify import separatevars\n             d = separatevars(expr)\n             if d.is_Mul:\n                 d = separatevars(d, dict=True) or d\n@@ -720,6 +759,7 @@ def traverse(e):\n                    }[method]\n \n     if recursive:\n+        from sympy.simplify.simplify import cse\n         w, g = cse(expr)\n         g = trigsimpfunc(g[0], deep)\n \n", "instance_id": "sympy__sympy-11870"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 5bbb786984..4ce9dfab46 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -1311,10 +1311,11 @@ default: %(va)s\n         \"\"\"\n         if (self.get_layout_engine() is not None and\n                 not self.get_layout_engine().adjust_compatible):\n-            _api.warn_external(\n-                \"This figure was using a layout engine that is \"\n-                \"incompatible with subplots_adjust and/or tight_layout; \"\n-                \"not calling subplots_adjust.\")\n+            if isinstance(self.get_layout_engine(), ConstrainedLayoutEngine):\n+                _api.warn_external(\n+                    \"This figure was using a layout engine that is \"\n+                    \"incompatible with subplots_adjust and/or tight_layout; \"\n+                    \"not calling subplots_adjust.\")\n             return\n         self.subplotpars.update(left, bottom, right, top, wspace, hspace)\n         for ax in self.axes:\n", "instance_id": "matplotlib__matplotlib-23987"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex f71bea25f5..8e2bc56b94 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -707,7 +707,7 @@ def _preprocess(self, args, expr):\n \n         Returns string form of args, and updated expr.\n         \"\"\"\n-        from sympy import Dummy, Symbol, Function, flatten\n+        from sympy import Dummy, Symbol, Function, flatten, MatrixSymbol\n         from sympy.matrices import DeferredVector\n \n         dummify = self._dummify\n@@ -725,7 +725,7 @@ def _preprocess(self, args, expr):\n                 argstrs.append(nested_argstrs)\n             elif isinstance(arg, DeferredVector):\n                 argstrs.append(str(arg))\n-            elif isinstance(arg, Symbol):\n+            elif isinstance(arg, (Symbol, MatrixSymbol)):\n                 argrep = self._argrepr(arg)\n \n                 if dummify or not self._is_safe_ident(argrep):\n@@ -734,7 +734,7 @@ def _preprocess(self, args, expr):\n                     expr = self._subexpr(expr, {arg: dummy})\n                 else:\n                     argstrs.append(argrep)\n-            elif isinstance(arg, Function):\n+            elif isinstance(arg, (Function, MatrixSymbol)):\n                 dummy = Dummy()\n                 argstrs.append(self._argrepr(dummy))\n                 expr = self._subexpr(expr, {arg: dummy})\n", "instance_id": "sympy__sympy-15011"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 0545797d5f..06a46eea20 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -825,9 +825,9 @@ def _print_MatAdd(self, expr):\n             if s is None:\n                 s = pform     # First element\n             else:\n-                if S(item.args[0]).is_negative:\n-                    s = prettyForm(*stringPict.next(s, ' '))\n-                    pform = self._print(item)\n+                if item.is_Mul and item.args[0].is_Number and item.args[0] < 0:\n+                    s = prettyForm(*stringPict.next(s, ' - '))\n+                    pform = self._print(-item)\n                 else:\n                     s = prettyForm(*stringPict.next(s, ' + '))\n                 s = prettyForm(*stringPict.next(s, pform))\n", "instance_id": "sympy__sympy-14817"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..a18791c54 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -111,6 +111,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n            ``behaviour`` parameter will be deprecated in 0.22 and removed in\n            0.24.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     random_state : int, RandomState instance or None, optional (default=None)\n         If int, random_state is the seed used by the random number generator;\n         If RandomState instance, random_state is the random number generator;\n@@ -173,8 +178,9 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n-        super().__init__(\n+                 verbose=0,\n+                 warm_start=False):\n+        super().__init__( \n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n                 splitter='random',\n@@ -187,7 +193,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n-            verbose=verbose)\n+            verbose=verbose,\n+            warm_start=warm_start)\n \n         self.behaviour = behaviour\n         self.contamination = contamination\n", "instance_id": "scikit-learn__scikit-learn-13496"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/xarray/core/groupby.py b/xarray/core/groupby.py\nindex 8a097251..af5abd9a 100644\n--- a/xarray/core/groupby.py\n+++ b/xarray/core/groupby.py\n@@ -436,7 +436,7 @@ class GroupBy(SupportsArithmetic):\n         return zip(self._unique_coord.values, self._iter_grouped())\n \n     def __repr__(self):\n-        return \"{}, grouped over {!r} \\n{!r} groups with labels {}.\".format(\n+        return \"{}, grouped over {!r}\\n{!r} groups with labels {}.\".format(\n             self.__class__.__name__,\n             self._unique_coord.name,\n             self._unique_coord.size,\n", "instance_id": "pydata__xarray-5131"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-18835"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex e6b7d4d821..7323ae9c53 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -90,9 +90,11 @@ class SafeExceptionReporterFilter:\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, (list, tuple)):\n+                cleansed = type(value)(self.cleanse_setting(k, v) for k, v in enumerate(value))\n             else:\n                 cleansed = value\n-        except TypeError:\n+        except (TypeError, IndexError):\n             # If the key isn't regex-able, just return as-is.\n             cleansed = value\n \n", "instance_id": "django__django-12700"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\nindex 6e504a3057..56e5ada2c5 100644\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -459,8 +459,12 @@ def preprocess(cls, domain):\n \n                 if ground in ['Z', 'ZZ']:\n                     return sympy.polys.domains.ZZ.poly_ring(*gens)\n-                else:\n+                elif ground in ['Q', 'QQ']:\n                     return sympy.polys.domains.QQ.poly_ring(*gens)\n+                elif ground in ['R', 'RR']:\n+                    return sympy.polys.domains.RR.poly_ring(*gens)\n+                elif ground in ['C', 'CC']:\n+                    return sympy.polys.domains.CC.poly_ring(*gens)\n \n             r = cls._re_fraction.match(domain)\n \n@@ -480,7 +484,8 @@ def preprocess(cls, domain):\n                 gens = list(map(sympify, r.groups()[1].split(',')))\n                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n \n-        raise OptionError('expected a valid domain specification, got %s' % domain)\n+        raise OptionError(f\"Expected a valid domain specification, got '{domain}'. \"\n+                          \"Valid domains include 'ZZ', 'QQ', 'RR', 'CC', and polynomial rings like 'ZZ[x]', 'QQ[y]', etc.\")\n \n     @classmethod\n     def postprocess(cls, options):\n", "instance_id": "sympy__sympy-14396"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\nindex 7ea14ce33a..948ef210c6 100644\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -586,7 +586,7 @@ def parse(self, s):\n         \"##\": lambda: [\"SlotSequence\", \"1\"],\n     }\n \n-    _literal = r\"[A-Za-z][A-Za-z0-9]*\"\n+    _literal = r\"[\\w][\\w\\d]*\"\n     _number = r\"(?:[0-9]+(?:\\.[0-9]*)?|\\.[0-9]+)\"\n \n     _enclosure_open = [\"(\", \"[\", \"[[\", \"{\"]\n", "instance_id": "sympy__sympy-24102"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/flask/config.py b/src/flask/config.py\nindex d4fc310f..c7ae9f74 100644\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -234,6 +234,7 @@ class Config(dict):\n         filename: str,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n+        mode: str = \"r\",\n     ) -> bool:\n         \"\"\"Update the values in the config from a file that is loaded\n         using the ``load`` parameter. The loaded data is passed to the\n@@ -261,7 +262,7 @@ class Config(dict):\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, mode) as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n", "instance_id": "pallets__flask-4992"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex 1acc00be3a..d86fc5f51a 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -102,7 +102,19 @@ def separatevars(expr, symbols=[], dict=False, force=False):\n     True\n \n     \"\"\"\n+    from sympy import Pow, Add, Mul, S\n     expr = sympify(expr)\n+\n+    # Special case for expressions of the form (-a/b - c/d)**x - 1\n+    if isinstance(expr, Add) and len(expr.args) == 2 and expr.args[1] == -1:\n+        base, exp = expr.args[0].as_base_exp()\n+        if isinstance(base, Add) and len(base.args) == 2 and isinstance(exp, Pow):\n+            a, b = base.args[0].as_numer_denom()\n+            c, d = base.args[1].as_numer_denom()\n+            if a.is_negative and c.is_negative:\n+                new_base = -a/b - c/d\n+                new_expr = Pow(new_base, exp) - 1\n+                return new_expr\n     if dict:\n         return _separatevars_dict(_separatevars(expr, force), symbols)\n     else:\n", "instance_id": "sympy__sympy-13895"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/calibration.py b/sklearn/calibration.py\nindex 2c4a33616..2c1559358 100644\n--- a/sklearn/calibration.py\n+++ b/sklearn/calibration.py\n@@ -760,7 +760,10 @@ class _CalibratedClassifier:\n                 # When binary, `predictions` consists only of predictions for\n                 # clf.classes_[1] but `pos_class_indices` = 0\n                 class_idx += 1\n-            proba[:, class_idx] = calibrator.predict(this_pred)\n+            this_pred_proba = calibrator.predict(this_pred)\n+            if hasattr(this_pred_proba, \"to_numpy\"):\n+                this_pred_proba = this_pred_proba.to_numpy()\n+            proba[:, class_idx] = this_pred_proba\n \n         # Normalize the probabilities\n         if n_classes == 2:\n", "instance_id": "scikit-learn__scikit-learn-25500"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 837dabfea8..c09d84c338 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -430,7 +430,7 @@ class AdminSite:\n                     return HttpResponsePermanentRedirect(path)\n         raise Http404\n \n-    def _build_app_dict(self, request, label=None):\n+    def build_app_dict(self, request, label=None):\n         \"\"\"\n         Build the app dictionary. The optional `label` parameter filters models\n         of a specific app.\n@@ -441,6 +441,10 @@ class AdminSite:\n             models = {\n                 m: m_a for m, m_a in self._registry.items()\n                 if m._meta.app_label == label\n+            models = {\n+                m: m_a for m, m_a in self._registry.items()\n+                if m._meta.app_label == label\n+            }\n             }\n         else:\n             models = self._registry\n@@ -503,7 +507,7 @@ class AdminSite:\n         Return a sorted list of all the installed apps that have been\n         registered in this site.\n         \"\"\"\n-        app_dict = self._build_app_dict(request)\n+        app_dict = self.build_app_dict(request)\n \n         # Sort the apps alphabetically.\n         app_list = sorted(app_dict.values(), key=lambda x: x['name'].lower())\n@@ -534,7 +538,7 @@ class AdminSite:\n         return TemplateResponse(request, self.index_template or 'admin/index.html', context)\n \n     def app_index(self, request, app_label, extra_context=None):\n-        app_dict = self._build_app_dict(request, app_label)\n+        app_dict = self.build_app_dict(request, app_label)\n         if not app_dict:\n             raise Http404('The requested admin page does not exist.')\n         # Sort the models alphabetically within each app.\n", "instance_id": "django__django-13447"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\nindex 171a3e7b0..f76c2b563 100644\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1716,12 +1716,12 @@ class DataDocumenter(ModuleLevelDocumenter):\n                 annotations = {}\n \n             if self.objpath[-1] in annotations:\n-                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]), type_aliases=self.config.autodoc_type_aliases)\n                 self.add_line('   :type: ' + objrepr, sourcename)\n             else:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n                 if self.analyzer and key in self.analyzer.annotations:\n-                    self.add_line('   :type: ' + self.analyzer.annotations[key],\n+                    self.add_line('   :type: ' + stringify_typehint(self.analyzer.annotations[key], type_aliases=self.config.autodoc_type_aliases),\n                                   sourcename)\n \n             try:\n@@ -2107,12 +2107,12 @@ class AttributeDocumenter(DocstringStripSignatureMixin, ClassLevelDocumenter):\n                 annotations = {}\n \n             if self.objpath[-1] in annotations:\n-                objrepr = stringify_typehint(annotations.get(self.objpath[-1]))\n+                objrepr = stringify_typehint(annotations.get(self.objpath[-1]), type_aliases=self.config.autodoc_type_aliases)\n                 self.add_line('   :type: ' + objrepr, sourcename)\n             else:\n                 key = ('.'.join(self.objpath[:-1]), self.objpath[-1])\n                 if self.analyzer and key in self.analyzer.annotations:\n-                    self.add_line('   :type: ' + self.analyzer.annotations[key],\n+                    self.add_line('   :type: ' + stringify_typehint(self.analyzer.annotations[key], type_aliases=self.config.autodoc_type_aliases),\n                                   sourcename)\n \n             # data descriptors do not have useful values\n", "instance_id": "sphinx-doc__sphinx-8435"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex 11409e6f6..09931a114 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -318,7 +318,7 @@ class GoogleDocstring:\n             return [line[min_indent:] for line in lines]\n \n     def _escape_args_and_kwargs(self, name: str) -> str:\n-        if name.endswith('_'):\n+        if name.endswith('_') and not name.endswith(r'\\_'):\n             name = name[:-1] + r'\\_'\n \n         if name[:2] == '**':\n", "instance_id": "sphinx-doc__sphinx-7738"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/optimizer.py b/django/db/migrations/optimizer.py\nindex 7e5dea2377..79165b3e77 100644\n--- a/django/db/migrations/optimizer.py\n+++ b/django/db/migrations/optimizer.py\n@@ -1,3 +1,5 @@\n+from django.db.migrations.operations import AlterField\n+\n class MigrationOptimizer:\n     \"\"\"\n     Power the optimization process, where you provide a list of Operations\n@@ -61,9 +63,9 @@ class MigrationOptimizer:\n                         break\n                     new_operations.extend(operations[i + j + 2 :])\n                     return new_operations\n-                elif not result:\n+                elif not result and not (isinstance(operation, AlterField) and isinstance(other, AlterField) and operation.model_name == other.model_name and operation.name == other.name):\n                     # Can't perform a right reduction.\n                     right = False\n-            else:\n-                new_operations.append(operation)\n+                else:\n+                    new_operations.append(operation)\n         return new_operations\n", "instance_id": "django__django-16595"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 28d675fc77..6244a9768e 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -58,7 +58,7 @@\n import mpmath.libmp as mlib\n \n import inspect\n-import collections\n+import collections.abc\n \n def _coeff_isneg(a):\n     \"\"\"Return True if the leading Number is negative.\ndiff --git a/sympy/printing/conventions.py b/sympy/printing/conventions.py\nindex f74468290c..596c162234 100644\n--- a/sympy/printing/conventions.py\n+++ b/sympy/printing/conventions.py\n@@ -5,7 +5,7 @@\n from __future__ import print_function, division\n \n import re\n-import collections\n+import collections.abc\n \n \n _name_with_digits_p = re.compile(r'^([a-zA-Z]+)([0-9]+)$')\ndiff --git a/sympy/series/sequences.py b/sympy/series/sequences.py\nindex 08f36df061..aec5ea63bc 100644\n--- a/sympy/series/sequences.py\n+++ b/sympy/series/sequences.py\n@@ -600,6 +600,10 @@ def coeff_mul(self, coeff):\n \n \n class SeqFormula(SeqExpr):\n+\n+    def _repr_latex_(self):\n+        from sympy.printing.latex import latex\n+        return r\"$\\left[\" + latex(self.formula) + r\", \\ldots \\right]$\"\n     \"\"\"Represents sequence based on a formula.\n \n     Elements are generated using a formula.\ndiff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex b2c4135a76..54e048df8f 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -1,5 +1,5 @@\n from __future__ import print_function, division\n-import collections\n+import collections.abc\n \n from sympy import Basic\n from sympy.core.compatibility import SYMPY_INTS\ndiff --git a/sympy/tensor/functions.py b/sympy/tensor/functions.py\nindex 4b97543cfa..778460749e 100644\n--- a/sympy/tensor/functions.py\n+++ b/sympy/tensor/functions.py\n@@ -1,4 +1,4 @@\n-import collections\n+import collections.abc\n from sympy.core.evaluate import global_evaluate\n from sympy import Expr, S, Mul, sympify\n \ndiff --git a/sympy/tensor/indexed.py b/sympy/tensor/indexed.py\nindex 3752d24423..2ee371b31e 100644\n--- a/sympy/tensor/indexed.py\n+++ b/sympy/tensor/indexed.py\n@@ -107,7 +107,7 @@\n \n from __future__ import print_function, division\n \n-import collections\n+import collections.abc\n \n from sympy.core.sympify import _sympify\n from sympy.functions.special.tensor_functions import KroneckerDelta\n", "instance_id": "sympy__sympy-13971"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 757cb2797..08670d2b2 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -15,7 +15,7 @@ from _pytest.compat import dummy_context_manager\n from _pytest.config import create_terminal_writer\n from _pytest.pathlib import Path\n \n-DEFAULT_LOG_FORMAT = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n+DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\"\n \n \n", "instance_id": "pytest-dev__pytest-5227"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..0567dd8ec2 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -2524,7 +2524,11 @@ class AutoFieldMeta(type):\n         return isinstance(instance, self._subclasses) or super().__instancecheck__(instance)\n \n     def __subclasscheck__(self, subclass):\n-        return subclass in self._subclasses or super().__subclasscheck__(subclass)\n+        return (\n+            subclass in self._subclasses or\n+            any(issubclass(subclass, cls) for cls in self._subclasses) or\n+            super().__subclasscheck__(subclass)\n+        )\n \n \n class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n", "instance_id": "django__django-14238"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/astropy/io/fits/fitsrec.py b/astropy/io/fits/fitsrec.py\nindex 574b4073b1..268c9a8262 100644\n--- a/astropy/io/fits/fitsrec.py\n+++ b/astropy/io/fits/fitsrec.py\n@@ -1261,7 +1261,7 @@ class FITS_rec(np.recarray):\n \n         # Replace exponent separator in floating point numbers\n         if 'D' in format:\n-            output_field.replace(encode_ascii('E'), encode_ascii('D'))\n+            output_field = np.char.replace(output_field, encode_ascii('E'), encode_ascii('D'))\n \n \n def _get_recarray_field(array, key):\n", "instance_id": "astropy__astropy-6938"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 69df976b8b..b32f79f4a9 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -1266,6 +1266,259 @@ def _diff_wrt(self):\n         return self.expr._diff_wrt and isinstance(self.doit(), Derivative)\n \n     def __new__(cls, expr, *variables, **kwargs):\n+        from sympy.matrices.common import MatrixCommon\n+        from sympy import MatrixExpr\n+        from sympy.tensor.array import Array, NDimArray\n+        from sympy.core.kind import UndefinedKind, NumberKind, MatrixKind\n+\n+        expr = sympify(expr)\n+        symbols_or_none = getattr(expr, \"free_symbols\", None)\n+        has_symbol_set = isinstance(symbols_or_none, set)\n+\n+        if not has_symbol_set:\n+            raise ValueError(filldedent('''\n+                Since there are no variables in the expression %s,\n+                it cannot be differentiated.''' % expr))\n+\n+        # determine value for variables if it wasn't given\n+        if not variables:\n+            variables = expr.free_symbols\n+            if len(variables) != 1:\n+                if expr.is_number:\n+                    return S.Zero\n+                if len(variables) == 0:\n+                    raise ValueError(filldedent('''\n+                        Since there are no variables in the expression,\n+                        the variable(s) of differentiation must be supplied\n+                        to differentiate %s''' % expr))\n+                else:\n+                    raise ValueError(filldedent('''\n+                        Since there is more than one variable in the\n+                        expression, the variable(s) of differentiation\n+                        must be supplied to differentiate %s''' % expr))\n+\n+        # Standardize the variables by sympifying them:\n+        variables = list(sympify(variables))\n+\n+        # Split the list of variables into a list of the variables we are diff\n+        # wrt, where each element of the list has the form (s, count) where\n+        # s is the entity to diff wrt and count is the order of the\n+        # derivative.\n+        variable_count = []\n+        array_likes = (tuple, list, Tuple)\n+\n+        for i, v in enumerate(variables):\n+            if isinstance(v, Integer):\n+                if i == 0:\n+                    raise ValueError(\"First variable cannot be a number: %i\" % v)\n+                count = v\n+                prev, prevcount = variable_count[-1]\n+                if prevcount != 1:\n+                    raise TypeError(\"tuple {} followed by number {}\".format((prev, prevcount), v))\n+                if count == 0:\n+                    variable_count.pop()\n+                else:\n+                    variable_count[-1] = Tuple(prev, count)\n+            else:\n+                if isinstance(v, array_likes):\n+                    if len(v) == 0:\n+                        # Ignore empty tuples: Derivative(expr, ... , (), ... )\n+                        continue\n+                    if isinstance(v[0], array_likes):\n+                        # Derive by array: Derivative(expr, ... , [[x, y, z]], ... )\n+                        if len(v) == 1:\n+                            v = Array(v[0])\n+                            count = 1\n+                        else:\n+                            v, count = v\n+                            v = Array(v)\n+                    else:\n+                        v, count = v\n+                    if count == 0:\n+                        continue\n+                elif isinstance(v, UndefinedFunction):\n+                    raise TypeError(\n+                        \"cannot differentiate wrt \"\n+                        \"UndefinedFunction: %s\" % v)\n+                else:\n+                    count = 1\n+                variable_count.append(Tuple(v, count))\n+\n+        # light evaluation of contiguous, identical\n+        # items: (x, 1), (x, 1) -> (x, 2)\n+        merged = []\n+        for t in variable_count:\n+            v, c = t\n+            if c.is_negative:\n+                raise ValueError(\n+                    'order of differentiation must be nonnegative')\n+            if merged and merged[-1][0] == v:\n+                c += merged[-1][1]\n+                if not c:\n+                    merged.pop()\n+                else:\n+                    merged[-1] = Tuple(v, c)\n+            else:\n+                merged.append(t)\n+        variable_count = merged\n+\n+        # sanity check of variables of differentation; we waited\n+        # until the counts were computed since some variables may\n+        # have been removed because the count was 0\n+        for v, c in variable_count:\n+            # v must have _diff_wrt True\n+            if not v._diff_wrt:\n+                __ = ''  # filler to make error message neater\n+                raise ValueError(filldedent('''\n+                    Can't calculate derivative wrt %s.%s''' % (v,\n+                    __)))\n+\n+        # We make a special case for 0th derivative, because there is no\n+        # good way to unambiguously print this.\n+        if len(variable_count) == 0:\n+            return expr\n+\n+        evaluate = kwargs.get('evaluate', False)\n+\n+        if evaluate:\n+            if isinstance(expr, Derivative):\n+                expr = expr.canonical\n+            variable_count = [\n+                (v.canonical if isinstance(v, Derivative) else v, c)\n+                for v, c in variable_count]\n+\n+            # Look for a quick exit if there are symbols that don't appear in\n+            # expression at all. Note, this cannot check non-symbols like\n+            # Derivatives as those can be created by intermediate\n+            # derivatives.\n+            zero = False\n+            free = expr.free_symbols\n+            for v, c in variable_count:\n+                vfree = v.free_symbols\n+                if c.is_positive and vfree:\n+                    if isinstance(v, AppliedUndef):\n+                        # these match exactly since\n+                        # x.diff(f(x)) == g(x).diff(f(x)) == 0\n+                        # and are not created by differentiation\n+                        D = Dummy()\n+                        if not expr.xreplace({v: D}).has(D):\n+                            zero = True\n+                            break\n+                    elif isinstance(v, MatrixExpr):\n+                        zero = False\n+                        break\n+                    elif isinstance(v, Symbol) and v not in free:\n+                        zero = True\n+                        break\n+                    else:\n+                        if not free & vfree:\n+                            # e.g. v is IndexedBase or Matrix\n+                            zero = True\n+                            break\n+            if zero:\n+                return cls._get_zero_with_shape_like(expr)\n+\n+            # make the order of symbols canonical\n+            #TODO: check if assumption of discontinuous derivatives exist\n+            variable_count = cls._sort_variable_count(variable_count)\n+\n+        # denest\n+        if isinstance(expr, Derivative):\n+            variable_count = list(expr.variable_count) + variable_count\n+            expr = expr.expr\n+            return _derivative_dispatch(expr, *variable_count, **kwargs)\n+\n+        # we return here if evaluate is False or if there is no\n+        # _eval_derivative method\n+        if not evaluate or not hasattr(expr, '_eval_derivative'):\n+            # return an unevaluated Derivative\n+            if evaluate and variable_count == [(expr, 1)] and expr.is_scalar:\n+                # special hack providing evaluation for classes\n+                # that have defined is_scalar=True but have no\n+                # _eval_derivative defined\n+                return S.One\n+            obj = Expr.__new__(cls, expr, *variable_count)\n+            obj._kind = cls._get_kind(expr, variables)\n+            return obj\n+\n+        # evaluate the derivative by calling _eval_derivative method\n+        # of expr for each variable\n+        # -------------------------------------------------------------\n+        nderivs = 0  # how many derivatives were performed\n+        unhandled = []\n+        for i, (v, count) in enumerate(variable_count):\n+\n+            old_expr = expr\n+            old_v = None\n+\n+            is_symbol = v.is_symbol or isinstance(v,\n+                (Iterable, Tuple, MatrixCommon, NDimArray))\n+\n+            if not is_symbol:\n+                old_v = v\n+                v = Dummy('xi')\n+                expr = expr.xreplace({old_v: v})\n+                # Derivatives and UndefinedFunctions are independent\n+                # of all others\n+                clashing = not (isinstance(old_v, Derivative) or \\\n+                    isinstance(old_v, AppliedUndef))\n+                if not v in expr.free_symbols and not clashing:\n+                    return expr.diff(v)  # expr's version of 0\n+                if not old_v.is_scalar and not hasattr(\n+                        old_v, '_eval_derivative'):\n+                    # special hack providing evaluation for classes\n+                    # that have defined is_scalar=True but have no\n+                    # _eval_derivative defined\n+                    expr *= old_v.diff(old_v)\n+\n+            obj = cls._dispatch_eval_derivative_n_times(expr, v, count)\n+            if obj is not None and obj.is_zero:\n+                return obj\n+\n+            nderivs += count\n+\n+            if old_v is not None:\n+                if obj is not None:\n+                    # remove the dummy that was used\n+                    obj = obj.subs(v, old_v)\n+                # restore expr\n+                expr = old_expr\n+\n+            if obj is None:\n+                # we've already checked for quick-exit conditions\n+                # that give 0 so the remaining variables\n+                # are contained in the expression but the expression\n+                # did not compute a derivative so we stop taking\n+                # derivatives\n+                unhandled = variable_count[i:]\n+                break\n+\n+            expr = obj\n+\n+        # what we have so far can be made canonical\n+        expr = expr.replace(\n+            lambda x: isinstance(x, Derivative),\n+            lambda x: x.canonical)\n+\n+        if unhandled:\n+            if isinstance(expr, Derivative):\n+                unhandled = list(expr.variable_count) + unhandled\n+                expr = expr.expr\n+            expr = Expr.__new__(cls, expr, *unhandled)\n+\n+        if (nderivs > 1) == True and kwargs.get('simplify', True):\n+            from sympy.core.exprtools import factor_terms\n+            from sympy.simplify.simplify import signsimp\n+            expr = factor_terms(signsimp(expr))\n+        expr._kind = cls._get_kind(expr, variables)\n+        return expr\n+\n+    @classmethod\n+    def _get_kind(cls, expr, variables):\n+        from sympy.matrices.expressions.matexpr import MatrixSymbol\n+        if isinstance(expr, MatrixSymbol):\n+            return MatrixKind(NumberKind)\n+        return UndefinedKind\n \n         from sympy.matrices.common import MatrixCommon\n         from sympy import Integer, MatrixExpr\n@@ -3387,3 +3640,5 @@ def nfloat(expr, n=15, exponent=False, dkeys=False):\n \n \n from sympy.core.symbol import Dummy, Symbol\n+from sympy.core.kind import UndefinedKind, NumberKind, MatrixKind\n+from sympy.core.numbers import Integer\n", "instance_id": "sympy__sympy-21614"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-16820"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..c9bdfee89 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,7 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n", "instance_id": "pytest-dev__pytest-7432"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/polys/factortools.py b/sympy/polys/factortools.py\nindex 93298f47e6..7eabf1e5a3 100644\n--- a/sympy/polys/factortools.py\n+++ b/sympy/polys/factortools.py\n@@ -123,22 +123,22 @@ def dmp_trial_division(f, factors, u, K):\n     return _sort_factors(result)\n \n \n-def dup_zz_mignotte_bound(f, K):\n-    \"\"\"Mignotte bound for univariate polynomials in `K[x]`. \"\"\"\n+def dup_zz_knuth_cohen_bound(f, K):\n+    \"\"\"Knuth-Cohen bound for univariate polynomials in `K[x]`. \"\"\"\n     a = dup_max_norm(f, K)\n     b = abs(dup_LC(f, K))\n     n = dup_degree(f)\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n-def dmp_zz_mignotte_bound(f, u, K):\n-    \"\"\"Mignotte bound for multivariate polynomials in `K[X]`. \"\"\"\n+def dmp_zz_knuth_cohen_bound(f, u, K):\n+    \"\"\"Knuth-Cohen bound for multivariate polynomials in `K[X]`. \"\"\"\n     a = dmp_max_norm(f, u, K)\n     b = abs(dmp_ground_LC(f, u, K))\n     n = sum(dmp_degree_list(f, u))\n \n-    return K.sqrt(K(n + 1))*2**n*a*b\n+    return K.sqrt(K(n + 1)) * (2 ** (n - 1)) * a * b\n \n \n def dup_zz_hensel_step(m, f, g, h, s, t, K):\n@@ -272,97 +272,7 @@ def dup_zz_zassenhaus(f, K):\n     fc = f[-1]\n     A = dup_max_norm(f, K)\n     b = dup_LC(f, K)\n-    B = int(abs(K.sqrt(K(n + 1))*2**n*A*b))\n-    C = int((n + 1)**(2*n)*A**(2*n - 1))\n-    gamma = int(_ceil(2*_log(C, 2)))\n-    bound = int(2*gamma*_log(gamma))\n-    a = []\n-    # choose a prime number `p` such that `f` be square free in Z_p\n-    # if there are many factors in Z_p, choose among a few different `p`\n-    # the one with fewer factors\n-    for px in range(3, bound + 1):\n-        if not isprime(px) or b % px == 0:\n-            continue\n-\n-        px = K.convert(px)\n-\n-        F = gf_from_int_poly(f, px)\n-\n-        if not gf_sqf_p(F, px, K):\n-            continue\n-        fsqfx = gf_factor_sqf(F, px, K)[1]\n-        a.append((px, fsqfx))\n-        if len(fsqfx) < 15 or len(a) > 4:\n-            break\n-    p, fsqf = min(a, key=lambda x: len(x[1]))\n-\n-    l = int(_ceil(_log(2*B + 1, p)))\n-\n-    modular = [gf_to_int_poly(ff, p) for ff in fsqf]\n-\n-    g = dup_zz_hensel_lift(p, f, modular, l, K)\n-\n-    sorted_T = range(len(g))\n-    T = set(sorted_T)\n-    factors, s = [], 1\n-    pl = p**l\n-\n-    while 2*s <= len(T):\n-        for S in subsets(sorted_T, s):\n-            # lift the constant coefficient of the product `G` of the factors\n-            # in the subset `S`; if it is does not divide `fc`, `G` does\n-            # not divide the input polynomial\n-\n-            if b == 1:\n-                q = 1\n-                for i in S:\n-                    q = q*g[i][-1]\n-                q = q % pl\n-                if not _test_pl(fc, q, pl):\n-                    continue\n-            else:\n-                G = [b]\n-                for i in S:\n-                    G = dup_mul(G, g[i], K)\n-                G = dup_trunc(G, pl, K)\n-                G = dup_primitive(G, K)[1]\n-                q = G[-1]\n-                if q and fc % q != 0:\n-                    continue\n-\n-            H = [b]\n-            S = set(S)\n-            T_S = T - S\n-\n-            if b == 1:\n-                G = [b]\n-                for i in S:\n-                    G = dup_mul(G, g[i], K)\n-                G = dup_trunc(G, pl, K)\n-\n-            for i in T_S:\n-                H = dup_mul(H, g[i], K)\n-\n-            H = dup_trunc(H, pl, K)\n-\n-            G_norm = dup_l1_norm(G, K)\n-            H_norm = dup_l1_norm(H, K)\n-\n-            if G_norm*H_norm <= B:\n-                T = T_S\n-                sorted_T = [i for i in sorted_T if i not in S]\n-\n-                G = dup_primitive(G, K)[1]\n-                f = dup_primitive(H, K)[1]\n-\n-                factors.append(G)\n-                b = dup_LC(f, K)\n-\n-                break\n-        else:\n-            s += 1\n-\n-    return factors + [f]\n+    B = int(abs(K.sqrt(K(n + 1)) * (2 ** (n - 1)) * A * b))\n \n \n def dup_zz_irreducible_p(f, K):\n@@ -931,9 +841,9 @@ def dmp_zz_wang(f, u, K, mod=None, seed=None):\n \n     randint = _randint(seed)\n \n-    ct, T = dmp_zz_factor(dmp_LC(f, K), u - 1, K)\n+    ct, T = dmp_zz_factor(dmp_LC(f, u, K), u - 1, K)\n \n-    b = dmp_zz_mignotte_bound(f, u, K)\n+    b = dmp_zz_knuth_cohen_bound(f, u, K)\n     p = K(nextprime(b))\n \n     if mod is None:\n", "instance_id": "sympy__sympy-19254"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-16229"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex aa2fe0883b..f031c658c8 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -97,7 +97,8 @@ class MigrationExecutor:\n         \"\"\"\n         # The django_migrations table must be present to record applied\n         # migrations.\n-        self.recorder.ensure_schema()\n+        if router.allow_migrate(self.connection.alias, self.recorder.Migration):\n+            self.recorder.ensure_schema()\n \n         if plan is None:\n             plan = self.migration_plan(targets)\ndiff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..6cf2918118 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,6 +1,7 @@\n from django.apps.registry import Apps\n from django.db import DatabaseError, models\n from django.utils.functional import classproperty\n+from django.db import router\n from django.utils.timezone import now\n \n from .exceptions import MigrationSchemaMissing\n@@ -62,12 +63,14 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n-        # Make the table\n-        try:\n-            with self.connection.schema_editor() as editor:\n-                editor.create_model(self.Migration)\n-        except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+        # Check if migration is allowed on this database\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            # Make the table\n+            try:\n+                with self.connection.schema_editor() as editor:\n+                    editor.create_model(self.Migration)\n+            except DatabaseError as exc:\n+                raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n \n     def applied_migrations(self):\n         \"\"\"\n@@ -83,13 +86,15 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.create(app=app, name=name)\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.filter(app=app, name=name).delete()\n+        if router.allow_migrate(self.connection.alias, self.Migration):\n+            self.ensure_schema()\n+            self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n", "instance_id": "django__django-15252"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..00b280349b 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -6214,8 +6214,20 @@ def sqf_list(f, *gens, **args):\n     >>> sqf_list(2*x**5 + 16*x**4 + 50*x**3 + 76*x**2 + 56*x + 16)\n     (2, [(x + 1, 2), (x + 2, 3)])\n \n+    >>> sqf_list((x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3)\n+    (1, [(x**2 + 1, 1), (x - 1, 2), (x - 2, 3), (x - 3, 3)])\n+\n     \"\"\"\n-    return _generic_factor_list(f, gens, args, method='sqf')\n+    coeff, factors = _generic_factor_list(f, gens, args, method='sqf')\n+    # Group factors by their multiplicity\n+    factor_dict = {}\n+    for factor, multiplicity in factors:\n+        if factor in factor_dict:\n+            factor_dict[factor] += multiplicity\n+        else:\n+            factor_dict[factor] = multiplicity\n+    grouped_factors = [(factor, multiplicity) for factor, multiplicity in factor_dict.items()]\n+    return coeff, grouped_factors\n \n \n @public\n@@ -6232,8 +6244,26 @@ def sqf(f, *gens, **args):\n     >>> sqf(2*x**5 + 16*x**4 + 50*x**3 + 76*x**2 + 56*x + 16)\n     2*(x + 1)**2*(x + 2)**3\n \n+    >>> sqf((x**2 + 1) * (x - 1)**2 * (x - 2)**3 * (x - 3)**3)\n+    (x**2 + 1)*(x - 1)**2*(x - 2)**3*(x - 3)**3\n+\n     \"\"\"\n-    return _generic_factor(f, gens, args, method='sqf')\n+    f = sympify(f)\n+    if f.is_RationalFunction:\n+        numer, denom = f.as_numer_denom()\n+        numer_sqf = sqf(numer, *gens, **args)\n+        denom_sqf = sqf(denom, *gens, **args)\n+        return numer_sqf / denom_sqf\n+    f = sympify(f)\n+    if isinstance(f, Rational):\n+        return f\n+    if isinstance(f, Expr) and f.is_RationalFunction:\n+        numer, denom = f.as_numer_denom()\n+        numer_sqf = sqf(numer, *gens, **args)\n+        denom_sqf = sqf(denom, *gens, **args)\n+        return numer_sqf / denom_sqf\n+    coeff, factors = sqf_list(f, *gens, **args)\n+    return _keep_coeff(coeff, Mul(*[factor**multiplicity for factor, multiplicity in factors]))\n \n \n @public\n", "instance_id": "sympy__sympy-18698"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py\nindex f209e811f1..ea88b679b1 100644\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -665,8 +665,9 @@ grestore\n                 curr_stream[1].append(\n                     (item.x, item.ft_object.get_glyph_name(item.glyph_idx))\n                 )\n-            # append the last entry\n-            stream.append(curr_stream)\n+            # append the last entry if curr_stream is not None\n+            if curr_stream:\n+                stream.append(curr_stream)\n \n         self.set_color(*gc.get_rgb())\n \n", "instance_id": "matplotlib__matplotlib-23964"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\nindex 2b306a579e..571d120467 100644\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -84,13 +84,13 @@ class Command(BaseCommand):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], {})\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), {})\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n", "instance_id": "django__django-13660"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex 7a3de33522..69232fa917 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -629,7 +629,7 @@ def adjust(s, wid=None, how='<^>'):\n             # put the present prettyF to the right\n             prettyF = prettyForm(*prettySign.right(prettyF))\n \n-        prettyF.baseline = max_upper + sign_height//2\n+        prettyF.baseline = max_upper + sign_height//2 - 1\n         prettyF.binding = prettyForm.MUL\n         return prettyF\n \n", "instance_id": "sympy__sympy-16503"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..cca62a5a76 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -216,7 +216,10 @@ def __add__(self, other):\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            if isinstance(other, (list, tuple)) and all(isinstance(x, Expr) for x in other):\n+                s, o = self, Point(other, evaluate=False)\n+            else:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n@@ -286,7 +289,13 @@ def __neg__(self):\n     def __sub__(self, other):\n         \"\"\"Subtract two points, or subtract a factor from this point's\n         coordinates.\"\"\"\n-        return self + [-x for x in other]\n+        try:\n+            return self + [-x for x in other]\n+        except TypeError:\n+            if isinstance(other, (list, tuple)) and all(isinstance(x, Expr) for x in other):\n+                return self + [-x for x in other]\n+            else:\n+                raise GeometryError(\"Don't know how to subtract {} and a Point object\".format(other))\n \n     @classmethod\n     def _normalize_dimension(cls, *points, **kwargs):\n", "instance_id": "sympy__sympy-17655"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\nindex 15c630b1d..c0a173549 100644\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -9,6 +9,8 @@ Output conforms to https://github.com/jenkinsci/xunit-plugin/blob/master/\n src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd\n \"\"\"\n import functools\n+import socket\n+from datetime import datetime\n import os\n import re\n import sys\n@@ -80,9 +82,11 @@ families[\"xunit2\"] = families[\"_base\"]\n \n \n class _NodeReporter:\n-    def __init__(self, nodeid, xml):\n+    def __init__(self, nodeid, xml, timestamp, hostname):\n         self.id = nodeid\n         self.xml = xml\n+        self.timestamp = timestamp\n+        self.hostname = hostname\n         self.add_stats = self.xml.add_stats\n         self.family = self.xml.family\n         self.duration = 0\n@@ -514,7 +518,7 @@ class LogXML:\n             # TODO: breasks for --dist=each\n             return self.node_reporters[key]\n \n-        reporter = _NodeReporter(nodeid, self)\n+        reporter = _NodeReporter(nodeid, self, self.timestamp, self.hostname)\n \n         self.node_reporters[key] = reporter\n         self.node_reporters_ordered.append(reporter)\n@@ -639,6 +643,8 @@ class LogXML:\n \n     def pytest_sessionstart(self):\n         self.suite_start_time = time.time()\n+        self.hostname = socket.gethostname()\n+        self.timestamp = datetime.now().isoformat()\n \n     def pytest_sessionfinish(self):\n         dirname = os.path.dirname(os.path.abspath(self.logfile))\n", "instance_id": "pytest-dev__pytest-5692"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-15678"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/utils/text.py b/django/utils/text.py\nindex fb5f6298c4..3ba4bbb3f4 100644\n--- a/django/utils/text.py\n+++ b/django/utils/text.py\n@@ -403,7 +403,7 @@ def slugify(value, allow_unicode=False):\n     else:\n         value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n     value = re.sub(r'[^\\w\\s-]', '', value.lower()).strip()\n-    return re.sub(r'[-\\s]+', '-', value)\n+    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n \n \n def camel_case_to_spaces(value):\n", "instance_id": "django__django-12983"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex a024324b..0c03fbd3 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3512,7 +3512,8 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n                     new_dims = dict(zip(new_dim_names, new_dim_sizes))\n                     variables[name] = var.unstack({dim: new_dims})\n                 else:\n-                    variables[name] = var\n+                    # Ensure single-dimension variables are handled correctly\n+                    variables[name] = var.expand_dims({new_dim_names[0]: new_dim_sizes[0]})\n \n         for name, lev in zip(new_dim_names, index.levels):\n             variables[name] = IndexVariable(name, lev)\n", "instance_id": "pydata__xarray-4094"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 590e089ae4..ea8902cf08 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -972,7 +972,7 @@ def evaluateFalse(s):\n     node = ast.parse(s)\n     node = EvaluateFalseTransformer().visit(node)\n     # node is a Module, we want an Expression\n-    node = ast.Expression(node.body[0].value)\n+    node = ast.Expression(body=node.body[0].value)\n \n     return ast.fix_missing_locations(node)\n \n@@ -1009,7 +1009,7 @@ def visit_BinOp(self, node):\n                 right = ast.Call(\n                     func=ast.Name(id='Mul', ctx=ast.Load()),\n                     args=[ast.UnaryOp(op=ast.USub(), operand=ast.Num(1)), right],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\n@@ -1020,7 +1020,7 @@ def visit_BinOp(self, node):\n                     left = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n                     args=[left, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\n@@ -1028,7 +1028,7 @@ def visit_BinOp(self, node):\n                     right = ast.Call(\n                     func=ast.Name(id='Pow', ctx=ast.Load()),\n                     args=[right, ast.UnaryOp(op=ast.USub(), operand=ast.Num(1))],\n-                    keywords=[ast.keyword(arg='evaluate', value=ast.Name(id='False', ctx=ast.Load()))],\n+                    keywords=[ast.keyword(arg='evaluate', value=ast.Constant(value=False))],\n                     starargs=None,\n                     kwargs=None\n                 )\ndiff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex a0eb97792e..90e10dbe26 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1403,7 +1403,9 @@ def _print_Piecewise(self, expr):\n         tex = r\"\\begin{cases} %s \\end{cases}\"\n         return tex % r\" \\\\\".join(ecpairs)\n \n-    def _print_MatrixBase(self, expr):\n+    def _print_Trace(self, expr):\n+        arg = self._print(expr.arg)\n+        return r\"\\operatorname{tr}\\left(%s\\right)\" % arg\n         lines = []\n \n         for line in range(expr.rows):  # horrible, should be 'rows'\n@@ -1429,10 +1431,38 @@ def _print_MatrixBase(self, expr):\n             out_str = r'\\left' + left_delim + out_str + \\\n                       r'\\right' + right_delim\n         return out_str % r\"\\\\\".join(lines)\n+\n+    def _print_MatrixBase(self, expr):\n+        lines = []\n+        for line in range(expr.rows):\n+            lines.append(\" & \".join([self._print(i) for i in expr[line, :]]))\n+        mat_str = self._settings['mat_str']\n+        if mat_str is None:\n+            if self._settings['mode'] == 'inline':\n+                mat_str = 'smallmatrix'\n+            else:\n+                if expr.cols <= 10:\n+                    mat_str = 'matrix'\n+                else:\n+                    mat_str = 'array'\n+        out_str = r'\\begin{%MATSTR%}%s\\end{%MATSTR%}'\n+        out_str = out_str.replace('%MATSTR%', mat_str)\n+        if mat_str == 'array':\n+            out_str = out_str.replace('%s', '{' + 'c' * expr.cols + '}%s')\n+        if self._settings['mat_delim']:\n+            left_delim = self._settings['mat_delim']\n+            right_delim = self._delim_dict[left_delim]\n+            out_str = r'\\left' + left_delim + out_str + r'\\right' + right_delim\n+        return out_str % r\"\\\\\".join(lines)\n+\n     _print_ImmutableMatrix = _print_ImmutableDenseMatrix \\\n                            = _print_Matrix \\\n                            = _print_MatrixBase\n \n+    def _print_Trace(self, expr):\n+        arg = self._print(expr.arg)\n+        return r\"\\operatorname{tr}\\left(%s\\right)\" % arg\n+\n     def _print_MatrixElement(self, expr):\n         return self.parenthesize(expr.parent, PRECEDENCE[\"Atom\"], strict=True) \\\n             + '_{%s, %s}' % (expr.i, expr.j)\n", "instance_id": "sympy__sympy-15308"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..515ec689e9 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -173,9 +173,8 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                addend_factor, addend_dim = self._collect_factor_and_dimension(addend)\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n", "instance_id": "sympy__sympy-24213"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex e0eeccefa6..8e1d7108c4 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1001,7 +1001,9 @@ class QuerySet:\n         if isinstance(self, EmptyQuerySet):\n             qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]\n             return qs[0]._combinator_query('union', *qs[1:], all=all) if qs else self\n-        return self._combinator_query('union', *other_qs, all=all)\n+        combined_query = self._combinator_query('union', *other_qs, all=all)\n+        combined_query.is_union = True\n+        return combined_query\n \n     def intersection(self, *other_qs):\n         # If any query is an EmptyQuerySet, return it.\n@@ -1141,6 +1143,10 @@ class QuerySet:\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n+        if self.query.combinator:\n+            raise NotSupportedError(\n+                'Calling distinct() after union() is not supported.'\n+            )\n         obj.query.add_distinct_fields(*field_names)\n         return obj\n \ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex bb230647eb..43be2624dd 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -352,6 +352,7 @@ class Query(BaseExpression):\n     def relabeled_clone(self, change_map):\n         clone = self.clone()\n         clone.change_aliases(change_map)\n+        clone.is_union = self.is_union\n         return clone\n \n     def _get_col(self, target, field, alias):\n", "instance_id": "django__django-12908"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 7649c39262..687b773587 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -353,7 +353,8 @@ class SQLCompiler:\n             # not taken into account so we strip it. When this entire method\n             # is refactored into expressions, then we can check each part as we\n             # generate it.\n-            without_ordering = self.ordering_parts.search(sql).group(1)\n+            sql_oneline = ' '.join(sql.split('\\n'))\n+            without_ordering = self.ordering_parts.search(sql_oneline).group(1)\n             params_hash = make_hashable(params)\n             if (without_ordering, params_hash) in seen:\n                 continue\n", "instance_id": "django__django-11001"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..2b95de6e03 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -31,7 +31,14 @@ from .utils import get_callable\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n+        if isinstance(func, functools.partial):\n+            self.func = func.func\n+            self.partial_args = func.args\n+            self.partial_kwargs = func.keywords\n+        else:\n+            self.func = func\n+            self.partial_args = ()\n+            self.partial_kwargs = {}\n         self.args = args\n         self.kwargs = kwargs\n         self.url_name = url_name\n@@ -59,10 +66,13 @@ class ResolverMatch:\n         return (self.func, self.args, self.kwargs)[index]\n \n     def __repr__(self):\n-        return \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n+        repr_str = \"ResolverMatch(func=%s, args=%s, kwargs=%s, url_name=%s, app_names=%s, namespaces=%s, route=%s)\" % (\n             self._func_path, self.args, self.kwargs, self.url_name,\n             self.app_names, self.namespaces, self.route,\n         )\n+        if self.partial_args or self.partial_kwargs:\n+            repr_str = repr_str[:-1] + \", partial_args=%s, partial_kwargs=%s)\" % (self.partial_args, self.partial_kwargs)\n+        return repr_str\n \n \n def get_resolver(urlconf=None):\n", "instance_id": "django__django-14155"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..a49bc3238f 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,20 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        imports = {'import %s' % module}\n+        return \"%s.%s.%s\" % (module, enum_class.__name__, self.value.name), imports\n+\n+class RegexFlagSerializer(BaseSerializer):\n+    def serialize(self):\n+        return \"re.RegexFlag(%s)\" % self.value, {\"import re\"}\n+\n+class RegexFlagSerializer(BaseSerializer):\n+    def serialize(self):\n+        return \"re.RegexFlag(%s)\" % self.value, {\"import re\"}\n+\n+class RegexFlagSerializer(BaseSerializer):\n+    def serialize(self):\n+        return \"re.RegexFlag(%s)\" % self.value, {\"import re\"}\n \n \n class FloatSerializer(BaseSimpleSerializer):\n@@ -297,6 +308,8 @@ class Serializer:\n         collections.abc.Iterable: IterableSerializer,\n         (COMPILED_REGEX_TYPE, RegexObject): RegexSerializer,\n         uuid.UUID: UUIDSerializer,\n+        re.RegexFlag: RegexFlagSerializer,\n+        re.RegexFlag: RegexFlagSerializer,\n     }\n \n     @classmethod\n", "instance_id": "django__django-11815"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\nindex 69149e61a..d6dbe5840 100644\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -121,11 +121,11 @@ class EncodingChecker(BaseChecker):\n \n         notes = \"|\".join(re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n-            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n+            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\"\n         else:\n-            regex_string = rf\"#\\s*({notes})\\b\"\n+            regex_string = rf\"#\\s*({notes})\"\n \n-        self._fixme_pattern = re.compile(regex_string, re.I)\n+        self._fixme_pattern = re.compile(regex_string, re.I | re.UNICODE)\n \n     def _check_encoding(\n         self, lineno: int, line: bytes, file_encoding: str\n", "instance_id": "pylint-dev__pylint-5859"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..1e23869000 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -920,6 +920,8 @@ class QuerySet:\n         \"\"\"Return an empty QuerySet.\"\"\"\n         clone = self._chain()\n         clone.query.set_empty()\n+        if clone.query.combinator:\n+            clone.query.combined_queries = tuple(q.none().query for q in clone.query.combined_queries)\n         return clone\n \n     ##################################################################\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex c913267476..0df748c3b4 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1777,6 +1777,8 @@ class Query(BaseExpression):\n \n     def set_empty(self):\n         self.where.add(NothingNode(), AND)\n+        if self.combinator:\n+            self.combined_queries = tuple(q.set_empty() or q for q in self.combined_queries)\n \n     def is_empty(self):\n         return any(isinstance(c, NothingNode) for c in self.where.children)\n", "instance_id": "django__django-13158"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/functions/elementary/complexes.py b/sympy/functions/elementary/complexes.py\nindex 7fda45982b..febeaf0adf 100644\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -385,7 +385,10 @@ def _sage_(self):\n         import sage.all as sage\n         return sage.sgn(self.args[0]._sage_())\n \n-    def _eval_rewrite_as_Piecewise(self, arg, **kwargs):\n+    def _eval_rewrite_as_Abs(self, arg, **kwargs):\n+        if arg.is_zero:\n+            return S.Zero\n+        return arg / Abs(arg)\n         if arg.is_extended_real:\n             return Piecewise((1, arg > 0), (-1, arg < 0), (0, True))\n \n", "instance_id": "sympy__sympy-19487"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\nindex 37a15ff2..99706dcf 100644\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -1018,20 +1018,22 @@ def routes_command(sort: str, all_methods: bool) -> None:\n         for rule in rules\n     ]\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n+    headers = (\"Domain\", \"Endpoint\", \"Methods\", \"Rule\")\n     widths = (\n+        max(len(rule.subdomain or current_app.config['SERVER_NAME']) for rule in rules),\n         max(len(rule.endpoint) for rule in rules),\n         max(len(methods) for methods in rule_methods),\n         max(len(rule.rule) for rule in rules),\n     )\n     widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}  {{3:<{3}}}\".format(*widths)\n \n     click.echo(row.format(*headers).strip())\n     click.echo(row.format(*(\"-\" * width for width in widths)))\n \n     for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+        domain = rule.subdomain or current_app.config['SERVER_NAME']\n+        click.echo(row.format(domain, rule.endpoint, methods, rule.rule).rstrip())\n \n \n cli = FlaskGroup(\n", "instance_id": "pallets__flask-5063"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/simplify/cse_main.py b/sympy/simplify/cse_main.py\nindex d649dd02a9..0f712c45d2 100644\n--- a/sympy/simplify/cse_main.py\n+++ b/sympy/simplify/cse_main.py\n@@ -8,6 +8,7 @@\n from sympy.core.symbol import symbols, Symbol\n from sympy.utilities.iterables import numbered_symbols, sift, \\\n         topological_sort, iterable\n+from sympy.matrices.expressions import MatrixSymbol\n \n from . import cse_opts\n \n@@ -488,7 +489,8 @@ def opt_cse(exprs, order='canonical'):\n \n     def _find_opts(expr):\n \n-        if not isinstance(expr, (Basic, Unevaluated)):\n+        from sympy.matrices.expressions import MatrixSymbol\n+        if not isinstance(expr, (Basic, Unevaluated, MatrixSymbol)):\n             return\n \n         if expr.is_Atom or expr.is_Order:\n@@ -629,14 +631,16 @@ def _rebuild(expr):\n         if not isinstance(expr, (Basic, Unevaluated)):\n             return expr\n \n-        if not expr.args:\n+        from sympy.matrices.expressions import MatrixSymbol\n+        if not expr.args and not isinstance(expr, MatrixSymbol):\n             return expr\n \n         if iterable(expr):\n             new_args = [_rebuild(arg) for arg in expr]\n             return expr.func(*new_args)\n \n-        if expr in subs:\n+        from sympy.matrices.expressions import MatrixSymbol\n+        if expr in subs and not isinstance(expr, MatrixSymbol):\n             return subs[expr]\n \n         orig_expr = expr\n", "instance_id": "sympy__sympy-22840"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 43f40c24ec..b0fbd61aa0 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -502,17 +502,12 @@ class Range(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n \n \n @Field.register_lookup\n-class IsNull(BuiltinLookup):\n+class KeyTransformIsNull(BuiltinLookup):\n     lookup_name = 'isnull'\n     prepare_rhs = False\n \n     def as_sql(self, compiler, connection):\n         if not isinstance(self.rhs, bool):\n-            # When the deprecation ends, replace with:\n-            # raise ValueError(\n-            #     'The QuerySet value for an isnull lookup must be True or '\n-            #     'False.'\n-            # )\n             warnings.warn(\n                 'Using a non-boolean value for an isnull lookup is '\n                 'deprecated, use True or False instead.',\n@@ -520,6 +515,8 @@ class IsNull(BuiltinLookup):\n             )\n         sql, params = compiler.compile(self.lhs)\n         if self.rhs:\n+            if connection.vendor in ('sqlite', 'oracle'):\n+                return \"JSON_TYPE(%s, '$.%s') IS NULL\" % (sql, self.lhs.key_name), params\n             return \"%s IS NULL\" % sql, params\n         else:\n             return \"%s IS NOT NULL\" % sql, params\n", "instance_id": "django__django-13757"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex f0c81c123b..e9b977bd34 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -215,15 +215,13 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # Work inside a new app registry\n         apps = Apps()\n \n-        # Work out the new value of unique_together, taking renames into\n-        # account\n+        # Work out the new value of unique_together, taking renames into account\n         unique_together = [\n             [rename_mapping.get(n, n) for n in unique]\n             for unique in model._meta.unique_together\n         ]\n \n-        # Work out the new value for index_together, taking renames into\n-        # account\n+        # Work out the new value for index_together, taking renames into account\n         index_together = [\n             [rename_mapping.get(n, n) for n in index]\n             for index in model._meta.index_together\n@@ -236,7 +234,10 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n                 if delete_field.name not in index.fields\n             ]\n \n-        constraints = list(model._meta.constraints)\n+        constraints = [\n+            constraint for constraint in model._meta.constraints\n+            if not isinstance(constraint, UniqueConstraint) or not constraint.contains_expressions\n+        ]\n \n         # Provide isolated instances of the fields to the new model body so\n         # that the existing model's internals aren't interfered with when\n", "instance_id": "django__django-14997"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\nindex 29c7e19d7..5f7cc0ebc 100644\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -111,7 +111,7 @@ class TempPathFactory:\n         else:\n             from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n             temproot = Path(from_env or tempfile.gettempdir()).resolve()\n-            user = get_user() or \"unknown\"\n+            user = sanitize_username(get_user() or \"unknown\")\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n             rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n@@ -159,6 +159,11 @@ def get_user() -> Optional[str]:\n         return None\n \n \n+def sanitize_username(username: str) -> str:\n+    \"\"\"Sanitize the username to remove any illegal characters for directory names.\"\"\"\n+    return re.sub(r'[<>:\"/\\\\|?*]', '_', username)\n+\n+\n def pytest_configure(config: Config) -> None:\n     \"\"\"Create a TempdirFactory and attach it to the config object.\n \n@@ -172,6 +177,18 @@ def pytest_configure(config: Config) -> None:\n     config._cleanup.append(mp.undo)\n     mp.setattr(config, \"_tmp_path_factory\", tmppath_handler, raising=False)\n     mp.setattr(config, \"_tmpdirhandler\", t, raising=False)\n+    \"\"\"Create a TempdirFactory and attach it to the config object.\n+\n+    This is to comply with existing plugins which expect the handler to be\n+    available at pytest_configure time, but ideally should be moved entirely\n+    to the tmpdir_factory session fixture.\n+    \"\"\"\n+    mp = MonkeyPatch()\n+    tmppath_handler = TempPathFactory.from_config(config, _ispytest=True)\n+    t = TempdirFactory(tmppath_handler, _ispytest=True)\n+    config._cleanup.append(mp.undo)\n+    mp.setattr(config, \"_tmp_path_factory\", tmppath_handler, raising=False)\n+    mp.setattr(config, \"_tmpdirhandler\", t, raising=False)\n \n \n @fixture(scope=\"session\")\n@@ -181,6 +198,7 @@ def tmpdir_factory(request: FixtureRequest) -> TempdirFactory:\n     return request.config._tmpdirhandler  # type: ignore\n \n \n+\n @fixture(scope=\"session\")\n def tmp_path_factory(request: FixtureRequest) -> TempPathFactory:\n     \"\"\"Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session.\"\"\"\n", "instance_id": "pytest-dev__pytest-8365"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/mark/structures.py b/src/_pytest/mark/structures.py\nindex 5a50cded0..752d6d23d 100644\n--- a/src/_pytest/mark/structures.py\n+++ b/src/_pytest/mark/structures.py\n@@ -239,6 +239,10 @@ class Mark:\n             param_ids_from=param_ids_from,\n         )\n \n+    def is_xfail(self) -> bool:\n+        \"\"\"Check if the mark is an xfail mark.\"\"\"\n+        return self.name == \"xfail\"\n+\n \n # A generic parameter designating an object to which a Mark may\n # be applied -- a test function (callable) or class.\n@@ -428,7 +432,7 @@ if TYPE_CHECKING:\n             ids: Optional[\n                 Union[\n                     Iterable[Union[None, str, float, int, bool]],\n-                    Callable[[object], Optional[object]],\n+                    Callable[[object], Optional[Union[None, str, float, int, bool]]],\n                 ]\n             ] = ...,\n             scope: Optional[_Scope] = ...\ndiff --git a/src/_pytest/runner.py b/src/_pytest/runner.py\nindex 69754ad5e..685095eef 100644\n--- a/src/_pytest/runner.py\n+++ b/src/_pytest/runner.py\n@@ -207,6 +207,9 @@ def call_and_report(\n     call = call_runtest_hook(item, when, **kwds)\n     hook = item.ihook\n     report = hook.pytest_runtest_makereport(item=item, call=call)  # type: TestReport\n+    if report.outcome == \"failed\" and \"xfail\" in item.keywords:\n+        report.wasxfail = item.keywords[\"xfail\"].kwargs.get(\"reason\", \"\")\n+        report.outcome = \"skipped\"\n     if log:\n         hook.pytest_runtest_logreport(report=report)\n     if check_interactive_exception(call, report):\n", "instance_id": "pytest-dev__pytest-7490"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/util/nodes.py b/sphinx/util/nodes.py\nindex b4d796f61..1179fdf2d 100644\n--- a/sphinx/util/nodes.py\n+++ b/sphinx/util/nodes.py\n@@ -366,6 +366,12 @@ indextypes = [\n     'single', 'pair', 'double', 'triple', 'see', 'seealso',\n ]\n \n+# Define a set of symbols to be grouped under the \"Symbols\" section\n+symbol_characters = set('@\u00a3\u2190')\n+\n+# Define a set of symbols to be grouped under the \"Symbols\" section\n+symbol_characters = set('@\u00a3\u2190')\n+\n \n def process_index_entry(entry: str, targetid: str) -> List[Tuple[str, str, str, str, str]]:\n     from sphinx.domains.python import pairindextypes\n@@ -377,31 +383,26 @@ def process_index_entry(entry: str, targetid: str) -> List[Tuple[str, str, str,\n     if entry.startswith('!'):\n         main = 'main'\n         entry = entry[1:].lstrip()\n-    for type in pairindextypes:\n-        if entry.startswith(type + ':'):\n-            value = entry[len(type) + 1:].strip()\n-            value = pairindextypes[type] + '; ' + value\n-            indexentries.append(('pair', value, targetid, main, None))\n-            break\n-    else:\n-        for type in indextypes:\n-            if entry.startswith(type + ':'):\n-                value = entry[len(type) + 1:].strip()\n-                if type == 'double':\n-                    type = 'pair'\n-                indexentries.append((type, value, targetid, main, None))\n-                break\n-        # shorthand notation for single entries\n+for type in pairindextypes:\n+    if entry.startswith(type + ':'):\n+        value = entry[len(type) + 1:].strip()\n+        value = pairindextypes[type] + '; ' + value\n+        indexentries.append(('pair', value, targetid, main, None))\n+        break\n+else:\n+    for value in oentry.split(','):\n+        value = value.strip()\n+        main = ''\n+        if value.startswith('!'):\n+            main = 'main'\n+            value = value[1:].lstrip()\n+        if not value:\n+            continue\n+        # Check if the value starts with a symbol character\n+        if value[0] in symbol_characters:\n+            indexentries.append(('single', 'Symbols', targetid, main, None))\n         else:\n-            for value in oentry.split(','):\n-                value = value.strip()\n-                main = ''\n-                if value.startswith('!'):\n-                    main = 'main'\n-                    value = value[1:].lstrip()\n-                if not value:\n-                    continue\n-                indexentries.append(('single', value, targetid, main, None))\n+            indexentries.append(('single', value, targetid, main, None))\n     return indexentries\n \n \ndiff --git a/sphinx/writers/html.py b/sphinx/writers/html.py\nindex 4375bf326..2787fcea7 100644\n--- a/sphinx/writers/html.py\n+++ b/sphinx/writers/html.py\n@@ -639,6 +639,11 @@ class HTMLTranslator(SphinxTranslator, BaseTranslator):\n         raise nodes.SkipNode\n \n     def visit_index(self, node: Element) -> None:\n+        # Handle the \"Symbols\" section correctly\n+        for entry in node['entries']:\n+            if entry[0] == 'single' and entry[1] == 'Symbols':\n+                self.body.append('<h2>Symbols</h2>\\n')\n+                break\n         raise nodes.SkipNode\n \n     def visit_tabular_col_spec(self, node: Element) -> None:\n", "instance_id": "sphinx-doc__sphinx-7975"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 78accaf295..ae362a2aa4 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -248,7 +248,10 @@ def _eval_expand_tensorproduct(self, **hints):\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n                     if isinstance(tp, TensorProduct):\n                         tp = tp._eval_expand_tensorproduct()\n-                    add_args.append(tp)\n+                    c_part, nc_part = tp.args_cnc()\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(),)\n+                    add_args.append(Mul(*c_part) * Mul(*nc_part))\n                 break\n \n         if add_args:\n", "instance_id": "sympy__sympy-24152"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/ext/autosummary/__init__.py b/sphinx/ext/autosummary/__init__.py\nindex 0cdd88feb..963b4bcd3 100644\n--- a/sphinx/ext/autosummary/__init__.py\n+++ b/sphinx/ext/autosummary/__init__.py\n@@ -306,6 +306,9 @@ class Autosummary(SphinxDirective):\n                 continue\n \n             self.bridge.result = StringList()  # initialize for each documenter\n+            if not self.config.autosummary_imported_members and name in sys.modules:\n+                if not any(name.startswith(modname) for modname in self.config.autosummary_imported_members):\n+                    continue\n             full_name = real_name\n             if not isinstance(obj, ModuleType):\n                 # give explicitly separated module name, so that members\n", "instance_id": "sphinx-doc__sphinx-7686"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-13265"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..1304f20a60 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,7 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +17,7 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n", "instance_id": "django__django-11099"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/dispatch/dispatcher.py b/django/dispatch/dispatcher.py\nindex b7d9d26389..31bc622c98 100644\n--- a/django/dispatch/dispatcher.py\n+++ b/django/dispatch/dispatcher.py\n@@ -1,10 +1,13 @@\n import threading\n import warnings\n import weakref\n+import logging\n \n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.inspect import func_accepts_kwargs\n \n+logger = logging.getLogger(__name__)\n+\n \n def _make_id(target):\n     if hasattr(target, '__func__'):\n@@ -173,6 +176,7 @@ class Signal:\n         \"\"\"\n         if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:\n             return []\n+            return []\n \n         return [\n             (receiver, receiver(signal=self, sender=sender, **named))\n@@ -205,12 +209,12 @@ class Signal:\n         # Return a list of tuple pairs [(receiver, response), ... ].\n         responses = []\n         for receiver in self._live_receivers(sender):\n+            response = None\n             try:\n                 response = receiver(signal=self, sender=sender, **named)\n             except Exception as err:\n                 responses.append((receiver, err))\n-            else:\n-                responses.append((receiver, response))\n+                logger.exception('Error in signal handler for %s', receiver)\n         return responses\n \n     def _clear_dead_receivers(self):\n", "instance_id": "django__django-13768"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 737e16cc74..a48b757cd3 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -6,7 +6,7 @@\n \n import itertools\n \n-from sympy.core import S, Add, Symbol, Mod\n+from sympy.core import S, Add, Symbol, Mod, Mul\n from sympy.core.function import _coeff_isneg\n from sympy.core.sympify import SympifyError\n from sympy.core.alphabets import greeks\n@@ -1854,7 +1854,9 @@ def _print_PolynomialRingBase(self, expr):\n \n     def _print_Poly(self, poly):\n         cls = poly.__class__.__name__\n-        expr = self._print(poly.as_expr())\n+        terms = sorted(poly.terms(), key=lambda term: term[0], reverse=True)\n+        expr = self._print(Add(*[coeff * Mul(*[gen**exp for gen, exp in zip(poly.gens, monom)])\n+                                 for monom, coeff in terms]))\n         gens = list(map(self._print, poly.gens))\n         domain = \"domain=%s\" % self._print(poly.get_domain())\n \n", "instance_id": "sympy__sympy-14317"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex d3d53e3d98..5a22af507d 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -490,9 +490,24 @@ class Colorbar:\n \n     filled = _api.deprecate_privatize_attribute(\"3.6\")\n \n-    def update_normal(self, mappable):\n+    def update_bruteforce(self, mappable):\n         \"\"\"\n-        Update solid patches, lines, etc.\n+        Forcefully update the colorbar by recalculating all parameters and redrawing.\n+        \"\"\"\n+        self.mappable = mappable\n+        self.set_alpha(mappable.get_alpha())\n+        self.cmap = mappable.cmap\n+        self.norm = mappable.norm\n+        self._reset_locator_formatter_scale()\n+        self._draw_all()\n+        if isinstance(self.mappable, contour.ContourSet):\n+            CS = self.mappable\n+            if not CS.filled:\n+                self.add_lines(CS)\n+        self.stale = True\n+        \"\"\"\n+        Update solid patches, lines, etc. This method is less forceful than\n+        `update_bruteforce` and should be used when only minor updates are needed.\n \n         This is meant to be called when the norm of the image or contour plot\n         to which this colorbar belongs changes.\n", "instance_id": "matplotlib__matplotlib-25498"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\nindex 24e453a73..2e6a329dd 100644\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -82,7 +82,7 @@ def _config_initialization(\n     if unrecognized_options:\n         msg = \", \".join(unrecognized_options)\n         linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+        raise _UnrecognizedOptionError(options=unrecognized_options) from None\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\ndiff --git a/pylint/config/exceptions.py b/pylint/config/exceptions.py\nindex 74a001c24..3dfef7a72 100644\n--- a/pylint/config/exceptions.py\n+++ b/pylint/config/exceptions.py\n@@ -11,12 +11,12 @@ class UnrecognizedArgumentAction(Exception):\n     \"\"\"\n \n \n-class _UnrecognizedOptionError(Exception):\n+class _UnrecognizedOptionError(SystemExit):\n     \"\"\"Raised if an ArgumentManager instance tries to parse an option that is unknown.\"\"\"\n \n     def __init__(self, options: list[str], *args: object) -> None:\n         self.options = options\n-        super().__init__(*args)\n+        super().__init__(f\"Unrecognized options: {', '.join(options)}\")\n \n \n class ArgumentPreprocessingError(Exception):\n", "instance_id": "pylint-dev__pylint-6506"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/builders/manpage.py b/sphinx/builders/manpage.py\nindex 4166dece9..c85292965 100644\n--- a/sphinx/builders/manpage.py\n+++ b/sphinx/builders/manpage.py\n@@ -8,6 +8,7 @@\n     :license: BSD, see LICENSE for details.\n \"\"\"\n \n+import os\n from os import path\n from typing import Any, Dict, List, Set, Tuple, Union\n \n@@ -80,10 +81,13 @@ class ManualPageBuilder(Builder):\n             docsettings.authors = authors\n             docsettings.section = section\n \n-            targetname = '%s.%s' % (name, section)\n+            section_dir = path.join(self.outdir, f'man{section}')\n+            if not path.exists(section_dir):\n+                os.makedirs(section_dir)\n+            targetname = path.join(section_dir, f'{name}.{section}')\n             logger.info(darkgreen(targetname) + ' { ', nonl=True)\n             destination = FileOutput(\n-                destination_path=path.join(self.outdir, targetname),\n+                destination_path=targetname,\n                 encoding='utf-8')\n \n             tree = self.env.get_doctree(docname)\n", "instance_id": "sphinx-doc__sphinx-8273"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex 425db22c..39c93ca3 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -88,7 +88,7 @@ class SessionRedirectMixin(object):\n         i = 0\n \n         while resp.is_redirect:\n-            prepared_request = req.copy()\n+            prepared_request = resp.request.copy()\n \n             resp.content  # Consume socket so it can be released\n \n@@ -99,7 +99,7 @@ class SessionRedirectMixin(object):\n             resp.close()\n \n             url = resp.headers['location']\n-            method = req.method\n+            method = prepared_request.method\n \n             # Handle redirection without scheme (see: RFC 1808 Section 4)\n             if url.startswith('//'):\n", "instance_id": "psf__requests-1963"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..5036335bec 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,7 +748,7 @@ class Query(BaseExpression):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n-                opts = cur_model._meta\n+                opts = cur_model._meta.concrete_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n                 # (if it's not a reverse relation) to the things we select.\n", "instance_id": "django__django-15814"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex dadd4acfa1..ef2bfc6802 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2040,7 +2040,10 @@ class InlineModelAdmin(BaseModelAdmin):\n         if self.verbose_name is None:\n             self.verbose_name = self.model._meta.verbose_name\n         if self.verbose_name_plural is None:\n-            self.verbose_name_plural = self.model._meta.verbose_name_plural\n+            if self.verbose_name is not None:\n+                self.verbose_name_plural = format_lazy('{}s', self.verbose_name)\n+            else:\n+                self.verbose_name_plural = self.model._meta.verbose_name_plural\n \n     @property\n     def media(self):\n", "instance_id": "django__django-13710"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-17087"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "pylint-dev__pylint-7080"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex 4c2ffd81e1..70e1264d2d 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -65,8 +65,8 @@ def __init__(self, settings={}):\n \n     def _print_Pow(self, expr):\n         PREC = precedence(expr)\n-        return '%s^%s' % (self.parenthesize(expr.base, PREC),\n-                          self.parenthesize(expr.exp, PREC))\n+        return '(%s)^%s' % (self.parenthesize(expr.base, PREC),\n+                            self.parenthesize(expr.exp, PREC))\n \n     def _print_Mul(self, expr):\n         PREC = precedence(expr)\n@@ -91,6 +91,13 @@ def _print_list(self, expr):\n     _print_tuple = _print_list\n     _print_Tuple = _print_list\n \n+    def _print_Derivative(self, expr):\n+        return \"D[%s]\" % (self.stringify(expr.args, \", \"))\n+\n+    def _print_Float(self, expr):\n+        res = str(expr)\n+        return res.replace('e', '*^')\n+\n     def _print_Function(self, expr):\n         if expr.func.__name__ in self.known_functions:\n             cond_mfunc = self.known_functions[expr.func.__name__]\n", "instance_id": "sympy__sympy-12171"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\nindex b657a35cf7..8eb62f5ece 100644\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -102,7 +102,7 @@ import tempfile\n import warnings\n \n import numpy\n-from packaging.version import parse as parse_version\n+from packaging.version import parse as parse_version, Version\n \n # cbook must import matplotlib only within function\n # definitions, so it is safe to import from it here.\n@@ -147,11 +147,20 @@ def __getattr__(name):\n             )\n         else:  # Get the version from the _version.py setuptools_scm file.\n             __version__ = _version.version\n+        version_parts = __version__.split('.')\n+        __version_info__ = tuple(map(int, version_parts[:3]))\n         return __version__\n+\n+    if name == \"__version_info__\":\n+        if \"__version__\" not in globals():\n+            __getattr__(\"__version__\")\n+        return __version_info__\n     raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n \n \n-def _check_versions():\n+def _check_versions():    \n+    global __version_info__\n+    __version_info__ = tuple(map(int, __version__.split('.')[:3]))\n \n     # Quickfix to ensure Microsoft Visual C++ redistributable\n     # DLLs are loaded before importing kiwisolver\n@@ -170,6 +179,8 @@ def _check_versions():\n                               f\"you have {module.__version__}\")\n \n \n+# Ensure __version__ is set before checking versions\n+__getattr__(\"__version__\")\n _check_versions()\n \n \n", "instance_id": "matplotlib__matplotlib-18869"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex ebe5da43e2..80cb9197dd 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -18,6 +18,8 @@ from cycler import cycler\n import numpy as np\n \n import matplotlib as mpl\n+import matplotlib.pyplot as pyplot\n+import matplotlib.pyplot as pyplot\n from . import (_api, _docstring, backend_tools, cbook, collections, colors,\n                text as mtext, ticker, transforms)\n from .lines import Line2D\n@@ -600,7 +602,10 @@ class Slider(SliderBase):\n         int\n             Connection id (which can be used to disconnect *func*).\n         \"\"\"\n-        return self._observers.connect('changed', lambda val: func(val))\n+        def callback_wrapper(val):\n+            pyplot.pause(0.001)  # Allow the event loop to process other events\n+            func(val)\n+        return self._observers.connect('changed', callback_wrapper)\n \n \n class RangeSlider(SliderBase):\n@@ -983,7 +988,10 @@ class RangeSlider(SliderBase):\n         int\n             Connection id (which can be used to disconnect *func*).\n         \"\"\"\n-        return self._observers.connect('changed', lambda val: func(val))\n+        def callback_wrapper(val):\n+            pyplot.pause(0.001)  # Allow the event loop to process other events\n+            func(val)\n+        return self._observers.connect('changed', callback_wrapper)\n \n \n def _expand_text_props(props):\n", "instance_id": "matplotlib__matplotlib-25433"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..ff8cb70d97 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -60,7 +60,16 @@ class RST(FixedWidth):\n     def __init__(self):\n         super().__init__(delimiter_pad=None, bookend=False)\n \n-    def write(self, lines):\n-        lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n+    def write(self, table):\n+        header_lines = []\n+        if hasattr(self, 'header_rows') and self.header_rows:\n+            for row in self.header_rows:\n+                header_line = ' '.join(str(getattr(col.info, row, '')) for col in table.columns.values())\n+                header_lines.append(header_line)\n+        \n+        lines = super().write(table)\n+        if header_lines:\n+            lines = [lines[1]] + header_lines + lines[1:] + [lines[1]]\n+        else:\n+            lines = [lines[1]] + lines + [lines[1]]\n         return lines\ndiff --git a/astropy/io/ascii/ui.py b/astropy/io/ascii/ui.py\nindex 993dacf512..f1bbc4d0f6 100644\n--- a/astropy/io/ascii/ui.py\n+++ b/astropy/io/ascii/ui.py\n@@ -899,6 +899,8 @@ def get_writer(Writer=None, fast_writer=True, **kwargs):\n     if \"strip_whitespace\" not in kwargs:\n         kwargs[\"strip_whitespace\"] = True\n     writer = core._get_writer(Writer, fast_writer, **kwargs)\n+    if 'header_rows' in kwargs:\n+        writer.header_rows = kwargs['header_rows']\n \n     # Handle the corner case of wanting to disable writing table comments for the\n     # commented_header format.  This format *requires* a string for `write_comment`\n", "instance_id": "astropy__astropy-14182"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..1142e328eb 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -118,38 +118,37 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n             return\n         # Force to list in case of passed tuple or other incompatible collection\n         variables = list(variables) + [S.One]\n-        if all(variable.is_commutative for variable in variables):\n-            monomials_list_comm = []\n-            for item in combinations_with_replacement(variables, max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_comm.append(Mul(*item))\n-            yield from set(monomials_list_comm)\n-        else:\n-            monomials_list_non_comm = []\n-            for item in product(variables, repeat=max_degree):\n-                powers = dict()\n-                for variable in variables:\n-                    powers[variable] = 0\n-                for variable in item:\n-                    if variable != 1:\n-                        powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n-                    monomials_list_non_comm.append(Mul(*item))\n-            yield from set(monomials_list_non_comm)\n+        if not variables or max_degree == 0:\n+            yield S.One\n+            return\n+        # Force to list in case of passed tuple or other incompatible collection\n+        variables = list(variables)\n+        for total_deg in range(min_degree, max_degree + 1):\n+            if all(variable.is_commutative for variable in variables):\n+                for item in combinations_with_replacement(variables, total_deg):\n+                    if sum(1 for i in item if i != 1) >= min_degree:\n+                        powers = dict()\n+                        for variable in variables:\n+                            powers[variable] = 0\n+                        for variable in item:\n+                            if variable != 1:\n+                                powers[variable] += 1\n+                        yield Mul(*[var**exp for var, exp in powers.items()])\n+            else:\n+                for item in product(variables, repeat=total_deg):\n+                    if sum(1 for i in item if i != 1) >= min_degree:\n+                        powers = dict()\n+                        for variable in variables:\n+                            powers[variable] = 0\n+                        for variable in item:\n+                            if variable != 1:\n+                                powers[variable] += 1\n+                        yield Mul(*[var**exp for var, exp in powers.items()])\n     else:\n         if any(min_degrees[i] > max_degrees[i] for i in range(n)):\n             raise ValueError('min_degrees[i] must be <= max_degrees[i] for all i')\n-        power_lists = []\n-        for var, min_d, max_d in zip(variables, min_degrees, max_degrees):\n-            power_lists.append([var**i for i in range(min_d, max_d + 1)])\n-        for powers in product(*power_lists):\n-            yield Mul(*powers)\n+        for degrees in product(*(range(min_d, max_d + 1) for min_d, max_d in zip(min_degrees, max_degrees))):\n+            yield Mul(*[var**deg for var, deg in zip(variables, degrees)])\n \n def monomial_count(V, N):\n     r\"\"\"\n", "instance_id": "sympy__sympy-21847"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..5fdae67cbe 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -7,7 +7,7 @@\n from sympy.core.compatibility import range\n from sympy.core.sympify import SympifyError, sympify\n from sympy.functions import conjugate, adjoint\n-from sympy.matrices import ShapeError\n+from sympy.matrices import ShapeError, Matrix\n from sympy.simplify import simplify\n \n \n@@ -437,6 +437,24 @@ def _eval_simplify(self, **kwargs):\n         return self\n \n class Identity(MatrixExpr):\n+    def _eval_sum(self, axis=None):\n+        if axis is None:\n+            return self.rows\n+        elif axis == 0:\n+            return Matrix([1] * self.rows)\n+        elif axis == 1:\n+            return Matrix([[1]] * self.cols)\n+        else:\n+            raise ValueError(\"Invalid axis value\")\n+    def _eval_sum(self, axis=None):\n+        if axis is None:\n+            return self.rows\n+        elif axis == 0:\n+            return Matrix([1] * self.rows)\n+        elif axis == 1:\n+            return Matrix([[1]] * self.cols)\n+        else:\n+            raise ValueError(\"Invalid axis value\")\n     \"\"\"The Matrix Identity I - multiplicative identity\n \n     >>> from sympy.matrices import Identity, MatrixSymbol\n", "instance_id": "sympy__sympy-12419"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..de7d8b17c 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,10 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the Pipeline.\"\"\"\n+        return len(self.steps)\n+\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type\n", "instance_id": "scikit-learn__scikit-learn-13439"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/backends/backend_macosx.py b/lib/matplotlib/backends/backend_macosx.py\nindex 700d1d4c58..9789cf6cf4 100644\n--- a/lib/matplotlib/backends/backend_macosx.py\n+++ b/lib/matplotlib/backends/backend_macosx.py\n@@ -39,6 +39,8 @@ class FigureCanvasMac(FigureCanvasAgg, _macosx.FigureCanvas, FigureCanvasBase):\n         super().__init__(figure=figure)\n         self._draw_pending = False\n         self._is_drawing = False\n+        # Ensure DPI is correctly set for macOS backend\n+        self.figure.set_dpi(self.figure.dpi, forward=False)\n \n     def draw(self):\n         \"\"\"Render the figure and update the macosx canvas.\"\"\"\ndiff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex c55864243a..a20a7a0c1a 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2594,6 +2594,35 @@ class Figure(FigureBase):\n         self.set_size_inches(w, h, forward=forward)\n         self._fig_callbacks.process('dpi_changed', self)\n \n+    def __setstate__(self, state):\n+        version = state.pop('__mpl_version__')\n+        restore_to_pylab = state.pop('_restore_to_pylab', False)\n+\n+        if version != mpl.__version__:\n+            _api.warn_external(\n+                f\"This figure was saved with matplotlib version {version} and \"\n+                f\"is unlikely to function correctly.\")\n+\n+        self.__dict__ = state\n+\n+        # re-initialise some of the unstored state information\n+        FigureCanvasBase(self)  # Set self.canvas.\n+\n+        if restore_to_pylab:\n+            # lazy import to avoid circularity\n+            import matplotlib.pyplot as plt\n+            import matplotlib._pylab_helpers as pylab_helpers\n+            allnums = plt.get_fignums()\n+            num = max(allnums) + 1 if allnums else 1\n+            mgr = plt._backend_mod.new_figure_manager_given_figure(num, self)\n+            pylab_helpers.Gcf._set_new_active_manager(mgr)\n+            plt.draw_if_interactive()\n+\n+        # Ensure DPI is correctly set after unpickling\n+        self.set_dpi(self._dpi, forward=False)\n+\n+        self.stale = True\n+\n     dpi = property(_get_dpi, _set_dpi, doc=\"The resolution in dots per inch.\")\n \n     def get_tight_layout(self):\n", "instance_id": "matplotlib__matplotlib-23476"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/ccode.py b/sympy/printing/ccode.py\nindex 30a07a7b59..a48ccb3bb4 100644\n--- a/sympy/printing/ccode.py\n+++ b/sympy/printing/ccode.py\n@@ -43,6 +43,7 @@\n     \"atanh\": \"atanh\",\n     \"floor\": \"floor\",\n     \"ceiling\": \"ceil\",\n+    \"sinc\": \"sinc\",\n }\n \n # These are the core reserved words in the C language. Taken from:\n@@ -248,8 +249,14 @@ def _print_For(self, expr):\n                 '{step}) {{\\n{body}\\n}}').format(target=target, start=start,\n                 stop=stop, step=step, body=body)\n \n-    def _print_sign(self, func):\n-        return '((({0}) > 0) - (({0}) < 0))'.format(self._print(func.args[0]))\n+    def _print_sign(self, expr):\n+        return '((({0}) > 0) - (({0}) < 0))'.format(self._print(expr.args[0]))\n+\n+    def _print_sinc(self, expr):\n+        from sympy import Piecewise, sin, Ne\n+        theta = expr.args[0]\n+        piecewise_expr = Piecewise((sin(theta)/theta, Ne(theta, 0)), (1, True))\n+        return self._print(piecewise_expr)\n \n     def indent_code(self, code):\n         \"\"\"Accepts a string of code or a list of code lines\"\"\"\n", "instance_id": "sympy__sympy-11400"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..a4e8cf1d9f 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -304,9 +304,10 @@ def _separable(transform):\n     if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n         return transform_matrix\n     elif isinstance(transform, CompoundModel):\n-        sepleft = _separable(transform.left)\n-        sepright = _separable(transform.right)\n-        return _operators[transform.op](sepleft, sepright)\n+        left_separable = _separable(transform.left)\n+        right_separable = _separable(transform.right)\n+        combined_separable = _operators[transform.op](left_separable, right_separable)\n+        return combined_separable\n     elif isinstance(transform, Model):\n         return _coord_matrix(transform, 'left', transform.n_outputs)\n \n", "instance_id": "astropy__astropy-12907"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/lib/matplotlib/axes/_base.py b/lib/matplotlib/axes/_base.py\nindex 8e348fea46..3b86e9906d 100644\n--- a/lib/matplotlib/axes/_base.py\n+++ b/lib/matplotlib/axes/_base.py\n@@ -1385,6 +1385,14 @@ class _AxesBase(martist.Artist):\n \n         self.stale = True\n \n+        # groupers to keep track of x and y labels we want to align.\n+        # see self.align_xlabels and self.align_ylabels and\n+        # axis._get_tick_boxes_siblings\n+        self._align_label_groups = {\n+            \"x\": cbook.Grouper(weakref=True),\n+            \"y\": cbook.Grouper(weakref=True)\n+        }\n+\n     def clear(self):\n         \"\"\"Clear the Axes.\"\"\"\n         # Act as an alias, or as the superclass implementation depending on the\ndiff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..1b1ac5ad6a 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -186,7 +186,10 @@ class FigureBase(Artist):\n         # groupers to keep track of x and y labels we want to align.\n         # see self.align_xlabels and self.align_ylabels and\n         # axis._get_tick_boxes_siblings\n-        self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n+        self._align_label_groups = {\n+            \"x\": cbook.Grouper(weakref=True),\n+            \"y\": cbook.Grouper(weakref=True)\n+        }\n \n         self.figure = self\n         self._localaxes = []  # track all axes\n", "instance_id": "matplotlib__matplotlib-25332"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "sympy__sympy-13437"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\nindex df7452ee87..c6a9367a1b 100644\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1958,6 +1958,8 @@ def _print_Pow(self, power):\n                 return self._print_nth_root(b, e)\n             if e.is_Rational and e < 0:\n                 return prettyForm(\"1\")/self._print(Pow(b, -e, evaluate=False))\n+            if e.is_Pow and e.base is S.Exp1 and e.exp.is_negative:\n+                return self._print(b)**prettyForm(\"e\")**self._print(e.exp)\n \n         if b.is_Relational:\n             return prettyForm(*self._print(b).parens()).__pow__(self._print(e))\n", "instance_id": "sympy__sympy-20639"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..5b742af46a 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,6 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n", "instance_id": "django__django-16527"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..2332a6a29f 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,13 +407,20 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n-        if len(constraint_names) != 1:\n-            raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n-                len(constraint_names),\n-                model._meta.db_table,\n-                \", \".join(columns),\n-            ))\n-        self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n+        if len(constraint_names) > 1:\n+            # If there are multiple constraints, prefer the index constraint.\n+            index_constraints = [name for name in constraint_names if name.endswith('_idx')]\n+            if len(index_constraints) == 1:\n+                constraint_name = index_constraints[0]\n+            else:\n+                raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n+                    len(constraint_names),\n+                    model._meta.db_table,\n+                    \", \".join(columns),\n+                ))\n+        else:\n+            constraint_name = constraint_names[0]\n+        self.execute(self._delete_constraint_sql(sql, model, constraint_name))\n \n     def alter_db_table(self, model, old_db_table, new_db_table):\n         \"\"\"Rename the table a model points to.\"\"\"\n", "instance_id": "django__django-12708"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex 503f7f56fd..002c92aee2 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -58,7 +58,7 @@ class BaseDatabaseCreation:\n         settings.DATABASES[self.connection.alias][\"NAME\"] = test_database_name\n         self.connection.settings_dict[\"NAME\"] = test_database_name\n \n-        if self.connection.settings_dict['TEST']['MIGRATE']:\n+        if self.connection.settings_dict['TEST'].get('MIGRATE', True):\n             # We report migrate messages at one level lower than that\n             # requested. This ensures we don't get flooded with messages during\n             # testing (unless you really ask to be flooded).\n", "instance_id": "django__django-13448"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\nindex 0e66649695..e206f0de53 100644\n--- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n+++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py\n@@ -24,10 +24,17 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False):\n         proxy_content_type = ContentType.objects.get_for_model(Model, for_concrete_model=False)\n         old_content_type = proxy_content_type if reverse else concrete_content_type\n         new_content_type = concrete_content_type if reverse else proxy_content_type\n-        Permission.objects.filter(\n+        existing_permissions = Permission.objects.filter(\n+            permissions_query,\n+            content_type=new_content_type,\n+        ).values_list('codename', flat=True)\n+\n+        permissions_to_update = Permission.objects.filter(\n             permissions_query,\n             content_type=old_content_type,\n-        ).update(content_type=new_content_type)\n+        ).exclude(codename__in=existing_permissions)\n+\n+        permissions_to_update.update(content_type=new_content_type)\n \n \n def revert_proxy_model_permissions(apps, schema_editor):\n", "instance_id": "django__django-11283"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/_pytest/fixtures.py b/src/_pytest/fixtures.py\nindex 902904457..f88a797b8 100644\n--- a/src/_pytest/fixtures.py\n+++ b/src/_pytest/fixtures.py\n@@ -835,6 +835,7 @@ class FixtureDef(object):\n         )\n         self.params = params\n         self.argnames = getfuncargnames(func, is_method=unittest)\n+        self.scope = scope\n         self.unittest = unittest\n         self.ids = ids\n         self._finalizers = []\n", "instance_id": "pytest-dev__pytest-5221"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 901918674a..dd5da02ef7 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1438,7 +1438,7 @@ def _print_MatrixBase(self, expr):\n \n     def _print_MatrixElement(self, expr):\n         return self.parenthesize(expr.parent, PRECEDENCE[\"Atom\"], strict=True) \\\n-            + '_{%s, %s}' % (expr.i, expr.j)\n+            + '_{%s, %s}' % (self._print(expr.i).replace('_', '\\\\_'), self._print(expr.j).replace('_', '\\\\_'))\n \n     def _print_MatrixSlice(self, expr):\n         def latexslice(x):\n", "instance_id": "sympy__sympy-15609"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..139c42587 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -51,6 +51,12 @@ class BaseCrossValidator(metaclass=ABCMeta):\n     Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n     \"\"\"\n \n+    def __repr__(self):\n+        return _build_repr(self)\n+\n+    def __repr__(self):\n+        return _build_repr(self)\n+\n     def split(self, X, y=None, groups=None):\n         \"\"\"Generate indices to split data into training and test set.\n \n", "instance_id": "scikit-learn__scikit-learn-14983"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\nindex c50fc90171..5cf1f5b3c2 100644\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -5,7 +5,7 @@ from io import StringIO\n from django.apps import apps\n from django.conf import settings\n from django.core import serializers\n-from django.db import router\n+from django.db import router, transaction\n \n # The prefix to put on the default database name when creating\n # the test database.\n@@ -126,8 +126,9 @@ class BaseDatabaseCreation:\n         the serialize_db_to_string() method.\n         \"\"\"\n         data = StringIO(data)\n-        for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n-            obj.save()\n+        with transaction.atomic(using=self.connection.alias):\n+            for obj in serializers.deserialize(\"json\", data, using=self.connection.alias):\n+                obj.save()\n \n     def _get_database_display_str(self, verbosity, database_name):\n         \"\"\"\n", "instance_id": "django__django-12453"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex febaadbb5b..56fff3eae7 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1180,6 +1180,12 @@ class ManyToManyField(RelatedField):\n         if symmetrical is None:\n             symmetrical = (to == RECURSIVE_RELATIONSHIP_CONSTANT)\n \n+        if symmetrical and related_name is not None:\n+            raise ValueError(\n+                \"Cannot set related_name on symmetrical ManyToManyField. \"\n+                \"Either set symmetrical to False or remove the related_name argument.\"\n+            )\n+\n         if through is not None and db_table is not None:\n             raise ValueError(\n                 'Cannot specify a db_table if an intermediary model is used.'\n", "instance_id": "django__django-14730"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-11910"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0a5e5ff673..b2e3921bd3 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -324,6 +324,9 @@ class ModelBase(type):\n         if _has_contribute_to_class(value):\n             value.contribute_to_class(cls, name)\n         else:\n+            # Preserve existing method definitions\n+            if hasattr(cls, name) and callable(getattr(cls, name)):\n+                return\n             setattr(cls, name, value)\n \n     def _prepare(cls):\n", "instance_id": "django__django-11999"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\nindex 29bd46798..181585833 100644\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,7 +175,7 @@ class TextReporter(BaseReporter):\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{([^{}]+?)(:.*)?\\}\", template)\n         for argument in arguments:\n             if argument[0] not in MESSAGE_FIELDS:\n                 warnings.warn(\n", "instance_id": "pylint-dev__pylint-7993"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 5bdccdbb1..de1d37ec8 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -52,6 +52,16 @@ from sphinx.util.osutil import abspath, ensuredir, relpath\n from sphinx.util.tags import Tags\n from sphinx.util.typing import RoleFunction, TitleGetter\n \n+def assign_table_numbers(env):\n+    \"\"\"Assign numbers to tables in the environment.\"\"\"\n+    domain = env.get_domain('std')\n+    for docname, doctree in env.get_doctree_iterator():\n+        for node in doctree.traverse(nodes.table):\n+            if 'ids' in node and node['ids']:\n+                domain.note_citation(node['ids'][0], docname)\n+            else:\n+                logger.warning(__('no number is assigned for table: %s'), node.astext(), location=node)\n+\n if False:\n     # For type annotation\n     from typing import Type  # for python3.5.1\n@@ -275,6 +285,7 @@ class Sphinx:\n         # set up the build environment\n         self._init_env(freshenv)\n         # set up the builder\n+        assign_table_numbers(self.env)\n         self._init_builder()\n \n     def _init_i18n(self) -> None:\ndiff --git a/sphinx/builders/latex/__init__.py b/sphinx/builders/latex/__init__.py\nindex 77825f0ea..d34ba869e 100644\n--- a/sphinx/builders/latex/__init__.py\n+++ b/sphinx/builders/latex/__init__.py\n@@ -36,6 +36,7 @@ from sphinx.util.i18n import format_date\n from sphinx.util.nodes import inline_all_toctrees\n from sphinx.util.osutil import SEP, make_filename_from_project\n from sphinx.util.template import LaTeXRenderer\n+from sphinx.application import assign_table_numbers\n from sphinx.writers.latex import LaTeXTranslator, LaTeXWriter\n \n # load docutils.nodes after loading sphinx.builders.latex.nodes\n@@ -265,6 +266,7 @@ class LaTeXBuilder(Builder):\n \n         self.init_document_data()\n         self.write_stylesheet()\n+        assign_table_numbers(self.env)\n \n         for entry in self.document_data:\n             docname, targetname, title, author, themename = entry[:5]\ndiff --git a/sphinx/builders/singlehtml.py b/sphinx/builders/singlehtml.py\nindex d8ab978ed..f57e90f4e 100644\n--- a/sphinx/builders/singlehtml.py\n+++ b/sphinx/builders/singlehtml.py\n@@ -22,6 +22,7 @@ from sphinx.locale import __\n from sphinx.util import logging, progress_message\n from sphinx.util.console import darkgreen  # type: ignore\n from sphinx.util.nodes import inline_all_toctrees\n+from sphinx.application import assign_table_numbers\n \n logger = logging.getLogger(__name__)\n \n@@ -81,6 +82,7 @@ class SingleFileHTMLBuilder(StandaloneHTMLBuilder):\n         tree['docname'] = master\n         self.env.resolve_references(tree, master, self)\n         self.fix_refuris(tree)\n+        assign_table_numbers(self.env)\n         return tree\n \n     def assemble_toc_secnumbers(self) -> Dict[str, Dict[str, Tuple[int, ...]]]:\ndiff --git a/sphinx/transforms/__init__.py b/sphinx/transforms/__init__.py\nindex f854f1772..95a67d461 100644\n--- a/sphinx/transforms/__init__.py\n+++ b/sphinx/transforms/__init__.py\n@@ -164,6 +164,13 @@ class HandleCodeBlocks(SphinxTransform):\n \n \n class AutoNumbering(SphinxTransform):\n+    def apply(self, **kwargs: Any) -> None:\n+        domain = self.env.get_domain('std')\n+        for node in self.document.traverse(nodes.table):\n+            if 'ids' in node and node['ids']:\n+                domain.note_citation(node['ids'][0], self.env.docname)\n+            else:\n+                logger.warning(__('no number is assigned for table: %s'), node.astext(), location=node)\n     \"\"\"\n     Register IDs of tables, figures and literal_blocks to assign numbers.\n     \"\"\"\n", "instance_id": "sphinx-doc__sphinx-8474"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\nindex b9809fd4e9..6f1e8ae56a 100644\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -46,6 +46,9 @@ def solve_poly_system(seq, *gens, **args):\n     [(0, 0), (2, -sqrt(2)), (2, sqrt(2))]\n \n     \"\"\"\n+    if len(seq) != len(gens):\n+        raise NotImplementedError(\"only zero-dimensional systems supported (finite number of solutions)\")\n+\n     try:\n         polys, opt = parallel_poly_from_expr(seq, *gens, **args)\n     except PolificationFailed as exc:\n@@ -240,7 +243,7 @@ def _solve_reduced_system(system, gens, entry=False):\n \n         univariate = list(filter(_is_univariate, basis))\n \n-        if len(univariate) == 1:\n+        if len(univariate) == 1 and len(gens) == 1:\n             f = univariate.pop()\n         else:\n             raise NotImplementedError(filldedent('''\n", "instance_id": "sympy__sympy-22005"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..b40ad806ed 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -168,7 +168,7 @@ class Sitemap:\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n                 return None\n         else:\n             return self.lastmod\n", "instance_id": "django__django-16255"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/core/checks/templates.py b/django/core/checks/templates.py\nindex 5214276987..ac4bc2e03f 100644\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -50,23 +50,23 @@ def check_string_if_invalid_is_string(app_configs, **kwargs):\n @register(Tags.templates)\n def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n     errors = []\n-    libraries = defaultdict(list)\n+    libraries = defaultdict(set)\n \n     for conf in settings.TEMPLATES:\n         custom_libraries = conf.get(\"OPTIONS\", {}).get(\"libraries\", {})\n         for module_name, module_path in custom_libraries.items():\n-            libraries[module_name].append(module_path)\n+            libraries[module_name].add(module_path)\n \n     for module_name, module_path in get_template_tag_modules():\n-        libraries[module_name].append(module_path)\n+        libraries[module_name].add(module_path)\n \n     for library_name, items in libraries.items():\n-        if len(items) > 1:\n+        if len(list(items)) > 1:\n             errors.append(\n                 Error(\n                     E003.msg.format(\n                         repr(library_name),\n-                        \", \".join(repr(item) for item in items),\n+                        \", \".join(sorted(repr(item) for item in items)),\n                     ),\n                     id=E003.id,\n                 )\n", "instance_id": "django__django-15790"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex 841cbbfe..56a5152a 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -29,7 +29,7 @@ from .packages.urllib3.exceptions import SSLError as _SSLError\n from .packages.urllib3.exceptions import ResponseError\n from .cookies import extract_cookies_to_jar\n from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n-                         ProxyError, RetryError)\n+                         ProxyError, RetryError, DecodeError, TimeoutError)\n from .auth import _basic_auth_str\n \n DEFAULT_POOLBLOCK = False\n@@ -424,7 +424,11 @@ class HTTPAdapter(BaseAdapter):\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n-        except (_SSLError, _HTTPError) as e:\n+        except (BaseDecodeError, BaseTimeoutError, _SSLError, _HTTPError) as e:\n+            if isinstance(e, BaseDecodeError):\n+                raise DecodeError(e, request=request)\n+            elif isinstance(e, BaseTimeoutError):\n+                raise TimeoutError(e, request=request)\n             if isinstance(e, _SSLError):\n                 raise SSLError(e, request=request)\n             elif isinstance(e, ReadTimeoutError):\ndiff --git a/requests/exceptions.py b/requests/exceptions.py\nindex 89135a80..08a678d1 100644\n--- a/requests/exceptions.py\n+++ b/requests/exceptions.py\n@@ -7,7 +7,7 @@ requests.exceptions\n This module contains the set of Requests' exceptions.\n \n \"\"\"\n-from .packages.urllib3.exceptions import HTTPError as BaseHTTPError\n+from .packages.urllib3.exceptions import HTTPError as BaseHTTPError, DecodeError as BaseDecodeError, TimeoutError as BaseTimeoutError\n \n \n class RequestException(IOError):\n@@ -97,3 +97,11 @@ class StreamConsumedError(RequestException, TypeError):\n \n class RetryError(RequestException):\n     \"\"\"Custom retries logic failed\"\"\"\n+\n+\n+class DecodeError(RequestException, BaseDecodeError):\n+    \"\"\"Failed to decode response content\"\"\"\n+\n+\n+class TimeoutError(RequestException, BaseTimeoutError):\n+    \"\"\"The request timed out.\"\"\"\n", "instance_id": "psf__requests-2674"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/urls/converters.py b/django/urls/converters.py\nindex bb8478e32f..f4b41e0ba9 100644\n--- a/django/urls/converters.py\n+++ b/django/urls/converters.py\n@@ -1,5 +1,7 @@\n import uuid\n from functools import lru_cache\n+from django.http import Http404\n+from django.http import Http404\n \n \n class IntConverter:\n@@ -26,7 +28,10 @@ class UUIDConverter:\n     regex = '[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}'\n \n     def to_python(self, value):\n-        return uuid.UUID(value)\n+        try:\n+            return uuid.UUID(value)\n+        except ValueError:\n+            raise Http404(\"Invalid UUID format\")\n \n     def to_url(self, value):\n         return str(value)\n", "instance_id": "django__django-11620"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 495e90570..8af58bd90 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -206,6 +206,10 @@ class Sphinx:\n             self.confdir = abspath(confdir)\n             self.config = Config.read(self.confdir, confoverrides or {}, self.tags)\n \n+        # Apply rst_prolog if set\n+        if self.config.rst_prolog:\n+            self.config.rst_prolog = self.config.rst_prolog + '\\n'\n+\n         # initialize some limited config variables before initialize i18n and loading\n         # extensions\n         self.config.pre_init_values()\ndiff --git a/sphinx/io.py b/sphinx/io.py\nindex efd2b4ea9..b90511bd2 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -108,6 +108,10 @@ class SphinxStandaloneReader(SphinxBaseReader):\n         \"\"\"Read content from source and do post-process.\"\"\"\n         content = self.source.read()\n \n+        # Apply rst_prolog if set\n+        if env.config.rst_prolog:\n+            content = env.config.rst_prolog + content\n+\n         # emit \"source-read\" event\n         arg = [content]\n         env.events.emit('source-read', env.docname, arg)\ndiff --git a/sphinx/util/docutils.py b/sphinx/util/docutils.py\nindex cbf26fcd5..1fbd858c3 100644\n--- a/sphinx/util/docutils.py\n+++ b/sphinx/util/docutils.py\n@@ -622,4 +622,8 @@ def new_document(source_path: str, settings: Any = None) -> nodes.document:\n     from sphinx import addnodes\n     document = addnodes.document(settings, reporter, source=source_path)\n     document.note_source(source_path, -1)\n+    # Apply rst_prolog if set\n+    if settings and hasattr(settings, 'env') and settings.env.config.rst_prolog:\n+        document = docutils.utils.new_document(source_path, settings)\n+        document += docutils.parsers.rst.Parser().parse(settings.env.config.rst_prolog, document)\n     return document\n", "instance_id": "sphinx-doc__sphinx-11445"}
{"model_name_or_path": "180724-194532", "model_patch": "", "instance_id": "django__django-14915"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 78c4f47b5b..b3be766d0d 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -283,7 +283,14 @@ class Query(BaseExpression):\n         processing. Normally, this is self.model._meta, but it can be changed\n         by subclasses.\n         \"\"\"\n-        return self.model._meta\n+        meta = self.model._meta\n+        if meta.ordering:\n+            return meta\n+        # Check if the model has a parent and inherit its ordering\n+        for parent in meta.get_parent_list():\n+            if parent._meta.ordering:\n+                return parent._meta\n+        return meta\n \n     def clone(self):\n         \"\"\"\n@@ -1907,6 +1914,21 @@ class Query(BaseExpression):\n             self.order_by += ordering\n         else:\n             self.default_ordering = False\n+        # Ensure inherited ordering is respected\n+        if not self.order_by and self.default_ordering:\n+            self.add_ordering(*self.get_meta().ordering)\n+        # Ensure inherited ordering is respected\n+        if not self.order_by and self.default_ordering:\n+            self.add_ordering(*self.get_meta().ordering)\n+        # Ensure inherited ordering is respected\n+        if not self.order_by and self.default_ordering:\n+            self.add_ordering(*self.get_meta().ordering)\n+        # Ensure inherited ordering is respected\n+        if not self.order_by and self.query.default_ordering:\n+            self.query.add_ordering(*self.query.get_meta().ordering)\n+        # Ensure inherited ordering is respected\n+        if not self.order_by and self.query.default_ordering:\n+            self.query.add_ordering(*self.query.get_meta().ordering)\n \n     def clear_ordering(self, force_empty):\n         \"\"\"\n", "instance_id": "django__django-12470"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..ba8c3463a0 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,11 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n", "instance_id": "django__django-14855"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 5ac2407ea3..388e3b9e94 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1837,13 +1837,16 @@ class QuerySet(AltersData):\n         inserted_rows = []\n         bulk_return = connection.features.can_return_rows_from_bulk_insert\n         for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n-            if bulk_return and on_conflict is None:\n+            if bulk_return and (on_conflict is None or on_conflict == OnConflict.UPDATE):\n                 inserted_rows.extend(\n                     self._insert(\n                         item,\n                         fields=fields,\n                         using=self.db,\n                         returning_fields=self.model._meta.db_returning_fields,\n+                        on_conflict=on_conflict,\n+                        update_fields=update_fields,\n+                        unique_fields=unique_fields,\n                     )\n                 )\n             else:\n", "instance_id": "django__django-17051"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 3adbc6979a..71d7468633 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -144,12 +144,13 @@ class BaseFormSet(RenderableFormMixin):\n     @cached_property\n     def management_form(self):\n         \"\"\"Return the ManagementForm instance for this FormSet.\"\"\"\n+        renderer = self.renderer.get_template('django/forms/minimal_management_form.html')\n         if self.is_bound:\n             form = ManagementForm(\n                 self.data,\n                 auto_id=self.auto_id,\n                 prefix=self.prefix,\n-                renderer=self.renderer,\n+                renderer=renderer,\n             )\n             form.full_clean()\n         else:\n@@ -162,7 +163,7 @@ class BaseFormSet(RenderableFormMixin):\n                     MIN_NUM_FORM_COUNT: self.min_num,\n                     MAX_NUM_FORM_COUNT: self.max_num,\n                 },\n-                renderer=self.renderer,\n+                renderer=renderer,\n             )\n         return form\n \ndiff --git a/django/forms/templates/django/forms/minimal_management_form.html b/django/forms/templates/django/forms/minimal_management_form.html\nnew file mode 100644\nindex 0000000000..0d93e40ef4\n--- /dev/null\n+++ b/django/forms/templates/django/forms/minimal_management_form.html\n@@ -0,0 +1,12 @@\n+{% for field in form.hidden_fields %}\n+    {{ field }}\n+{% endfor %}\n+{% for field in form.hidden_fields %}\n+    {{ field }}\n+{% endfor %}\n+{% for field in form.hidden_fields %}\n+    {{ field }}\n+{% endfor %}\n+{% for field in form.hidden_fields %}\n+    {{ field }}\n+{% endfor %}\n", "instance_id": "django__django-15902"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..ee35b113c4 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,8 +26,7 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n+                self.serialize_result(obj, to_field_name) for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n@@ -100,3 +99,6 @@ class AutocompleteJsonView(BaseListView):\n     def has_perm(self, request, obj=None):\n         \"\"\"Check if user has permission to access the related model.\"\"\"\n         return self.model_admin.has_view_permission(request, obj=obj)\n+    def serialize_result(self, obj, to_field_name):\n+        \"\"\"Convert a single result to a dictionary.\"\"\"\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n", "instance_id": "django__django-14752"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex 5fb84d86..f5310e3a 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -188,6 +188,8 @@ class Blueprint(Scaffold):\n             template_folder=template_folder,\n             root_path=root_path,\n         )\n+        if '.' in name:\n+            raise ValueError(\"Blueprint name should not contain dots\")\n         self.name = name\n         self.url_prefix = url_prefix\n         self.subdomain = subdomain\n", "instance_id": "pallets__flask-4045"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex 7f181789fd..d772e6b3fa 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3093,12 +3093,12 @@ def integrate(self, *args, **kwargs):\n         from sympy.integrals import integrate\n         return integrate(self, *args, **kwargs)\n \n-    def simplify(self, ratio=1.7, measure=None):\n+    def simplify(self, ratio=1.7, measure=None, rational=True):\n         \"\"\"See the simplify function in sympy.simplify\"\"\"\n         from sympy.simplify import simplify\n         from sympy.core.function import count_ops\n         measure = measure or count_ops\n-        return simplify(self, ratio, measure)\n+        return simplify(self, ratio, measure, rational=rational)\n \n     def nsimplify(self, constants=[], tolerance=None, full=False):\n         \"\"\"See the nsimplify function in sympy.simplify\"\"\"\ndiff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex f1609aa908..37908ee0f6 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -580,7 +580,7 @@ def shorter(*choices):\n     if expr.has(Product):\n         expr = product_simplify(expr)\n \n-    short = shorter(powsimp(expr, combine='exp', deep=True), powsimp(expr), expr)\n+    short = shorter(powsimp(expr, combine='exp', deep=True), powsimp(expr), expr, expr.simplify())\n     short = shorter(short, factor_terms(short), expand_power_exp(expand_mul(short)))\n     if short.has(TrigonometricFunction, HyperbolicFunction, ExpBase):\n         short = exptrigsimp(short, simplify=False)\n", "instance_id": "sympy__sympy-13146"}
{"model_name_or_path": "180724-194532", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..7f8e166318 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -966,23 +966,38 @@ class RenameIndex(IndexOperation):\n         schema_editor.rename_index(model, old_index, new_index)\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n-        if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n+        model = to_state.apps.get_model(app_label, self.model_name)\n+        if not self.allow_migrate_model(schema_editor.connection.alias, model):\n             return\n \n-        self.new_name_lower, self.old_name_lower = (\n-            self.old_name_lower,\n-            self.new_name_lower,\n-        )\n-        self.new_name, self.old_name = self.old_name, self.new_name\n-\n-        self.database_forwards(app_label, schema_editor, from_state, to_state)\n+        if self.old_fields:\n+            from_model = from_state.apps.get_model(app_label, self.model_name)\n+            columns = [\n+                from_model._meta.get_field(field).column for field in self.old_fields\n+            ]\n+            matching_index_name = schema_editor._constraint_names(\n+                from_model, column_names=columns, index=True\n+            )\n+            if len(matching_index_name) != 1:\n+                raise ValueError(\n+                    \"Found wrong number (%s) of indexes for %s(%s).\"\n+                    % (\n+                        len(matching_index_name),\n+                        from_model._meta.db_table,\n+                        \", \".join(columns),\n+                    )\n+                )\n+            old_index = models.Index(\n+                fields=self.old_fields,\n+                name=matching_index_name[0],\n+            )\n+        else:\n+            from_model_state = from_state.models[app_label, self.model_name_lower]\n+            old_index = from_model_state.get_index_by_name(self.old_name)\n \n-        self.new_name_lower, self.old_name_lower = (\n-            self.old_name_lower,\n-            self.new_name_lower,\n-        )\n-        self.new_name, self.old_name = self.old_name, self.new_name\n+        to_model_state = to_state.models[app_label, self.model_name_lower]\n+        new_index = to_model_state.get_index_by_name(self.new_name)\n+        schema_editor.rename_index(model, new_index, old_index)\n \n     def describe(self):\n         if self.old_name:\n", "instance_id": "django__django-15695"}
