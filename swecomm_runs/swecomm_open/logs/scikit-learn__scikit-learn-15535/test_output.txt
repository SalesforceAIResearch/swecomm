+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /opt/miniconda3/bin/conda
++++ dirname /opt/miniconda3/bin
+++ PATH=/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_1='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_1=/opt/miniconda3
++ CONDA_PREFIX_1=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /testbed
+ git config --global --add safe.directory /testbed
+ cd /testbed
+ git status
On branch main
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   sklearn/metrics/cluster/_supervised.py

no changes added to commit (use "git add" and/or "git commit -a")
+ git show
commit 70b0ddea992c01df1a41588fa9e2d130fb6b13f8
Author: Alec Peters <alec.peters@gmail.com>
Date:   Mon Nov 4 16:34:59 2019 -0800

    FEA Allow nan/inf in feature selection (#11635)

diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst
index 898da8c81..279a8eab0 100644
--- a/doc/whats_new/v0.22.rst
+++ b/doc/whats_new/v0.22.rst
@@ -110,7 +110,6 @@ Changelog
     :pr:`123456` by :user:`Joe Bloggs <joeongithub>`.
     where 123456 is the *pull request* number, not the issue number.
 
-
 :mod:`sklearn.base`
 ...................
 
@@ -368,6 +367,15 @@ Changelog
 :mod:`sklearn.feature_selection`
 ................................
 
+- |Enhancement| Updated the following :mod:`feature_selection` estimators to allow
+  NaN/Inf values in ``transform`` and ``fit``:
+  :class:`feature_selection.RFE`, :class:`feature_selection.RFECV`,
+  :class:`feature_selection.SelectFromModel`,
+  and :class:`feature_selection.VarianceThreshold`. Note that if the underlying
+  estimator of the feature selector does not allow NaN/Inf then it will still
+  error, but the feature selectors themselves no longer enforce this
+  restriction unnecessarily. :issue:`11635` by :user:`Alec Peters <adpeters>`.
+
 - |Fix| Fixed a bug where :class:`feature_selection.VarianceThreshold` with
   `threshold=0` did not remove constant features due to numerical instability,
   by using range rather than variance in this case.
diff --git a/sklearn/feature_selection/_base.py b/sklearn/feature_selection/_base.py
index bcd983418..20a54c41a 100644
--- a/sklearn/feature_selection/_base.py
+++ b/sklearn/feature_selection/_base.py
@@ -71,7 +71,9 @@ class SelectorMixin(TransformerMixin, metaclass=ABCMeta):
         X_r : array of shape [n_samples, n_selected_features]
             The input samples with only the selected features.
         """
-        X = check_array(X, dtype=None, accept_sparse='csr')
+        tags = self._get_tags()
+        X = check_array(X, dtype=None, accept_sparse='csr',
+                        force_all_finite=not tags.get('allow_nan', True))
         mask = self.get_support()
         if not mask.any():
             warn("No features were selected: either the data is"
diff --git a/sklearn/feature_selection/_from_model.py b/sklearn/feature_selection/_from_model.py
index 3e324fbec..674127f06 100644
--- a/sklearn/feature_selection/_from_model.py
+++ b/sklearn/feature_selection/_from_model.py
@@ -131,6 +131,10 @@ class SelectFromModel(MetaEstimatorMixin, SelectorMixin, BaseEstimator):
     threshold_ : float
         The threshold value used for feature selection.
 
+    Notes
+    -----
+    Allows NaN/Inf in the input if the underlying estimator does as well.
+
     Examples
     --------
     >>> from sklearn.feature_selection import SelectFromModel
@@ -249,3 +253,7 @@ class SelectFromModel(MetaEstimatorMixin, SelectorMixin, BaseEstimator):
             self.estimator_ = clone(self.estimator)
         self.estimator_.partial_fit(X, y, **fit_params)
         return self
+
+    def _more_tags(self):
+        estimator_tags = self.estimator._get_tags()
+        return {'allow_nan': estimator_tags.get('allow_nan', True)}
diff --git a/sklearn/feature_selection/_rfe.py b/sklearn/feature_selection/_rfe.py
index 86362f27e..12e99175c 100644
--- a/sklearn/feature_selection/_rfe.py
+++ b/sklearn/feature_selection/_rfe.py
@@ -103,6 +103,10 @@ class RFE(SelectorMixin, MetaEstimatorMixin, BaseEstimator):
     >>> selector.ranking_
     array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])
 
+    Notes
+    -----
+    Allows NaN/Inf in the input if the underlying estimator does as well.
+
     See also
     --------
     RFECV : Recursive feature elimination with built-in cross-validated
@@ -150,7 +154,9 @@ class RFE(SelectorMixin, MetaEstimatorMixin, BaseEstimator):
         # and is used when implementing RFECV
         # self.scores_ will not be calculated when calling _fit through fit
 
-        X, y = check_X_y(X, y, "csc", ensure_min_features=2)
+        tags = self._get_tags()
+        X, y = check_X_y(X, y, "csc", ensure_min_features=2,
+                         force_all_finite=not tags.get('allow_nan', True))
         # Initialization
         n_features = X.shape[1]
         if self.n_features_to_select is None:
@@ -326,7 +332,9 @@ class RFE(SelectorMixin, MetaEstimatorMixin, BaseEstimator):
         return self.estimator_.predict_log_proba(self.transform(X))
 
     def _more_tags(self):
-        return {'poor_score': True}
+        estimator_tags = self.estimator._get_tags()
+        return {'poor_score': True,
+                'allow_nan': estimator_tags.get('allow_nan', True)}
 
 
 class RFECV(RFE):
@@ -421,6 +429,8 @@ class RFECV(RFE):
     ``ceil((n_features - min_features_to_select) / step) + 1``,
     where step is the number of features removed at each iteration.
 
+    Allows NaN/Inf in the input if the underlying estimator does as well.
+
     Examples
     --------
     The following example shows how to retrieve the a-priori not known 5
@@ -479,7 +489,8 @@ class RFECV(RFE):
             train/test set. Only used in conjunction with a "Group" :term:`cv`
             instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).
         """
-        X, y = check_X_y(X, y, "csr", ensure_min_features=2)
+        X, y = check_X_y(X, y, "csr", ensure_min_features=2,
+                         force_all_finite=False)
 
         # Initialization
         cv = check_cv(self.cv, y, is_classifier(self.estimator))
diff --git a/sklearn/feature_selection/_variance_threshold.py b/sklearn/feature_selection/_variance_threshold.py
index 15576fe31..4f9d720b7 100644
--- a/sklearn/feature_selection/_variance_threshold.py
+++ b/sklearn/feature_selection/_variance_threshold.py
@@ -29,6 +29,10 @@ class VarianceThreshold(SelectorMixin, BaseEstimator):
     variances_ : array, shape (n_features,)
         Variances of individual features.
 
+    Notes
+    -----
+    Allows NaN in the input.
+
     Examples
     --------
     The following dataset has integer features, two of which are the same
@@ -61,7 +65,8 @@ class VarianceThreshold(SelectorMixin, BaseEstimator):
         -------
         self
         """
-        X = check_array(X, ('csr', 'csc'), dtype=np.float64)
+        X = check_array(X, ('csr', 'csc'), dtype=np.float64,
+                        force_all_finite='allow-nan')
 
         if hasattr(X, "toarray"):   # sparse matrix
             _, self.variances_ = mean_variance_axis(X, axis=0)
@@ -69,16 +74,18 @@ class VarianceThreshold(SelectorMixin, BaseEstimator):
                 mins, maxes = min_max_axis(X, axis=0)
                 peak_to_peaks = maxes - mins
         else:
-            self.variances_ = np.var(X, axis=0)
+            self.variances_ = np.nanvar(X, axis=0)
             if self.threshold == 0:
                 peak_to_peaks = np.ptp(X, axis=0)
 
         if self.threshold == 0:
             # Use peak-to-peak to avoid numeric precision issues
             # for constant features
-            self.variances_ = np.minimum(self.variances_, peak_to_peaks)
+            compare_arr = np.array([self.variances_, peak_to_peaks])
+            self.variances_ = np.nanmin(compare_arr, axis=0)
 
-        if np.all(self.variances_ <= self.threshold):
+        if np.all(~np.isfinite(self.variances_) |
+                  (self.variances_ <= self.threshold)):
             msg = "No feature in X meets the variance threshold {0:.5f}"
             if X.shape[0] == 1:
                 msg += " (X contains only one sample)"
@@ -90,3 +97,6 @@ class VarianceThreshold(SelectorMixin, BaseEstimator):
         check_is_fitted(self)
 
         return self.variances_ > self.threshold
+
+    def _more_tags(self):
+        return {'allow_nan': True}
diff --git a/sklearn/feature_selection/tests/test_from_model.py b/sklearn/feature_selection/tests/test_from_model.py
index a1f6a9d97..57bd88a30 100644
--- a/sklearn/feature_selection/tests/test_from_model.py
+++ b/sklearn/feature_selection/tests/test_from_model.py
@@ -10,10 +10,28 @@ from sklearn import datasets
 from sklearn.linear_model import LogisticRegression, SGDClassifier, Lasso
 from sklearn.svm import LinearSVC
 from sklearn.feature_selection import SelectFromModel
-from sklearn.ensemble import RandomForestClassifier
+from sklearn.experimental import enable_hist_gradient_boosting  # noqa
+from sklearn.ensemble import (RandomForestClassifier,
+                              HistGradientBoostingClassifier)
 from sklearn.linear_model import PassiveAggressiveClassifier
 from sklearn.base import BaseEstimator
 
+
+class NaNTag(BaseEstimator):
+    def _more_tags(self):
+        return {'allow_nan': True}
+
+
+class NoNaNTag(BaseEstimator):
+    def _more_tags(self):
+        return {'allow_nan': False}
+
+
+class NaNTagRandomForest(RandomForestClassifier):
+    def _more_tags(self):
+        return {'allow_nan': True}
+
+
 iris = datasets.load_iris()
 data, y = iris.data, iris.target
 rng = np.random.RandomState(0)
@@ -320,3 +338,40 @@ def test_threshold_without_refitting():
     # Set a higher threshold to filter out more features.
     model.threshold = "1.0 * mean"
     assert X_transform.shape[1] > model.transform(data).shape[1]
+
+
+def test_fit_accepts_nan_inf():
+    # Test that fit doesn't check for np.inf and np.nan values.
+    clf = HistGradientBoostingClassifier(random_state=0)
+
+    model = SelectFromModel(estimator=clf)
+
+    nan_data = data.copy()
+    nan_data[0] = np.NaN
+    nan_data[1] = np.Inf
+
+    model.fit(data, y)
+
+
+def test_transform_accepts_nan_inf():
+    # Test that transform doesn't check for np.inf and np.nan values.
+    clf = NaNTagRandomForest(n_estimators=100, random_state=0)
+    nan_data = data.copy()
+
+    model = SelectFromModel(estimator=clf)
+    model.fit(nan_data, y)
+
+    nan_data[0] = np.NaN
+    nan_data[1] = np.Inf
+
+    model.transform(nan_data)
+
+
+def test_allow_nan_tag_comes_from_estimator():
+    allow_nan_est = NaNTag()
+    model = SelectFromModel(estimator=allow_nan_est)
+    assert model._get_tags()['allow_nan'] is True
+
+    no_nan_est = NoNaNTag()
+    model = SelectFromModel(estimator=no_nan_est)
+    assert model._get_tags()['allow_nan'] is False
diff --git a/sklearn/feature_selection/tests/test_rfe.py b/sklearn/feature_selection/tests/test_rfe.py
index 724c749ee..ccd3c0a1b 100644
--- a/sklearn/feature_selection/tests/test_rfe.py
+++ b/sklearn/feature_selection/tests/test_rfe.py
@@ -2,6 +2,7 @@
 Testing Recursive feature elimination
 """
 
+import pytest
 import numpy as np
 from numpy.testing import assert_array_almost_equal, assert_array_equal
 from scipy import sparse
@@ -54,6 +55,9 @@ class MockClassifier:
     def set_params(self, **params):
         return self
 
+    def _get_tags(self):
+        return {}
+
 
 def test_rfe_features_importance():
     generator = check_random_state(0)
@@ -369,3 +373,25 @@ def test_rfe_cv_groups():
     )
     est_groups.fit(X, y, groups=groups)
     assert est_groups.n_features_ > 0
+
+
+@pytest.mark.parametrize("cv", [
+    None,
+    5
+])
+def test_rfe_allow_nan_inf_in_x(cv):
+    iris = load_iris()
+    X = iris.data
+    y = iris.target
+
+    # add nan and inf value to X
+    X[0][0] = np.NaN
+    X[0][1] = np.Inf
+
+    clf = MockClassifier()
+    if cv is not None:
+        rfe = RFECV(estimator=clf, cv=cv)
+    else:
+        rfe = RFE(estimator=clf)
+    rfe.fit(X, y)
+    rfe.transform(X)
diff --git a/sklearn/feature_selection/tests/test_variance_threshold.py b/sklearn/feature_selection/tests/test_variance_threshold.py
index 9dc7effd3..77d9c9445 100644
--- a/sklearn/feature_selection/tests/test_variance_threshold.py
+++ b/sklearn/feature_selection/tests/test_variance_threshold.py
@@ -46,3 +46,15 @@ def test_zero_variance_floating_point_error():
         msg = "No feature in X meets the variance threshold 0.00000"
         with pytest.raises(ValueError, match=msg):
             VarianceThreshold().fit(X)
+
+
+def test_variance_nan():
+    arr = np.array(data, dtype=np.float64)
+    # add single NaN and feature should still be included
+    arr[0, 0] = np.NaN
+    # make all values in feature NaN and feature should be rejected
+    arr[:, 1] = np.NaN
+
+    for X in [arr, csr_matrix(arr), csc_matrix(arr), bsr_matrix(arr)]:
+        sel = VarianceThreshold().fit(X)
+        assert_array_equal([0, 3, 4], sel.get_support(indices=True))
+ git diff 70b0ddea992c01df1a41588fa9e2d130fb6b13f8
diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py
index 4bddae35c..91c57d15e 100644
--- a/sklearn/metrics/cluster/_supervised.py
+++ b/sklearn/metrics/cluster/_supervised.py
@@ -589,12 +589,11 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):
 
     Parameters
     ----------
-    labels_true : int array, shape = [n_samples]
+    labels_true : array-like of shape (n_samples,)
         A clustering of the data into disjoint subsets.
 
-    labels_pred : int array-like of shape (n_samples,)
+    labels_pred : array-like of shape (n_samples,)
         A clustering of the data into disjoint subsets.
-
     contingency : {None, array, sparse matrix}, \
                   shape = [n_classes_true, n_classes_pred]
         A contingency matrix given by the :func:`contingency_matrix` function.
@@ -617,6 +616,11 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):
     """
     if contingency is None:
         labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
+        # Convert string labels to integers
+        if labels_true.dtype.kind in {'U', 'S'}:
+            _, labels_true = np.unique(labels_true, return_inverse=True)
+        if labels_pred.dtype.kind in {'U', 'S'}:
+            _, labels_pred = np.unique(labels_pred, return_inverse=True)
         contingency = contingency_matrix(labels_true, labels_pred, sparse=True)
     else:
         contingency = check_array(contingency,
+ source /opt/miniconda3/bin/activate
++ _CONDA_ROOT=/opt/miniconda3
++ . /opt/miniconda3/etc/profile.d/conda.sh
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1='(testbed) '
+++ __conda_exe shell.posix activate
+++ /opt/miniconda3/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ eval 'PS1='\''(base) '\''
export PATH='\''/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3'\''
export CONDA_SHLVL='\''3'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_2='\''/opt/miniconda3/envs/testbed'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+++ PS1='(base) '
+++ export PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ PATH=/opt/miniconda3/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
+++ export CONDA_PREFIX=/opt/miniconda3
+++ CONDA_PREFIX=/opt/miniconda3
+++ export CONDA_SHLVL=3
+++ CONDA_SHLVL=3
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ CONDA_PREFIX_2=/opt/miniconda3/envs/testbed
+++ export CONDA_EXE=/opt/miniconda3/bin/conda
+++ CONDA_EXE=/opt/miniconda3/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ conda activate testbed
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate testbed
+ '[' -n '' ']'
+ local ask_conda
++ PS1='(base) '
++ __conda_exe shell.posix activate testbed
++ /opt/miniconda3/bin/conda shell.posix activate testbed
+ ask_conda='PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
+ eval 'PS1='\''(testbed) '\''
export PATH='\''/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
export CONDA_PREFIX='\''/opt/miniconda3/envs/testbed'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''testbed'\''
export CONDA_PROMPT_MODIFIER='\''(testbed) '\''
export CONDA_PREFIX_3='\''/opt/miniconda3'\''
export CONDA_EXE='\''/opt/miniconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/opt/miniconda3/bin/python'\'''
++ PS1='(testbed) '
++ export PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ PATH=/opt/miniconda3/envs/testbed/bin:/opt/miniconda3/condabin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
++ export CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ CONDA_PREFIX=/opt/miniconda3/envs/testbed
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=testbed
++ CONDA_DEFAULT_ENV=testbed
++ export 'CONDA_PROMPT_MODIFIER=(testbed) '
++ CONDA_PROMPT_MODIFIER='(testbed) '
++ export CONDA_PREFIX_3=/opt/miniconda3
++ CONDA_PREFIX_3=/opt/miniconda3
++ export CONDA_EXE=/opt/miniconda3/bin/conda
++ CONDA_EXE=/opt/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/opt/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ python -m pip install -v --no-use-pep517 --no-build-isolation -e .
Using pip 21.2.2 from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/pip (python 3.6)
Obtaining file:///testbed
    Running command python setup.py egg_info
    running egg_info
    creating /tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info
    writing /tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/PKG-INFO
    writing dependency_links to /tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/dependency_links.txt
    writing requirements to /tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/requires.txt
    writing top-level names to /tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/top_level.txt
    writing manifest file '/tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/SOURCES.txt'
    reading manifest file '/tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file '/tmp/pip-pip-egg-info-jf6348vi/scikit_learn.egg-info/SOURCES.txt'
    Partial import of sklearn during the build process.
Requirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.19.2)
Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.5.2)
Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/testbed/lib/python3.6/site-packages (from scikit-learn==0.22.dev0) (1.1.1)
Installing collected packages: scikit-learn
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 0.22.dev0
    Uninstalling scikit-learn-0.22.dev0:
      Removing file or directory /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link
      Removing pth entries from /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/easy-install.pth:
      Removing entry: /testbed
      Successfully uninstalled scikit-learn-0.22.dev0
  Running setup.py develop for scikit-learn
    Running command /opt/miniconda3/envs/testbed/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '"'"'/testbed/setup.py'"'"'; __file__='"'"'/testbed/setup.py'"'"';f = getattr(tokenize, '"'"'open'"'"', open)(__file__) if os.path.exists(__file__) else io.StringIO('"'"'from setuptools import setup; setup()'"'"');code = f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' develop --no-deps
    C compiler: gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC

    compile options: '-c'
    extra options: '-fopenmp'
    gcc: test_openmp.c
    gcc -pthread -B /opt/miniconda3/envs/testbed/compiler_compat -Wl,--sysroot=/ objects/test_openmp.o -o test_openmp -fopenmp
    running develop
    running build_scripts
    running egg_info
    running build_src
    build_src
    building library "libsvm-skl" sources
    building extension "sklearn.__check_build._check_build" sources
    building extension "sklearn.preprocessing._csr_polynomial_expansion" sources
    building extension "sklearn.cluster._dbscan_inner" sources
    building extension "sklearn.cluster._hierarchical_fast" sources
    building extension "sklearn.cluster._k_means_elkan" sources
    building extension "sklearn.cluster._k_means_fast" sources
    building extension "sklearn.datasets._svmlight_format_fast" sources
    building extension "sklearn.decomposition._online_lda_fast" sources
    building extension "sklearn.decomposition._cdnmf_fast" sources
    building extension "sklearn.ensemble._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._gradient_boosting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.histogram" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.splitting" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._binning" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._predictor" sources
    building extension "sklearn.ensemble._hist_gradient_boosting._loss" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.common" sources
    building extension "sklearn.ensemble._hist_gradient_boosting.utils" sources
    building extension "sklearn.feature_extraction._hashing_fast" sources
    building extension "sklearn.manifold._utils" sources
    building extension "sklearn.manifold._barnes_hut_tsne" sources
    building extension "sklearn.metrics.cluster._expected_mutual_info_fast" sources
    building extension "sklearn.metrics._pairwise_fast" sources
    building extension "sklearn.neighbors._ball_tree" sources
    building extension "sklearn.neighbors._kd_tree" sources
    building extension "sklearn.neighbors._dist_metrics" sources
    building extension "sklearn.neighbors._typedefs" sources
    building extension "sklearn.neighbors._quad_tree" sources
    building extension "sklearn.tree._tree" sources
    building extension "sklearn.tree._splitter" sources
    building extension "sklearn.tree._criterion" sources
    building extension "sklearn.tree._utils" sources
    building extension "sklearn.utils.sparsefuncs_fast" sources
    building extension "sklearn.utils._cython_blas" sources
    building extension "sklearn.utils.arrayfuncs" sources
    building extension "sklearn.utils.murmurhash" sources
    building extension "sklearn.utils.graph_shortest_path" sources
    building extension "sklearn.utils._fast_dict" sources
    building extension "sklearn.utils._openmp_helpers" sources
    building extension "sklearn.utils._seq_dataset" sources
    building extension "sklearn.utils._weight_vector" sources
    building extension "sklearn.utils._random" sources
    building extension "sklearn.utils._logistic_sigmoid" sources
    building extension "sklearn.svm._libsvm" sources
    building extension "sklearn.svm._liblinear" sources
    building extension "sklearn.svm._libsvm_sparse" sources
    building extension "sklearn.linear_model._cd_fast" sources
    building extension "sklearn.linear_model._sgd_fast" sources
    building extension "sklearn.linear_model._sag_fast" sources
    building extension "sklearn._isotonic" sources
    building data_files sources
    build_src: building npy-pkg config files
    writing scikit_learn.egg-info/PKG-INFO
    writing dependency_links to scikit_learn.egg-info/dependency_links.txt
    writing requirements to scikit_learn.egg-info/requires.txt
    writing top-level names to scikit_learn.egg-info/top_level.txt
    reading manifest file 'scikit_learn.egg-info/SOURCES.txt'
    reading manifest template 'MANIFEST.in'
    adding license file 'COPYING'
    writing manifest file 'scikit_learn.egg-info/SOURCES.txt'
    running build_ext
    customize UnixCCompiler
    customize UnixCCompiler using build_clib
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    customize UnixCCompiler
    customize UnixCCompiler using build_ext_subclass
    Creating /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scikit-learn.egg-link (link to .)
    Adding scikit-learn 0.22.dev0 to easy-install.pth file

    Installed /testbed
    Partial import of sklearn during the build process.
Successfully installed scikit-learn-0.22.dev0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
+ git checkout 70b0ddea992c01df1a41588fa9e2d130fb6b13f8 sklearn/metrics/cluster/tests/test_common.py
Updated 0 paths from 91b9ea3fe
+ git apply -v -
Checking patch sklearn/metrics/cluster/tests/test_common.py...
Applied patch sklearn/metrics/cluster/tests/test_common.py cleanly.
+ pytest -rA sklearn/metrics/cluster/tests/test_common.py
============================= test session starts ==============================
platform linux -- Python 3.6.13, pytest-6.2.4, py-1.11.0, pluggy-0.13.1
rootdir: /testbed, configfile: setup.cfg
collected 60 items

sklearn/metrics/cluster/tests/test_common.py ........................... [ 45%]
.FFFFFFFF........................                                        [100%]

=================================== FAILURES ===================================
______________ test_format_invariance[adjusted_mutual_info_score] ______________

metric_name = 'adjusted_mutual_info_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:743: in adjusted_mutual_info_score
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
_________________ test_format_invariance[adjusted_rand_score] __________________

metric_name = 'adjusted_rand_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:219: in adjusted_rand_score
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
__________________ test_format_invariance[completeness_score] __________________

metric_name = 'completeness_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:462: in completeness_score
    return homogeneity_completeness_v_measure(labels_true, labels_pred)[1]
sklearn/metrics/cluster/_supervised.py:302: in homogeneity_completeness_v_measure
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
__________________ test_format_invariance[homogeneity_score] ___________________

metric_name = 'homogeneity_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:392: in homogeneity_score
    return homogeneity_completeness_v_measure(labels_true, labels_pred)[0]
sklearn/metrics/cluster/_supervised.py:302: in homogeneity_completeness_v_measure
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
__________________ test_format_invariance[mutual_info_score] ___________________

metric_name = 'mutual_info_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:618: in mutual_info_score
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
_____________ test_format_invariance[normalized_mutual_info_score] _____________

metric_name = 'normalized_mutual_info_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:852: in normalized_mutual_info_score
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
___________________ test_format_invariance[v_measure_score] ____________________

metric_name = 'v_measure_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:562: in v_measure_score
    beta=beta)[2]
sklearn/metrics/cluster/_supervised.py:302: in homogeneity_completeness_v_measure
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
________________ test_format_invariance[fowlkes_mallows_score] _________________

metric_name = 'fowlkes_mallows_score'

    @pytest.mark.filterwarnings('ignore::FutureWarning')
    @pytest.mark.parametrize(
        "metric_name", dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
    )
    # For all clustering metrics Input parameters can be both
    # in the form of arrays lists, positive, negative or string
    def test_format_invariance(metric_name):
        y_true = [0, 0, 0, 0, 1, 1, 1, 1]
        y_pred = [0, 1, 2, 3, 4, 5, 6, 7]
    
        def generate_formats(y):
            y = np.array(y)
            yield y, 'array of ints'
            yield y.tolist(), 'list of ints'
            yield [str(x) + "-a" for x in y.tolist()], 'list of strs'
            yield (np.array([str(x) + "-a" for x in y.tolist()], dtype=object),
                   'array of strs')
            yield y - 1, 'including negative ints'
            yield y + 1, 'strictly positive ints'
    
        if metric_name in SUPERVISED_METRICS:
            metric = SUPERVISED_METRICS[metric_name]
            score_1 = metric(y_true, y_pred)
            y_true_gen = generate_formats(y_true)
            y_pred_gen = generate_formats(y_pred)
            for (y_true_fmt, fmt_name), (y_pred_fmt, _) in zip(y_true_gen,
                                                               y_pred_gen):
>               assert score_1 == metric(y_true_fmt, y_pred_fmt)

sklearn/metrics/cluster/tests/test_common.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
sklearn/metrics/cluster/_supervised.py:941: in fowlkes_mallows_score
    labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
sklearn/metrics/cluster/_supervised.py:46: in check_clusterings
    labels_true, ensure_2d=False, ensure_min_samples=0
sklearn/utils/validation.py:514: in check_array
    array = np.asarray(array, order=order, dtype=dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array(['0-a', '0-a', '0-a', '0-a', '1-a', '1-a', '1-a', '1-a'],
      dtype=object)
dtype = <class 'numpy.float64'>, order = None

    @set_module('numpy')
    def asarray(a, dtype=None, order=None):
        """Convert the input to an array.
    
        Parameters
        ----------
        a : array_like
            Input data, in any form that can be converted to an array.  This
            includes lists, lists of tuples, tuples, tuples of tuples, tuples
            of lists and ndarrays.
        dtype : data-type, optional
            By default, the data-type is inferred from the input data.
        order : {'C', 'F'}, optional
            Whether to use row-major (C-style) or
            column-major (Fortran-style) memory representation.
            Defaults to 'C'.
    
        Returns
        -------
        out : ndarray
            Array interpretation of `a`.  No copy is performed if the input
            is already an ndarray with matching dtype and order.  If `a` is a
            subclass of ndarray, a base class ndarray is returned.
    
        See Also
        --------
        asanyarray : Similar function which passes through subclasses.
        ascontiguousarray : Convert input to a contiguous array.
        asfarray : Convert input to a floating point ndarray.
        asfortranarray : Convert input to an ndarray with column-major
                         memory order.
        asarray_chkfinite : Similar function which checks input for NaNs and Infs.
        fromiter : Create an array from an iterator.
        fromfunction : Construct an array by executing a function on grid
                       positions.
    
        Examples
        --------
        Convert a list into an array:
    
        >>> a = [1, 2]
        >>> np.asarray(a)
        array([1, 2])
    
        Existing arrays are not copied:
    
        >>> a = np.array([1, 2])
        >>> np.asarray(a) is a
        True
    
        If `dtype` is set, array is copied only if dtype does not match:
    
        >>> a = np.array([1, 2], dtype=np.float32)
        >>> np.asarray(a, dtype=np.float32) is a
        True
        >>> np.asarray(a, dtype=np.float64) is a
        False
    
        Contrary to `asanyarray`, ndarray subclasses are not passed through:
    
        >>> issubclass(np.recarray, np.ndarray)
        True
        >>> a = np.array([(1.0, 2), (3.0, 4)], dtype='f4,i4').view(np.recarray)
        >>> np.asarray(a) is a
        False
        >>> np.asanyarray(a) is a
        True
    
        """
>       return array(a, dtype, copy=False, order=order)
E       ValueError: could not convert string to float: '0-a'

/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/core/_asarray.py:83: ValueError
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetric_non_symmetric_union
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[adjusted_rand_score-y10-y20]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[v_measure_score-y11-y21]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[mutual_info_score-y12-y22]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[adjusted_mutual_info_score-y13-y23]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[normalized_mutual_info_score-y14-y24]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_symmetry[fowlkes_mallows_score-y15-y25]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_non_symmetry[homogeneity_score-y10-y20]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_non_symmetry[completeness_score-y11-y21]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[adjusted_rand_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[homogeneity_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[completeness_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[v_measure_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[adjusted_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[fowlkes_mallows_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_normalized_output[normalized_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[adjusted_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[adjusted_rand_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[completeness_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[homogeneity_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[normalized_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[v_measure_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[fowlkes_mallows_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[silhouette_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[silhouette_manhattan]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[calinski_harabasz_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_permute_labels[davies_bouldin_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[silhouette_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[silhouette_manhattan]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[calinski_harabasz_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[davies_bouldin_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[adjusted_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[adjusted_rand_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[completeness_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[homogeneity_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[normalized_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[v_measure_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_single_sample[fowlkes_mallows_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[adjusted_mutual_info_score-adjusted_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[adjusted_rand_score-adjusted_rand_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[completeness_score-completeness_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[homogeneity_score-homogeneity_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[mutual_info_score-mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[normalized_mutual_info_score-normalized_mutual_info_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[v_measure_score-v_measure_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[fowlkes_mallows_score-fowlkes_mallows_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[silhouette_score-silhouette_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[silhouette_manhattan-metric_func9]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[calinski_harabasz_score-calinski_harabasz_score]
PASSED sklearn/metrics/cluster/tests/test_common.py::test_inf_nan_input[davies_bouldin_score-davies_bouldin_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[adjusted_mutual_info_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[adjusted_rand_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[completeness_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[homogeneity_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[mutual_info_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[normalized_mutual_info_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[v_measure_score]
FAILED sklearn/metrics/cluster/tests/test_common.py::test_format_invariance[fowlkes_mallows_score]
========================= 8 failed, 52 passed in 0.67s =========================
+ git checkout 70b0ddea992c01df1a41588fa9e2d130fb6b13f8 sklearn/metrics/cluster/tests/test_common.py
Updated 1 path from 91b9ea3fe
