--- a/sklearn/ensemble/iforest.py
+++ b/sklearn/ensemble/iforest.py
@@ -119,6 +119,11 @@
 
     verbose : int, optional (default=0)
         Controls the verbosity of the tree building process.
+
+    warm_start : bool, optional (default=False)
+        When set to ``True``, reuse the solution of the previous call to fit
+        and add more estimators to the ensemble, otherwise, just fit a whole
+        new forest. See :term:`the Glossary <warm_start>`.
 
 
     Attributes
@@ -173,7 +178,8 @@
                  n_jobs=None,
                  behaviour='old',
                  random_state=None,
-                 verbose=0):
+                 verbose=0,
+                 warm_start=False):
         super().__init__(
             base_estimator=ExtraTreeRegressor(
                 max_features=1,
@@ -187,10 +193,12 @@
             max_features=max_features,
             n_jobs=n_jobs,
             random_state=random_state,
-            verbose=verbose)
+            verbose=verbose,
+            warm_start=warm_start)
 
         self.behaviour = behaviour
         self.contamination = contamination
+        self.warm_start = warm_start
 
     def _set_oob_score(self, X, y):
         raise NotImplementedError("OOB score not supported by iforest")
--- a/sklearn/ensemble/tests/test_iforest.py
+++ b/sklearn/ensemble/tests/test_iforest.py
@@ -359,3 +359,30 @@
 ):
     test_iforest_works(contamination)
     assert mocked_get_chunk.call_count == n_predict_calls
+
+def test_warm_start():
+    """Test the warm_start functionality of IsolationForest."""
+    X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]
+    
+    # First, fit an IsolationForest with 5 estimators
+    clf = IsolationForest(n_estimators=5, random_state=42, warm_start=True)
+    clf.fit(X)
+    assert len(clf.estimators_) == 5
+
+    # Now, fit it again with 10 estimators
+    clf.set_params(n_estimators=10)
+    clf.fit(X)
+    assert len(clf.estimators_) == 10
+
+    # Check that the first 5 estimators are the same
+    clf_no_warm_start = IsolationForest(n_estimators=5, random_state=42, warm_start=False)
+    clf_no_warm_start.fit(X)
+    
+    for i in range(5):
+        assert np.all(clf.estimators_[i].tree_.feature == clf_no_warm_start.estimators_[i].tree_.feature)
+        assert np.all(clf.estimators_[i].tree_.threshold == clf_no_warm_start.estimators_[i].tree_.threshold)
+
+    # Check that fitting with warm_start=False resets the estimators
+    clf.set_params(warm_start=False, n_estimators=5)
+    clf.fit(X)
+    assert len(clf.estimators_) == 5
